Job id,companyId,title,description,contractType
4016891837,165158.0,Data Engineer (L5) - Games,"Netflix is one of the world's leading entertainment services, with 283 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.

Now is an amazing time to join Netflix as we seek to entertain the world. We have over 250 million paid members in over 190 countries, and we won’t stop there. Games are our next big frontier and an incredible opportunity for us to deliver new experiences to delight and entertain our quickly growing membership. You will be joining us at an exciting time as we roll out more games on both mobile and cloud and be in a position to help us redefine what a Netflix subscription means for our members around the world.

Data Science and Engineering (‘DSE’) at Netflix is aimed at using data, analytics, and sciences to improve various aspects of our business. We are looking for a Data Engineer to join our Games DSE team, supporting end-to-end analytics & data needs for the Games space. This role will be partnering closely with our Game stakeholders to develop software and data solutions that enable analysis across the entire library of games.

What You'll Do

In Games Product:


 * You’ll take ownership and increase automation and scale of complex data sets that drive use cases by our analytical partners. This includes games ‘impression’ data (how are users finding our games?) as well as game platform data (what is the usage and health of our game backend features)
 * You’ll build robust data pipelines that output very high data quality at scale using any combination of Spark, Flink, Python and Scala.
 * You’ll collaborate with our logging infrastructure team to develop and maintain key schemas for use by all games.
   
   

Who You Are


 * 7+ years in software development, with experience building systems that collect or process data for use in analytics products.
 * Enjoy a high level of autonomy in managing cross-functional engineering projects. We value people over process.
 * Have experience building production data pipelines using Spark, Flink or Hive/Hadoop. Have hands-on experience with schema design and data modeling.
 * Have programming proficiency in Python, or Scala/Java. You have a software engineering mindset and strive to write elegant, maintainable code. You may even be a software engineer with a focus or passion for data-driven solutions.
 * Have strong SQL skills and knowledge
 * You have excellent communication in sharing context to effectively collaborate with analytical partners, domain experts, and other consumers of your work, preferably in supporting an engineering or product function. We like to collaborate across teams, and so do you.
 * You are ambitious and willing to take action but not stubborn. You have the awareness to recognize when you're wrong and move past your own mistakes. You are humbly confident in yourself and your work.
   
   

Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $170,000 - $720,000. Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more detail about our Benefits here. Netflix is a unique culture and environment.

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.",Full-time
4130985970,165158.0,Data Visualization Engineer (L5) - Product,"Netflix is one of the world's leading entertainment services, with 283 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.

Everything that we build to delight our members, and all of the work we do to figure out how to do that better, relies on our extensive infrastructure, which spans what we rent from AWS (we are AWS’s biggest customer) to what we build ourselves (we operate our own custom-built content delivery network, Open Connect). Because this infrastructure is so central to everything we do, we want to ensure we are using it in the most effective and efficient way. Doing that well starts with great visibility into how we are using our infrastructure, and actionable metrics and analytics to help us take action as needed.

As a Senior Visualization Engineer you will join the team of Analytics Engineers, Data Engineers, and Data Scientists who partner with our infrastructure engineering teams to design and build visualization tools that help us make better decisions about our infrastructure, using data. You will work closely with engineering leadership, and our Strategy, Planning & Analysis partners to understand the most important decisions to be made in the Infrastructure space, and will then collaborate with Data Engineers and Data Scientists to tell that story through building and optimizing a performant, user-centric suite of infrastructure visualizations.

The ideal candidate will excel in data analytics, storytelling with data, cross-functional collaboration, and share a passion for continuously improving the way we use data to make the Netflix infrastructure better.

To learn more about our team, read here.

In This Role, You Will


 * Create a vision for how to best tell the story of how Netflix is using our infrastructure and build consensus around this vision with our partners in Engineering Leadership and Strategy, Planning and Analysis.
 * Bring together multiple data sources, metrics and analytics to keep our business informed about how our infrastructure systems are performing.
 * Work with data and engineering stakeholders to rapidly iterate on your initial designs based on user feedback.
 * Work with our Data Engineering partners, and other Data Scientists on the team to make sure we have great data to support the products we are building.
 * Provide mentorship and guidance to other analytics practitioners on the team.
 * Connect with the larger analytics community at Netflix to bring more visibility to our work.
   
   

You Are


 * Experienced with delivering visualization tools or suites that enable a wide range of technical and business stakeholders, from software engineers to business leadership
 * Experienced at crafting compelling narratives and data visualizations using a variety of tools - ranging from BI platforms (eg. Tableau, Superset/Preset), to JavaScript charting libraries (open source, or bespoke enterprise solutions). Experience with D3 is not required, but a plus
 * Experienced at developing web applications using JavaScript (TypeScript preferred) and common libraries and frameworks (React, React Router, React Query, Node)
 * Able to work “full stack” to create data pipelines and data models using SQL or Python. Experience with data engineering frameworks like Apache Iceberg or Druid is a plus
 * Experienced at telling stories with data and communicating to stakeholders at all levels of the business.
 * A strong product thinker with good product sense: you know how to get at what our partners need and how to develop solutions to satisfy those needs.
 * An exceptional communicator with both technical and non-technical audiences.
 * Comfortable with ambiguity, and thrive with minimal oversight and process.
   
   

A few more things to know: Our culture is unique and we live by our values, so it's worth learning more about Netflix at jobs.netflix.com/culture. We regularly share examples of our work on our tech blog. You will need to be comfortable working in the most agile of environments. Requirements will be vague. Iterations will be rapid. You will need to be nimble and take smart risks. Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top-of-market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $170,000 - $720,000. Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more details about our Benefits here. Netflix is a unique culture and environment. Learn more here.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity of thought and background builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.",Full-time
4083508705,2620735.0,"Data Engineer, Central Data","At Lyft, our purpose is to serve and connect. To do this, we start with our own community by creating an open, inclusive, and diverse organization.

At Lyft, data isn't just part of our decision-making process; it's the foundation. It drives our ability to deliver exceptional transportation experiences and offers insights into the impact of our product launches and features.

Joining Lyft as a Data Engineer means becoming a pivotal part of a team dedicated to shaping the future of transportation. You'll be tasked with developing robust data pipelines—encompassing data transport, collection, and storage—and providing services that enable our leadership to make informed, risk-reducing decisions. We are in search of a Data Engineer to join the Central Data Engineering Team within Data Platform, responsible for designing and managing the most foundational datasets at Lyft (Rides, Routes, Sessions) . These datasets drive key parts of the Lyft business and support a variety of use cases, including but not limited to Pricing, Mapping, and Marketplace.

As a Data Engineer, with your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance the data pipelines. Your work will have a major impact on several areas of the business.

We are looking for candidates who are self starters and have a proven track record of delivering data solutions that can solve critical business needs. The candidate should be able to dive deep into any problems with lots of ambiguity and build a technical solution to solve it. They should be willing to take ownership of a project or a feature and be able to drive it from design to implementation.

Responsibilities:


 * Owner of the core company data pipeline, responsible for scaling up data processing flow to meet the rapid data growth at Lyft
 * Evolve data model and data schema based on business and engineering needs
 * Implement systems tracking data quality and consistency
 * Develop tools supporting self-service data pipeline management (ETL)
 * SQL and Spark/Trino job tuning to improve data processing performance
 * Write well-crafted, well-tested, readable, maintainable code
 * Participate in code reviews to ensure code quality and distribute knowledge
 * Unblock, support and communicate with internal & external partners to achieve results
   
   

Experience:


 * 3+ years of data engineering industry experience
 * Experience with Data Ecosystem (Spark, Trino, Snowflake, Bigquery, Databricks)
 * Strong skills in a scripting language (Python, Bash)
 * Good understanding of SQL Engine and able to conduct advanced performance tuning
 * 1+ years of experience with workflow management tools (Airflow, Dagster, Prefect, Glue)
 * Experience of working directly with cross-functional data analytics, data scientists, and engineering teams to bridge Lyft’s business goals with data engineering
   
   

Benefits:


 * Great medical, dental, and vision insurance options with additional programs available when enrolled
 * Mental health benefits
 * Family building benefits
 * Child care and pet benefits
 * 401(k) plan to help save for your future
 * In addition to 12 observed holidays, salaried team members have discretionary paid time off, hourly team members have 15 days paid time off
 * 18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible
 * Subsidized commuter benefits
 * Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program
   
   

Lyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law.

This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Wednesdays, and Thursdays. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #Hybrid

The expected base pay range for this position in the San Francisco area is $128,000 - $160,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.",Full-time
4075195230,165158.0,Data Engineer (L5) - Data Systems Product,"Netflix is one of the world's leading entertainment services, with 283 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.

At Netflix, our mission is to entertain the world. With 278 million paid members in over 190 countries on millions of devices; enjoying TV series, documentaries, and feature films across a wide variety of genres and languages - Netflix is reinventing entertainment from end to end. We are revolutionizing how shows and movies are produced, pushing technological boundaries to efficiently deliver streaming video at a massive scale over the internet, and continuously improving the end-to-end user experience with Netflix across their member journey.

We pride ourselves on using data to inform our decision-making as we work towards our mission. This requires curating data across various domains such as Growth, Finance, Product, Content, and Studio. All of this data collection and curation is made possible thanks to the amazing Data Engineers of Netflix who bring this data to life.

Data Engineering at Netflix is a role that requires building systems to process data efficiently and modeling the data to power analytics. These solutions can range from batch data pipelines that bring to life business metrics to real-time processing services that integrate with our core product features. In addition, we require our Data Engineers to have a rich understanding of large distributed systems on which our data solutions rely. Candidates should have knowledge across several of these skill sets and usually need to be deep in at least one. As a Data Engineer, you also need to have strong communication skills since you will need to collaborate with business, engineering, and data science teams to enable a culture of learning. Learn more about the work of data engineers at Netflix.

Location of work: We are considering candidates willing to relocate to Los Gatos or Los Angeles, California, as well as fully remote candidates (remote in the US with occasional visits to Los Gatos).

Who are we?

The Product Data Systems (PDS) team owns and provides access to key data-centric services ( both real-time and batch) for the Netflix Consumer Product landscape. We focus on aggregation, enrichment, domain-specific processing, summarization, storage and serving of high-quality data used to drive areas such as Machine Learning, Games, Ads, Live, and Streaming Video on Demand, as well as metrics used to help drive decisions for our business. For a data engineer on this team, you will focus much of your time on building and maintaining robust data pipelines, owning and providing access to an array of large data tables, and helping drive innovation on high-scale (volume) and high-complexity services at the core of Netflix’s product line.

Who are you?


 * You are proficient in Java or Scala and comfortable working with SQL
 * You have a strong background in at least one of the following: distributed data processing or software engineering of data services, or distributed systems with a focus on data-oriented services at high scale
 * You are familiar with big data technologies like Spark or Flink and comfortable working with web-scale datasets (Experience with Spark Streaming is a plus)
 * You have experience managing PB+ data tables and pipelines at web scale in production environments
 * You have extensive experience with data modeling
 * You relate to and embody many of the aspects of the Netflix Culture. You love working independently while also collaborating and giving/receiving candid feedback
 * You are comfortable working in a rapidly changing environment with ambiguous requirements. You are nimble and take intelligent risks
 * You are comfortable with and have experience doing oncall rotations.
   
   

A few more things to know: Our culture is unique and we live by our values, so it's worth learning more about Netflix at jobs.netflix.com/culture. We regularly share examples of our work on our tech blog. You will need to be comfortable working in the most agile of environments. Requirements will be vague. Iterations will be rapid. You will need to be nimble and take smart risks. Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top-of-market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $170,000 - $720,000. Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more details about our Benefits here. Netflix is a unique culture and environment. Learn more here.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity of thought and background builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.",Full-time
4120819959,10667.0,"Data Engineer, Analytics","Are you passionate about Facebook’s product, analytics and technology? The Analytics, Data Engineering team is looking for fast-moving analytics candidates and data junkies who want to make an impact. Our data warehouse team works very closely with Product Managers, Product Analysts and Internet Marketers to figure out ways to acquire new users, retain existing users and optimize user experience - all of this using massive amounts of data. In this role, you will see a direct link between your work, company growth, and user satisfaction. You will work with some of the brightest minds in the industry, and you'll have the opportunity to solve some of the most challenging business problems on the web and mobile Internet, at a scale that few companies can match.

Data Engineer, Analytics Responsibilities:


 * Architect, implement and deploy new data models and data processes in production
 * Perform data analysis to generate business insights
 * Interface with Engineers, Product Managers and Product Analysts to understand product goals and data needs
 * Build data expertise and own data quality for allocated areas of ownership
 * Manage data warehouse plans for a product or a group of products
 * Support critical data processes running in production
   
   

Minimum Qualifications:


 * Currently has, or is in the process of obtaining, a Bachelors or Masters degree in Computer Science, Mathematics, or related technical field
 * Programming knowledge in Python or Java
 * Knowledge of SQL
 * Knowledge of database systems
 * Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment
 * Currently has, or is in the process of obtaining a Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. Degree must be completed prior to joining Meta.
   
   

Preferred Qualifications:


 * Experience thriving in a fast-paced work environment
 * Curious, self-driven, analytical and excited to play with data
 * Experience in collaborating with individuals and organizations
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$46.63/hour to $134,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4125815879,80392352.0,Data Engineer (Junior),"In the next 30 years, the world will transform every part of the built environment to be climate positive green infrastructure. Knowing what, where, and how to build infrastructure like solar farms is one of the great opportunities of our time. However, there are problems!

The Problem

80% of clean energy projects developers start never actually get built because most projects are started without deep due diligence on zoning and interconnection due to the cost of collecting that data. This means $17B worth of canceled projects per year.

Our Solution

Paces is software for green infrastructure developers to identify the best places to build and manage their projects. First we collect environmental, permitting, zoning, energy grid data from various different sources; then we analyze the data and use AI to identify the best places for developers to build their next projects.

Our Team

We are building a team where people can proudly say their time at Paces was the most impactful, meaningful work of their career. Our amazing team in Brooklyn, New York includes incredible engineers and growth team members from companies like AWS, Meta AI, Deepmind, Replica, Yotpo, Rent The Runway & Leap.

Paces is growing rapidly and looking for exceptional people to join who want to have a massive positive climate impact while building a great culture! We are looking for a data engineer passionate about building robust data pipelines as we scale up.

🏆 What You’ll Achieve


 * Design, implement, and maintain scalable ETL data pipelines from hundreds of data sources
 * Optimize our storage and retrieval systems for performance and reliability
 * Ensure data quality, consistency, and security across the platform
 * Collaborate closely with our CTO, Data Infra Lead, Product Lead, and team to directly impact product roadmap
   
   

📈 Requirements


 * Solid understanding of data engineering concepts, with a strong grasp of data structures, algorithms, and system design
 * Strong coding skills with demonstrated proficiency in relevant programming languages, such as Python, Rust, Scala
 * Advanced SQL expertise, including experience with complex queries, query optimization, and working with various database systems
 * Hands-on experience with big data tools (e.g. Spark) and data pipeline orchestration tools (e.g. Dagster, Airflow, Prefect)
 * Proven experience in building robust, scalable and performant data pipelines on the cloud (AWS / GCP / Azure)
   
   

✨ About You

You will thrive in our culture if you:


 * Have a strong bias towards action and prioritize results over processes
 * Share our passion to build something that fights climate change
 * Easily handle the unstructured environment of fast moving startups
 * Have the hunger to grow together with Paces as we scale up
   
   

🚀 Bonus Points


 * Previous experience at a high-growth, fast-paced startup
 * Previous experience working with (geo)spatial datasets and libraries (e.g. GEOS, GDAL)
 * Hands-on experience with novel data tools and frameworks such Apache Arrow, DuckDB, DeltaLake, Apache Iceberg
   
   

💰 Compensation And Benefits


 * 100K - 150K annual compensation
 * Competitive equity compensation
 * 401(k) matching
 * Health, Dental and Vision insurance
 * Hybrid working in the office 2-4 times per week",Full-time
3982462774,165158.0,Data Engineer (L5),"Netflix is one of the world's leading entertainment services, with 283 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.

At Netflix, our mission is to entertain the world. With 278 million paid members in over 190 countries on millions of devices; enjoying TV series, documentaries, and feature films across a wide variety of genres and languages - Netflix is reinventing entertainment from end to end. We are revolutionizing how shows and movies are produced, pushing technological boundaries to efficiently deliver streaming video at a massive scale over the internet, and continuously improving the end-to-end user experience with Netflix across their member journey.

We pride ourselves on using data to inform our decision-making as we work towards our mission. This requires curating data across various domains such as Growth, Finance, Product, Content, and Studio. All of this data collection and curation is made possible thanks to the amazing Data Engineers of Netflix who bring this data to life.

Data Engineering at Netflix is a role that requires building systems to process data efficiently and modeling the data to power analytics. These solutions can range from batch data pipelines that bring to life business metrics to real-time processing services that integrate with our core product features. In addition, we require our Data Engineers to have a rich understanding of large distributed systems on which our data solutions rely. Candidates should have knowledge across several of these skill sets and usually need to be deep in at least one. As a Data Engineer, you also need to have strong communication skills since you will need to collaborate with business, engineering, and data science teams to enable a culture of learning. Learn more about the work of data engineers at Netflix.

Location of work: We are considering candidates who are willing to relocate to Los Gatos, California, as well as fully-remote candidates (remote in the US with occasional visits to Los Gatos) depending on the team your skills are most aligned with.

Who are you?


 * You strive to write elegant code, and you're comfortable with picking up new technologies independently
 * You are proficient in at least one major programming language (e.g. Java, Scala, Python) and comfortable working with SQL
 * You enjoy helping teams push the boundaries of analytical insights, creating new product features using data, and powering machine learning models
 * You have a strong background in at least one of the following: distributed data processing or software engineering of data services, or data modeling
 * You are familiar with big data technologies like Spark or Flink and comfortable working with web-scale datasets
 * You have an eye for detail, good data intuition, and a passion for data quality
 * You appreciate the importance of great documentation and data debugging skills
 * You relate to and embody many of the aspects of the Netflix Culture. You love working independently while also collaborating and giving/receiving candid feedback
 * You are comfortable working in a rapidly changing environment with ambiguous requirements. You are nimble and take intelligent risks
   
   

Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for is $170,000 - $720,000.

Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more detail about our Benefits here.

Netflix is a unique culture and environment. Learn more here.

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.",Full-time
3989284331,165158.0,Data Engineer (L5) - Ads,"Netflix is one of the world's leading entertainment services, with 283 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.

Who are we?

Netflix is the world's leading internet entertainment service with over 220+ million memberships in over 190 countries enjoying TV series, documentaries and feature films across a wide variety of genres and languages. And as of November 2022 we added an advertisement branch to our business, making Netflix service accessible to an even broader member base with ad-supported plans!

About The Team

Ads Data Engineering team sits at the core of building a data ecosystem that will power Netflix’ understanding and decision making about what impact ads have on our business. This team’s main focus is to build rich, connected, and easily accessible data products about ad inventories, forecasting, targeting, ad serving, pacing and much more. We are looking for passionale, mature, and curious software engineers with strong data intuition, analytical mindset and ad ecosystem experience, to contribute to the team’s impact in a quickly evolving.

Who are you?


 * Beyond talented, you are curious, creative, and tenacious.
 * Sharp communicator who can break down and explain complex data problems in clear and concise language.
 * You have an extensive background and strong technical expertise working with data at scale, experience with advertising data (preferred) and understand how to build for privacy, and business impact
 * You have a high tolerance for ambiguity and fast-changing context
 * Hands-on experience building batch or streaming production data pipelines, ideally using one or more distributed processing frameworks such as Spark, Flink or Hive/Hadoop
 * Knowledge in data modeling and establishing data architecture across multiple systems
 * Thrive in a fast paced environment, and see yourself as a partner with the business with the shared goal of moving the business forward.
 * Create code that is understandable, simple, and clean, and take pride in its beauty.
 * Love freedom and hate being micromanaged. Given context, you're capable of self-direction.
 * Passionate about data quality and delivering effective data to impact the business.
   
   

What will you do?


 * Architect, strengthen, and expand the core data products that scale our Ads business. You’ll get on a team of talented data engineers and envision how all the data elements from multiple sources should fit together as a whole, and then execute on that plan.
 * Fully own critical portions of Netflix' Ads data products. Collaborate with stakeholders to understand needs, model tables using software engineering and data warehouse best practices, and develop large scale data processing solutions to ensure the timely delivery of high quality data.
 * Partner with Analytics Engineers, Data Scientists, and Software Engineers to create data products that will serve analysis, ML and reporting needs intuitively
 * Develop best practices for governance of data sets with sensitive information
 * Build strong and collaborative partnerships with data scientists, analytics engineers, and Machine Learning practitioners
   
   

What (ideally) do you know?


 * Domains related to advertising, data privacy, GDPR
 * Data warehousing, data modeling, and data transformation for both batch and streaming
 * Hands on command programming languages such as python, scala or java as well data exploration using sql
 * Expert at building performant data pipelines and optimizing existing workflows for new features
 * Big Data tech - Hadoop, Spark, Flink, Stream processing, Hive, Presto, etc.
 * Experience with sourcing and modeling data from application APIs
 * Team based software development tools and best practices
   
   

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.",Full-time
4148718851,165158.0,Data Engineer (L4) - Security,"Netflix is one of the world's leading entertainment services, with 283 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.

Securing our members’ data appropriately is key to maintaining a high level of trust with our customers. In addition, securing our technology infrastructure and understanding inherent risks are essential to enable us to scale our business effectively while maintaining a healthy security posture.

The Security Data Engineering team builds data products which provide visibility into security, fraud and technology risks across customer accounts as well as internal systems and data. This role is specifically focused on enabling our security teams in detecting and mitigating various types of security risks affecting our expansive cloud technology footprint. This requires a holistic understanding of our infrastructure topology, access controls, security policies and usage patterns. Centralizing various data points which help us understand these dimensions is key to success in this role.

We are looking for a Data Engineer to build reliable data pipelines and easy-to-use data products that allow our stakeholders to easily leverage data in an effective manner. As part of this team, you will work on diverse data technologies such as Spark, Presto, Flink, Kafka and others to build insightful, scalable and robust data pipelines; write ETL jobs to collect and aggregate data; and build high quality data models that describe the entities, interactions and usage patterns of our technology footprint.

The ideal candidate will bring a strong track record of having built data systems and frameworks to strengthen the security posture at large consumer businesses. They will have a deep background in distributed data processing and share our passion for continuously improving Netflix's security posture.

This role is based in the contiguous US and our teams work in a hybrid-working model.

Who You Are


 * Passionate about building intuitive data products to understand and mitigate security risks
 * Highly proficient in at least one of Java, Python or Scala (Scala preferred) with at least 2 years of data engineering experience
 * Advanced level SQL skills in a complex data environment
 * Experienced in engineering data pipelines using big data technologies (Spark, Presto, Flink etc.) on medium to large scale data sets
 * Comfortable working cross functionally with multiple types of stakeholders groups
 * Able to successfully lead large, complex systems design and implementation challenges independently
 * Prior experience in the security space is strongly preferred
   
   

What You Will Do


 * Engineer efficient, adaptable and scalable data pipelines to process structured and unstructured data
 * Develop a deep understanding of the security ecosystem at Netflix
 * Partner with the security engineering teams to understand product goals and provide data which empowers teams to improve our security posture
 * Maintain and rethink existing datasets and pipelines
 * Enable smart analytics by building robust, reliable, and useful data sets that can power various analytic techniques like regression, classification, clustering etc
 * Join a stunning team of data engineers with diverse skill sets, partnering closely with analytics engineering and data science counterparts
   
   

At Netflix, we carefully consider a wide range of compensation factors to determine your personal top of market. We rely on market indicators to determine compensation and consider your specific job, skills, and experience to get it right. These considerations can cause your compensation to vary and will also be dependent on your location.

The overall market range for roles in this area of Netflix is typically $170,000 - $720,000.

This market range is based on total compensation (vs. only base salary), which is in line with our compensation philosophy. Netflix is a unique culture and environment. Learn more here.

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.",Full-time
4070167112,165158.0,"Data Visualization Engineer Intern, Summer 2025","Netflix is one of the world's leading entertainment services, with 283 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.

The Role

Our mission to entertain the world is anchored in our content, and data is a crucial component in shaping our comprehensive content strategy. We focus on creating analytical products that support our content partners in their complex and nuanced decision-making processes. We are a highly collaborative team that partners across Netflix to drive impact.

Visualization Engineers at Netflix are expert data storytellers who build visually compelling and highly-performant products that serve as company-wide sources of truth. These products play a critical role in creating a shared understanding of the success of our business. Visualization Engineers typically have skills that span across a few broad categories: web development, application design/development, visualization design/development, data preparation/analysis, and product management.

Who are you?


 * Currently pursuing a Bachelor’s or Master’s degree in Computer Science, Engineering, Mathematics, or a related analytics field
    * Expected graduation earliest in Dec 2025, any month in 2026 or later

 * You are a passionate data visualization enthusiast. You notice when a fantastic story or insight is being communicated through visually appealing data visualizations.
 * You have experience with data storytelling through building web apps and interactive visualizations. You have experience with front-end JavaScript and Node.js. You have experience working with visualization libraries, plus a component framework like React.
 * You enjoy the challenge of making complex data intuitive to a broad audience. You welcome user feedback and use that information to iterate on your tools.
 * You are aware of design concepts related to chart forms, typography, and the use of color, and are able to design clear, legible charts.
 * You have experience in designing, building, and iterating on interfaces, with a strong sense of the entire user experience, not just the individual pieces.
 * You have experience working with data from a variety of sources, including API endpoints and relational databases.
   

What will you learn?


 * Designing compelling data stories
 * Building visually stunning user experiences centered around data-driven insights
 * How to work closely with business stakeholders in a fast-paced environment
 * Translating sophisticated data science outputs into easily digestible and actionable insights
 * Collaborating with the data visualization community within Netflix. Exploring existing products and strategies.
 * Partnering with other roles in Data Science & Engineering and building relationships with Analytics Engineers, Data Engineers and Data Scientists
   
   

Internships at Netflix

At Netflix, we offer a personalized experience for interns, and our aim is to offer an experience that mimics what it is like to actually work here. We match qualified interns with projects and groups based on interests and skill sets, and fully embed interns within those groups for the summer. Netflix is a unique place to work and we live by our values, so it's worth learning more about our culture.

Internships are paid and are a minimum of 12 weeks, with a choice of a few fixed start dates in May or June 2025 to accommodate varying school calendars. Conditions permitting, our summer internships will be located in our Los Gatos, CA office, or in our Los Angeles, CA office, depending on the team.

At Netflix, we carefully consider a wide range of compensation factors to determine the Intern top of market. We rely on market indicators to determine compensation and consider your specific job, skills, and experience to get it right. These considerations can cause your compensation to vary and will also be dependent on your location.

The overall market range for Netflix Internships is typically $40/hour - $110/hour.

This market range is based on total compensation (vs. only base salary), which is in line with our compensation philosophy. Netflix is a unique culture and environment. Learn more here.

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.",Internship
4083507967,2620735.0,"Data Engineer, Central Data","At Lyft, our purpose is to serve and connect. To do this, we start with our own community by creating an open, inclusive, and diverse organization.

At Lyft, data isn't just part of our decision-making process; it's the foundation. It drives our ability to deliver exceptional transportation experiences and offers insights into the impact of our product launches and features.

Joining Lyft as a Data Engineer means becoming a pivotal part of a team dedicated to shaping the future of transportation. You'll be tasked with developing robust data pipelines—encompassing data transport, collection, and storage—and providing services that enable our leadership to make informed, risk-reducing decisions. We are in search of a Data Engineer to join the Central Data Engineering Team within Data Platform, responsible for designing and managing the most foundational datasets at Lyft (Rides, Routes, Sessions) . These datasets drive key parts of the Lyft business and support a variety of use cases, including but not limited to Pricing, Mapping, and Marketplace.

As a Data Engineer, with your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance the data pipelines. Your work will have a major impact on several areas of the business.

We are looking for candidates who are self starters and have a proven track record of delivering data solutions that can solve critical business needs. The candidate should be able to dive deep into any problems with lots of ambiguity and build a technical solution to solve it. They should be willing to take ownership of a project or a feature and be able to drive it from design to implementation.

Responsibilities:


 * Owner of the core company data pipeline, responsible for scaling up data processing flow to meet the rapid data growth at Lyft
 * Evolve data model and data schema based on business and engineering needs
 * Implement systems tracking data quality and consistency
 * Develop tools supporting self-service data pipeline management (ETL)
 * SQL and Spark/Trino job tuning to improve data processing performance
 * Write well-crafted, well-tested, readable, maintainable code
 * Participate in code reviews to ensure code quality and distribute knowledge
 * Unblock, support and communicate with internal & external partners to achieve results
   
   

Experience:


 * 3+ years of data engineering industry experience
 * Experience with Data Ecosystem (Spark, Trino, Snowflake, Bigquery, Databricks)
 * Strong skills in a scripting language (Python, Bash)
 * Good understanding of SQL Engine and able to conduct advanced performance tuning
 * 1+ years of experience with workflow management tools (Airflow, Dagster, Prefect, Glue)
 * Experience of working directly with cross-functional data analytics, data scientists, and engineering teams to bridge Lyft’s business goals with data engineering
   
   

Benefits:


 * Great medical, dental, and vision insurance options with additional programs available when enrolled
 * Mental health benefits
 * Family building benefits
 * Child care and pet benefits
 * 401(k) plan to help save for your future
 * In addition to 12 observed holidays, salaried team members have discretionary paid time off, hourly team members have 15 days paid time off
 * 18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible
 * Subsidized commuter benefits
 * Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program
   
   

Lyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law.

This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Wednesdays, and Thursdays. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #Hybrid

The expected base pay range for this position in the Seattle area is $117,760 - $147,200. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.",Full-time
4120823533,10667.0,"Data Engineer, Analytics","Are you passionate about Facebook’s product, analytics and technology? The Analytics, Data Engineering team is looking for fast-moving analytics candidates and data junkies who want to make an impact. Our data warehouse team works very closely with Product Managers, Product Analysts and Internet Marketers to figure out ways to acquire new users, retain existing users and optimize user experience - all of this using massive amounts of data. In this role, you will see a direct link between your work, company growth, and user satisfaction. You will work with some of the brightest minds in the industry, and you'll have the opportunity to solve some of the most challenging business problems on the web and mobile Internet, at a scale that few companies can match.

Data Engineer, Analytics Responsibilities:


 * Architect, implement and deploy new data models and data processes in production
 * Perform data analysis to generate business insights
 * Interface with Engineers, Product Managers and Product Analysts to understand product goals and data needs
 * Build data expertise and own data quality for allocated areas of ownership
 * Manage data warehouse plans for a product or a group of products
 * Support critical data processes running in production
   
   

Minimum Qualifications:


 * Currently has, or is in the process of obtaining, a Bachelors or Masters degree in Computer Science, Mathematics, or related technical field
 * Programming knowledge in Python or Java
 * Knowledge of SQL
 * Knowledge of database systems
 * Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment
 * Currently has, or is in the process of obtaining a Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. Degree must be completed prior to joining Meta.
   
   

Preferred Qualifications:


 * Experience thriving in a fast-paced work environment
 * Curious, self-driven, analytical and excited to play with data
 * Experience in collaborating with individuals and organizations
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$46.63/hour to $134,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4120822675,10667.0,Data Engineer Intern,"Every month, billions of people leverage Meta products to connect with friends and loved ones from across the world. On the Data Engineering Team, our mission is to support these products both internally and externally by delivering the best data foundation that drives impact through informed decision making. As a highly collaborative organization, our data engineers work cross-functionally with software engineering, data science, and product management to optimize growth, strategy, and experience for over three billion users, as well as our internal employee community. In this role, you will see a direct correlation between your work, company growth, and user satisfaction. Beyond this, you will work with some of the brightest minds in the industry, and you'll have a unique opportunity to solve some of the most interesting data challenges with efficiency and integrity, at a scale few companies can match. As we continue to expand and create, we have a lot of exciting work ahead of us!

Data Engineer Intern Responsibilities:


 * Architect, implement and deploy new data models and data processes in production
 * Perform data analysis to generate business insights
 * Interface with Engineers, Product Managers and Data Scientists to understand product goals and data needs
 * Build data expertise and own data quality for allocated areas of ownership
 * Manage data warehouse plans for a product or a group of products
 * Support critical data processes running in production
   
   

Minimum Qualifications:


 * Currently has, or is in the process of obtaining, a Bachelors, or Masters degree in Computer Science, Information Science, Mathematics, or related technical field
 * Knowledge of SQL, data modeling and at least one programming language(e.g., Python, C++, C#, Scala)
 * Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment
   
   

Preferred Qualifications:


 * Intent to return to degree-program after the completion of the internship
 * Curious, self-driven, analytical and excited to play with data
 * Ability to thrive in a fast paced work environment
 * Experience in collaborating with individuals and organizations
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$7,469/month to $9,000/month + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4137309292,165158.0,Data Engineer (L5) - Commerce Product Data Engineering,"Netflix is one of the world's leading entertainment services, with 283 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.

About The Team

The Commerce Product Data Engineering team is responsible for data that is critical in driving business growth at Netflix. Our work empowers product managers and business leaders to rapidly experiment and innovate on product experiences that drive towards our goal to “Entertain the World”. In this role, you will partner closely with other engineers and data scientists to power experimentation, analytical data products, and machine learning models. This is an opportunity for someone with a strong data engineering background to demonstrate their thought leadership in crafting metrics and elegant insights that have a direct impact on the business.

In this role, you will be an instrumental contributor in developing experimentation and reporting data pipelines that will help us continue to build our ads business. We are invested in protecting our members’ data, and in this particular role we are looking for someone who is capable of being a strong cross-functional partner and data steward to ensure we manage sensitive datasets in a privacy-compliant manner. Since the data you manage will help the company weigh trade-offs and inform key strategic decisions, you will need to build a holistic understanding of the space while also developing deep domain knowledge to inform your technical decision-making.

Who Are You


 * You are proficient in at least one major language (e.g., Java, Scala, Python) and SQL (any variant). You strive to write elegant and maintainable code, and you're comfortable with picking up new technologies.
 * You are proficient in working with distributed systems and have experience with different distributed processing frameworks that can handle data in batch and real-time e.g. Flink, Spark, etc.
 * You have a product mindset and are curious to understand what the business needs. You have a naturally collaborative style and build strong partnerships with cross-functional stakeholders across organizational lines working effectively with various teams, including data science, privacy, platform, and ads teams
 * You have a solid handle on best practices relating to data governance and are capable of applying your strong data stewardship skills to managing sensitive datasets and ensuring their quality and security.
 * You have experience complying with internally or externally imposed privacy constraints and regulations (e.g., GDPR) when it comes to managing data.
 * You proactively think about ways to build upon and improve the systems you work with and are opinionated about engineering principles and have demonstrated experience delivering positive outcomes by putting those principles into practice.
 * You leverage your own judgement and input from others to deliver data to meet short-term business needs while also continuously striving for ways to improve our efficiency and effectiveness in delivering long-term value and unlocking new capabilities and insights.
 * You relate to and embody many aspects of Netflix's Culture. You love working independently while also collaborating and giving/receiving candid feedback.
   
   

A few more things to know: Our culture is unique and we live by our values, so it's worth learning more about Netflix at jobs.netflix.com/culture. We regularly share examples of our work on our tech blog. You will need to be comfortable working in the most agile of environments. Requirements will be vague. Iterations will be rapid. You will need to be nimble and take smart risks. Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top-of-market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $170,000 - $720,000. Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more details about our Benefits here. Netflix is a unique culture and environment. Learn more here.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity of thought and background builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.",Full-time
4150398486,3526554.0,Data Engineer,"Bustle Digital Group (BDG) is looking for a talented Data Engineer to join our growing data team. You will work alongside the Director of Data Engineering to build, optimize, and scale our data infrastructure, supporting the development of data-driven products and insights that power our advertising, affiliate sales, and editorial content strategies. This is a fantastic opportunity to work with large-scale data pipelines, cutting-edge technologies, and a dynamic team that values innovation and impact.






What You'll Do
 * Develop & Maintain Data Pipelines: Build scalable and efficient ETL pipelines to support analytics, reporting, and machine learning initiatives
 * Optimize Data Storage & Performance: Work with large datasets to improve storage solutions, query performance, and data accessibility
 * Collaborate Cross-Functionally: Partner with engineering and business teams to develop data solutions that enhance advertising, affiliate sales, and editorial insights
 * Ensure Data Quality & Reliability: Implement monitoring, validation, and governance processes to maintain the integrity and security of our data
 * Contribute to Data Strategy: Support the Director of Data Engineering in designing and implementing scalable data architectures and best practices
   




Who You Are
 * Experienced Data Engineer: 2+ years of experience working with data infrastructure, ETL processes, and large-scale datasets
 * Proficient in SQL & Python: Strong knowledge of SQL for querying and manipulating data, and experience with Python for scripting and automation
 * Cloud & Big Data Savvy: Hands-on experience with cloud platforms (AWS, GCP, or Azure), data warehouses (BigQuery, Redshift, Snowflake), and distributed processing (Spark, Airflow, or similar)
 * Experience working data generating frontends in React and TypeScript
 * Problem Solver & Innovator: Passionate about solving complex data challenges and improving system efficiency
 * Team Player & Communicator: Strong collaboration skills, with the ability to explain technical concepts to non-technical stakeholders
   




BDG Benefits
 * Competitive Compensation: Market-based salary with annual reviews
 * Unlimited PTO: Take the time you need to recharge and stay productive
 * Health & Wellness: Comprehensive medical, dental, and vision coverage for you and your dependents
 * Retirement Savings: 401(k) plan
 * Flexible Work Options: Work remotely or connect with the team in our NYC office
   





BDG is a leading independent media company with a portfolio of influential brands, including Bustle, Nylon, W, and Inverse. Our content reaches over 115 million readers monthly. Data is at the core of our business, driving audience insights, content monetization, and strategic decision-making.



Join BDG and help shape the future of data-driven media! Apply now to become part of our innovative and fast-growing team.



Compensation: Salary will be commensurate with experience and qualifications, with a competitive benefits package offered.

",Full-time
4016895582,165158.0,Data Engineer (L5) - Product (Device),"Netflix is one of the world's leading entertainment services, with 283 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.

The Device pod within the Streaming Data Engineering team partners with multiple engineering teams, producing high-quality and large-scale datasets, a source of truth for how Netflix services operate on the vast landscape of devices that support Netflix. This team helps to create datasets used to certify and retire devices, categorize them, and identify changes in this constantly changing environment.

This role is focused on supporting Netflix’s core data assets, delivering high-quality business datasets and metrics, and building systems to process batch and real-time data at a large scale. Additionally, a candidate should have a rich understanding of large distributed systems, modern big data technologies, and software development techniques. Since data engineers are responsible for their pipelines at Netflix, this role requires engineers to take ownership of the operational excellence in their domain. In addition, the ideal candidate will have excellent data intuition and share our passion for continuously improving how we handle streaming data at Netflix.

Who are you?


 * You strive to write elegant code and are comfortable with independently picking up new technologies.
 * You have mastery over at least one major programming language (e.g., Java, Scala, Python) and are comfortable working with SQL.
 * You enjoy helping teams push the boundaries of analytical insights, creating new product features using data, and powering machine-learning models.
 * You have a strong background in at least one of the following: distributed data processing or software engineering of data services.
 * You are familiar with big data technologies like Spark and Flink and comfortable working with web-scale datasets.
 * You are passionate about the end-to-end software development lifecycle, focusing on automation, testing, CI/CD, and documentation.
 * At Netflix, you own your code, services, and pipelines. You have practical, solid DevOps and Operation fundamentals, and you enjoy total ownership of your domain.
 * You have a solid understanding of the device lifecycle.
 * You have an eye for detail, good data intuition, and a passion for data quality.
 * You relate to and embody many of the aspects of the Netflix Culture. You love working independently while also collaborating and giving/receiving candid feedback.
 * You are comfortable working in a rapidly changing environment with ambiguous requirements. You are nimble and take intelligent risks.
   
   

What You Will Do


 * Help Netflix support and evolve the device data model by improving data excellence and quality, supporting analytics, developing and maintaining metrics, and partnering with engineering to deliver the next generation of Netflix experiences.
 * Engineer efficient, adaptable, and scalable data pipelines to process structured and unstructured data
 * Partner with numerous engineering teams, analytics engineers, and data scientists to enhance playback-related datasets.
 * Maintain and rethink existing pipelines to improve scalability and maintainability.
   
   

Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $170,000 - $720,000. Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more detail about our Benefits here. Netflix is a unique culture and environment.

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.",Full-time
4120828009,10667.0,"Data Engineer, Analytics","Are you passionate about Facebook’s product, analytics and technology? The Analytics, Data Engineering team is looking for fast-moving analytics candidates and data junkies who want to make an impact. Our data warehouse team works very closely with Product Managers, Product Analysts and Internet Marketers to figure out ways to acquire new users, retain existing users and optimize user experience - all of this using massive amounts of data. In this role, you will see a direct link between your work, company growth, and user satisfaction. You will work with some of the brightest minds in the industry, and you'll have the opportunity to solve some of the most challenging business problems on the web and mobile Internet, at a scale that few companies can match.

Data Engineer, Analytics Responsibilities:


 * Architect, implement and deploy new data models and data processes in production
 * Perform data analysis to generate business insights
 * Interface with Engineers, Product Managers and Product Analysts to understand product goals and data needs
 * Build data expertise and own data quality for allocated areas of ownership
 * Manage data warehouse plans for a product or a group of products
 * Support critical data processes running in production
   
   

Minimum Qualifications:


 * Currently has, or is in the process of obtaining, a Bachelors or Masters degree in Computer Science, Mathematics, or related technical field
 * Programming knowledge in Python or Java
 * Knowledge of SQL
 * Knowledge of database systems
 * Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment
 * Currently has, or is in the process of obtaining a Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. Degree must be completed prior to joining Meta.
   
   

Preferred Qualifications:


 * Experience thriving in a fast-paced work environment
 * Curious, self-driven, analytical and excited to play with data
 * Experience in collaborating with individuals and organizations
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$46.63/hour to $134,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4131815217,80392352.0,Data Engineer,"In the next 30 years, the world will transform every part of the built environment to be climate positive green infrastructure. Knowing what, where, and how to build infrastructure like solar farms is one of the great opportunities of our time. However, there are problems!

The Problem

80% of clean energy projects developers start never actually get built because most projects are started without deep due diligence on zoning and interconnection due to the cost of collecting that data. This means $17B worth of canceled projects per year.

Our Solution

Paces is software for green infrastructure developers to identify the best places to build and manage their projects. First we collect environmental, permitting, zoning, energy grid data from various different sources; then we analyze the data and use AI to identify the best places for developers to build their next projects.

Our Team

We are building a team where people can proudly say their time at Paces was the most impactful, meaningful work of their career. Our amazing team in Brooklyn, New York includes incredible engineers and growth team members from companies like AWS, Meta AI, Deepmind, Replica, Yotpo, Rent The Runway & Leap.

Paces is growing rapidly and looking for exceptional people to join who want to have a massive positive climate impact while building a great culture! We are looking for a data engineer passionate about building robust data pipelines as we scale up.

🏆 What You’ll Achieve


 * Design, implement, and maintain scalable ETL data pipelines from hundreds of data sources
 * Optimize our storage and retrieval systems for performance and reliability
 * Ensure data quality, consistency, and security across the platform
 * Collaborate closely with our CTO, Data Infra Lead, Product Lead, and team to directly impact product roadmap
   
   

📈 Requirements


 * Solid understanding of data engineering concepts, with a strong grasp of data structures, algorithms, and system design
 * Strong coding skills with demonstrated proficiency in relevant programming languages, such as Python, Rust, Scala
 * Advanced SQL expertise, including experience with complex queries, query optimization, and working with various database systems
 * Hands-on experience with big data tools (e.g. Spark) and data pipeline orchestration tools (e.g. Dagster, Airflow, Prefect)
 * Proven experience in building robust, scalable and performant data pipelines on the cloud (AWS / GCP / Azure)
   
   

✨ About You

You will thrive in our culture if you:


 * Have a strong bias towards action and prioritize results over processes
 * Share our passion to build something that fights climate change
 * Easily handle the unstructured environment of fast moving startups
 * Have the hunger to grow together with Paces as we scale up
   
   

🚀 Bonus Points


 * Previous experience at a high-growth, fast-paced startup
 * Previous experience working with (geo)spatial datasets and libraries (e.g. GEOS, GDAL)
 * Hands-on experience with novel data tools and frameworks such Apache Arrow, DuckDB, DeltaLake, Apache Iceberg
   
   

💰 Compensation And Benefits


 * 120K - 170K annual compensation
 * Competitive equity compensation
 * 401(k) matching
 * Health, Dental and Vision insurance
 * Hybrid working in the office 2-4 times per week",Full-time
4120820960,10667.0,"Data Engineer, Analytics","Are you passionate about Facebook’s product, analytics and technology? The Analytics, Data Engineering team is looking for fast-moving analytics candidates and data junkies who want to make an impact. Our data warehouse team works very closely with Product Managers, Product Analysts and Internet Marketers to figure out ways to acquire new users, retain existing users and optimize user experience - all of this using massive amounts of data. In this role, you will see a direct link between your work, company growth, and user satisfaction. You will work with some of the brightest minds in the industry, and you'll have the opportunity to solve some of the most challenging business problems on the web and mobile Internet, at a scale that few companies can match.

Data Engineer, Analytics Responsibilities:


 * Architect, implement and deploy new data models and data processes in production
 * Perform data analysis to generate business insights
 * Interface with Engineers, Product Managers and Product Analysts to understand product goals and data needs
 * Build data expertise and own data quality for allocated areas of ownership
 * Manage data warehouse plans for a product or a group of products
 * Support critical data processes running in production
   
   

Minimum Qualifications:


 * Currently has, or is in the process of obtaining, a Bachelors or Masters degree in Computer Science, Mathematics, or related technical field
 * Programming knowledge in Python or Java
 * Knowledge of SQL
 * Knowledge of database systems
 * Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment
 * Currently has, or is in the process of obtaining a Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. Degree must be completed prior to joining Meta.
   
   

Preferred Qualifications:


 * Experience thriving in a fast-paced work environment
 * Curious, self-driven, analytical and excited to play with data
 * Experience in collaborating with individuals and organizations
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$46.63/hour to $134,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4122379882,78378114.0,Junior Data Engineer,"Overview and Responsibilities:

Paramount Data technology Solutions (DTS) team plays a crucial role in Paramount's global engineering organization. Through our projects we ensure that millions of users worldwide can enjoy Paramount content through web, mobile, and TV applications. We are seeking a motivated and diligent Junior Data Engineer to join our team! This role will focus on designing, implementing, and maintaining scalable data pipelines, ensuring data quality, and enabling robust analytics solutions. The ideal candidate is passionate about working with data, has experience with Python, Airflow, and cloud platforms (AWS, Azure, or GCP), and is eager to learn and grow in a fast-paced environment!

Responsibilities:


 * Design, develop, and maintain robust and scalable data pipelines using Python and Apache Airflow
 * Implement ETL (Extract, Transform, Load) processes for diverse data sources, ensuring data quality and consistency.
 * Collaborate with data scientists, analysts, and other engineers to understand data needs and translate them into efficient, well-documented solution
 * Monitor and solve data pipelines, proactively identifying and resolving issues to maintain high availability.
 * Contribute to the development and improvement of our data infrastructure, using open-source technologies and cloud-native services. While our current platform is GCP, experience with other cloud providers (AWS, Azure) is highly valued as we strive for platform-agnostic solutions.
 * Work with Kubernetes to manage and orchestrate our data pipelines.
 * Participate actively in agile development sprints, contributing to sprint planning, daily stand-ups, and retrospectives.
 * Create code that is clean, well-documented, and can be easily tested, following established coding standards.
 * Participate in code reviews, offering constructive feedback and continuously improving our codebase.
 * Stay abreast of the latest technologies and trends in data engineering, proactively suggesting improvements to our processes and tools.
   
   

Basic Qualifications:


 * Bachelor's degree in Computer Science, Engineering, or a related field
 * 3+ years of experience in data engineering or a related field
 * Strong programming skills in Python
 * Experience with Apache Airflow or similar workflow management tool
 * Experience with Kubernetes for container orchestration
 * Experience with at least one major cloud provider (GCP, AWS, or Azure); experience with multiple is a strong plus
 * Demonstrated ability to adapt to different cloud environments is crucial
 * Understanding of data warehousing concepts and principles.
 * Proficiency with SQL and experience with relational and/or NoSQL database
 * Excellent problem-solving and analytical skills
 * Strong communication and collaboration skills, essential for working effectively within an agile team
   
   

Additional Qualifications:


 * Experience with data modeling and schema design
 * Experience with big data technologies (e.g., Spark, Hadoop)
 * Experience with CI/CD pipelines and terraform
 * Experience with containerization tools (e.g., Docker, Kubernetes)
 * Experience using Git
   
   

Paramount Global (NASDAQ: PARA, PARAA) is a leading global media and entertainment company that creates premium content and experiences for audiences worldwide. Driven by iconic studios, networks and streaming services, Paramount's portfolio of consumer brands includes CBS, Showtime Networks, Paramount Pictures, Nickelodeon, MTV, Comedy Central, BET, Paramount+, Pluto TV and Simon & Schuster, among others. Paramount delivers the largest share of the U.S. television audience and boasts one of the industry's most important and extensive libraries of TV and film titles. In addition to offering innovative streaming services and digital video products, the company provides powerful capabilities in production, distribution and advertising solutions.

Additional Information

Hiring Salary Range: $80,000.00 - 95,000.00. The hiring salary range for this position applies to New York, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible.

https://www.paramount.com/careers/benefits

Paramount is an equal opportunity employer (EOE) including disability/vet.

At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.

If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",Full-time
4120820951,10667.0,"Data Engineer, Analytics","Are you passionate about Facebook’s product, analytics and technology? The Analytics, Data Engineering team is looking for fast-moving analytics candidates and data junkies who want to make an impact. Our data warehouse team works very closely with Product Managers, Product Analysts and Internet Marketers to figure out ways to acquire new users, retain existing users and optimize user experience - all of this using massive amounts of data. In this role, you will see a direct link between your work, company growth, and user satisfaction. You will work with some of the brightest minds in the industry, and you'll have the opportunity to solve some of the most challenging business problems on the web and mobile Internet, at a scale that few companies can match.

Data Engineer, Analytics Responsibilities:


 * Architect, implement and deploy new data models and data processes in production
 * Perform data analysis to generate business insights
 * Interface with Engineers, Product Managers and Product Analysts to understand product goals and data needs
 * Build data expertise and own data quality for allocated areas of ownership
 * Manage data warehouse plans for a product or a group of products
 * Support critical data processes running in production
   
   

Minimum Qualifications:


 * Currently has, or is in the process of obtaining, a Bachelors or Masters degree in Computer Science, Mathematics, or related technical field
 * Programming knowledge in Python or Java
 * Knowledge of SQL
 * Knowledge of database systems
 * Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment
 * Currently has, or is in the process of obtaining a Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. Degree must be completed prior to joining Meta.
   
   

Preferred Qualifications:


 * Experience thriving in a fast-paced work environment
 * Curious, self-driven, analytical and excited to play with data
 * Experience in collaborating with individuals and organizations
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$46.63/hour to $134,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4133335951,80392352.0,Data Engineer,"In the next 30 years, the world will transform every part of the built environment to be climate positive green infrastructure. Knowing what, where, and how to build infrastructure like solar farms is one of the great opportunities of our time. However, there are problems!

The Problem

80% of clean energy projects developers start never actually get built because most projects are started without deep due diligence on zoning and interconnection due to the cost of collecting that data. This means $17B worth of canceled projects per year.

Our Solution

Paces is software for green infrastructure developers to identify the best places to build and manage their projects. First we collect environmental, permitting, zoning, energy grid data from various different sources; then we analyze the data and use AI to identify the best places for developers to build their next projects.

Our Team

We are building a team where people can proudly say their time at Paces was the most impactful, meaningful work of their career. Our amazing team in Brooklyn, New York includes incredible engineers and growth team members from companies like AWS, Meta AI, Deepmind, Replica, Yotpo, Rent The Runway & Leap.

Paces is growing rapidly and looking for exceptional people to join who want to have a massive positive climate impact while building a great culture! We are looking for a data engineer passionate about building robust data pipelines as we scale up.

🏆 What You’ll Achieve


 * Design, implement, and maintain scalable ETL data pipelines from hundreds of data sources
 * Optimize our storage and retrieval systems for performance and reliability
 * Ensure data quality, consistency, and security across the platform
 * Collaborate closely with our CTO, Data Infra Lead, Product Lead, and team to directly impact product roadmap
   
   

📈 Requirements


 * Solid understanding of data engineering concepts, with a strong grasp of data structures, algorithms, and system design
 * Strong coding skills with demonstrated proficiency in relevant programming languages, such as Python, Rust, Scala
 * Advanced SQL expertise, including experience with complex queries, query optimization, and working with various database systems
 * Hands-on experience with big data tools (e.g. Spark) and data pipeline orchestration tools (e.g. Dagster, Airflow, Prefect)
 * Proven experience in building robust, scalable and performant data pipelines on the cloud (AWS / GCP / Azure)
   
   

✨ About You

You will thrive in our culture if you:


 * Have a strong bias towards action and prioritize results over processes
 * Share our passion to build something that fights climate change
 * Easily handle the unstructured environment of fast moving startups
 * Have the hunger to grow together with Paces as we scale up
   
   

🚀 Bonus Points


 * Previous experience at a high-growth, fast-paced startup
 * Previous experience working with (geo)spatial datasets and libraries (e.g. GEOS, GDAL)
 * Hands-on experience with novel data tools and frameworks such Apache Arrow, DuckDB, DeltaLake, Apache Iceberg
   
   

💰 Compensation And Benefits


 * 120K - 170K annual compensation
 * Competitive equity compensation
 * 401(k) matching
 * Health, Dental and Vision insurance
 * Hybrid working in the office 2-4 times per week",Full-time
4148264684,16153604.0,Data Engineer,"Technology ReTech Labs, Inc., a SymphonyAI company and a company developing innovative technology platforms and solutions for retail and ecommerce, has the following open degreed/experienced position(s) available in San Diego, CA & Telecommuting Permitted: Data Engineer, 40 hrs/wk, $77,542-$120,704/yr. Email CV w/ Ref# AO-RL to ReTech Labs, Inc., Recruiting@symphonyai.com. EEO

recblid 0vkspmcfpr3uibm1ik7ntq7vbiki7m",Full-time
4125537833,1447520.0,Data Engineer - Samsung Ads,"Position Summary

Technical professionals are defined by what they create. Samsung has the risk taking corporate culture, strategic R&D investments and global know-how to imagine, develop and market products that lead the industry. Samsung Ads group located in Mountain View, CA is currently recruiting world-class engineers who share our “Innovation through passion” philosophy and thrive in a well-paced, results-driven environment. Samsung Ads team is responsible for delivering market leading Advertising products and services delivering billions of ad impressions to hundreds of millions of devices.

Role And Responsibilities

Responsibilities


 * Design and develop scalable data stores and frameworks with sub-second query latency on highly multi-dimensional data.
 * Engineering solutions to aggregate and automate large scale data flows from varying sources
 * Build real time streaming pipelines that deliver data with measurable quality under the SLA
 * Ability to effectively communicate ideas to peers and distributed teams
 * Delivering products with top notch quality in a fast-paced environment
 * Contributing towards building a system with a test-driven development / agile approach
 * Collaborate with other team members in breaking down tasks and implementation of the initiatives all the way to release.
   
   
   

Skills And Qualifications

Requirements:


 * Bachelor's or Master’s degree in Computer Science/Engineering with experience directly related to position.
 * Experience with large-scale distributed systems as pertains to data storage and computing
 * Experience building data lakes and data warehouses on AWS
 * Extensive experience with Amazon AWS technologies S3, EMR, Redshift or similar cloud offerings.
 * Strong development skills in Java, Scala and Spark with Scala.
 * Knowledge of various databases / database technologies - Oracle, Postgres, Cassandra (NoSQL), Vertica or other columnar databases.
 * Works on complex issues where analyzing situations or data requires an in-depth evaluation of variables.
 * Exercises judgement in selecting methods, techniques and evaluation criteria to obtain results
 * Champion best practices for high availability, scalability and reliability of data processing components
 * Advanced disciplinary knowledge in data technologies like Airflow, Spark, Python, Sql, Java, AWS and strong CS Fundamentals
 * Exposure to statistical data structures such as HyperLogLog, MinHash etc
 * Demonstrated strength in data modeling, ETL development, and data warehousing
 * Highly proficient in Object Oriented Design and Development.
   
   
   

Not-Required but Preferred:


 * Experience working in the Advertising domain a big plus
   
   
   

CALIFORNIA ONLY

Salary Range Pay Transparency: Compensation for this role, for candidates based in Mountain View, CA is expected to be between $115,000 and $140,000. Actual pay will be determined considering factors such as relevant skills and experience, and comparison to other employees in the role. Regular full-time employees (salaried or hourly) have access to benefits including: Medical, Dental, Vision, Life Insurance, 401(k), Employee Purchase Program, Tuition Assistance (after 6 months), Paid Time Off, Student Loan Program (after 6 months), Wellness Incentives, and many more.


 * Please visit Samsung membership to see Privacy Policy, which defaults according to your location. You can change Country/Language at the bottom of the page. If you are European Economic Resident, please click here.
   
   
   

At Samsung, we believe that innovation and growth are driven by an inclusive culture and a diverse workforce. We aim to create a global team where everyone belongs and has equal opportunities, inspiring our talent to be their true selves. Together, we are building a better tomorrow for our customers, partners, and communities.


 * Samsung Electronics America, Inc. and its subsidiaries are committed to employing a diverse workforce, and provide Equal Employment Opportunity for all individuals regardless of race, color, religion, gender, age, national origin, marital status, sexual orientation, gender identity, status as a protected veteran, genetic information, status as a qualified individual with a disability, or any other characteristic protected by law.
   
   
   

Reasonable Accommodations for Qualified Individuals with Disabilities During the Application Process

Samsung Electronics America is committed to providing reasonable accommodations for qualified individuals with disabilities in our job application process. If you have a disability and require a reasonable accommodation in order to participate in the application process, please contact our Reasonable Accommodation Team (855-557-3247) or SEA_Accommodations_Ext@sea.samsung.com for assistance. This number is for accommodation requests only and is not intended for general employment inquiries.",Full-time
4028650304,165158.0,Data Engineer (L5) - Security,"Netflix is one of the world's leading entertainment services, with 283 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.

Netflix is enjoyed by more than 200 million members globally, entertaining new audiences every day. Securing our members data and accounts appropriately is key to maintaining a high level of trust with our customers. In addition, securing our service and guarding against fraudulent behavior is essential to enable us to scale our business effectively.

The Security Data Engineering team builds data products which provide visibility into security and fraud risks across customer accounts as well as internal systems and data. This role is specifically focused on enabling our security teams in detecting and mitigating various types of fraud like account takeovers, unauthorized third party apps, account sharing fraud etc. This requires a holistic understanding of members' activity patterns across various dimensions like geography, device types, content types and more. Centralizing various data points which help us understand these dimensions is key to success in this role.

We are looking for a Data Engineer to build reliable data pipelines and intuitive data products that allow our stakeholders to easily leverage data in an effective manner. As part of this team, you will work on diverse data technologies such as Spark, Presto, Flink, Kafka and others to build insightful, scalable and robust data pipelines; write ETL jobs to collect and aggregate data; and build high quality data models that describe the entities, interactions and usage patterns of the Netflix product.

The ideal candidate will bring a strong track record of having built data systems and frameworks to strengthen the security posture at large consumer businesses. They will have a deep background in distributed data processing and share our passion for continuously improving Netflix's security posture.

Who You Are


 * Passionate about building intuitive data products to mitigate security and fraud risks
 * Highly proficient in at least one of Java, Python or Scala with at least 7 years of software/data engineering experience
 * Advanced level SQL skills in a complex data environment
 * At least 5 years of experience in engineering data pipelines using big data technologies (Hive, Presto, Spark, Flink) on medium to large scale data sets
 * Comfortable working cross functionally with multiple types of stakeholders groups
 * Able to successfully lead large, complex systems design and implementation challenges independently
 * Prior experience in the security and fraud space is strongly preferre
   
   

What You Will Do


 * Engineer efficient, adaptable and scalable data pipelines to process structured and unstructured data
 * Develop a deep understanding of the security ecosystem at Netflix
 * Partner with the security engineering teams to understand product goals and provide data which empowers teams to improve our fraud and security posture
 * Maintain and rethink existing datasets and pipelines
 * Enable smart analytics by building robust, reliable, and useful data sets that can power various analytic techniques like regression, classification, clustering etc
 * Join a stunning team of data engineers with diverse skill sets, partnering closely with analytics engineering and data science counterparts
   
   

A Few More Things To Know

Our culture is unique and we live by our values, so it's worth learning more about Netflix at jobs.netflix.com/culture. We regularly share examples of our work on our tech blog. You will need to be comfortable working in the most agile of environments. Requirements will be vague. Iterations will be rapid. You will need to be nimble and take smart risks.

Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $100,000 - $720,000. Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off.

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.",Full-time
4130614316,3832633.0,Data Engineer,"About Calm

Calm is on a mission to support everyone on every step of their mental health journey. With the #1 app for sleep, meditation and relaxation as well as a growing library of digital, evidence-based mental health programs, Calm offers trusted support for individuals and organizations alike. Our flagship consumer app provides personalized content and activities – featuring a range of experts and beloved celebrity voices – to help users manage stress, improve sleep and live mindfully. Our workplace and healthcare solutions offer a consumer-friendly approach to clinical content and HIPAA-compliant resources in order to drive positive health and business outcomes. Named a TIME100 Most Influential Company, Calm supports more than 150 million people and 3,500 organizations across seven languages and 190 countries.

What We Do

As a data organization, we focus on making data a competitive advantage for Calm. We’re product-minded, team-oriented, and grounded in our mission of making the world a happier and healthier place. We work closely with teams across the company such as product, finance, marketing, data science, and more. As a team, we strive to always improve.

What You’ll Do

We’re looking for someone who is comfortable with ambiguity, assesses what needs to be done, and delivers with the right balance of velocity and technical debt. As a Data Engineer, you’ll leverage all sorts of data, from application event streams to product databases to third-party data, to help stakeholders create products and answer business questions. Our stack spans AWS and GCP, with technologies like Airflow, Databricks, BigQuery, Postgres, and dbt. Specifically, you will:


 * Work with business stakeholders to understand their goals, challenges, and decisions
 * Assist with building solutions that standardize our data approach to common problems across the company
 * Incorporate observability and testing best practices into projects
 * Assist in the development of processes to ensure our data is trusted and well-documented
 * Effectively work with data analysts on refining the data model used for reporting and analytical purposes
 * Improve availability and consistency of data points crucial for analysis
   
   

Some past projects include:


 * Standing up a reporting system in BigQuery from scratch, including data replication, infrastructure setup, dbt model creation, and integration with reporting endpoints
 * Creating a user-level feature store and related API endpoints to support machine learning tasks such as content recommendation and persona creation
 * Remodeling a critical data pipeline to decrease our model count by 50% and reduce run time by 83%
 * Integrate our Data Warehouse with 3rd party applications for personalization that reaches tens of millions of customers
 * Revamping orchestration and execution to reduce critical data delivery times by 70%
   
   

Skills And Qualifications (Who You Are)

Demonstrated experience with the following languages/technologies/frameworks (or equivalents):
 * Python
 * Docker
 * Kubernetes
 * GCP and/or AWS
 * Relational DBs / SQL
 * Data Warehouses and Lakes, such as Bigquery, Databricks, or Snowflake
 * Experience in designing and building data pipelines that scale
 * Strong communication skills, with the ability to convey technical solutions to both technical and non-technical stakeholders
 * Experience working effectively in a fast-paced, agile environment as part of a collaborative team
 * Ability to work independently and as part of a team
 * Willingness and enthusiasm to learn new technologies and tackle challenging problems
 * Pragmatism: balancing scrappiness and rigor
   
   

Nice to Haves


 * Experience building across clouds
 * Experience with streaming systems like Segment
 * Knowledge of different data modeling paradigms, e.g. relational, data vault, and medallion
 * Some experience in Infrastructure as Code tools like Terraform
   
   

Minimum Requirements


 * This role typically requires 5+ years of related experience
   
   

Calm uses a geographic pay model that determines salaries based on the location where an employee lives. For this position, the base pay ranges across Calm’s pay tiers is $130,000 - $210,000. The base pay range represents the low and high end of Calm’s salary range for this position. Not all candidates will be eligible for the upper end of the salary range. Exact salary will ultimately depend on multiple factors, which include the successful candidate's geographic location, skills, experience and other qualifications. Calm uses employee zip code to determine which pay range applies. This role is also eligible for equity + comprehensive benefits + 401k + flexible time off.

Please note that Calm may leverage artificial intelligence technology in the application review process.

Calm is committed to providing reasonable accommodations for qualified individuals with disabilities, including disabled veterans. If you require a reasonable accommodation to complete any part of the application or interview process, please contact Calm’s Recruiting team at recruitingaccommodations@calm.com. All accommodation requests will be handled confidentially and assessed on a case-by-case basis.

We believe that mental health is health, and every person should be considered in the discussion. That’s why we’re proud to be an equal opportunity workplace, committed to providing equal employment opportunities to all applicants and employees regardless of race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, medical condition, genetic information, military or veteran status, gender identity or expression, sexual orientation, or any other characteristic protected by applicable federal, state or local law.

Calm is deeply committed to diversity, equity and inclusion. We strive to create a mindful and respectful environment where everyone can bring their authentic self to work, and experience a culture that is free of harassment, racism, and discrimination.

Employment offers are contingent upon the successful completion of a background check. Roles which require access to certain types of information may also require the successful completion of a drug screening.

FOR US BASED POSITIONS: Calm participates in e-verify. E-verify provides the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.


 * Right to Work
 * E-Verify Participation
   
   ",Full-time
4120828070,10667.0,Data Engineer Intern,"Every month, billions of people leverage Meta products to connect with friends and loved ones from across the world. On the Data Engineering Team, our mission is to support these products both internally and externally by delivering the best data foundation that drives impact through informed decision making. As a highly collaborative organization, our data engineers work cross-functionally with software engineering, data science, and product management to optimize growth, strategy, and experience for over three billion users, as well as our internal employee community. In this role, you will see a direct correlation between your work, company growth, and user satisfaction. Beyond this, you will work with some of the brightest minds in the industry, and you'll have a unique opportunity to solve some of the most interesting data challenges with efficiency and integrity, at a scale few companies can match. As we continue to expand and create, we have a lot of exciting work ahead of us!

Data Engineer Intern Responsibilities:


 * Architect, implement and deploy new data models and data processes in production
 * Perform data analysis to generate business insights
 * Interface with Engineers, Product Managers and Data Scientists to understand product goals and data needs
 * Build data expertise and own data quality for allocated areas of ownership
 * Manage data warehouse plans for a product or a group of products
 * Support critical data processes running in production
   
   

Minimum Qualifications:


 * Currently has, or is in the process of obtaining, a Bachelors, or Masters degree in Computer Science, Information Science, Mathematics, or related technical field
 * Knowledge of SQL, data modeling and at least one programming language(e.g., Python, C++, C#, Scala)
 * Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment
   
   

Preferred Qualifications:


 * Intent to return to degree-program after the completion of the internship
 * Curious, self-driven, analytical and excited to play with data
 * Ability to thrive in a fast paced work environment
 * Experience in collaborating with individuals and organizations
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$7,469/month to $9,000/month + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4149214885,222322.0,Data Engineer Intern,"Kwik Trip Inc. Become part of our fast paced, guest centric Information Technology Department and receive hands-on work experience by supporting our Data Services Team.







We are seeking a skilled and motivated Data Engineer Intern to join our team. The ideal candidate will design, build, and maintain scalable and efficient data pipelines and infrastructure. You will play a critical role in enabling data-driven decision-making by ensuring the organization’s data is accessible, accurate, and secure.







Regular tasks include:

 * Design and implement data models for structured and unstructured data.
 * Optimize data pipelines for performance and scalability.
 * Manage data storage solutions, such as data warehouses and data lakes.
 * Ensure data integrity, accuracy, and security.







Qualifications:

 * Student obtaining an undergraduate degree in Data Science, Computer Science or a related field.
 * Working knowledge of SQL and Python.
 * General understanding of Snowflake, Databricks, Azure services such as Data Factory a plus.
 * Excellent oral and written communication skills.
 * Strong analytical and problem-solving skills.
 * Ability to multi-task.
 * Accurate and attention to detail; self-motivated.
 * Ability to resolve high priority issues.
 * Ability to learn, understand, and apply new technologies.
 * Ability to maintain confidential information.







Work Schedule: This is a paid internship. Interested candidates must be willing to work up to 20 hours per week Monday through Friday during the school semesters and up to 40 hours during school breaks. It is important to note that we offer flexibility with school scheduling.







Note: Applicants must be currently attending school for Data Science, Computer Science or a related field.",Part-time
4125730825,2454643.0,Data Engineer," * Candidates must live local to one of they hiring locations: NYC or Boulder, CO. This is a Hybrid role. **
   
   

As a Data Engineer, you will work with the Fulfillment Planning Technology team to help build the next generation suite of internal tools that enable Planning and Operations teams to see and act quickly to changing business conditions. The Data Engineer will build scalable data pipelines, infrastructure and tools that power our products and services.

You will …


 * Work with analysts, engineers and planners to design, build, and maintain efficient, scalable and reliable data pipelines to support our business-critical needs in data ingestion, processing, and analysis
 * Develop and maintain efficient, scalable and reliable code in Python and SQL
 * Collaborate with other team members to troubleshoot, perform root cause analysis and optimize existing data pipelines and tools
 * Work with other team members to ensure effective tool integration with other systems and workflows
   
   

At a minimum, you have …


 * Bachelor’s or Master’s degree in Computer Science, Engineering or related field
 * 3+ years of data engineering experience in Fulfillment, Logistics, Supply Chain, Production, or related field working with physical goods
 * Strong proficiency in Python and SQL
 * Experience working with distributed systems, building and maintaining pipelines using various cloud technologies (AWS, Snowflake)
 * Experience in containerization and orchestration (Docker, Kubernetes, Airflow, GCP)
 * Startup experience a plus
   
   

You’ll get…


 * Competitive salary, 401k with company match that vests immediately upon participation, and company equity plan based on role
 * Generous PTO, including sabbatical, and parental leave of up to 16 weeks
 * Comprehensive health and wellness benefits with options at $0 monthly, effective first day of employment
 * Tuition reimbursement for continuing education
 * Up to 75% discount on subscriptions to HelloFresh meal plans (HelloFresh, Green Chef, Every plate, and Factor_)
 * Access to 7 different Employee Resource Groups (ERGs) including those for BIPOC, women, veterans, parents, and LGBTQ+
 * Inclusive, collaborative, and dynamic work environment within a fast-paced, mission-driven company that is disrupting the traditional food supply chain
   
   

This job description is intended to provide a general overview of the responsibilities. However, the Company reserves the right to adjust, modify, or reassign work tasks and responsibilities as needed to meet changing business needs, operational requirements, or other factors

Application deadline - 2/20/24

New York Pay Range

$97,500—$130,000 USD

Colorado Pay Range

$93,750—$125,000 USD

JR102513",Full-time
4148527612,74737673.0,Data Engineer (Databricks preferred),"Onsite contract in Edison NJ area (4x per week)

Long term contract: 3 year commitment

Rate: 90-100/Hour USD

Previous Experience Working In Finance, Ideally Capital Markets, Required.

We’re looking for an experienced Data Engineer to join our client's team and drive the development of cutting-edge data solutions. If you have a passion for optimizing big data pipelines, working with cloud platforms, and delivering high-impact insights, this role is for you!

What You’ll Do


 * Design and build scalable data pipelines for seamless ingestion, transformation, and integration across diverse sources.
 * Develop and optimize Spark applications in Databricks to process and analyze large datasets efficiently.
 * Implement Delta Lake, data modeling, and cloud-based warehousing solutions.
 * Write clean, efficient code in Python, SQL, and PySpark to support data processing needs.
 * Work with structured, semi-structured, and unstructured data in event-driven and streaming environments.
 * Ensure high performance and scalability of Databricks workloads, while troubleshooting and optimizing jobs.
 * Enforce best practices in data governance, security, and compliance across cloud-based platforms.
 * Conduct code reviews to ensure optimal execution and adherence to industry standards.
   
   

Must-Have Skills


 * Expertise in Snowflake & Databricks
 * Advanced SQL & Python development
 * Hands-on experience with ADF & PySpark
 * Strong Data Warehouse architecture & modeling knowledge
   
   

Preferred Experience


 * 8+ years of Python and SQL coding experience
 * ETL development using Databricks and PySpark
 * Familiarity with cloud data warehouses (Synapse, BigQuery, Redshift, Snowflake)
 * OLTP & OLAP, Dimensional Data Modeling expertise
 * Experience leading cloud data migrations and architecting scalable solutions
 * Cloud certifications are a plus!",Full-time
4115021577,22688.0,Data Engineer,"Overview

Atlassian is looking for a Data Engineer to join our Data Engineering team and build world-class data solutions and applications that power crucial decisions throughout the organisation. We are looking for an open-minded, structured thinker who is passionate about building systems at scale. You will enable a world-class data engineering practice, drive the approach with which we use data, develop backend systems and data models to serve the needs of insights and play an active role in building Atlassian’s data-driven culture.

Working at Atlassian

Atlassians can choose where they work – whether in an office, from home, or a combination of the two. That way, Atlassians have more control over supporting their family, personal goals, and other priorities. We can hire people in any country where we have a legal entity. Interviews and onboarding are conducted virtually, a part of being a distributed-first company.

Responsibilities

Data is a BIG deal at Atlassian. We ingest over 180 billion events each month into our analytics platform and we have dozens of teams across the company driving their decisions and guiding their operations based on the data and services we provide.

The data engineering team manages several data models and data pipelines across Atlassian, including finance, growth, product analysis, customer support, sales, and marketing. You'll join a team that is smart and very direct. We ask hard questions and challenge each other to constantly improve our work.

As a Data Engineer, you will apply your technical expertise to build analytical data models that support a broad range of analytical requirements across the company. You will work with extended teams to evolve solutions as business processes and requirements change. You'll own problems end-to-end and on an ongoing basis, you'll improve the data by adding new sources, coding business rules, and producing new metrics that support the business.

Qualifications


 * Bachelor’s/Master's degree or equivalent in a STEM field with a minimum 2+ Years of Experience in Data Engineering or related field.
 * Expertise in Python or other modern programming languages.
 * Working knowledge of relational databases and query authoring via SQL.
 * Experience designing data models for optimal storage, retrieval and dashboarding to meet product and business requirements.
 * Experience building scalable data pipelines using Spark or Spark-SQL with Airflow scheduler/executor framework or similar scheduling tools.
 * Experience building real-time data pipelines using a micro-services architecture.
 * Experience working with AWS data services or similar Apache projects (Spark, Flink, Hive, and Kafka).
 * Understanding of Data Engineering tools/frameworks and standards to improve the productivity and quality of output for Data Engineers across the team.
 * Well-versed in modern software development practices (Agile, TDD, CICD).
   
   
   

Compensation

At Atlassian, we strive to design equitable, explainable, and competitive compensation programs. To support this goal, the baseline of our range is higher than that of the typical market range, but in turn we expect to hire most candidates near this baseline. Base pay within the range is ultimately determined by a candidate's skills, expertise, or experience. In the United States, we have three geographic pay zones. For this role, our current base pay ranges for new hires in each zone are:

Zone A: $140,100 - $186,800

Zone B: $126,100 - $168,200

Zone C: $116,300 - $155,100

This role may also be eligible for benefits, bonuses, commissions, and equity.

Please visit go.atlassian.com/payzones for more information on which locations are included in each of our geographic pay zones. However, please confirm the zone for your specific location with your recruiter.

Our Perks & Benefits

Atlassian offers a variety of perks and benefits to support you, your family and to help you engage with your local community. Our offerings include health coverage, paid volunteer days, wellness resources, and so much more. Visit go.atlassian.com/perksandbenefits to learn more.

About Atlassian

At Atlassian, we're motivated by a common goal: to unleash the potential of every team. Our software products help teams all over the planet and our solutions are designed for all types of work. Team collaboration through our tools makes what may be impossible alone, possible together.

We believe that the unique contributions of all Atlassians create our success. To ensure that our products and culture continue to incorporate everyone's perspectives and experience, we never discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. All your information will be kept confidential according to EEO guidelines.

To provide you the best experience, we can support with accommodations or adjustments at any stage of the recruitment process. Simply inform our Recruitment team during your conversation with them.

To learn more about our culture and hiring process, visit go.atlassian.com/crh .",Full-time
4149787322,1482.0,Software Engineer - Recent Graduate,"The Company
PayPal has been revolutionizing commerce globally for more than 25 years. Creating innovative experiences that make moving money, selling, and shopping simple, personalized, and secure, PayPal empowers consumers and businesses in approximately 200 markets to join and thrive in the global economy.

We operate a global, two-sided network at scale that connects hundreds of millions of merchants and consumers. We help merchants and consumers connect, transact, and complete payments, whether they are online or in person. PayPal is more than a connection to third-party payment networks. We provide proprietary payment solutions accepted by merchants that enable the completion of payments on our platform on behalf of our customers.

We offer our customers the flexibility to use their accounts to purchase and receive payments for goods and services, as well as the ability to transfer and withdraw funds. We enable consumers to exchange funds more safely with merchants using a variety of funding sources, which may include a bank account, a PayPal or Venmo account balance, PayPal and Venmo branded credit products, a credit card, a debit card, certain cryptocurrencies, or other stored value products such as gift cards, and eligible credit card rewards. Our PayPal, Venmo, and Xoom products also make it safer and simpler for friends and family to transfer funds to each other. We offer merchants an end-to-end payments solution that provides authorization and settlement capabilities, as well as instant access to funds and payouts. We also help merchants connect with their customers, process exchanges and returns, and manage risk. We enable consumers to engage in cross-border shopping and merchants to extend their global reach while reducing the complexity and friction involved in enabling cross-border trade.

Our beliefs are the foundation for how we conduct business every day. We live each day guided by our core values of Inclusion, Innovation, Collaboration, and Wellness. Together, our values ensure that we work together as one global team with our customers at the center of everything we do – and they push us to ensure we take care of ourselves, each other, and our communities.

Job Description Summary:
At PayPal, we’re literally reinventing how the world pays and gets paid. We understand that it’s about people. We connect individuals to let them shop, get paid, donate and send money using today’s technology with the confidence that comes from the security and control PayPal enables. Are you ready to help us change the world? The world’s leading payments company, PayPal, brings together a family of brands that are revolutionizing the way people move money. At PayPal you will be immersed in an amazing community with a vibrant culture that thrives on innovation, collaboration, inclusion and wellness. Software Engineers at PayPal develop innovative solutions and high-quality products that touch millions of people every day around the globe. Our engineers solve some of the most complex technical problems in the world of connected payments across all business units, including PayPal, Braintree, Venmo, Paydiant and others. We are looking for the highest levels of technical talent and programming skills, as well as a keen desire to deeply understand our products and services to push our technology forward with respect to functionality, performance, reliability, and scalability. You’ll work alongside the best and the brightest engineering talent in the industry. We have opportunities in a wide range of areas including development, design, search, platform, test, quality, big data, front end and back end. As a core participant of your team, you’ll estimate engineering efforts, design your changes, implement and test your changes, push to live, and triage production issues. You need to be dynamic, collaborative, and curious as we build new experiences, improve existing products, and develop distributed systems powering the world’s largest e-commerce and payments websites at a scale only a few companies can match.

Job Description:
Key Responsibilities:


 * Code high-volume and scalable software (front-end and/or back-end focused). This may include creating web applications using React/Node, creating back-end services using Java, SQL, ReST and/or building and developing new user-facing experiences
 * Partner closely with cross functional teams in design, product and other business units
   
   
   

 Basic Requirements:


 * Strong applied experience. You’ve built, broken, and rebuilt software applications. We’re looking for creative thinkers who also know how to create real-world products.
 * Working knowledge of web technologies (such as HTTP, HTML/DOM, JavaScript, CSS, AJAX)
 * Familiarity with any or multiple of the following: Node.js applications, Java, C++. Python
 * Understanding of concepts like Web Services, SOA, REST APIs
 * A constant desire to grow, learn, and explore new things
   
   
   

Recent Graduate Position Information and Requirements:


 * This is a Recent Graduate Full-Time position.
 * Must have graduated within the past 12 months, or will be graduating by Spring 2025, with a Bachelor’s or Master’s degree in Computer Science or related field from an accredited college or university.
 * Must reside in the U.S.
 * Must be able to obtain authorization to work in the U.S.
   
   
   

globaluniversitygraduatesoftwareengineering

For the majority of employees, PayPal's balanced hybrid work model offers 3 days in the office for effective in-person collaboration and 2 days at your choice of either the PayPal office or your home workspace, ensuring that you equally have the benefits and conveniences of both locations.

Our Benefits:

At PayPal, we’re committed to building an equitable and inclusive global economy. And we can’t do this without our most important asset—you. That’s why we offer benefits to help you thrive in every stage of life. We champion your financial, physical, and mental health by offering valuable benefits and resources to help you care for the whole you.

We have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https://www.paypalbenefits.com

Who We Are:

To learn more about our culture and community visit https://about.pypl.com/who-we-are/default.aspx

Commitment to Diversity and Inclusion

PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state, or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at paypalglobaltalentacquisition@paypal.com.

Belonging at PayPal:

Our employees are central to advancing our mission, and we strive to create an environment where everyone can do their best work with a sense of purpose and belonging. Belonging at PayPal means creating a workplace with a sense of acceptance and security where all employees feel included and valued. We are proud to have a diverse workforce reflective of the merchants, consumers, and communities that we serve, and we continue to take tangible actions to cultivate inclusivity and belonging at PayPal.

Any general requests for consideration of your skills, please Join our Talent Community.

We know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please don’t hesitate to apply.

As part of PayPal’s commitment to employees’ health and safety, we have established in-office Covid-19 protocols and requirements, based on expert guidance. Depending on location, this might include a Covid-19 vaccination requirement for any employee whose role requires them to work onsite. Employees may request reasonable accommodation based on a medical condition or religious belief that prevents them from being vaccinated.

Notice to Applicants and Employees who reside within New York city. Click https://careers.pypl.com/Contact-Us/default.aspx

to view the notice.

REQ ID R0119020",Full-time
4138463912,81884275.0,Data Engineer,"About Suno

At Suno, we are building a future where anyone can make music. You can make a song for any moment with just a few short words. Award-winning artists use Suno, but our core user base consists of everyday people making music — often for the first time.

We are a team of musicians and AI experts, including alumni from Spotify, TikTok, Meta and Kensho. We like to ship code, make music and drink coffee. Our company culture celebrates music and experimenting with sound — from lunchroom conversations to the studio in our office.

About The Role

We’re seeking talented data engineers to join our founding team, working closely with key stakeholders and taking ownership of building and shaping Suno’s core data foundation.

Check out our Suno version of the job here!

What You’ll Do


 * Serve as a critical contributor to the Suno products team, providing insights and solutions that influence high-level decisions and shape the product roadmap.
 * Design, develop, and maintain complex data products, systems, platforms, and pipelines to build scalable, secure, and high-quality big data solutions that seamlessly integrate diverse data sources, process high-volume real-time and batch data, and ensure data integrity, quality, and compliance.
 * Collaborate with scientists, ML engineers, software developers, business leaders, and product teams to define data requirements, architect solutions, and implement data-driven opportunities that enhance customer experiences.
 * Leverage advanced analytics and data engineering practices to uncover actionable customer insights that drive the development of innovative and enhanced customer experiences for Suno.
 * Implement and monitor data systems to ensure high availability, reliability, and scalability while advocating for and applying best practices in big data engineering and analytics.
   
   

What You’ll Need


 * 5+ years of experience in data engineering, with a strong grasp of Big Data engineering concepts, data architecture design, and performance optimization.
 * Experience with data modeling, warehousing and building ETL pipelines.
 * Experience with SQL and Python.
 * Experience in scaling data pipelines from the ground up (0 to 1)
 * Familiarity with Airflow, DBT, and Snowflake is a strong advantage.
 * Passionate about engineering excellence, rapid iteration, learning, and hard work.
 * Technical leadership or management experience is a plus.
 * A love of music (listening, exploring, making) is a huge plus.
   
   

Additional Notes: Applicants must be eligible to work in the US.

Compensation

The annual salary/OTE range for the target level for this role is $170,000 - $240,000 + target equity + benefits (including medical, dental, vision, and 401k)

Benefits


 * Healthcare for you and your dependents, with vision and dental
 * 401k with match
 * Generous commuter benefit
 * Flexible PTO
   
   ",Full-time
4148227249,204575.0,Data Engineer,"If you're a passionate problem-solver who loves diving into complex data sets, possesses broad programming savvy and excels at building reliable data pipelines, you'll love being a data engineer at InterWorks. As part of our Data team, you'll empower our customers to make well-informed, data-driven decisions. Together, we'll combine expert application of new software and technologies with a unique perspective on bridging the traditional Business-IT divide. Technical stuff aside, you'll be part of close-knit and helpful team that delivers nothing but the best work to our customers and each other.

Please be advised that this role is required to be located in the InterWorks Oklahoma City office in Oklahoma City, Oklahoma. Remote work or telecommuting arrangements outside of this jurisdiction are not permissible for this position.

Salary range commensurate with experience and qualifications, Data Engineer/Data Architect: $80,000-$140,000

What You'll Do


 * Tackle diverse projects that range in duration from a few days to a few months for clients ranging from local businesses to the Fortune 500
 * Design, develop and implement large scale, high-volume, high-performance data infrastructure and pipelines for Data Lake and Data Warehouse
 * Design cloud-native data pipelines, automation routines, and database schemas that can be leveraged to do predictive and prescriptive machine learning
 * Communicate ideas clearly, both verbally and through concise documentation, to various business sponsors, business analysts and technical resources
 * Build and implement ETL frameworks to improve code quality and reliability
 * Build and enforce common design patterns to increase code maintainability
 * Work with disparate data sources (relational databases, flat files, Excel, HDFS/Big Data systems, high-performance analytical databases, etc.) to unify client data
   
   

What You'll Need

Must-Haves:


 * Excellent SQL fluency
 * Strong ETL proficiency using GUI-based tools or code-based patterns
 * Understanding of data-modeling principles
 * Passion for delivering compelling solutions that exceed client expectations
 * Excellent verbal and written communication
 * Strong problem-solving skills
 * Business acumen
 * A thirst to learn
 * Adaptability and flexibility in changing situations
   
   

What We'd Like You to Have


 * Experience with software engineering practices
 * Experience with modern data-engineering practices and frameworks
 * Experience with integration from semi-structured file and API sources
 * Matillion, Fivetran, DBT or other ETL tools
 * AWS / Microsoft Azure cloud exposure
 * Snowflake / Databricks / Amazon Redshift / Google BigQuery / Azure Synapse
   
   

Why InterWorks

InterWorks is a people-focused tech consultancy that empowers clients with customized, collaborative solutions, and we love pursuing innovation alongside people who inspire us. Our approach to work and community is unique and unconventional—just like us—and that's the way we want it. The only thing missing is you. At InterWorks, we value unique contributions, our people are the glue that holds our business together. We're always looking for the right people, and we could be your perfect fit.",Full-time
4142248460,1318.0,Data Engineer,"About Wipro:

Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients’ most complex digital transformation needs. We leverage our holistic portfolio of capabilities in consulting, design, engineering, operations, and emerging technologies to help clients realize their boldest ambitions and build future-ready, sustainable businesses. A company recognized globally for its comprehensive portfolio of services, strong commitment to sustainability and good corporate citizenship, we have over 250,000 dedicated employees serving clients across 66 countries. We deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world.

A PROUD HISTORY OF OVER 75 YEARS

FY22 REVENUE 10.4 BN USD

WE’RE PRESENT IN 66 COUNTRIES

OVER 1,400 ACTIVE GLOBAL CLIENTS




Role - Snowflake Data Engineer




Location - Boston, MA ( Hybrid)




JD –




Snowflake SnowPro Certification – required.

8+ years’ experience in cloud-based solutions.

8+ years in hands on snowflake development5

Hands on experience in Design, build data pipelines on cloud-based infrastructure having extensively worked on Azure, snowflake, DBT, Airflow and cosmos db.

Having done end to end build from ingestion, transformation, and extract generation in Snowflake.

Experience in writing stored procedures in JavaScript.

Knowledge and experience in python, is a plus.

Optimize and tune snowflake performance including query optimization and have experience in scaling strategies.

Address data issues, root cause analysis and production support.

Experience working in a Financial Industry.

Understanding Agile methodologies.




“Expected annual pay for this role ranges from [$110,000] to [$130,000]. Based on the position, the role is also eligible for Wipro’s standard benefits including a full range of medical and dental benefits options, disability insurance, paid time off (inclusive of sick leave), other paid and unpaid leave options.”




Wipro is an Equal Employment Opportunity employer and makes all employment and employment-related decisions without regard to a person's race, sex, national origin, ancestry, disability, sexual orientation, or any other status protected by applicable law.",Full-time
4079358073,93246786.0,Data Engineer,"Data Engineer - New Jersey

New Jersey **HYBRID FROM DAY 1**

MUST COMPLETE GLIDER

SAMPLE RESUME ATTACHED OF GUYS ON TEAM

Data Engineer Job Description

What You’ll Bring:


 * BS or MS degree in Computer Science or a related technical field and 10+ years of experience.
 * Hands on experience in Data space with an eco-system using Spark, Scala/Python.
 * Expertise with working on at least one big data technology like Hadoop, Kafka, Cassandra.
 * Hands on Experience with PL/SQL to query data & generate insights using complex queries, stored procedures, and user defined functions.
 * Familiarty with Engineering practices in Analytics space using tools like PowerBi, Tableau Or Looker.
 * Solid knowledge of Linux systems with the ability to troubleshoot issues in complex, distributed, multi-tier architectures.
 * Excellent debugging and problem solving capability.
 * Experience performing regular support & maintenance of the system to keep it optimum efficiency level.
 * Working experience in coordinating with & driving teams across Various geographies & time zones to a common software deliverable.
 * Experience in bootstrap production and non-prod environments in public/private clouds
 * Experience in secure, scalable and highly available online services
 * Good written and verbal communication skills?.
 * Engage with Product Management and Business to drive the agenda, set your priorities and deliver awesome products.?
 * Enable data scientists, business and product partners to fully leverage our platform
 * Lead the discovery phase of medium to large projects to come up with high-level design.
   
   

Even Better If You Have


 * Experience collaborating with multiple teams
 * Experience in Big Data applications
 * Experience developing with web/app containers such as Apache/Tomcat
 * Follows the industry trends in the online world
 * Good knowledge of High performance Stream processing, Large Scale Messaging Systems",Contract
4054258701,5837.0,Data Engineer - 75% Remote,"Work at OMRON!

OMRON is a global leader in the field of automation, an $8 billion global technology company celebrating more than 80 years of success. OMRON’s business fields cover a broad spectrum, ranging from industrial automation and electronic components to social systems and healthcare. OMRON Management Center of America, Inc. is the regional headquarters for OMRON in the Americas.

Data Engineer

As a Data Engineer at OMRON, you will play a crucial role in designing, implementing, and maintaining robust data pipelines and infrastructure on Snowflake, leveraging your expertise in data integration tools and AWS cloud services. You will work closely with cross-functional teams to ensure the efficient flow of data across various systems and platforms, while also validating data integrity and adherence to best practices. Additionally, you will contribute to data modeling efforts and collaborate with data Analysts/scientists to support advanced analytics initiatives. Experience with Power BI visualizations will be considered a plus.

Our Commitment To Employees


 * Training and Career Development Program to give employees a learning path with the necessary tools and resources they need to help build their career at Omron.
 * Great financial opportunities with competitive compensation, immediate 401k match with 100% vesting, profit sharing, and Blue Cross Blue Shield for medical, dental, vision and prescription drug benefits.
 * Community Awareness that includes activities with local non-profit organizations and a Matching Gift Program.
 * Work-Life Balance with Flexible Work Arrangements, Flexible Work Hours, and Sick/Vacation/Holiday Pay.
 * Wellness Activities such as Walking Contests, Nutritional Learning Sessions, On Site Flu shots and Health Screenings.
   
   

Responsibilities


 * Design, develop, and maintain data pipelines on Snowflake using Appflow, IICS, or other data integration tools.
 * Ensure data quality and integrity by implementing rigorous validation processes and recommending best practices for data management.
 * Collaborate with stakeholders to understand data requirements and translate them into scalable and efficient solutions.
 * Implement and optimize data models to support analytics and reporting needs, considering performance and scalability requirements.
 * Work closely with AWS cloud services, leveraging various tools and services for data storage, processing, and analysis.
 * Collaborate with data experts to deploy machine learning models and support data science projects.
 * Develop Power BI visualizations and dashboards to provide insights to stakeholders and drive decision-making.
 * Stay abreast of emerging technologies and industry trends, continuously improving processes and solutions.
 * Other duties and miscellaneous projects as needed
   
   

Job Requirements


 * Bachelor’s degree in business or technical field; master’s degree preferred.
 * Proven experience as a Data Engineer, with a focus on Snowflake, data integration tools, and AWS cloud services.
 * Strong proficiency in SQL
 * Experience with programming languages such as Python is a big plus
 * Experience with data modeling concepts and tools.
 * Familiarity with data science techniques and tools is a plus.
 * Experience with Power BI or other data visualization tools is preferred.
 * Excellent problem-solving skills and attention to detail.
 * Strong communication and collaboration skills, with the ability to work effectively in a team environment
   
   

The pay Range for this role is $85,000 - $95,000 per year, however, base pay offered may vary depending on geographic region, internal equity, job-related knowledge, skills, and experience among other factors. This position is also eligible for an annual performance-based bonus program. Candidates will be assessed and provided offers against the minimum qualifications of the role and their individual expereince.

Don't meet every single requirement? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every single qualification. At Omron we are dedicated to building a diverse, inclusive and authentic workplace, so if you're excited about this role but your past experience doesn't align perfectly with every qualification in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles.

Omron is an Equal Opportunity Employer. We provide equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, we comply with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",Full-time
4150714152,1916708.0,Software Engineer - New Grad 2025,"#TeamNextdoor

Nextdoor is where you connect to the neighborhoods that matter to you so you can belong. Our purpose is to cultivate a kinder world where everyone has a neighborhood they can rely on.

Neighbors around the world turn to Nextdoor daily to receive trusted information, give and get help, get things done, and build real-world connections with those nearby — neighbors, businesses, and public services. Today, neighbors rely on Nextdoor in more than 315,000 neighborhoods across 11 countries.

Meet your Future Neighbors

As a Software Engineer at Nextdoor, you will join a dedicated team of developers, product managers, and designers who are passionate about leveraging technology to create a kinder world where everyone can rely on their neighbors. Our close-knit team of engineers wears multiple hats and works across various languages and services to deliver value to our neighbors. We prioritize moving quickly and making a significant impact, while maintaining high standards for quality and reliability as we build a great product. In this role, you will have opportunities to both learn from and mentor your co-workers.

Our New Grad positions are based in our offices in San Francisco or New York City. We offer a hybrid work environment, with the expectation to work in office six times per month. Learn more about the experiences of our new grads here.

The Impact You’ll Make

We empower our teams to take full ownership of bringing Nextdoor to life, offering you the chance to make significant contributions across our entire engineering stack and tackle exciting challenges. As a new grad engineer, you'll hit the ground running, with the opportunity to push code to production in your first week.

Beyond coding, you'll help shape the features we build through collaboration and customer feedback. You'll work closely with product managers and designers to ensure our products are user-friendly, beneficial to our customers, and aligned with the Nextdoor platform experience. We believe engineers should be involved in all aspects of product development, from conception and planning to roadmap building, shipping, and performance evaluation, which guides future iterations.

What You’ll Bring To The Team


 * Bachelor’s degree in a technical discipline; expected graduation between 2024 and Summer 2025
 * Solid understanding of data structures and algorithms
 * Familiarity with programming principles and a desire to learn more
 * Willingness to communicate and collaborate; we want to hear your ideas
 * Flexibility and adaptability in a fast-paced startup environment
 * Enthusiasm for learning about new technologies and systems
 * Effective time management and prioritization skills
 * Experience in software design and development
 * Passion for Nextdoor’s mission and purpose
   
   

Rewards

Compensation, benefits, perks, and recognition programs at Nextdoor come together to create one overall rewards package. The starting salary for this role is expected to be $140,000 on an annualized basis, or potentially greater in the event that your 'level' of proficiency exceeds the level expected for the role. Compensation may also vary by geography.

We also expect to award a meaningful equity grant for this role. With equal quarterly vesting, your first vest date would be within the first 3 months of your start date.

Benefits

We’ve got you covered! We are dedicated to supporting your personal and professional growth with a comprehensive benefits package that includes:


 * A variety of health plans, and a OneMedical membership for concierge care
 * Flexible paid time off
 * Dedicated volunteer days
 * Monthly wellness stipend
 * Mental health support
 * Gender affirming care
 * Stocked micro-kitchens and lunches at our offices
   
   

At Nextdoor, we empower our employees to build stronger local communities. To create a platform where all feel welcome, we want our workforce to reflect the diversity of the neighbors we seek to serve. We encourage everyone interested in our purpose to apply. We do not discriminate on the basis of race, gender, religion, sexual orientation, age, or any other trait that unfairly targets a group of people. In accordance with the San Francisco Fair Chance Ordinance, we always consider qualified applicants with arrest and conviction records.",Full-time
4120823536,10667.0,"Data Engineer, Analytics","Are you passionate about Facebook’s product, analytics and technology? The Analytics, Data Engineering team is looking for fast-moving analytics candidates and data junkies who want to make an impact. Our data warehouse team works very closely with Product Managers, Product Analysts and Internet Marketers to figure out ways to acquire new users, retain existing users and optimize user experience - all of this using massive amounts of data. In this role, you will see a direct link between your work, company growth, and user satisfaction. You will work with some of the brightest minds in the industry, and you'll have the opportunity to solve some of the most challenging business problems on the web and mobile Internet, at a scale that few companies can match.

Data Engineer, Analytics Responsibilities:


 * Architect, implement and deploy new data models and data processes in production
 * Perform data analysis to generate business insights
 * Interface with Engineers, Product Managers and Product Analysts to understand product goals and data needs
 * Build data expertise and own data quality for allocated areas of ownership
 * Manage data warehouse plans for a product or a group of products
 * Support critical data processes running in production
   
   

Minimum Qualifications:


 * Currently has, or is in the process of obtaining, a Bachelors or Masters degree in Computer Science, Mathematics, or related technical field
 * Programming knowledge in Python or Java
 * Knowledge of SQL
 * Knowledge of database systems
 * Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment
 * Currently has, or is in the process of obtaining a Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. Degree must be completed prior to joining Meta.
   
   

Preferred Qualifications:


 * Experience thriving in a fast-paced work environment
 * Curious, self-driven, analytical and excited to play with data
 * Experience in collaborating with individuals and organizations
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$46.63/hour to $134,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4080016680,2658876.0,Data Engineer,"ABOUT THE ROLE


Peloton is looking for a talented Data Engineer to join the Data Science team. In this role, you will help scale Peloton’s data infrastructure for business needs by building batch and streaming data pipelines that process terabytes of data daily. You will have the opportunity to work with multiple teams of engineers and business partners to support analytics and reporting data needs across the organization. 


This role will be hybrid, not remote.


YOUR DAILY IMPACT AT PELOTON

   
   
 * Build and maintain data pipelines to support the data and analytics needs of different stakeholders across multiple business verticals including Supply Chain, Logistics, Finance, Marketing, Product, etc. 
   
   
 * Understand end to end data interactions and dependencies across complex data pipelines and data transformation and how they impact business decisions.
   
   
 * Collaborate with the team to develop best practices in building our next generation data platform.
   
   
 * Implement data lake ingestion pipelines using Apache Spark and Apache Hudi.
   
   


YOU BRING TO PELOTON

   
   
 * 3+ years in data engineering roles or 4+ years in data-intensive engineering or software development roles.
   
   
 * Bachelor’s degree in a STEM related field. Advanced degree preferred.
   
   
 * Strong knowledge of at least one programming language{ {:}} Python (preferred) or Java
   .
 * 
   Working knowledge of developing ETL/ELT pipelines, including data processing and transforming data to meet business goals
   .
 * 
   1+ years of experience with big data architectures and tools to efficiently process large volumes of data
   .
 * 
   Familiar with REST for accessing cloud based services
   .
 * 
   Excellent knowledge about databases or data warehouses, such as PostgreSQL or Redshift
   .
 * 
   Strong understanding and working knowledge of using SQL (PostgreSQL or Redshift preferred) for various reporting and transformation needs
   .
 * 
   Comfortable with Linux operating system and command line tools such as Bash
   .
 * 
   Team player with excellent communication, adaptability and collaboration skills
   .
 * 
   Experience running Agile methodology and applying SCRUM to data engineering
   .
 * 
   Experience with GIT and Github
   .



BONUS POINTS IF YOU HAVE
   
   
 * 
   Experience working in a cloud-based ecosystem, preferably AWS (including RDS, Redshift, Athena, Glue, etc.)
   .
 * 
   Experience with Apache Hadoop, Hive, Spark or PySpark
   .
 * 
   Experience with orchestration tools such as Apache Airflow
   .
 * 
   Experience with data integration tools such as Airbyte
   .









The base salary range represents the low and high end of the anticipated salary range for this position based at our New York City headquarters. The actual base salary offered for this position will depend on numerous factors including individual performance, business objectives, and if the location for the job changes. Our base salary is just one component of Peloton’s competitive total rewards strategy that also includes annual equity awards and an Employee Stock Purchase Plan as well as other region-specific health and welfare benefits.As an organization, one of our top priorities is to maintain the health and wellbeing for our employees and their family. To achieve this goal, we offer robust and comprehensive benefits including{ {:}}
- Medical, dental and vision insurance
- Generous paid time off policy
- Short-term and long-term disability
- Access to mental health services
- 401k, tuition reimbursement and student loan paydown plans
- Employee Stock Purchase Plan
- Fertility and adoption support and up to 18 weeks of paid parental leave 
- Child care and family care discounts
- Free access to Peloton Digital App and apparel and product discounts
- Commuter benefits and Citi Bike Discount
- Pet insurance and so much more!


 Base Salary Range{ {:}} $140,389 USD - $182,506

U

SD &nb

s

p;
ABOUT PELOTON{

{

:}}
Peloton (NASDAQ{ {:}} PTON) provides Members with expert instruction, and world class content to create impactful and entertaining workout experiences for anyone, anywhere and at any stage in their fitness journey. At home, outdoors, traveling, or at the gym, Peloton brings together innovative hardware, distinctive software, and exclusive content. Founded in 2012 and headquartered in New York City, Peloton has millions of Members across the US, UK, Canada, Germany, Australia, and Austria. For more information, visit www.onepeloton

.

com.
Peloton is an equal opportunity employer and complies with all applicable federal, state, and local fair employment practices laws. Equal employment opportunity has been, and will continue to be, a fundamental principle at Peloton, where all team members, applicants, and other covered persons are considered on the basis of their personal capabilities and qualifications without discrimination because of race, color, religion, sex, age, national origin, disability, pregnancy, genetic information, military or veteran status, sexual orientation, gender identity or expression, marital and civil partnership/union status, alienage or citizenship status, creed, genetic predisposition or carrier status, unemployment status, familial status, domestic violence, sexual violence or stalking victim status, caregiver status, or any other protected characteristic as established by applicable law. This policy of equal employment opportunity applies to all practices and procedures relating to recruitment and hiring, compensation, benefits, termination, and all other terms and conditions of employment.  If you would like to request any accommodations from application through to interview, please email{ {:}} applicantaccommodations@onepeloton.com.Qualified applicants with arrest or conviction records will be considered for employment in accordance with the Los Angeles County Fair Chance Ordinance for Employers and the California Fair Chance Act, the City of Los Angeles Fair Chance Initiative for Hiring Ordinance and the San Francisco Fair Chance Ordinance, as applicable to applicants applying for positions in these jurisdic

t

ions.
Please be aware that fictitious job openings, consulting engagements, solicitations, or employment offers may be circulated on the Internet in an attempt to obtain privileged information, or to induce you to pay a fee for services related to recruitment or training. Peloton does NOT charge any application, processing, or training fee at any stage of the recruitment or hiring process. All genuine job openings will be posted here on our careers page and all communications from the Peloton recruiting team and/or hiring managers will be from an @onepeloton.com email address.

&

nbsp;
If you have any doubts about the authenticity of an email, letter or telephone communication purportedly from, for, or on behalf of Peloton, please email applicantaccommodations@onepeloton.com before taking any further action in relation to the correspon

d

ence.
Peloton does not accept unsolicited agency resumes. Agencies should not forward resumes to our jobs alias, Peloton employees or any other organization location. Peloton is not responsible for any agency fees related to unsolicited re

sumes.",Full-time
4120826362,10667.0,Data Engineer Intern,"Every month, billions of people leverage Meta products to connect with friends and loved ones from across the world. On the Data Engineering Team, our mission is to support these products both internally and externally by delivering the best data foundation that drives impact through informed decision making. As a highly collaborative organization, our data engineers work cross-functionally with software engineering, data science, and product management to optimize growth, strategy, and experience for over three billion users, as well as our internal employee community. In this role, you will see a direct correlation between your work, company growth, and user satisfaction. Beyond this, you will work with some of the brightest minds in the industry, and you'll have a unique opportunity to solve some of the most interesting data challenges with efficiency and integrity, at a scale few companies can match. As we continue to expand and create, we have a lot of exciting work ahead of us!

Data Engineer Intern Responsibilities:


 * Architect, implement and deploy new data models and data processes in production
 * Perform data analysis to generate business insights
 * Interface with Engineers, Product Managers and Data Scientists to understand product goals and data needs
 * Build data expertise and own data quality for allocated areas of ownership
 * Manage data warehouse plans for a product or a group of products
 * Support critical data processes running in production
   
   

Minimum Qualifications:


 * Currently has, or is in the process of obtaining, a Bachelors, or Masters degree in Computer Science, Information Science, Mathematics, or related technical field
 * Knowledge of SQL, data modeling and at least one programming language(e.g., Python, C++, C#, Scala)
 * Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment
   
   

Preferred Qualifications:


 * Intent to return to degree-program after the completion of the internship
 * Curious, self-driven, analytical and excited to play with data
 * Ability to thrive in a fast paced work environment
 * Experience in collaborating with individuals and organizations
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$7,469/month to $9,000/month + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4073150825,3365729.0,Data Engineer I,"Condé Nast is a global media company producing the highest quality content with a footprint of more than 1 billion consumers in 32 territories through print, digital, video and social platforms. The company’s portfolio includes many of the world’s most respected and influential media properties including Vogue, Vanity Fair, Glamour, Self, GQ, The New Yorker, Condé Nast Traveler/Traveller, Allure, AD, Bon Appétit and Wired, among others.

Job Description

Location:

New York, NY

Condé Nast is a premier media company renowned for producing the highest qualitycontent for the world's most influential audiences, attracting more than 100 million consumers across its industry-leading print, digital and video brands.

Condé Nast is home to many of the world's most-celebrated magazine and website brands.

The company's reputation for excellence is the result of our commitment to publishing the best consumer, trade, and lifestyle content. Our brands include Vogue, Epicurious, Vanity Fair, The New Yorker, Wired, and many more. Passion is the core of our philosophy at Condé Nast. Our mission is not only to inform readers but to ignite and nourish their passions.

The Data Solutions Engineering team have a wide range of responsibilities and play a critical role in shaping how Condé Nast enables its business using data. The team is responsible for building data pipelines, data products and tools that enable our Data Scientists, Analysts in various business units, Business Intelligence Engineers and Executives to solve challenging use cases in our industry. We are seeking a Data Engineer who will build and maintain data pipelines across business areas such as subscriptions, video, clickstream, commerce, social and advertising within Condé Nast. If you are looking for a challenging environment and to work with a world class team of data engineers in a well balanced environment and seasoned company, come join us:

RESPONSIBILITIES:


 * Design, build and test batch and streaming data pipelines capable of processing
   
   

large volumes of data


 * Build efficient code to transform raw data into datasets for analysis, reporting and machine learning models
 * Collaborate with other data engineers to implement a shared technical vision
 * Participate in the entire software development lifecycle, from concept to release
   
   

MINIMUM QUALIFICATIONS:


 * Applicants should have a degree (B.S. or higher) in Computer Science or a relateddiscipline or relevant professional experience
 * 2.5+ years of distributed data processing experience designing scalable &
   
   

automated software systems


 * Experience in processing structured and unstructured data into a form suitable for analysis and reporting
 * Experience with data modelling, batch data pipeline design and implementation
 * Experience building batch or real-time data pipelines
 * Proficiency in Python/PySpark or Scala
 * Proficiency in SQL
 * Experience with data processing frameworks such as Apache Spark (we use
   
   

Databricks)


 * Experience in cloud-based infrastructures such as AWS or GCP
 * Exposure to orchestration platforms such as Airflow (we use Astronomer)
 * Proven attention to detail, critical thinking, and the ability to work independently
   
   

within a cross-functional team


 * Comfortable with CI/CD (we use GitHub Actions) Pipelines
 * Experience with Git version control, and other software adjacent tools
 * Terraform is used Infra as service tool.
   
   

Salay Range: $119K - $137K

What happens next?

If you are interested in this opportunity, please apply below, and we will review your application as soon as possible. You can update your resume or upload a cover letter at any time by accessing your candidate profile.

Condé Nast is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, age, familial status and other legally protected characteristics.",Full-time
4147841624,28665250.0,Data Engineer,"APiJET is a Seattle-based pioneer in real-time aircraft data analytics and software products. Our team works with advanced algorithms and data streams to uncover hidden efficiencies that enable our customers to operate more efficiently and reduce their environmental footprints. We work across diverse data sets spanning public source and private aerospace data, searching for meaningful patterns to drive our platform. If you want something new and challenging the status quo, check us out!

As a Data Engineer, you will build and maintain ETL systems within AWS, utilizing in-house and cloud-specific tooling. You will develop and improve the data lake, data collection systems, data integrity, and other strategic systems that support the data science team, the customer, and the business. Your contribution will be key to the success of the company!

Duties And Responsibilities

Build and support data systems and pipelines by:


 * Cleaning and transforming raw data (internally and externally sourced) to be ingested by reports and applications.
 * Implementing data mart tools to facilitate data mining and curation needs.
 * Optimizing and automating ETL processes.
   
   

Enhance Data Quality And Reliability By


 * Analyzing and organizing data, including ad-hoc request fulfillment and deep data exploration.
 * Implementing, monitoring, and alarming on ETL pipelines and bad data.
 * Generating reports on data quality and anomalies.
   
   

Collaborate with data scientists and software architects on data exploration projects by:


 * Developing analytical tools and programs to support the data team.
 * Extracting and preparing data based on requirements and specifications.
   
   

Required Skills And Abilities


 * 3+ years previous experience as a data engineer or a similar role.
 * 3+ years implementing data models, data mining, data pipelines, and similar activities.
 * 2+ years in Python programming (PySpark, Pandas, and AWS-related data-wrangling tools).
 * 3+ years working with AWS services to deliver quality, reliable, and timely data pipeline solutions.
 * 2+ years supporting containerized and serverless pipelines.
 * 2+ years working with large datasets.
   
   

Soft Skills


 * Comfortable in an Agile task management environment (Atlassian Suite, Agile methodologies).
 * Ability to work with ambiguous requirements.
 * Clear written and verbal communication. Being hybrid, asynchronous communication is a necessity.
 * A people person, collaboration is a must!
   
   

Educational and Physical Requirements


 * Must have a bachelor's degree in computer science, a related field, or equivalent experience.
 * Must be a U.S. Person (U.S. Citizen or Green Card holder).
 * The company is headquartered in Seattle, Washington, and this position must reside within a 30-mile radius of Seattle due to the hybrid nature of the role.",Full-time
4148224948,204575.0,Data Engineer,"If you're a passionate problem-solver who loves diving into complex data sets, possesses broad programming savvy and excels at building reliable data pipelines, you'll love being a data engineer at InterWorks. As part of our Data team, you'll empower our customers to make well-informed, data-driven decisions. Together, we'll combine expert application of new software and technologies with a unique perspective on bridging the traditional Business-IT divide. Technical stuff aside, you'll be part of close-knit and helpful team that delivers nothing but the best work to our customers and each other.

Please be advised that this role is required to be located in the InterWorks Stillwater office in Stillwater, Oklahoma. Remote work or telecommuting arrangements outside of this jurisdiction are not permissible for this position.

Salary range commensurate with experience and qualifications, Data Engineer/Data Architect: $65,000-$140,000

What You'll Do


 * Tackle diverse projects that range in duration from a few days to a few months for clients ranging from local businesses to the Fortune 500
 * Design, develop and implement large scale, high-volume, high-performance data infrastructure and pipelines for Data Lake and Data Warehouse
 * Design cloud-native data pipelines, automation routines, and database schemas that can be leveraged to do predictive and prescriptive machine learning
 * Communicate ideas clearly, both verbally and through concise documentation, to various business sponsors, business analysts and technical resources
 * Build and implement ETL frameworks to improve code quality and reliability
 * Build and enforce common design patterns to increase code maintainability
 * Work with disparate data sources (relational databases, flat files, Excel, HDFS/Big Data systems, high-performance analytical databases, etc.) to unify client data
   
   

What You'll Need

Must-Haves:


 * Excellent SQL fluency
 * Strong ETL proficiency using GUI-based tools or code-based patterns
 * Understanding of data-modeling principles
 * Passion for delivering compelling solutions that exceed client expectations
 * Excellent verbal and written communication
 * Strong problem-solving skills
 * Business acumen
 * A thirst to learn
 * Adaptability and flexibility in changing situations
   
   

What We'd Like You to Have


 * Experience with software engineering practices
 * Experience with modern data-engineering practices and frameworks
 * Experience with integration from semi-structured file and API sources
 * Matillion, Fivetran, DBT or other ETL tools
 * AWS / Microsoft Azure cloud exposure
 * Snowflake / Databricks / Amazon Redshift / Google BigQuery / Azure Synapse
   
   

Why InterWorks

InterWorks is a people-focused tech consultancy that empowers clients with customized, collaborative solutions, and we love pursuing innovation alongside people who inspire us. Our approach to work and community is unique and unconventional—just like us—and that's the way we want it. The only thing missing is you. At InterWorks, we value unique contributions, our people are the glue that holds our business together. We're always looking for the right people, and we could be your perfect fit.",Full-time
4115017957,22688.0,Data Engineer,"Overview

Atlassian is looking for a Data Engineer to join our Data Engineering team and build world-class data solutions and applications that power crucial decisions throughout the organisation. We are looking for an open-minded, structured thinker who is passionate about building systems at scale. You will enable a world-class data engineering practice, drive the approach with which we use data, develop backend systems and data models to serve the needs of insights and play an active role in building Atlassian’s data-driven culture.

Working at Atlassian

Atlassians can choose where they work – whether in an office, from home, or a combination of the two. That way, Atlassians have more control over supporting their family, personal goals, and other priorities. We can hire people in any country where we have a legal entity. Interviews and onboarding are conducted virtually, a part of being a distributed-first company.

Responsibilities

Data is a BIG deal at Atlassian. We ingest over 180 billion events each month into our analytics platform and we have dozens of teams across the company driving their decisions and guiding their operations based on the data and services we provide.

The data engineering team manages several data models and data pipelines across Atlassian, including finance, growth, product analysis, customer support, sales, and marketing. You'll join a team that is smart and very direct. We ask hard questions and challenge each other to constantly improve our work.

As a Data Engineer, you will apply your technical expertise to build analytical data models that support a broad range of analytical requirements across the company. You will work with extended teams to evolve solutions as business processes and requirements change. You'll own problems end-to-end and on an ongoing basis, you'll improve the data by adding new sources, coding business rules, and producing new metrics that support the business.

Qualifications


 * Bachelor’s/Master's degree or equivalent in a STEM field with a minimum 2+ Years of Experience in Data Engineering or related field.
 * Expertise in Python or other modern programming languages.
 * Working knowledge of relational databases and query authoring via SQL.
 * Experience designing data models for optimal storage, retrieval and dashboarding to meet product and business requirements.
 * Experience building scalable data pipelines using Spark or Spark-SQL with Airflow scheduler/executor framework or similar scheduling tools.
 * Experience building real-time data pipelines using a micro-services architecture.
 * Experience working with AWS data services or similar Apache projects (Spark, Flink, Hive, and Kafka).
 * Understanding of Data Engineering tools/frameworks and standards to improve the productivity and quality of output for Data Engineers across the team.
 * Well-versed in modern software development practices (Agile, TDD, CICD).
   
   
   

Compensation

At Atlassian, we strive to design equitable, explainable, and competitive compensation programs. To support this goal, the baseline of our range is higher than that of the typical market range, but in turn we expect to hire most candidates near this baseline. Base pay within the range is ultimately determined by a candidate's skills, expertise, or experience. In the United States, we have three geographic pay zones. For this role, our current base pay ranges for new hires in each zone are:

Zone A: $140,100 - $186,800

Zone B: $126,100 - $168,200

Zone C: $116,300 - $155,100

This role may also be eligible for benefits, bonuses, commissions, and equity.

Please visit go.atlassian.com/payzones for more information on which locations are included in each of our geographic pay zones. However, please confirm the zone for your specific location with your recruiter.

Our Perks & Benefits

Atlassian offers a variety of perks and benefits to support you, your family and to help you engage with your local community. Our offerings include health coverage, paid volunteer days, wellness resources, and so much more. Visit go.atlassian.com/perksandbenefits to learn more.

About Atlassian

At Atlassian, we're motivated by a common goal: to unleash the potential of every team. Our software products help teams all over the planet and our solutions are designed for all types of work. Team collaboration through our tools makes what may be impossible alone, possible together.

We believe that the unique contributions of all Atlassians create our success. To ensure that our products and culture continue to incorporate everyone's perspectives and experience, we never discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. All your information will be kept confidential according to EEO guidelines.

To provide you the best experience, we can support with accommodations or adjustments at any stage of the recruitment process. Simply inform our Recruitment team during your conversation with them.

To learn more about our culture and hiring process, visit go.atlassian.com/crh .",Full-time
4115023391,22688.0,Data Engineer,"Overview

Atlassian is looking for a Data Engineer to join our Data Engineering team and build world-class data solutions and applications that power crucial decisions throughout the organisation. We are looking for an open-minded, structured thinker who is passionate about building systems at scale. You will enable a world-class data engineering practice, drive the approach with which we use data, develop backend systems and data models to serve the needs of insights and play an active role in building Atlassian’s data-driven culture.

Working at Atlassian

Atlassians can choose where they work – whether in an office, from home, or a combination of the two. That way, Atlassians have more control over supporting their family, personal goals, and other priorities. We can hire people in any country where we have a legal entity. Interviews and onboarding are conducted virtually, a part of being a distributed-first company.

Responsibilities

Data is a BIG deal at Atlassian. We ingest over 180 billion events each month into our analytics platform and we have dozens of teams across the company driving their decisions and guiding their operations based on the data and services we provide.

The data engineering team manages several data models and data pipelines across Atlassian, including finance, growth, product analysis, customer support, sales, and marketing. You'll join a team that is smart and very direct. We ask hard questions and challenge each other to constantly improve our work.

As a Data Engineer, you will apply your technical expertise to build analytical data models that support a broad range of analytical requirements across the company. You will work with extended teams to evolve solutions as business processes and requirements change. You'll own problems end-to-end and on an ongoing basis, you'll improve the data by adding new sources, coding business rules, and producing new metrics that support the business.

Qualifications


 * Bachelor’s/Master's degree or equivalent in a STEM field with a minimum 2+ Years of Experience in Data Engineering or related field.
 * Expertise in Python or other modern programming languages.
 * Working knowledge of relational databases and query authoring via SQL.
 * Experience designing data models for optimal storage, retrieval and dashboarding to meet product and business requirements.
 * Experience building scalable data pipelines using Spark or Spark-SQL with Airflow scheduler/executor framework or similar scheduling tools.
 * Experience building real-time data pipelines using a micro-services architecture.
 * Experience working with AWS data services or similar Apache projects (Spark, Flink, Hive, and Kafka).
 * Understanding of Data Engineering tools/frameworks and standards to improve the productivity and quality of output for Data Engineers across the team.
 * Well-versed in modern software development practices (Agile, TDD, CICD).
   
   
   

Compensation

At Atlassian, we strive to design equitable, explainable, and competitive compensation programs. To support this goal, the baseline of our range is higher than that of the typical market range, but in turn we expect to hire most candidates near this baseline. Base pay within the range is ultimately determined by a candidate's skills, expertise, or experience. In the United States, we have three geographic pay zones. For this role, our current base pay ranges for new hires in each zone are:

Zone A: $140,100 - $186,800

Zone B: $126,100 - $168,200

Zone C: $116,300 - $155,100

This role may also be eligible for benefits, bonuses, commissions, and equity.

Please visit go.atlassian.com/payzones for more information on which locations are included in each of our geographic pay zones. However, please confirm the zone for your specific location with your recruiter.

Our Perks & Benefits

Atlassian offers a variety of perks and benefits to support you, your family and to help you engage with your local community. Our offerings include health coverage, paid volunteer days, wellness resources, and so much more. Visit go.atlassian.com/perksandbenefits to learn more.

About Atlassian

At Atlassian, we're motivated by a common goal: to unleash the potential of every team. Our software products help teams all over the planet and our solutions are designed for all types of work. Team collaboration through our tools makes what may be impossible alone, possible together.

We believe that the unique contributions of all Atlassians create our success. To ensure that our products and culture continue to incorporate everyone's perspectives and experience, we never discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. All your information will be kept confidential according to EEO guidelines.

To provide you the best experience, we can support with accommodations or adjustments at any stage of the recruitment process. Simply inform our Recruitment team during your conversation with them.

To learn more about our culture and hiring process, visit go.atlassian.com/crh .",Full-time
4115019764,22688.0,Data Engineer,"Overview

Atlassian is looking for a Data Engineer to join our Data Engineering team and build world-class data solutions and applications that power crucial decisions throughout the organisation. We are looking for an open-minded, structured thinker who is passionate about building systems at scale. You will enable a world-class data engineering practice, drive the approach with which we use data, develop backend systems and data models to serve the needs of insights and play an active role in building Atlassian’s data-driven culture.

Working at Atlassian

Atlassians can choose where they work – whether in an office, from home, or a combination of the two. That way, Atlassians have more control over supporting their family, personal goals, and other priorities. We can hire people in any country where we have a legal entity. Interviews and onboarding are conducted virtually, a part of being a distributed-first company.

Responsibilities

Data is a BIG deal at Atlassian. We ingest over 180 billion events each month into our analytics platform and we have dozens of teams across the company driving their decisions and guiding their operations based on the data and services we provide.

The data engineering team manages several data models and data pipelines across Atlassian, including finance, growth, product analysis, customer support, sales, and marketing. You'll join a team that is smart and very direct. We ask hard questions and challenge each other to constantly improve our work.

As a Data Engineer, you will apply your technical expertise to build analytical data models that support a broad range of analytical requirements across the company. You will work with extended teams to evolve solutions as business processes and requirements change. You'll own problems end-to-end and on an ongoing basis, you'll improve the data by adding new sources, coding business rules, and producing new metrics that support the business.

Qualifications


 * Bachelor’s/Master's degree or equivalent in a STEM field with a minimum 2+ Years of Experience in Data Engineering or related field.
 * Expertise in Python or other modern programming languages.
 * Working knowledge of relational databases and query authoring via SQL.
 * Experience designing data models for optimal storage, retrieval and dashboarding to meet product and business requirements.
 * Experience building scalable data pipelines using Spark or Spark-SQL with Airflow scheduler/executor framework or similar scheduling tools.
 * Experience building real-time data pipelines using a micro-services architecture.
 * Experience working with AWS data services or similar Apache projects (Spark, Flink, Hive, and Kafka).
 * Understanding of Data Engineering tools/frameworks and standards to improve the productivity and quality of output for Data Engineers across the team.
 * Well-versed in modern software development practices (Agile, TDD, CICD).
   
   
   

Compensation

At Atlassian, we strive to design equitable, explainable, and competitive compensation programs. To support this goal, the baseline of our range is higher than that of the typical market range, but in turn we expect to hire most candidates near this baseline. Base pay within the range is ultimately determined by a candidate's skills, expertise, or experience. In the United States, we have three geographic pay zones. For this role, our current base pay ranges for new hires in each zone are:

Zone A: $140,100 - $186,800

Zone B: $126,100 - $168,200

Zone C: $116,300 - $155,100

This role may also be eligible for benefits, bonuses, commissions, and equity.

Please visit go.atlassian.com/payzones for more information on which locations are included in each of our geographic pay zones. However, please confirm the zone for your specific location with your recruiter.

Our Perks & Benefits

Atlassian offers a variety of perks and benefits to support you, your family and to help you engage with your local community. Our offerings include health coverage, paid volunteer days, wellness resources, and so much more. Visit go.atlassian.com/perksandbenefits to learn more.

About Atlassian

At Atlassian, we're motivated by a common goal: to unleash the potential of every team. Our software products help teams all over the planet and our solutions are designed for all types of work. Team collaboration through our tools makes what may be impossible alone, possible together.

We believe that the unique contributions of all Atlassians create our success. To ensure that our products and culture continue to incorporate everyone's perspectives and experience, we never discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. All your information will be kept confidential according to EEO guidelines.

To provide you the best experience, we can support with accommodations or adjustments at any stage of the recruitment process. Simply inform our Recruitment team during your conversation with them.

To learn more about our culture and hiring process, visit go.atlassian.com/crh .",Full-time
4130736027,1154342.0,Data Engineer,"Position Overview:   Reporting to the Head of Data Analytics & Strategy, the Data Engineer will design, implement, and maintain complex data storage, pipeline, and analytics systems that support and further develop the data infrastructure of the organization’s Quantitative and Fundamental investment groups. Responsibilities include building large data pipelines and developing APIs to retrieve data, all to innovate the next level of analytics systems that effectively integrate with and enhance current research applications

 

Responsibilities:

•           Work with researchers and portfolio managers to analyze and improve the architecture of or proprietary and derived data sets

•           Solve interesting data engineering problems in support of quantitative researches leveraging time-series data

•           Implement cloud data platforms capable of handling the computational complexities of machine learning workflows on large data sets

•           Write code that provides reliable automated data pipelines, included automated quality checks

•           Take ownership of the data engineering code base, focusing on high-quality delivery of both code and data

•           Be a technical leader by building pipelines to explore and leverage alternative non-traditional data sources

 

Qualifications:

•           1-8 years’ relevant experience and a degree in Computer Science (or related field) with a strong GPA

•           Strong foundational skills in SQL, query performance tuning, and bash/shell scripting

•           Expert-level programming skills in Python and proficient with one of the following: Java/Scala, C/C++

•           Expertise in data modeling and choosing an appropriate model given the situation

•           Capital Markets and Asset Management experience and related datasets/vendors is a plus

•           Ability to provide thought leadership and contribute to the firm's overall technology strategy",Full-time
4145898813,69639337.0,Data Engineer,"About the job




BeaconFire is based in Central NJ and specializes in software development, web development, and business intelligence. We are looking for candidates with a strong background in software engineering or computer science for a Data Engineer Developer position.




Preferred Qualifications:




Passion for data and a deep desire to learn.

Bachelor’s Degree in Computer Science/Information Technology, Data Analytics/Data Science, or related discipline.

Intermediate Python. Experience in data processing is a plus. (Numpy, Pandas, etc)

Strong written and verbal communication skills.

Ability to work both independently and as part of a team.




Job Responsibilities:




Collaborate with the analytics team to find reliable data solutions to meet business needs.

Design and implement scalable ETL or ELT processes to support the business demand for data.

Perform data extraction, manipulation, and production from database tables.

Build utilities, user-defined functions, and frameworks to better enable data flow patterns.

Build and incorporate automated unit tests, and participate in integration testing efforts.

Work with teams to resolve operational & performance issues.

Work with architecture/engineering leads and other teams to ensure quality solutions are implemented, and

engineering best practices are defined and adhered to.




Compensation: $65,000.00 to $80,000.00 /year




BeaconFire is an E-verified company that provides equal employment opportunities (visa sponsorship provided).",Contract
4137705228,9477.0,Data Engineer,"About Agero:

Wherever drivers go, we’re leading the way. Agero’s mission is to rethink the vehicle ownership experience through a powerful combination of passionate people and data-driven technology, strengthening our clients’ relationships with their customers. As the #1 B2B, white-label provider of digital driver assistance services, we’re pushing the industry in a new direction, taking manual processes, and redefining them as digital, transparent, and connected. This includes: an industry-leading dispatch management platform powered by Swoop; comprehensive accident management services; knowledgeable consumer affairs and connected vehicle capabilities; and a growing marketplace of services, discounts and support enabled by a robust partner ecosystem. The company has over 150 million vehicle coverage points in partnership with leading automobile manufacturers, insurance carriers and many others. Managing one of the largest national networks of service providers, Agero responds to approximately 12 million service events annually. Agero, a member company of The Cross Country Group, is headquartered in Medford, Mass., with operations throughout North America. To learn more, visit https://www.agero.com/.

Role Description & Mission:

We are seeking a Data Engineer who is passionate about data and eager to make a meaningful impact. In this role, you will design, build, and maintain the core data infrastructure that powers our analytics, machine learning, and data science initiatives. Your responsibilities will include optimizing data management processes, ensuring data quality and reliability, and developing scalable, efficient data models to support advanced analytics and data-driven decision-making. Success in this role requires a strong technical foundation, a collaborative mindset, and a drive to deliver innovative and impactful solutions.

Key Outcomes:


 * Data Pipelines:
    * Develop and maintain robust ETL/ELT pipelines to ingest data from diverse sources (relational and NoSQL databases, APIs, etc.), including implementing best practices for real-time and batch data ingestion.
    * Create and optimize data workflows using modern orchestration tools (e.g., Apache Airflow, Snowflake Tasks, Dagster, Mage).

 * Cloud Cost Optimization:
    * Monitor and optimize cloud costs (e.g., AWS, Snowflake) by analyzing resource usage and implementing cost-saving strategies.
    * Perform query optimization in Snowflake to reduce compute costs and improve performance.

 * Data Foundations:
    * Develop and maintain modern data architectures, including data lakes and data warehouses (e.g., Snowflake, Databricks, Redshift), considering trade-offs of different data storage solutions and ensuring alignment with business requirements and SLAs.

 * Data Modeling & Transformation:
    * Apply dimensional modeling techniques (Kimball), star and snowflake schemas, and normalization vs. denormalization strategies based on use cases.
    * Develop transformations using DBT (Core or Cloud), Spark (PySpark), or other frameworks.
    * Collaborate on emerging approaches such as data mesh or specialized templates (e.g., Jina) to handle complex data needs.

 * Coding:
    * Write reusable, efficient, and scalable code in Python, PySpark, and SQL.
    * Integrate serverless computing frameworks or modern API frameworks to support data-driven applications (FastAPI, Flask).
    * Develop and maintain data-intensive UIs and dashboards using tools like Streamlit, Dash, Plotly, or React.

 * Data Quality Control:
    * Establish data governance and data quality frameworks, using either custom solutions or popular open-source/commercial tools (e.g., DBT tests, Great Expectations, Soda).
    * Implement data observability solutions to monitor and alert on data integrity and reliability (e.g., Monte Carlo, Alation, or Elementary).
    * Define SLAs, SLOs, and processes to identify, troubleshoot, and resolve data issues.

 * Teamwork:
    * Work cross-functionally with data scientists, analysts, and business stakeholders to translate requirements into robust data solutions.
    * Follow and advocate for best practices in version control, CI/CD.
    * Document data flows, processes, and architecture to facilitate knowledge sharing and maintainability.
      

Skills, Education & Experience:

Education & Experience: Bachelor's degree in a technical field and 3+ years of industry experience or Master's degree in a technical field and 3+ years of industry experience. (2-5+ years of experience)

Technical Skills (Essential):


 * Extensive experience with Snowflake (preferred) or other cloud-based data warehousing solutions like Redshift or BigQuery.
 * Expertise in building and maintaining ETL/ELT pipelines using tools like Airflow, DBT, Fivetran, or similar frameworks.
 * Proficiency in Python (e.g., Pandas, PySpark) for data processing and transformation.
 * Advanced SQL skills for querying and managing relational and NoSQL databases (e.g., DynamoDB, MongoDB).
 * Solid understanding of data modeling techniques, including dimensional modeling (e.g., star schema, snowflake schema).
 * Knowledge of query optimization and cost management strategies for platforms like Snowflake and cloud environments.
 * Experience with data quality and observability frameworks (e.g., Great Expectations, Soda).
 * Proven expertise in designing and deploying data solutions in the cloud, with a focus on AWS services (e.g., EC2, S3, RDS, Lambda, IAM).
 * Experience in building and consuming data-intensive APIs using frameworks like FastAPI or Flask.
 * Familiarity with version control systems (e.g., Git) and implementing CI/CD pipelines.
   
   

Soft Skills:


 * Strong communication and collaboration skills with the ability to explain technical concepts to both technical and non-technical audiences.
 * Ability to manage multiple priorities and work independently
   
   

Bonus Skills:


 * Experience with data streaming platforms such as Kafka or Kinesis.
 * Familiarity with Agile methodologies (Scrum, Kanban) and IaC tools like Terraform or CloudFormation.
 * Knowledge of emerging technologies or frameworks in the data engineering ecosystem, such as Delta Lake, Iceberg, or Hudi.
   
   

Hiring In:

Role Description and Mission:

We're looking for a service oriented and resilient Performance Manager who is passionate about customer service, helping others and delivering strong results.

The Performance Manager creates and manages the overall service delivery strategy for all services for an assigned network region. Responsible for improving service delivery metrics, customer satisfaction and reducing costs within the candidate’s area of focus. Performs root cause analysis to identify under performing markets and executes on a strategy to improve performance metrics. Fosters strong partnerships with key providers through education of best practices. Manages providers to meet assigned performance metrics for all services. Assists with coordinating competitive intelligence and market feedback on essential issues.

Key Outcomes:


 * Implements a master strategy for assigned region and creates action plans to improve CSI and reduce claims expense.
 * Coach service providers on overall performance within assigned region.
 * Communicates product and process changes to individual providers.
 * Builds and maintains positive relationships with clients and service providers while providing enhanced service level performance.
 * Coordinates and completes targeted proactive analyses for managing network performance.
   
   

Skills, Education & Experience:


 * Bachelor’s degree in business or equivalent experience
 * 3 - 5 years of related supplier or asset management and/or procurement related experience
 * Previous service experience in service delivery is a plus
 * Strong analytical, communication and relationship building skills are a requirement
 * Excellent performance management and relationship building skills
 * Exceptional written and verbal communication skills. Works in a fast-paced environment, builds strong partnerships
 * Utilizes good judgment, analytical and decision-making skills
 * Works independently with minimal guidance
   
   

Hiring In:


 * United States: AZ, FL, IL, KY, MA, MI, NM, NH, TN, GA, NC, VA, CA
 * Canada: Province of Ontario
   
   

The base salary range presented represents the anticipated low and high end salary range for new hires in this position. Actual salaries may vary and may be above or below the range presented based on various factors, including, but not limited to, work location, experience, job related skills, and relevant training and education. The range listed is just one component of the total compensation package provided by Agero to employees.

National Pay Range

$97,000—$140,000 USD

D, E & I Mission & Culture at Agero:

We are all Change Drivers at Agero. Each day, we speak to thousands of drivers and tow professionals across one of the most diverse countries in the world. Our mission to safeguard drivers on the road, strengthen our clients’ relationships with their drivers, and support the communities we live and work in unites us together as one force driving positive change.

The road to positive change starts inside Agero. In celebrating each other’s differences, we lift each other up and create space for innovation and community. Bringing our whole selves to work powers our commitment, drive, agility, and courage - ensuring we are not only changing the landscape of the driver services industry, we also are making a difference in the lives of our customers with each call, chat, and rescue.

Agero Benefits Summary

At Agero, we are committed to supporting our associates by providing a comprehensive benefits package designed to promote well-being, personal growth, and financial security. Our benefits include:


 * Health and Wellness: Healthcare, dental, vision, disability, life insurance, and mental health benefits for associates and their families.
 * Financial Security: 401(k) plan with company match and tuition assistance to support your future goals.
 * Work-Life Balance: Flexible time off, paid sick leave, and ten paid holidays annually.
    * For Contact Center Roles: Accrual of up to 3 weeks Paid Time Off per year, paid sick leave, and ten paid holidays annually.

 * Family Support: Parental planning benefits to assist associates through life’s milestones.
 * Bonus/Incentive Programs
   
   

Join Agero and experience a workplace that invests in your success both personally and professionally.

THIS DESCRIPTION IS NOT INTENDED TO BE A COMPLETE STATEMENT OF JOB CONTENT, RATHER TO ACT AS A GUIDE TO THE ESSENTIAL FUNCTIONS PERFORMED. MANAGEMENT RETAINS THE DISCRETION TO ADD TO OR CHANGE THE DUTIES OF THE POSITION AT ANY TIME.

To review Agero's privacy policy click the link: https://www.agero.com/privacy.


 * Disclaimer: Agero is committed to creating a diverse and inclusive environment and encourages applications from all qualified candidates. Accommodation is available. Additionally, we offer accommodation for applicants with disabilities in our recruitment processes. If you require accommodation during the recruitment process, please contact recruiting@agero.com.
 * Agero communicates with candidates via text for matters related to submitted applications, questions, and availability for interviews. If you prefer not to receive texts, you can contact Agero's recruiting team directly at recruiting@agero.com.
 * In compliance with applicable regulations, we confirm this posting is for a current vacant position.",Full-time
4151051466,51732630.0,Data Engineer II,"Garner's mission is to transform the healthcare economy, delivering high quality and affordable care for all. By helping employers restructure their healthcare benefit to provide clear incentives and data-driven insights, we direct employees to higher quality and lower cost healthcare providers. The result is that patients get better health outcomes while doctors are rewarded for practicing well, not performing more procedures. We are backed by top-tier venture capital firms, are growing rapidly and looking to expand our team.

We are looking for a Data Engineer II to support our technical teams by ensuring secure access to data within our organization. The ideal candidate for this role will have strong technical and stakeholder management skills, as well as the desire to be a hands-on contributor to building out an enterprise-grade data platform from the ground up.

Responsibilities will include:


 * Collaborate with senior engineers to build and support the data platform and pipelines that power our business
 * Collaborate across disciplines to produce high-quality datasets and reports
 * Partner with engineers across Garner to define and implement coding standards, common libraries, and shared tooling
 * Partner with Data Science, Researchers, and Product Managers to convert ideas into reliable, performant production systems
 * Protect our users' privacy and security through best practices
   
   

Our Stack and Tooling:

AWS, Snowflake, Argo, dbt, Terraform, JetStream

The ideal candidate has:


 * 2+ years of software engineering experience
 * 2+ years of experience building data platforms and pipelines in a fast-paced environment
 * 2+ years of experience with SQL
 * 1+ years of experience of observability tooling such as Cloudwatch, Datadog, Prometheus
 * 1+ years of experience with container technologies such as Kubernetes, Docker
 * Experience with data warehouse technologies such as Snowflake, RedShift, or DataBricks
 * Experience building distributed systems and data processing environments
 * Experience with orchestration technologies such as Argo, Airflow
 * Conceptual thinking ability to understand and decompose abstract problems
 * An aptitude to learn new technologies and tools quickly
   
   

Why You Should Join Our Team:


 * You are mission-driven and want to work at a company that is changing healthcare
 * You want to be on a small, fast-paced team that nimbly moves to meet new challenges
 * You love reducing operational difficulties and costs associated with data
 * You're excited about researching and working with the latest tools and technologies
   
   

What we look for at Garner:


 * Mission First: Our mission is to transform our healthcare system, delivering high quality and affordable care to all. Everything else is secondary.
 * Expect Extraordinary: Our mission is audacious, so we will only succeed by producing exceptional results. We continually push ourselves and each other to new heights and beyond our comfort zones.
 * Courageous Communication: Transparency and candor are imperative to realizing our potential as an organization and as individuals—even when uncomfortable. Many companies talk about these values. We live them.
 * Supportive community: We know that people do their best work and learn the most when they feel genuinely supported and cared for. It's also more fun that way.
   
   

The target salary range for this position is $120,000-$160,000. Individual compensation for this role will depend on various factors, including qualifications, skills, and applicable laws. In addition to base compensation, this role is eligible to participate in our equity incentive and competitive benefits plans.

Garner Health is proud to be an Equal Employment Opportunity employer and values diversity in the workplace. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, political views or activity, or other applicable legally protected characteristics.

Garner Health is committed to providing accommodations for qualified individuals with disabilities in our recruiting process. If you need assistance or an accommodation due to a disability, you may contact us at talent@getgarner.com.

Beware of job scam fraudsters! Our recruiters use getgarner.com email addresses exclusively. We do not post open roles on Indeed, conduct interviews via text, instant message, or Teams and we do not ask candidates to download software, purchase equipment through us, or to provide sensitive information such as bank account or social security numbers. If you have been contacted by someone claiming to be a Garner recruiter or hiring manager from a different domain about a job offer, please report it as potential job fraud to law enforcement here and to candidateprotection@getgarner.com",Full-time
4117985552,13030788.0,Data Engineer,"Headway’s mission is a big one – to build a new mental health care system everyone can access. We’ve built technology that helps people find great therapists with the first software-enabled national network of providers accepting insurance.

1 in 4 people in the US have a treatable mental health condition, but the majority of providers don’t accept insurance, making therapy too expensive for most people. Headway is building a new mental healthcare system that everyone can access by making it easy for therapists to accept insurance and scale their practice.

Headway was founded in 2019. Since then, we’ve grown into a diverse, national network of over 45,000 mental healthcare providers across all 50 states who run their practice on our software and have served over 1 million patients. We’re a Series D company with over $325m in funding from a16z (Andreessen Horowitz), Accel, GV (formerly Google Ventures), Spark Capital, Thrive Capital, Forerunner Ventures and Health Care Service Corporation.

We want your time here to be the most meaningful experience of your career. Join us, and help change mental healthcare for the better.

About The Data Engineering Team

Headway is looking for a Data Engineer to help us get closer to executing our mission: to create access to affordable, quality mental healthcare across the United States. Data plays a critical role in Headway’s mission by empowering business decisions and operations at scale. The Data Engineering team builds the platform on which we process financial data and make business decisions. The data engineering team is partnered with most of the teams across Headway including the finance team, insurance systems team, data analytics, product and data science teams.

As a member of the Data Engineering team, you will be collaborating with others in designing, building and implementing data pipelines that serve the core product and various stakeholders. You will be partnering with the Data Science, Data Analytics and Core Infrastructure functions closely, and together help shape the data landscape for Headway.

As a Data Engineer, You Will


 * Collaborate on the design and improvements of the data infrastructure
 * Partner with product and engineering to advocate best practices and build supporting systems and infrastructure for the various data needs
 * Create data pipelines that stitch together various data sources in order to produce valuable business insights
 * Create real-time data pipelines in collaboration with the Data Science team
   
   

You Will Love This Role If You Have


 * 3+ years of experience in a data engineering role building products, ideally in a fast-paced environment
 * Good foundations in Python and SQL.
 * Experience with Spark, PySpark, DBT, Snowflake and Airflow
 * Knowledge of visualization tools, such as Metabase, Jupyter Notebooks (Python)
 * A knack for simplifying data, expressing information in charts and tables
 * Empathy: you are eager to see the world from your users’ perspectives
 * Energy: you're attracted to ambiguity & are a self-starter. You love to drive the direction of ambiguous projects
 * Motivation: our mission excites you. We are working to solve the biggest problems in mental health care today (access and affordability)
 * Experience with Looker and build Looker ML models is a plus
   
   

Our Interview Process

After you apply to Headway, here are some details of what to expect during the interview process.


 * Initial screen: You’ll connect with someone in recruiting so you can learn more about the team, Headway’s mission and exciting growth, and we can get a better idea of your background.
 * First round: You'll meet with a member of our data engineering team for a data systems interview.
 * Final rounds: You’ll meet several more team members for technical and non-technical interviews and leave with a fuller picture of what it’s like to work at Headway.
 * Reference Calls
 * Offer: Our favorite part of the process! We'll send over all of the details, including specifics on employee equity, and congratulatory messages from excited future team members!
   
   

Compensation And Benefits

Salary information is based on a single salary target per role, per level. Please note, this is not the start of a range:
 * The starting salary for a Data Engineer is $163,500
 * Benefits offered include:
    * Equity Compensation
    * Medical, Dental, and Vision coverage
    * HSA / FSA
    * 401K
    * Work-from-Home Stipend
    * Therapy Reimbursement
    * 16-week parental leave for eligible employees
    * Carrot Fertility annual reimbursement and membership
    * 13 paid holidays each year as well as a Holiday Break during the week between December 25th and December 31st
    * Flexible PTO
    * Employee Assistance Program (EAP)
    * Training and professional development
      

We believe a team's strength is in its people, and we cannot achieve this mission without a team that reflects the diversity of this problem – across race, ethnicity, gender, sexuality, age, national origin, religion, family status, disability, military status, and experience.

Headway is committed to the full inclusion of all qualified individuals. As part of this commitment, Headway will ensure that persons with disabilities are provided with reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or receive other benefits and privileges of employment, please contact talent@findheadway.com

Headway employees work remotely across the US, with the option to work from offices in New York City and San Francisco. Headway participates in E-Verify. To learn more, click here.",Full-time
4143932477,529693.0,Data Engineer,"We believe communication belongs to everyone. We exist to democratize phone service.  TextNow is evolving the way the world connects, and that's because we're made up of people with curious minds who bring an optimistic yet critical lens into the work we do.   We're the largest provider of free phone service in the nation. And we're just getting started.

Join us in our mission to break down barriers to communication and free the flow of conversation for people everywhere.

TextNow is looking for an experienced Data Engineer with hands-on experience designing and developing data platforms. You will own the design, development, and maintenance of TextNow's data platform , enabling us to make effective data-informed decisions. You will be part of cross-functional efforts to build scalable and reliable frameworks that support all of TextNow's business and data products. In this role, you can interact with different functional areas within the business and influence decision-making in a fast-growing mobile communications start-up.  

What You'll Do


 * Own TextNow's data warehouse, pipeline, and integration points between various business systems.  
 * Explore available technologies and develop solutions to build and improve our identity resolution solutions.
 * Design, Develop and support new and existing batch and real-time data pipelines and recommend improvements and modifications.  
 * Manage data to manage our AI/ML data products.  
 * Be a champion of TextNow's data ecosystem by working with engineering and infrastructure to implement data strategy for governance, security, privacy, quality, and retention that will satisfy business policies and requirements.  
 * Communicate strategies and processes around data modeling and architecture to cross-functional groups.  Identify, design, and implement internal process improvements.  
   
   

Who You Are


 * Have 3-8 years of experience working with data warehouse/data lake and ETL architectures, cloud data warehouses (Snowflake), and experience in Python and SQL, preferably at companies with fast-growing and evolving data needs.
 * Have at least 1-2+ years of experience with Airflow, Iceberg, Spark and Flink.
 * Exposure to AWS cloud data/ML services such as EKS, MWAA and Sagemaker.
 * Developed scalable data pipelines using Python/Scala, SQL, and distributed processing frameworks like Spark or Flink.
 * Experience driving technical vision for user identity resolution and data quality in previous roles is preferred.
 * Hands on experience working with building data features using Snowflake, dbt, and Python to power real-time AI/ML inference.
 * Respectfully candid with the ability to initiate and drive projects to completion.
 * Highly organized, structured work approach and dependable.
   
   

More about TextNow...

Our Values


 * Customer Obsessed (We strive to have a deep understanding of our customers)
 * Do Right By Our People (We treat each other with fairness, respect, and integrity)
 * Accept the Challenge (We adopt a ""Yes, We Can"" mindset to achieve ambitious goals)
 * Act Like an Owner (We treat this company like it's our own... because it is!)
 * Give a Damn! (We are deeply commited and passionate about our work and achieving results)
   
   

Benefits, Culture, & More


 * Strong work life blend
 * Flexible work arrangements (wfh, remote, or access to one of our office spaces)
 * Employee Stock Options
 * Unlimited vacation
 * Competitive pay and benefits
 * Parental leave
 * Benefits for both physical and mental well being (wellness credit and L&D credit)
 * We travel a few times a year for various team events, company wide off-sites, and more
   
   

Diversity And Inclusion

At TextNow, our mission is built around inclusion and offering a service for EVERYONE, in an industry that traditionally only caters to the few who have the means to afford it. We believe that diversity of thought and inclusion of others promotes a greater feeling of belonging and higher levels of engagement. We know that if we work together, we can do amazing things, and that our differences are what make our product and company great.

TextNow Candidate Policy

By submitting an application to TextNow, you agree to the collection, use, and disclosure of your personal information in accordance with the TextNow Candidate Policy",Full-time
4113799942,89214964.0,Data Engineer,"Our story

We’re a fast growing, Series A stage healthare AI company building a clinical operating system for MSK practices. We are revenue generating and are looking to carefully expand the team to help us scale to 1,000,000 patients and beyond!

The team is headquartered in NYC with a satellite office in Vancouver, BC. Much of our engineering team is remote - distributed throughout the US and Canada.

We live in Notion docs, Slack channels and Github with weekly meetings over Zoom. Meetings may feature honorary advisors, MedTech execs, and, if we’re lucky, Will’s cat or our Chief Pup Officer.

As Flagler continues to grow, there is a unique opportunity to build the foundations of data and infrastructure to help the product and company reach our full potential. This is where you come in — to design and build reliable, trusted, and timely analytics that accelerate the decision-making process of key product and business functions. You will have a strong impact on the roadmap and growth trajectory of our company.

Key Responsibilities

Databricks Platform Expertise


 * Develop, manage, and optimize data pipelines on the Databricks platform.
 * Debug and troubleshoot Spark applications to ensure reliability and performance.
 * Implement best practices for Spark compute and optimize workloads.
 * Python Development:
 * Write clean, efficient, and reusable Python code using object-oriented programming principles.
 * Design and build APIs to support data integration and application needs.
 * Develop scripts and tools to automate data processing and workflows.
   
   

MongoDB Management


 * Integrate, query, and manage data within MongoDB.
 * Ensure efficient storage and retrieval processes tailored to application requirements.
 * Optimize MongoDB performance for large-scale data handling.
 * Collaboration and Problem Solving:
 * Work closely with data scientists, analysts, and other stakeholders to understand data needs and deliver solutions.
 * Proactively identify and address technical challenges related to data processing and system design.
   
   

Required Qualifications


 * Proven experience working with Databricks and Spark compute.
 * Proficient in Python, including object-oriented programming and API development.
 * Familiarity with NoSQL (MongoDB preferred), including querying, data modeling, and optimization.
 * Strong problem-solving skills and ability to debug and optimize data processing tasks.
 * Experience with large-scale data processing and distributed systems.
   
   

Preferred Qualifications


 * Strong understanding of data architecture, ETL processes, and data warehousing concepts.
 * Knowledge of other big data technologies like Delta Lake, Hadoop, or Kafka.
 * Experience with cloud platforms (e.g., AWS, Azure, or GCP).
 * Familiarity with CI/CD pipelines and version control systems like Git.
   
   

Our values

We spend at least as much time with our co-workers as we do with our closest friends + family; if we intend to do the most important and challenging work of our lives, it’s important that these folks energize us, support us, inspire us, and push us to do our best work.

This is what you can expect of your teammates at Flagler:


 * Persistence + ownership of outcomes: We wear many hats and aren’t afraid to run through walls to solve hard problems.
 * Personal + professional growth: We push ourselves to learn new things and embrace challenges, even if it means that we sometimes fail.
 * Don’t take things personally: We value and react quickly to constructive feedback.
 * Speed is our ally: In the fast-paced world of startups, we understand the value of moving swiftly. We thrive on the adrenaline of working rapidly.
 * Be Right: We are highly detailed oriented and try to be right, a lot.
   
   

Hiring Process

Due to the high volume of applications, we only reach out to candidates selected for interviews. We do not have online leetcode assessments as an initial filter, so we only reach out to very few candidates for initial introduction.

Company Benefits

We'll treat you well. If any other benefits are important to you, we'd love to know


 * Competitive Salary & Meaningful Equity based on experience
 * Unlimited PTO
 * Health, dental, vision
 * 401k
 * Annual team offsite
   
   ",Full-time
4151640775,80446438.0,Software Engineer (all levels),"About Us

Pomelo Care is a multi-disciplinary team of clinicians, engineers and problem solvers who are passionate about improving care for moms and babies. We are transforming outcomes for pregnant people and babies with evidence-based pregnancy and newborn care at scale. Our technology-driven care platform enables us to engage patients early, conduct individualized risk assessments for poor pregnancy outcomes, and deliver coordinated, personalized virtual care throughout pregnancy, NICU stays, and the first postpartum year. We measure ourselves by reductions in preterm births, NICU admissions, c-sections and maternal mortality; we improve outcomes and reduce healthcare spend.

What you'll do

As An Early Member Of Our Engineering Team, You Will Have The Opportunity To Shape The Product, Codebase, And Culture At Pomelo For Years To Come. On Any Given Day, You May


 * Write clean, elegant code to build new features and keep our platform humming
 * Design new systems to enable Pomelo's clinical team to deliver personalized care to an expanding patient population
 * Build a caring mobile experience so pregnant people and new parents feel they have a support team in their pocket
 * Photoshop custom slack emojis to express new feelings that aren't yet part of our library
   
   

Who you are

You're An Enthusiastic And Collaborative Problem-solver Who Would Rather Talk To Your Customer Than Be Handed a Spec. You Have a Nose For Value And Proactively Identify Problems That Have a Big Impact On The Business. You Have a Passion For Using Technology To Effect Real, Tangible Good In The World. In Particular, You


 * Have a bachelors, masters or PhD in computer science or a related field
 * Have at least 3 years of experience shipping high-quality software with languages like Java, C++, Kotlin, C#, Go, Python
 * Have a strong understanding of relational databases
 * Have delivered and maintained software systems all the way to production
 * Enjoy tackling complex problems -- but strive to avoid unnecessary complexity
   
   

We'll be super excited if you:


 * Have experience at an early stage startup
 * Have developed apps using modern front-end frameworks like React, Vue.js, Svelte
 * Have developed distributed data processing systems against heterogeneous data sets
 * Contribute to open source projects
   
   

Why you should join our team

By joining Pomelo, you will get in on the ground floor of a fast-moving, well-funded, and mission-driven startup that always puts the patient first. You will learn, grow and be challenged -- and have fun with your team while doing it.

We strive to create an environment where employees from all backgrounds are respected. We also offer:


 * Competitive healthcare benefits
 * Generous equity compensation
 * Unlimited vacation
 * Membership in the First Round Network (a curated and confidential community with events, guides, thousands of Q&A questions, and opportunities for 1-1 mentorship)
   
   

At Pomelo, we are committed to hiring the best team to improve outcomes for all mothers and babies, regardless of their background. We need diverse perspectives to reflect the diversity of problems we face and the population we serve. We look to hire people from a variety of backgrounds, including but not limited to race, age, sexual orientation, gender identity and expression, national origin, religion, disability, and veteran status.

Our salary ranges are based on paying competitively for our company’s size and industry, and are one part of the total compensation package that also includes equity, benefits, and other opportunities at Pomelo Care. In accordance with New York City, Colorado, California, and other applicable laws, Pomelo Care is required to provide a reasonable estimate of the compensation range for this role. Individual pay decisions are ultimately based on a number of factors, including qualifications for the role, experience level, skillset, geography, and balancing internal equity. Given that this role is open to candidates of different skill levels, determining a salary range is challenging. A reasonable estimate of the current salary range is $135,000 to $230,000. We expect most candidates to fall in the middle of the range.

",Full-time
4066235570,1586.0,Data Engineer,"Description

Data Engineer

Come build the future as a Data Engineer at Amazon, where you will be inspired working along best-in-class inventors and innovators! You will have the opportunity to create meaningful experiences that deliver on the ever-evolving needs of our customers, and your work will impact millions of people around the world.

As an Amazon Data Engineer, you will solve unique and complex problems at a rapid pace, utilizing the latest technologies to create solutions that are highly scalable. You will find that there is an unlimited number of opportunities within Amazon, where developing your career across a wide range of teams is highly supported. We are committed to making your work experience as enjoyable as the experiences you’ll be creating for our customers.

Apply now and you will be eligible for Amazon Data Engineer positions that are based on your preferred location, team, and more. We’re hiring across Amazon Stores in the United States and Canada.

Teams with available positions include, but are not limited to:


 * Consumer Technology: Build new generation features and products for amazon.com, constantly improving the Customer and Seller experience for billions around the globe. Whether building site wide features such as reviews and recommendations, category specific software for the likes of Pharmacy, Electronics, Digital Software and Video Games or seller infrastructure, there are a variety of complex problems to tackle using a range of technologies in the design of your technical solutions.
 * Operations Technology: Shape the future of transportation planning and execution on a global scale, that impacts hundreds of fulfillment centers, thousands of Amazonians, and millions of customers across the world. Your technology will support thousands of operators worldwide to design, build and run the best-in-class Amazon transportation network. We are building intelligent software to make transportation more reliable, faster, and less costly, providing a better and less expensive experience for our customers.
 * Human Resources Technology: Create a seamless experience for millions of Amazonians and/or candidates. Whether supporting technologies for onboarding, time and attendance, compensation, amazon.jobs, or recruiting, you’ll deliver robust feature sets, elegant designs, intuitive user interfaces and systems that make it easy for Amazonians to excel at performing critical business functions.
   
   

About Us

Work/Life Balance

Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth

Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign opportunities based on what will help each team member develop into a better-rounded contributor.

Inclusive Team Culture

Here at Amazon, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Key job responsibilities


 * Design, implement, and support a platform providing secured access to large datasets.
 * Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.
 * Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation.
 * Tune application and query performance using profiling tools and SQL.
 * Analyze and solve problems at their root, stepping back to understand the broader context.
 * Learn and understand a broad range of Amazon’s data resources and know when, how, and which to use and which not to use.
 * Keep up to date with advances in big data technologies and run pilots to design the data architecture to scale with the increased data volume using AWS.
 * Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for datasets.
 * Triage many possible courses of action in a high-ambiguity environment, making use of both quantitative analysis and business judgment.
   
   

Basic Qualifications


 * 3+ years of data engineering experience
 * Proficient in SQL
 * Experience with data modeling, warehousing and building ETL pipelines
 * Experience in at least one modern scripting or programming language, such as Python, Java, Scala, or NodeJS
   
   

Preferred Qualifications


 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
 * Experience with big data technologies such as: Hadoop, Hive, Spark, EMR
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com LLC - A03

Job ID: A2820515",Full-time
4143545389,3015.0,Data Engineer II-R-240296,"Our Purpose

Mastercard powers economies and empowers people in 200+ countries and territories worldwide. Together with our customers, we’re helping build a sustainable economy where everyone can prosper. We support a wide range of digital payments choices, making transactions secure, simple, smart and accessible. Our technology and innovation, partnerships and networks combine to deliver a unique set of products and services that help people, businesses and governments realize their greatest potential.

Title And Summary

Data Engineer II

Overview

Mastercard’s Technical Implementation team is seeking a Data Engineer II to contribute to the data management aspects of client engagements, delivering and other innovative solutions within the Services group. In this role, you will develop robust data pipelines, implement scalable data solutions, and collaborate with cross-functional teams. Additionally, you will help foster a high-performance, collaborative workplace culture. This hybrid position is based in Arlington, VA, requiring three days per week onsite.

Technical Implementation is part of the Services within Mastercard group and one of its fastest-growing organizations. The Services group is responsible for acquiring, engaging, and retaining customers by managing fraud and risk, enhancing cybersecurity, and improving the digital payments experience. We provide value-added services and leverage expertise, data-driven insights, and execution.

100 of the largest corporations in the world use these products and services like Test & Learn™ for Sites, Test & Learn™ for Customers, Mastercard Intelligence Center, and other similar products which employ patented algorithms and workflows to design business experiences and interpret real-world data that evaluate, target, and refine business programs.

Technical Implementation is a core component to these services, managing the data acquisition, integration, and transformation of client provided data within Test & Learn and other platforms for global engagements.

Role


 * Support the design, implementation, and maintenance of enterprise ETL processes for data platforms, for a global client base.
 * Develop scalable and efficient code to process data, ensuring availability and accessibility in a timely manner.
 * Collaborate with senior engineers to address data challenges, contributing to solutions that maintain high data quality.
 * Assist in the data delivery process, working alongside Data Engineers and Analysts to support accurate, high-value data solutions across various clients and industries.
 * Build strong working relationships with team members and clients, contributing to both local and global projects.
 * Learn and apply industry best practices, including version control, code reviews, and data validation, to ensure quality in data processes.
 * Use SQL and other database technologies to help optimize data processing and reduce the time required to handle large data sets.
 * Participate in efforts to automate routine data tasks and streamline processes.
 * Comply with all Mastercard internal policies and adhere to external regulations.
   
   
   

All Abut You


 * Experience as a Data Engineer or in a similar role, with a strong understanding of data engineering concepts and methodologies.
 * Strong knowledge of writing and optimizing SQL queries to retrieve, manipulate, and analyze data efficiently.
 * Experience with Relational Databases (RDBMS), with strong hands-on expertise in Microsoft SQL Server and related technologies.
 * Familiarity with ETL frameworks and the ability to design, implement, and maintain data pipelines.
 * Understanding of data modeling concepts and database design to support scalable data solutions.
 * Familiarity with at least one scripting language (e.g., PowerShell, Python).
 * Ability to analyze and troubleshoot data issues and provide solutions with minimal supervision.
 * Basic knowledge of testing and validating data to ensure accuracy and consistency in data pipelines.
 * Excellent verbal and written communication skills, with the ability to articulate complex ideas clearly and concisely to both technical and non-technical stakeholders.
 * Bachelor's degree in a quantitative discipline such as Engineering, Mathematics, Finance, Business, or a related field. Equivalent practical experience may also be considered.
   
   
   

Mastercard is an inclusive equal opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. In the US or Canada, if you require accommodations or assistance to complete the online application process or during the recruitment process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.

Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:


 * Abide by Mastercard’s security policies and practices;
 * Ensure the confidentiality and integrity of the information being accessed;
 * Report any suspected information security violation or breach, and
 * Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.
   
   
   

In line with Mastercard’s total compensation philosophy and assuming that the job will be performed in the US, the successful candidate will be offered a competitive base salary based on location, experience and other qualifications for the role and may be eligible for an annual bonus or commissions depending on the role. Mastercard benefits for full time (and certain part time) employees generally include: insurance (including medical, prescription drug, dental, vision, disability, life insurance), flexible spending account and health savings account, paid leaves (including 16 weeks new parent leave, up to 20 paid days bereavement leave), 10 annual paid sick days, 10 or more annual paid vacation days based on level, 5 personal days, 10 annual paid U.S. observed holidays, 401k with a best-in-class company match, deferred compensation for eligible roles, fitness reimbursement or on-site fitness facilities, eligibility for tuition reimbursement, gender-inclusive benefits and many more.

Pay Ranges

Arlington, Virginia: $106,000 - $169,000 USD

R-240296

",Full-time
4143818260,18445891.0,Data Engineer,"Oshi Health is revolutionizing GI care with a digital clinic model that provides easy, convenient access to an integrated and multidisciplinary care team that takes a holistic approach to diagnosing, managing and treating digestive health conditions. Oshi Health has been recognized by Modern Healthcare and Builtin as the recipient of Best Place to Work awards. This recognition highlights our dedication to creating a workplace environment that prioritizes our team, fosters inclusivity, and is committed to our mission.

We take time to get to know each patient, develop a personalized, whole-person care plan that includes identification of symptom triggers and prescription of evidence-based interventions, including medications, dietary changes, and mental health support. Our care is delivered virtually through our app, via secure messaging and telehealth visits. When in-person diagnostics or procedures are needed, we take a concierge approach and coordinate access, care and follow up with local providers. For more information, visit us at: www.oshihealth.com

""Oshi Health will never contact job candidates via text message or any other messaging platform including WhatsApp, Signal, and Telegram. All official correspondence will occur through email. We will never ask you to share bank account information, cash a check from us, or purchase software or equipment as part of your interview or hiring process. If you have concerns, please reach out to careers@oshihealth.com, and we'll confirm whether you're engaging with one of our Oshi teammates!""

Data Engineer

Are you a highly-motivated Data Engineer looking to make a bigger impact at an organization that changes lives?

Do you thrive in a rapidly evolving, fast-paced environment requiring creativity, resourcefulness, high energy and an ability to adapt quickly?

Are you passionate about healthcare and looking to create a revolutionary new approach to digestive healthcare with a radically better patient experience?

If so, you could be a perfect fit for our team of professionals who share a mission to eliminate the impact of digestive health conditions through redesigned GI care that patients love

The Role

Oshi's Engineering team is seeking a Data Engineer to lead and manage the data operations of our increasingly complex care platform. At Oshi, data is central to all our operations across the organization. In this role, you will work with our data engineers to provide technical solutions and evolve our data platform and data ingestion processes. This is a hands-on role where you will also be responsible for implementing the solutions you design.

What you'll do:


 * Contribute to Oshi's existing data warehouse, supporting product, clinical, and strategy teams in developing underlying data models.
 * Collaborate with marketing and growth teams to build data pipelines and processes that support member marketing, analytic, and outreach efforts.
 * Develop reusable queries, data quality tests, and insights for reporting and backend systems.
 * Design and implement complex data models for various use cases, including real-time analytics, data pipelines, and business intelligence.
 * Work across the data stack, including CI/CD pipelines for data workflows, infrastructure as code, and platform integrations.
 * Support, expand, and help standardize data governance structures for handling sensitive client data.
 * Ensure the integrity and protection of data across Oshi's systems.
   
   

Who you are:


 * Hold a BS/BA degree in Computer Science, Math, Physics, or a related field, or have equivalent experience in a relevant area.
 * An experienced data engineer with experience in startup environments.
 * Have 3+ years of data development experience.
 * You can understand a complex requirement, componentize it, and develop a scalable solution.
 * Advanced SQL chops and knowledge of data warehousing standards.
 * Comfortable in one or more programming languages (e.g. golang/python) and efficient data transport/manipulation.
 * Familiar with dbt (Data Build Tool) for managing warehouse transformations.
 * Knowledge and experience with cloud environments and associated tooling is a plus.
 * Experience with FHIR standards, HL7, or other healthcare data interchange formats is a plus.
 * Knowledge about data security and HIPAA compliance, a plus.
   
   

We make healthcare more equitable and accessible:


 * Mission-driven organization focused on innovative digestive care
 * Thrive on diversity with monthly DEIB discussions, activities, and more
 * Virtual-first culture: Work from home anywhere in the US
 * Live our core values: Own the outcome, Do the right thing, Be direct and open, Learn and improve, Team, Thrive on diversity
   
   

We take care of our people:


 * Competitive compensation and meaningful equity
 * Employer-sponsored medical, dental and vision plans
 * Access to a ""Life Concierge"" through Overalls, because we know life happens
 * Tailored professional development opportunities to learn and grow
   
   

We rest, recharge and re-energize:


 * Unlimited paid time off — take what you need, when you need it
 * 13 paid company holidays to power down
 * Team events, such as virtual cooking classes, games, and more
 * Recognition of professional and personal accomplishments
   
   

Oshi Health's Core Values:

1. Own the Outcome


 * Do the Right Thing
 * Be Direct & Open
 * Learn & Improve
 * TEAM - Together Everyone Achieves More
 * Thrive on Diversity
   
   

Oshi Health is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

At Oshi, we determine salary ranges using market benchmarking and a geo-neutral compensation philosophy—your pay is based on the role and level, not your location.We believe in offering competitive compensation that reflects your unique skills, experience, and qualifications. While the salary range provided outlines the potential earning scope for this role, final offers are tailored to each candidate's expertise, contributions, and alignment with internal equity among peers in similar roles. Oshi utilizes the entire compensation range, and we expect candidates offered positions with our company to fall widely throughout the range.The candidate we hire may have more experience (or less) than what is outlined in this job description. If that's the case, an updated level and salary range will be shared during the hiring process.

Compensation Range

$110,000—$150,000 USD

Note: This job description serves as a general overview and may be subject to change based on organizational needs and requirements.

Oshi Health is an equal opportunity employer that is committed to creating a diverse work environment. To do that, we champion a workplace where each and every person is treated with dignity and respect and is valued for their unique perspective and contributions.

Oshi Health's policy is to maintain a working environment that encourages mutual respect, promotes harmonious and congenial relationships between employees, and is free from all forms of discrimination and harassment of any employee (or applicant for employment or service provider) by anyone, including supervisors, co-workers, vendors, or clients. Harassment and discrimination in any manner or form is expressly prohibited. There is no tolerance for discrimination or unequal treatment of any kind on the basis of race, color, religion, creed, gender, sex, sexual orientation, gender identity or expression, pregnancy, sexual and reproductive health decisions, national origin, age, disability, genetic information, marital status or civil partnership/union status, familial status, military or veteran status, predisposition or carrier status, domestic violence victim status, alienage or citizenship status, unemployment status, sexual violence or stalking victim status, caregiver status, or any other characteristic protected by law.

This practice applies to all terms, conditions and privileges of employment including, but not limited to, recruitment, selection, promotion, demotion, transfer, layoff, rehire, termination of employment, development and training, compensation, benefits and retirement.

For more information, visit us at www.oshihealth.com",Full-time
4144303905,1586.0,"Data Engineer, WWASFT","Description

WorldWide Amazon Stores FinTech (WWASFT) team is looking for an outstanding Data Engineer who is data-driven, uncompromisingly detail oriented, smart, efficient, and driven to help our business succeed. You have passion for technology. You are keen to leverage existing skills while trying new approaches. You are not tool-centric; you determine what technology works best for the problem at hand and apply it accordingly. You can explain complex concepts to your non-technical customers in simple terms.

As a Data Engineer, you will be working in one of the world's largest and most complex data warehouse environments. You will design, implement and support scalable data infrastructure solutions to integrate with multi heterogeneous data sources, aggregate and retrieve data in a fast and safe mode, curate data that can be used in reporting, analysis, machine learning models and ad-hoc data requests. You will be exposed to cutting edge AWS big data technologies. You should have excellent business and communication skills to be able to work with business owners and Tech leaders to gather infrastructure requirements, design data infrastructure, build up data pipelines and data-sets to meet business needs. You stay abreast of emerging technologies, investigating and implementing where appropriate.

Key job responsibilities


 * Design and develop the pipelines required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, Python and AWS big data technologies.
 * Oversee and continually improve production operations, including optimizing data delivery, re-designing infrastructure for greater scalability, code deployments, bug fixes and overall release management and coordination.
 * Establish and maintain best practices for the design, development and support of data integration solutions, including documentation.
 * Work closely with Product teams, Finance Teams, Software developers and Business Intelligence Engineer to explore new data sources and deliver the data.
 * Able to read, write, and debug data processing and orchestration code written Python/Scala etc following best coding standards (e.g. version controlled, code reviewed, etc.)
   
   

Basic Qualifications


 * 3+ years of data engineering experience
 * Experience with data modeling, warehousing and building ETL pipelines
 * Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets
 * Experience in at least one modern scripting or programming language, such as Python, Java, Scala, or NodeJS
   
   

Preferred Qualifications


 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
 * Experience working on and delivering end to end projects independently
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com Services LLC

Job ID: A2839788",Full-time
4143668384,1269.0,Associate Data Engineer,"Job Description

Document Ingestion is a top priority for Chubb. We are looking for an innovative, results-oriented Data Engineer who has an ambition to contribute to the success of our Document Ingestion program. The successful candidate will be self-motivated, creative, and they will be able to independently contribute to our major strategic initiative.

You will be responsible for contributing to the development and launch of solution across the Domain and/or Platform, supporting our overall strategy by helping define product features, helping build system architecture, and spearheading the best practices that enable a quality product.

The candidate is expected to work in a Agile development environment, building high quality software that adds business value to the organization. The candidate with be part of a geographically dispersed organization working towards a common goal.

The ideal candidate should have Knowledge of object-oriented programming, analysis, design and development (OOA/OOD) and the Python and strong data structures understanding, with more than 3 years of experience.

Activities


 * Contribute to the development and launch of solutions across the Domain and/or Platform, assisting in defining product features, building system architecture, and championing best practices for a quality product.
 * Collaborate with business stakeholders to translate their requirements into technical stories and software solutions.
 * Participate in solutioning and estimation activities for upcoming opportunities.
 * Work with a team of software developers to build high-quality software solutions that align with architecture guidelines.
 * Support technical solutioning and troubleshooting, collaborating closely with Tech Leads and Squads.
 * Collaborate with Platform teams to improve pluggable and reusable ingestion components.
 * Assist in the development of an analysis and design methodology, ensuring an agile implementation process that adheres to established standards and release cycles.
   
   

Qualifications


 * 3+ years of software engineering or data engineering, technology or insurance domain experience or a combination of both.
 * Education in business, data, engineering, mathematics or information management
 * Strong experience with Python, understanding of Java based microservices.
 * SOAP web services, REST APIs, Kafka, MQ, Git, TFS and/or DevOps tools
 * Unit and integration testing using Mockito.
 * Knowledge on CICD Jenkins pipeline and JIRA and experience in Version Control tools like GIT/SVN
 * Experience developing software/automation solutions using Python.
 * Experience with Cloud Computing, Azure, AKS, Python and Microservices
 * Good SQL and familiarity with relational databases
 * Exposure to DevOps, CI/CD (Jenkins, Jira etc.)
 * Comfort in a dynamic and fast-moving work environment.
 * Excellent verbal, written & interpersonal communication skills.
 * Proven ability as a structured, logical thinker
 * Insurance domain or financial services in general
   
   

The pay range for the role is $70,400 to $119,600. The specific offer will depend on an applicant’s skills and other factors. This role may also be eligible to participate in a discretionary annual incentive program.  Chubb offers a comprehensive benefits package, more details on which can be found on our careers website .  The disclosed pay range estimate may be adjusted for the applicable geographic differential for the location in which the position is filled.

About Us

Chubb is a world leader in insurance. With operations in 54 countries, Chubb provides commercial and personal property and casualty insurance, personal accident and supplemental health insurance, reinsurance, and life insurance to a diverse group of clients. The company is distinguished by its extensive product and service offerings, broad distribution capabilities, exceptional financial strength, underwriting excellence, superior claims handling expertise and local operations globally.

At Chubb, we are committed to equal employment opportunity and compliance with all laws and regulations pertaining to it. Our policy is to provide employment, training, compensation, promotion, and other conditions or opportunities of employment, without regard to race, color, religious creed, sex, gender, gender identity, gender expression, sexual orientation, marital status, national origin, ancestry, mental and physical disability, medical condition, genetic information, military and veteran status, age, and pregnancy or any other characteristic protected by law. Performance and qualifications are the only basis upon which we hire, assign, promote, compensate, develop and retain employees. Chubb prohibits all unlawful discrimination, harassment and retaliation against any individual who reports discrimination or harassment.",Full-time
4148834197,18059273.0,Data Engineer: Big Data,"About Us

Energize your career with one of Information Technology’s fastest growing companies.

You dream of a great career with a great company – where you can make an impact and help people. We dream of giving you the opportunity to do just this. And with the incredible growth of our business, it’s a dream that definitely can come true. Already one of the world’s leading IT companies, MNJ SOFTWARE is restlessly pursuing new ways to operate our service centers, improve our service levels and help people lead healthier lives. We live for the opportunity to make a difference and right now, we are living it up.

MNJ SOFTWARE is an IT services, business solutions and outsourcing organization that delivers real results to global businesses, ensuring a level of certainty no other firm can match.

MNJ SOFTWARE offers a consulting-led, integrated portfolio of IT and IT-enabled services delivered through its unique Global Network Delivery Model, recognized as the benchmark of excellence in software development.

MNJ SOFTWARE service offerings span business and technology consulting, application services, systems integration, product engineering, custom software development, maintenance, re-engineering, independent testing and validation services, IT infrastructure services and business process outsourcing.

MNJ SOFTWARE takes pride in building strategic long-term client relationships.

MNJ SOFTWARE is only hiring those authorized to work in the India and unable to provide visa sponsorship at this time.

Job Details

MNJ SOFTWARE is looking for talented individuals who are interested to be part of ""Our"" journey to build a best-in-class organization, driving to deliver real results to global businesses, ensuring a level of certainty no other firm can match.

Data Engineer: Big Data at MNJ SOFTWARE, you will participate in design, development and implementation of architectural deliverables of custom projects and products of MNJ SOFTWARE. The role includes working closely with lead, testers, customers, project/product managers and designers.

JobID

J0096

Title

Data Engineer: Big Data

Experience

3-6 yrs

Job Type

Permanent / Contract [Depends on Project Needs or C2H]

Position Type

Full time [Monday – Friday]. Employees are required to have flexibility to work any of our 9-hour shift schedules during our normal business hours of (6am - 10pm IST) or (6pm to 6am IST). It may be necessary, given the business need, to work occasional overtime [unpaid].

Qualification

ME/M.TECH/BE/B.TECH/MCA/M.Sc(IT) etc

Technical/Functional Skills


 * Strong knowledge of Go programming language, paradigms, constructs and idioms.
 * Knowledge of Common Goroutine and Channel patterns.
 * Experience with the full site of Go Frameworks and Tools.
 * Knowledge/Experience of any other backend language would be a plus.
 * Knowledge/Experience into Gin/Gonic framework would be a plus.
 * Good Communication Skills Required.
   
   

Roles & Responsibilities


 * Responsible to Longest data from Files, Streams and Databases.
 * Process the data with Spark, Scala, Kafka, Hive and Scoop.
 * Develops Hadoop applications using Horton Works or other Hadoop distribution.
 * Experienced with pulling data from various Database Systems, Network Elements and Unstructured text from web.
 * Social Media Sites and other Domain Specific file.
 * Develop efficient software code for multiple use cases leveraging Python and Big Data technologies for various use cases built on the platform.
 * Provide high operational excellence guaranteeing high availability and platform stability.
 * Implement scalable solutions to meet the Ever Increasing Data Volumes, using big Data/Cloud technologies Apache Spark, Kafka, Any Cloud computing etc.
   
   

Personal Attributes


 * Must be Analytical and possess good problem-solving capabilities
 * Independent thinker
   
   

Process

Aptitude Tests, Technical Tests, Interviews, Medical Health Checkup.

Reimbursement

Best in Industry

Certification

Optional

Location

Remote (Work From Home)

Competencies

Professionalism – Knowledge of general office and administrative support including MNJ SOFTWARE administrative policies, processes and procedures. Demonstrates professional competence and mastery of subject matter; is conscientious and efficient in meeting commitments, observing deadlines and achieving results; remains calm in stressful situations. Commitment to implementing the goal of gender equality by ensuring equal participation and full involvement of women and men in all aspects of work.

Teamwork – Works collaboratively with colleagues to achieve organizational goals; solicits input by genuinely valuing others’ ideas and expertise; is willing to learn from others; places team agenda before personal agenda; shares credit for team accomplishments and accepts joint responsibility for team shortcomings; ability to work beyond normal hours.

Planning and Organizing – Develops clear goals that are consistent with agreed strategies; identifies priority activities and assignments; adjusts priorities as required; allocates appropriate amount of time and resources for completing work; foresees risks and allows for contingencies when planning; uses time efficiently.

Assessment

Evaluation of qualified candidates may include an assessment exercise which may be followed by competency-based interview.

Languages

English is the working language of this above stated post. For this post, fluency in oral and written English is required.

Note

We're an Equal Opportunity Employer: You will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability.

No Fee

THE MNJ SOFTWARE DOES NOT CHARGE A FEE AT ANY STAGE OF THE RECRUITMENT PROCESS (APPLICATION, INTERVIEW MEETING, PROCESSING, OR TRAINING).

General Considerations

According to policies and processes of MNJ SOFTWARE, the paramount consideration in the employment of the staff is the necessity of securing the highest standards of efficiency, competence, and integrity. Candidates will not be considered for employment with the MNJ SOFTWARE if they have committed violations of national / international human rights law, violations of national / international humanitarian law, sexual exploitation, sexual abuse, or sexual harassment, or if there are reasonable grounds to believe that they have been involved in the commission of any of these acts. The term “sexual exploitation” means any actual or attempted abuse of a position of vulnerability, differential power, or trust, for sexual purposes, including, but not limited to, profiting monetarily, socially or politically from the sexual exploitation of another. The term “sexual abuse” means the actual or threatened physical intrusion of a sexual nature, whether by force or under unequal or coercive conditions. The term “sexual harassment” means any unwelcome conduct of a sexual nature that might reasonably be expected or be perceived to cause offence or humiliation, when such conduct interferes with work, is made a condition of employment or creates an intimidating, hostile or offensive work environment, and when the gravity of the conduct warrants the termination of the perpetrator’s working relationship. Candidates who have committed crimes other than minor traffic offences may not be considered for employment.

Due regard will be paid to the importance of recruiting the staff on as wide a geographical basis as possible. The MNJ SOFTWARE places no restrictions on the eligibility of men and women to participate in any capacity and under conditions of equality in its principal and subsidiary organs. The MNJ SOFTWARE OFFICE is a non-smoking environment.

The paramount consideration in the appointment, transfer, or promotion of staff shall be the necessity of securing the highest standards of efficiency, competence, and integrity. By accepting an offer of appointment, MNJ SOFTWARE staff members are subject to the authority of the Managers and assignment by him or her to any activities or offices of the MNJ SOFTWARE in accordance with staff regulation In this context, all internationally recruited staff members shall be required to move periodically to discharge new functions within or across duty stations under conditions established by the MNJ SOFTWARE.

The evaluation of applicants will be conducted on the basis of the information submitted in the application according to the evaluation criteria of the job opening and the applicable internal legislations of the MNJ SOFTWARE, the Staff Regulations and Rules, administrative issuances and guidelines. Applicants must provide complete and accurate information pertaining to their personal profile and qualifications according to the instructions provided in inspira to be considered for the current job opening. No amendment, addition, deletion, revision or modification shall be made to applications that have been submitted. Candidates under serious consideration for selection will be subject to reference checks to verify the information provided in the application.

Openings

Apply

Add to Cart",Contract
4105249872,1586.0,Data Engineer,"Description

Come build the future as a Data Engineer at Amazon, where you will be inspired working along best-in-class inventors and innovators! You will have the opportunity to create meaningful experiences that deliver on the ever-evolving needs of our customers, and your work will impact millions of people around the world.

As an Amazon Data Engineer, you will solve unique and complex problems at a rapid pace, utilizing the latest technologies to create solutions that are highly scalable. You will find that there is an unlimited number of opportunities within Amazon, where developing your career across a wide range of teams is highly supported. We are committed to making your work experience as enjoyable as the experiences you’ll be creating for our customers.

Apply now and you will be eligible for Amazon Data Engineer positions that are based on your preferred location, team, and more. We’re hiring across Amazon Stores in the United States and Canada.

Teams with available positions include, but are not limited to:


 * Consumer Technology: Build new generation features and products for amazon.com, constantly improving the Customer and Seller experience for billions around the globe. Whether building site wide features such as reviews and recommendations, category specific software for the likes of Pharmacy, Electronics, Digital Software and Video Games or seller infrastructure, there are a variety of complex problems to tackle using a range of technologies in the design of your technical solutions.
 * Operations Technology: Shape the future of transportation planning and execution on a global scale, that impacts hundreds of fulfillment centers, thousands of Amazonians, and millions of customers across the world. Your technology will support thousands of operators worldwide to design, build and run the best-in-class Amazon transportation network. We are building intelligent software to make transportation more reliable, faster, and less costly, providing a better and less expensive experience for our customers.
 * Human Resources Technology: Create a seamless experience for millions of Amazonians and/or candidates. Whether supporting technologies for onboarding, time and attendance, compensation, amazon.jobs, or recruiting, you’ll deliver robust feature sets, elegant designs, intuitive user interfaces and systems that make it easy for Amazonians to excel at performing critical business functions.
   
   

Key job responsibilities

Design, implement and support an analytical data infrastructure using AWS technologies

Build robust and scalable data integration (ETL) pipelines using SQL, and AWS data storage technologies like Aurora, Red Shift etc.

Design and develop Analytics applications using modern scripting languages (Python, R, PHP, etc) supporting critical business functions.

Gather business and functional requirements and translate these requirements into robust, scalable, operable solutions with a flexible and adaptable data architecture.

Lead architecture design and implementation of next generation BI solution

Continually improve ongoing reporting and analysis processes, automating or simplifying self-service modeling and production support for customers.

Basic Qualifications


 * 1+ years of data engineering experience
 * Experience with data modeling, warehousing and building ETL pipelines
 * Experience with one or more query language (e.g., SQL, PL/SQL, DDL, MDX, HiveQL, SparkSQL, Scala)
 * Experience with one or more scripting language (e.g., Python, KornShell)
   
   

Preferred Qualifications


 * Experience with big data technologies such as: Hadoop, Hive, Spark, EMR
 * Experience with any ETL tool like, Informatica, ODI, SSIS, BODI, Datastage, etc.
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $91,200/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com Services LLC

Job ID: A2804399",Full-time
4071353896,2751451.0,Data Engineer,"Renton WA ( Day 1 Onsite)

Job Functions / Responsibilities


 * Build and document automated data pipelines from a wide range of data sources with an emphasis on automation and scale
 * Develop highly available applications and APIs to support near-real-time integrations using an AWS-based technology stack
 * Ensure product and technical features are delivered to spec and on-time in a DevOps fashion
 * Contribute to overall architecture, framework, and design patterns to store and process high data volumes
 * Develop solutions to measure, improve, and monitor data quality based on business requirements
 * Design and implement reporting and analytics feature in collaboration with product owners, reporting analysts / data analysts, and business partners within an Agile / Scrum methodology
 * Proactively support product health by building solutions that are automated, scalable, and sustainable – be relentlessly focused on minimizing defects and technical debt
 * Provide post-implementation production support for data pipeline
   
   

Qualifications


 * Bachelors' degree in Computer Science, Informatics, or a related field required
 * Masters’ degree in Computer Science preferred
 * 3+ years of experience in a data engineering role
 * 2+ years of experience with AWS and related services (e.g., EC2, S3, SNS, Lambda, IAM, Snowflake)
 * Hands-on experience with ETL tools and techniques (Desirable)
 * Basic proficiency with a dialect of ANSI SQL, APIs, and Python
 * Knowledge of and experience with RDBMS platforms, such as MS SQL Server, MySQL, NoSQL, Postgres",Full-time
4148415800,3240627.0,Freelance Data Engineer,"Company Description

At Saatchi we believe in creating ideas that can live anywhere. And we believe that when we work as a team, nothing is impossible. We strive to bring out the best in each other and in ourselves and expect applicants to understand the value of close collaboration. We also believe that creating transformational work requires initiative, an entrepreneurial spirit and a bold commitment to achieving measurable results and business success for the Clients we service.

Saatchi & Saatchi currently maintains a hybrid work policy to work in-office three days per week and remotely the other two days each week.

Overview

As a Freelance Data Engineer, you will be responsible for building the infrastructure to leverage key data sources.

Success for this position is measured by the ability to automate data processes and ensure flawless execution, maintain the accuracy and consistency of data, innovate processes and teams via industry changes and new tools, deliver high-quality reporting in a timely fashion and with little to no supervision, and present the material both internally and externally.

An ideal candidate will have hands-on experience working with ETL technologies, data visualization and reporting technologies (Tableau), and be proficient in driving insights from large complex data sets.

Project Scope


 * Initial setup: Estimated 3-4 months
 * Potential ongoing maintenance and consultation
   
   

Responsibilities

Roles and Responsibilities include:


 * Design and implement scalable data architecture for both clickstream and survey data
 * Create efficient ETL/ELT pipelines with proper monitoring and error handling
 * Build aggregated tables from raw clickstream data optimized for specific use cases
 * Implement survey data standardization logic while maintaining flexibility for survey-specific variations
 * Set up proper data governance and access controls for cross-department usage
 * Provide thorough documentation and knowledge transfer
   
   

Qualifications

Ideal candidate experience should include:


 * Strong experience with data warehouse design and implementation
 * Expertise in building ETL/ELT pipelines for large-scale data
 * Experience with clickstream data processing and optimization
 * Proficiency with SQL and at least one programming language (Python preferred)
 * Experience with data modeling and schema design
 * Ability to translate between technical and business requirements
 * Experience working with marketing/advertising data
 * Strong communication skills and ability to surface technical decisions that impact business outcomes
 * Experience working with survey data and understanding of its nuances
 * Proactive approach to gathering business context and requirements
   
   

Additional Information

Our Publicis Groupe motto “Viva La Différence” means we’re better together, and we believe that our differences make us stronger. It means we honor and celebrate all identities, across all facets of intersectionality, and it underpins all that we do as an organization. We are focused on fostering belonging and creating equitable & inclusive experiences for all talent.

Publicis Groupe provides robust and inclusive benefit programs and policies to support the evolving and diverse needs of our talent and enable every person to grow and thrive. Our benefits package includes medical coverage, dental, vision, disability, 401K, as well as parental and family care leave, family forming assistance, tuition reimbursement, and flexible time off.

If you require accommodation or assistance with the application or onboarding process specifically, please contact USMSTACompliance@publicis.com. All your information will be kept confidential according to EEO guidelines.

Compensation Range: $75 - $85/hourly rate. This is the pay range the Company believes it will pay for this position at the time of this posting. Consistent with applicable law, compensation will be determined based on the skills, qualifications, and experience of the applicant along with the requirements of the position, and the Company reserves the right to modify this pay range at any time. Temporary roles may be eligible to participate in our freelancer/temporary employee medical plan through a third-party benefits administration system once certain criteria have been met. Temporary roles may also qualify for participation in our 401(k) plan after eligibility criteria have been met. For regular roles, the Company will offer medical coverage, dental, vision, disability, 401k, and paid time off. The Company anticipates the application deadline for this job posting will be February 28, 2025.",Temporary
4045409547,66321745.0,junior Data Engineer,"SYNERGISTIC wants every candidate to know we are always here to support your efforts. Indeed engagement is a priority for all SYNERGISTICIT Employees. No matter what issue you are facing, either it's a job search or upskilling your It portfolio, assistance in cracking interviews or anything, you can always count on a member of SynergisticIT to be there for you.

We at Synergistic it understand the problem and that's why for the past 10 years we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, bankofamerica, visa, etc to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, IT enthusiasts, Python/Java developers, Data analysts/ Data Scientists.

Who Should Apply Recent IT Graduates looking to make their careers in IT Industry Candidates having basic knowledge or with one or two years of experience in Data Science

Candidates looking to upskill/enhance their IT skills.

Candidates who are serious about their future in the IT Industry and have set big goals for themselves.

Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio.

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT,Graduation with Statistics or Mathematics.
 * Highly motivated, self-learner, and technically inquisitive
 * understanding of the software development life cycle
 * Excellent written and verbal communication skills
   
   

No third party candidates or c2c candidates

To apply for this position, please apply to the posting

No phone calls please . Shortlisted candidates would be reached out

Regards,

Prakash G

Talent Acuisition Manager

Phone:(151)0989-4911

Email:Prakash@synergisticit.com

Website : https://[www.synergisticit.com]www.synergisticit.com

39141 Civic Centre Dr, Fremont, CA

94539, United States",Full-time
4127696196,17981957.0,Data Engineer,"Two Chairs is building a new kind of mental health system based on the idea that the status quo isn’t good enough. Industry-best clinician experiences, better client outcomes, groundbreaking innovation, and access to the highest quality care are how we’ll raise the bar for the entire industry. With that, we're excited and honored to have been recognized as a 2024 Great Place to Work, 2024 Fortune Best Workplaces in the Bay Area, and 2023 San Francisco Business Times Bay Area Best Places to Work.

Diversity, equity, and inclusion are the principles guiding how we build our business and teams. We encourage interested candidates from diverse backgrounds to apply even if they don't think they meet every expectation of the role.

About The Role

As a Data Engineer, you'll play a key role in building scalable, reliable, and innovative data pipelines and data models that support our mission. You'll collaborate with stakeholders from Data Science, Product, Clinical Operations, and beyond to ensure the delivery of high-quality data through analytics engineering and data pipeline development, helping our operators, clinicians, and clients in their day-to-day.

You'll be responsible for ensuring Two Chairs’ data ecosystem serves quality data to inform decision making and enable great product experiences.

Core Areas of Responsibility


 * Build and maintain reliable data pipelines, working closely with Data Scientists, Data Engineers, and Backend engineers to ensure proper data movement and alignment
 * Implement monitoring, alerting, and data quality checks to ensure data integrity across key pipelines
 * Partner with people across the company (Product, Finance, Business Development, Operations, Clinical Care) to understand and solve data needs
 * Optimize query performance and manage costs for our BigQuery environment
 * Create and maintain API integrations to support data ingestion needs
 * Automate common data team tasks through notebooks and APIs (e.g. Looker)
 * Build data models, documentation, and tools to help data consumers confidently run queries and create dashboards
 * Learn and work within our established data architecture, suggesting improvements as you gain experience
   
   

Impact and Success Indicators

Where you'll make an impact in the first 90 days:


 * Gain a solid understanding of our existing data pipelines and tools
 * Successfully augment and maintain data pipelines
 * Learn our monitoring systems and respond effectively to alerts
 * Participate actively in sprint planning, standups, and retrospective meetings
 * Complete projects with support from senior team members
   
   

Where you'll make an impact in the first year:


 * Own end-to-end pipeline development for moderate complexity data projects
 * Build robust monitoring and data quality checks for key data assets
 * Create clear documentation parts of the data stack that you maintain
 * Develop strong working relationships with other data teammates and data consumers
 * Identify and implement optimization opportunities in existing pipelines
 * Collaborate with data scientists on new data sets for new products for clients and clinicians
   
   

We’re looking for someone with:


 * 2-4 years of hands-on experience with data pipelines and ETL processes
 * Experience with cloud platforms (preferably GCP) and data warehouses (preferably BigQuery)
 * Working knowledge of Python, SQL, and DBT or similar data modeling frameworks for data manipulation and pipeline development
 * Familiarity with data quality monitoring and alerting practices
 * Strong problem-solving skills and attention to detail
 * Ability to work collaboratively with engineers and non-technical teammates
 * Enthusiasm for learning and growing in a fast-paced environment
   
   

Compensation & Benefits

The salary range for this full-time, exempt role is $162,000 to $180,000. The final offer is dependent on qualifications and experience.

In addition, we offer perks and benefits that support the health and well-being of our teams, including:

Additional perks and benefits:


 * Equity in a high-growth start-up
 * Paid time off, including nine paid holidays and an additional Winter Office Closure from Christmas Day (Observed) through New Year's Day
 * Comprehensive medical, dental, and vision coverage
 * One-time $200 Work from Home reimbursement
 * 401(k) Retirement savings options
 * Annual $1,000 Productivity & Wellness Stipend to support your personal and professional goals
 * Annual $500 subsidized company contribution to your healthcare FSA or HSA
 * Paid parental leave
   
   

Outreach Notice to Applicants

We are thrilled that you’re interested in joining our team! To ensure a consistent and equitable hiring process for all candidates, we kindly ask that you refrain from reaching out to current employees regarding the role, your application, or the interview process. Our talent acquisition team is committed to carefully reviewing all applications and will reach out directly if they decide to move forward.

All applicants must be authorized to work for ANY employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time.",Full-time
3998840084,1431.0,Data Engineer,"Overview

PepsiCo operates in an environment undergoing immense and rapid change. Big-data and digital technologies are driving business transformation that is unlocking new capabilities and business innovations in areas like eCommerce, mobile experiences and IoT. The key to winning in these areas is being able to leverage enterprise data foundations built on PepsiCo’s global business scale to enable business insights, advanced analytics and new product development. PepsiCo’s Enterprise Data Operations (EDO) team is tasked with the responsibility of developing quality data collection processes, maintaining the integrity of our data foundations and enabling business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.

What PepsiCo Enterprise Data Operations (EDO) does:


 * Maintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company
 * Responsible for day-to-day data collection, transportation, maintenance/curation and access to the PepsiCo corporate data asset
 * Work cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders
 * Increase awareness about available data and democratize access to it across the company
   
   

As a member of the data engineering team, you will be the key technical expert developing and overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be an empowered member of a team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems.

Responsibilities


 * Active contributor to code development in projects and services.
 * Manage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products.
 * Build and own the automation and monitoring frameworks that captures metrics and operational KPIs for data pipeline quality and performance.
 * Responsible for implementing best practices around systems integration, security, performance and data management.
 * Empower the business by creating value through the increased adoption of data, data science and business intelligence landscape.
 * Collaborate with internal clients (data science and product teams) to drive solutioning and POC discussions.
 * Develop and optimize procedures to “productionalize” data science models.
 * Define and manage SLA’s for data products and processes running in production.
 * Support large-scale experimentation done by data scientists.
 * Prototype new approaches and build solutions at scale.
 * Research in state-of-the-art methodologies.
 * Create documentation for learnings and knowledge transfer.
 * Create and audit reusable packages or libraries.
   
   

Compensation & Benefits:


 * The expected compensation range for this position is between $100,000 - $167,500 based on a full-time schedule.
 * Location, confirmed job-related skills and experience will be considered in setting actual starting salary.
 * Bonus based on performance and eligibility; target payout is 8% of annual salary paid out annually.
 * Paid time off subject to eligibility, including paid parental leave, vacation, sick, and bereavement.
 * In addition to salary, PepsiCo offers a comprehensive benefits package to support our employees and their families, subject to elections and eligibility: Medical, Dental, Vision, Disability, Health and Dependent Care Reimbursement Accounts, Employee Assistance Program (EAP), Insurance (Accident, Group Legal, Life), Defined Contribution Retirement Plan.
   
   

Qualifications


 * 4+ years of overall technology experience that includes at least 3+ years of hands-on software development, data engineering, and systems architecture.
 * 3+ years of experience with Data Lake Infrastructure, Data Warehousing, and Data Analytics tools.
 * 3+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.).
 * 2+ years in cloud data engineering experience in Azure
 * Experience with Azure Data Factory, Azure Databricks and Azure Machine learning tools is a plus.
 * Fluent with Azure cloud services. Azure Certification is a plus.
 * Experience with integration of multi cloud services with on-premises technologies.
 * Experience with data modeling, data warehousing, and building high-volume ETL/ELT pipelines.
 * Experience with data profiling and data quality tools like Apache Griffin, Deequ, and Great Expectations.
 * Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.
 * Experience with at least one MPP database technology such as Redshift, Synapse or SnowFlake.
 * Experience with running and scaling applications on the cloud infrastructure and containerized services like Kubernetes.
 * Experience with version control systems like Github and deployment & CI tools.
 * Experience with Statistical/ML techniques is a plus.
 * Experience with building solutions in the retail or in the supply chain space is a plus
 * Understanding of metadata management, data lineage, and data glossaries is a plus.
 * Working knowledge of agile development, including DevOps and DataOps concepts.
 * Familiarity with business intelligence tools (such as PowerBI).
   
   

Education


 * BA/BS in Computer Science, Math, Physics, or other technical fields.
   
   

Skills, Abilities, Knowledge


 * Excellent communication skills, both verbal and written, along with the ability to influence and demonstrate confidence in communications with senior level management.
 * Proven track record of leading, mentoring data teams.
 * Strong change manager. Comfortable with change, especially that which arises through company growth. Able to lead a team effectively through times of change.
 * Ability to understand and translate business requirements into data and technical requirements.
 * High degree of organization and ability to manage multiple, competing projects and priorities simultaneously.
 * Positive and flexible attitude to enable adjusting to different needs in an ever-changing environment.
 * Strong leadership, organizational and interpersonal skills; comfortable managing trade-offs.
 * Foster a team culture of accountability, communication, and self-management.
 * Proactively drives impact and engagement while bringing others along.
 * Consistently attain/exceed individual and team goals
 * Ability to lead others without direct authority in a matrixed environment.
   
   

Competencies


 * Highly influential and having the ability to educate challenging stakeholders on the role of data and its purpose in the business.
 * Understands both the engineering and business side of the Data Products released.
 * Places the user in the center of decision making.
 * Teams up and collaborates for speed, agility, and innovation.
 * Experience with and embraces agile methodologies.
 * Strong negotiation and decision-making skill.
 * Experience managing and working with globally distributed teams.
   
   

EEO Statement

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.

PepsiCo is an Equal Opportunity Employer: Female / Minority / Disability / Protected Veteran / Sexual Orientation / Gender Identity

If you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy.

Please view our Pay Transparency Statement",Full-time
4072112483,80517752.0,Software Engineer - Post-training Data,"Magic’s mission is to build safe AGI that accelerates humanity’s progress on the world’s most important problems. We believe the most promising path to safe AGI lies in automating research and code generation to improve models and solve alignment more reliably than humans can alone. Our approach combines frontier-scale pre-training, domain-specific RL, ultra-long context, and inference-time compute to achieve this goal.

About the role:

As a Software Engineer working on our post-training data infrastructure, you write efficient and robust data pipelines and work with the research and Applied teams to devise strategies for gathering and maintaining specific, diverse datasets at scale.

What you might work on:


 * Develop creative ways to obtain post-training datasets teaching the model targeted capabilities.
 * Develop creative ways to reliably generate synthetic datasets
 * Iterate on filtering and scoring heuristics for a post-training dataset
 * Contribute to our data infrastructure by implementing, maintaining and testing data pipelines serving workloads across scales from gigabytes to 100s of petabytes
   
   

What we’re looking for:


 * Extreme attention to detail and commitment to data quality.
 * Ability to write reliable, well-tested code and quickly learn new tools, programming languages or frameworks needed for a given job.
 * Versatility in end-to-end data pipelines, from scraping to processing.
 * High intellectual agility and grit to tackle tough challenges.
   
   

Magic strives to be the place where high-potential individuals can do their best work. We value quick learning and grit just as much as skill and experience.

Our culture:


 * Integrity. Words and actions should be aligned
 * Hands-on. At Magic, everyone is building
 * Teamwork. We move as one team, not N individuals
 * Focus. Safely deploy AGI. Everything else is noise
 * Quality. Magic should feel like magic
   
   

Compensation, benefits and perks (US):


 * Annual salary range: $100K - $550K
 * Equity is a significant part of total compensation, in addition to salary
 * 401(k) plan with 6% salary matching
 * Generous health, dental and vision insurance for you and your dependents
 * Unlimited paid time off
 * Visa sponsorship and relocation stipend to bring you to SF, if possible
 * A small, fast-paced, highly focused team
   
   ",Full-time
4142968399,3450.0,Data Engineer,"Come join Analog Devices (ADI) – a place where Innovation meets Impact. For more than 55 years, Analog Devices has been inventing new breakthrough technologies that transform lives. At ADI you will work alongside the brightest minds to collaborate on solving complex problems that matter from autonomous vehicles, drones and factories to augmented reality and remote healthcare.

ADI fosters a culture that focuses on employees through beneficial programs, aligned goals, continuous learning opportunities, and practices that create a more sustainable future.

ADI At A Glance

Analog Devices, Inc. (NASDAQ: ADI) is a global semiconductor leader that bridges the physical and digital worlds to enable breakthroughs at the Intelligent Edge. ADI combines analog, digital, and software technologies into solutions that help drive advancements in digitized factories, mobility, and digital healthcare, combat climate change, and reliably connect humans and the world. With revenue of more than $12 billion in FY23 and approximately 26,000 people globally working alongside 125,000 global customers, ADI ensures today’s innovators stay Ahead of What’s Possible. Learn more at www.analog.com and on LinkedIn.

Job Description:

As a Data Engineer, you will be responsible for designing, building, and optimizing the organization’s data architecture. This role involves developing scalable data pipelines, managing large-scale databases, and ensuring efficient data processing. You will collaborate with stakeholders to understand data requirements and ensure that data infrastructure supports the organization's needs while maintaining the integrity and quality of data throughout its lifecycle.

Key Responsibilities:


 * Design, build, and maintain scalable data pipelines for extracting, transforming, and loading (ETL) data.
 * Develop and optimize relational and non-relational databases to ensure efficient data storage and retrieval.
 * Implement data warehousing solutions like Redshift or Snowflake to support large-scale data management.
 * Utilize scripting languages such as Python or R for data manipulation, automation, and analysis.
 * Ensure data integrity, accuracy, and consistency across all processes and systems.
 * Collaborate with cross-functional teams, including data scientists and analysts, to support their data needs and projects.
   
   

Skills You Will Need to Be Successful:


 * Strong expertise in SQL and relational/non-relational database management.
 * Advanced knowledge of ETL processes and data pipeline design.
 * Proficiency in data warehousing solutions (e.g., Redshift, Snowflake) for large-scale data storage.
 * Experience with scripting languages such as Python or R for data manipulation and automation.
 * Strong problem-solving skills with a focus on data accuracy and system optimization.
   
   

Minimum Qualifications:


 * Master’s Degree in Computer Science, Data Engineering, or a related field preferred
 * 2+ years of experience in data engineering, database management, or similar roles.
 * Proven experience with building and maintaining scalable data architectures.
   
   

For positions requiring access to technical data, Analog Devices, Inc. may have to obtain export licensing approval from the U.S. Department of Commerce - Bureau of Industry and Security and/or the U.S. Department of State - Directorate of Defense Trade Controls. As such, applicants for this position – except US Citizens, US Permanent Residents, and protected individuals as defined by 8 U.S.C. 1324b(a)(3) – may have to go through an export licensing review process.

Analog Devices is an equal opportunity employer. We foster a culture where everyone has an opportunity to succeed regardless of their race, color, religion, age, ancestry, national origin, social or ethnic origin, sex, sexual orientation, gender, gender identity, gender expression, marital status, pregnancy, parental status, disability, medical condition, genetic information, military or veteran status, union membership, and political affiliation, or any other legally protected group.

EEO is the Law: Notice of Applicant Rights Under the Law.

Job Req Type: Graduate Job

Required Travel: Yes, 10% of the time

The expected wage range for a new hire into this position is $97,060 to $133,458.


 * Actual wage offered may vary depending on work location, experience, education, training, external market data, internal pay equity, or other bona fide factors.
 * This position qualifies for a discretionary performance-based bonus which is based on personal and company factors.
 * This position includes medical, vision and dental coverage, 401k, paid vacation, holidays, and sick time, and other benefits.",Full-time
4148229125,204575.0,Data Engineer,"If you're a passionate problem-solver who loves diving into complex data sets, possesses broad programming savvy and excels at building reliable data pipelines, you'll love being a data engineer at InterWorks. As part of our Data team, you'll empower our customers to make well-informed, data-driven decisions. Together, we'll combine expert application of new software and technologies with a unique perspective on bridging the traditional Business-IT divide. Technical stuff aside, you'll be part of close-knit and helpful team that delivers nothing but the best work to our customers and each other.

Please be advised that this role is required to be located in the InterWorks Tulsa office in Tulsa, Oklahoma. Remote work or telecommuting arrangements outside of this jurisdiction are not permissible for this position.

Salary range commensurate with experience and qualifications, Data Engineer/Data Architect: $80,000-$140,000

What You'll Do


 * Tackle diverse projects that range in duration from a few days to a few months for clients ranging from local businesses to the Fortune 500
 * Design, develop and implement large scale, high-volume, high-performance data infrastructure and pipelines for Data Lake and Data Warehouse
 * Design cloud-native data pipelines, automation routines, and database schemas that can be leveraged to do predictive and prescriptive machine learning
 * Communicate ideas clearly, both verbally and through concise documentation, to various business sponsors, business analysts and technical resources
 * Build and implement ETL frameworks to improve code quality and reliability
 * Build and enforce common design patterns to increase code maintainability
 * Work with disparate data sources (relational databases, flat files, Excel, HDFS/Big Data systems, high-performance analytical databases, etc.) to unify client data
   
   

What You'll Need

Must-Haves:


 * Excellent SQL fluency
 * Strong ETL proficiency using GUI-based tools or code-based patterns
 * Understanding of data-modeling principles
 * Passion for delivering compelling solutions that exceed client expectations
 * Excellent verbal and written communication
 * Strong problem-solving skills
 * Business acumen
 * A thirst to learn
 * Adaptability and flexibility in changing situations
   
   

What We'd Like You to Have


 * Experience with software engineering practices
 * Experience with modern data-engineering practices and frameworks
 * Experience with integration from semi-structured file and API sources
 * Matillion, Fivetran, DBT or other ETL tools
 * AWS / Microsoft Azure cloud exposure
 * Snowflake / Databricks / Amazon Redshift / Google BigQuery / Azure Synapse
   
   

Why InterWorks

InterWorks is a people-focused tech consultancy that empowers clients with customized, collaborative solutions, and we love pursuing innovation alongside people who inspire us. Our approach to work and community is unique and unconventional—just like us—and that's the way we want it. The only thing missing is you. At InterWorks, we value unique contributions, our people are the glue that holds our business together. We're always looking for the right people, and we could be your perfect fit.",Full-time
4151579860,1337.0,Software Engineer - AI Platform,"Company Description
LinkedIn is the world’s largest professional network, built to help members of all backgrounds and experiences achieve more in their careers. Our vision is to create economic opportunity for every member of the global workforce. Every day our members use our products to make connections, discover opportunities, build skills and gain insights. We believe amazing things happen when we work together in an environment where everyone feels a true sense of belonging, and that what matters most in a candidate is having the skills needed to succeed. It inspires us to invest in our talent and support career growth. Join us to challenge yourself with work that matters.


At LinkedIn, our approach to flexible work is centered on trust and optimized for culture, connection, clarity, and the evolving needs of our business. The work location of this role is hybrid, meaning it will be performed both from home and from a LinkedIn office on select days, as determined by the business needs of the team.

Job Description
This role can be based in Mountain View, CA, San Francisco, CA, or Bellevue, WA.

Join us to push the boundaries of scaling large models together. The team is responsible for scaling LinkedIn’s AI model training, feature engineering and serving with hundreds of billions of parameters models and large scale feature engineering infra for all AI use cases from recommendation models, large language models, to computer vision models. We optimize performance across algorithms, AI frameworks, data infra, compute software, and hardware to harness the power of our GPU fleet with thousands of latest GPU cards. The team also works closely with the open source community and has many open source committers (TensorFlow, Horovod, Ray, vLLM, Hugginface, DeepSpeed etc.) in the team. Additionally, this team focussed on technologies like LLMs, GNNs, Incremental Learning, Online Learning and Serving performance optimizations across billions of user queries

Model Training Infrastructure: As an engineer on the AI Training Infra team, you will play a crucial role in building the next-gen training infrastructure to power AI use cases. You will design and implement high performance data I/O, work with open source teams to identify and resolve issues in popular libraries like Huggingface, Horovod and PyTorch, enable distributed training over 100s of billions of parameter models, debug and optimize deep learning training, and provide advanced support for internal AI teams in areas like model parallelism, tensor parallelism, Zero++ etc. Finally, you will assist in and guide the development of containerized pipeline orchestration infrastructure, including developing and distributing stable base container images, providing advanced profiling and observability, and updating internally maintained versions of deep learning frameworks and their companion libraries like Tensorflow, PyTorch, DeepSpeed, GNNs, Flash Attention. PyTorch Lightning and more and more.

Feature Engineering: this team shapes the future of AI with the state-of-the-art Feature Platform, which empowers AI Users to effortlessly create, compute, store, consume, monitor, and govern features within online, offline, and nearline environments, optimizing the process for model training and serving. As an engineer in the team, you will explore and innovate within the online, offline, and nearline spaces at scale (millions of QPS, multi terabytes of data, etc), developing and refining the infrastructure necessary to transform raw data into valuable feature insights. Utilizing leading open-source technologies like Spark, Beam, and Flink and more, you will play a crucial role in processing and structuring feature data, ensuring its most optimal storage in the Feature Store, and serving feature data with high performance.

Model Serving Infrastructure: this team builds low latency high performance applications serving very large & complex models across LLM and Personalization models. As an engineer, you will build compute efficient infra on top of native cloud, enable GPU based inference for a large variety of use cases, cuda level optimizations for high performance, enable on-device and online training. Challenges include scale (10s of thousands of QPS, multiple terabytes of data, billions of model parameters), agility (experiment with hundreds of new ML models per quarter using thousands of features), and enabling GPU inference at scale.

ML Ops: The MLOps and Experimentation team is responsible for the infrastructure that runs MLOps and experimentation systems across LinkedIn. From Ramping to Observability, this org powers the AI products that define LinkedIn. This team, inside MLOps, is responsible for AI Metadata, Observability, Orchestration, Ramping and Experimentation for all models; building tools that enable our product and infrastructure engineers to optimize their models and deliver the best performance possible.

As a Software Engineer, you will have first-hand opportunities to advance one of the most scalable AI platforms in the world. At the same time, you will work together with our talented teams of researchers and engineers to build your career and your personal brand in the AI industry.

Responsibilities
Designing, implementing, and optimizing the performance of large-scale distributed serving or training for personalized recommendation as well as large language models.

Improving the observability and understandability of various systems with a focus on improving developer productivity and system sustenance.

Partner with peers, leads and partners to define, scope, prioritize, and build impactful features at a high velocity.

Basic Qualifications:
Bachelor’s Degree in Computer Science or related technical discipline, or equivalent practical experience

1+ years of experience in the industry with leading/ building deep learning systems.

Experience with Java, C++, Python, Go, Rust, C# and/or Functional languages such as Scala or other relevant coding languages

Experience, qualifications in Machine Learning, AI

Preferred Qualifications:
2+ years of relevant work experience

MS or PhD in Computer Science or related technical discipline

Experience building ML applications, LLM serving, GPU serving.

Experience with search systems or similar large-scale distributed systems

Experience with distributed data processing engines like Flink, Beam, Spark etc., feature engineering,

Experience in distributed machine learning training infrastructure, including technologies like Horovod, PyTorch FSDP, DeepSpeed, Hugginface, PyTorch Lightning, LLMs, GNNs, MLFlow, Kubeflow and large scale distributed systems

Familiarity with containers and container orchestration systems like Kubernetes

Experience in deep learning frameworks and tensor libraries like PyTorch, Tensorflow, JAX/FLAX

Suggested Skills:
ML Algorithm Development
Experience in Machine Learning and Deep Learning
Distributed Systems

You will Benefit from our Culture:

We strongly believe in the well-being of our employees and their families. That is why we offer generous health and wellness programs and time away for employees of all levels.


LinkedIn is committed to fair and equitable compensation practices. The pay range for this role is $107,000 - $176,000. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to skill set, depth of experience, certifications, and specific work location. This may be different in other locations due to differences in the cost of labor.

The total compensation package for this position may also include annual performance bonus, stock, benefits and/or other applicable incentive compensation plans. For more information, visit https://careers.linkedin.com/benefits.



Equal Opportunity Statement
LinkedIn is committed to diversity in its workforce and is proud to be an equal opportunity employer. LinkedIn considers qualified applicants without regard to race, color, religion, creed, gender, national origin, age, disability, veteran status, marital status, pregnancy, sex, gender expression or identity, sexual orientation, citizenship, or any other legally protected class. LinkedIn is an Affirmative Action and Equal Opportunity Employer as described in our equal opportunity statement here: https://microsoft.sharepoint.com/:b:/t/LinkedInGCI/EeE8sk7CTIdFmEp9ONzFOTEBM62TPrWLMHs4J1C_QxVTbg?e=5hfhpE. Please reference https://www.eeoc.gov/sites/default/files/2023-06/22-088_EEOC_KnowYourRights6.12ScreenRdr.pdf and https://www.dol.gov/ofccp/regs/compliance/posters/pdf/OFCCP_EEO_Supplement_Final_JRF_QA_508c.pdf for more information.

LinkedIn is committed to offering an inclusive and accessible experience for all job seekers, including individuals with disabilities. Our goal is to foster an inclusive and accessible workplace where everyone has the opportunity to be successful.

If you need a reasonable accommodation to search for a job opening, apply for a position, or participate in the interview process, connect with us at accommodations@linkedin.com and describe the specific accommodation requested for a disability-related limitation.

Reasonable accommodations are modifications or adjustments to the application or hiring process that would enable you to fully participate in that process. Examples of reasonable accommodations include but are not limited to:

-Documents in alternate formats or read aloud to you
-Having interviews in an accessible location
-Being accompanied by a service dog
-Having a sign language interpreter present for the interview

A request for an accommodation will be responded to within three business days. However, non-disability related requests, such as following up on an application, will not receive a response.

LinkedIn will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by LinkedIn, or (c) consistent with LinkedIn's legal duty to furnish information.

Pay Transparency Policy Statement
As a federal contractor, LinkedIn follows the Pay Transparency and non-discrimination provisions described at this link: https://lnkd.in/paytransparency.

Global Data Privacy Notice for Job Candidates
This document provides transparency around the way in which LinkedIn handles personal data of employees and job applicants: https://lnkd.in/GlobalDataPrivacyNotice",Full-time
4100923585,3450.0,Associate Data Engineer,"Come join Analog Devices (ADI) – a place where Innovation meets Impact. For more than 55 years, Analog Devices has been inventing new breakthrough technologies that transform lives. At ADI you will work alongside the brightest minds to collaborate on solving complex problems that matter from autonomous vehicles, drones and factories to augmented reality and remote healthcare.

ADI fosters a culture that focuses on employees through beneficial programs, aligned goals, continuous learning opportunities, and practices that create a more sustainable future.

ADI At A Glance

Analog Devices, Inc. (NASDAQ: ADI) is a global semiconductor leader that bridges the physical and digital worlds to enable breakthroughs at the Intelligent Edge. ADI combines analog, digital, and software technologies into solutions that help drive advancements in digitized factories, mobility, and digital healthcare, combat climate change, and reliably connect humans and the world. With revenue of more than $12 billion in FY23 and approximately 26,000 people globally working alongside 125,000 global customers, ADI ensures today’s innovators stay Ahead of What’s Possible. Learn more at www.analog.com and on LinkedIn.

Job Description:

As an Associate Data Engineer, you will play a crucial role in designing, building, and maintaining data pipelines and databases. You will collaborate with data scientists, analysts, and other stakeholders to ensure that data infrastructure is reliable, scalable, and optimized for performance. This position will allow you to gain experience in managing data extraction, transformation, and loading (ETL) processes while ensuring data integrity across the organization.

Key Responsibilities:


 * Design and implement data pipelines for the efficient extraction, transformation, and loading (ETL) of data.
 * Support the development and maintenance of relational and non-relational databases, ensuring data accessibility and performance.
 * Work with data warehousing solutions such as Redshift or Snowflake to support large-scale data storage.
 * Write and maintain scripts in Python or R for data manipulation and processing.
 * Ensure the accuracy, consistency, and integrity of data across its lifecycle.
 * Collaborate with cross-functional teams to understand and meet data infrastructure needs.
   
   

Skills You Will Need to Be Successful:


 * Proficiency in SQL and knowledge of relational and non-relational databases.
 * Understanding of ETL processes and experience in designing scalable data pipelines.
 * Familiarity with data warehousing solutions like Redshift or Snowflake.
 * Experience with scripting languages such as Python or R for data manipulation.
 * Strong attention to detail with a focus on maintaining data accuracy and integrity.
   
   

Minimum Qualifications:


 * Bachelor’s Degree in Computer Science, Data Engineering, or a related field.
 * 0-2 years of experience in data engineering, database management, or similar roles.
 * Understanding of basic data engineering concepts and tools.
   
   

For positions requiring access to technical data, Analog Devices, Inc. may have to obtain export licensing approval from the U.S. Department of Commerce - Bureau of Industry and Security and/or the U.S. Department of State - Directorate of Defense Trade Controls. As such, applicants for this position – except US Citizens, US Permanent Residents, and protected individuals as defined by 8 U.S.C. 1324b(a)(3) – may have to go through an export licensing review process.

Analog Devices is an equal opportunity employer. We foster a culture where everyone has an opportunity to succeed regardless of their race, color, religion, age, ancestry, national origin, social or ethnic origin, sex, sexual orientation, gender, gender identity, gender expression, marital status, pregnancy, parental status, disability, medical condition, genetic information, military or veteran status, union membership, and political affiliation, or any other legally protected group.

EEO is the Law: Notice of Applicant Rights Under the Law.

Job Req Type: Graduate Job

Required Travel: Yes, 10% of the time

The expected wage range for a new hire into this position is $78,200 to $107,525.


 * Actual wage offered may vary depending on work location, experience, education, training, external market data, internal pay equity, or other bona fide factors.
 * This position qualifies for a discretionary performance-based bonus which is based on personal and company factors.
 * This position includes medical, vision and dental coverage, 401k, paid vacation, holidays, and sick time, and other benefits.",Full-time
4045412739,66321745.0,Junior Data Engineer (Remote),"Since 2010 and almost 14 years SynergisticIT has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients.

Post Covid the tech Layoffs have been massive—In 2022 there were 165,269 tech layoffs, In 2023 there were 264,220 tech layoffs and so far in 2024 there have been 126,382 tech layoffs. (Source Layoffs.fyi ) -Total layoffs as per this 555,871 tech layoffs.

Client, Dell and Cisco have announced 15,000/12,500 and 4000 tech layoffs respectively in August.

The Job market is Hyper Competitive. For 1 position 500-2000 candidates or more are applying and laid off job seekers are also competing for entry level Job positions.

Acquiring the right technology skillsets which are being demanded by clients and getting yourself in front of clients is the way to get to get Interviews and eventually a Job Offer. Survival of the Fittest is the only way to get a tech Job in this job market.

In this Layoffs fueled market also SynergisticIT's candidates are able to achieve multiple job offers and $100k &plus; salaries once they acquire the required skills.

Please check the below links to see success outcomes, salaries of our candidates.

https://www.synergisticit.com/candidate-outcomes/

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please visit the below videos exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, we are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Data Engineers, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

REQUIRED SKILLS For Java /Full Stack/Devops Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Knowledge of Core Java , javascript , C&plus;&plus; or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

For data Science/Data Analyst/AI/Machine learning Positions

Required Skills

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude

Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Full-time
4087169490,11137552.0,Data Engineer,"Data Engineer - LOCAL ONLY - NYC OR NJ

Long Term

2-3 years of experience, Snowflake, PYTHON, db and Azure products like ADF IS A MUST

SQL is a must- will be sql assessment

Computer Science degree- from reputable school (BIG PLUS)


 * Bachelor's Degree in Mathematics, Operations Research, Statistics, Computer Science, Engineering, or Physics; OR demonstrated capability to perform job responsibilities with a combination of a High School Diploma/GED and at least four (4) years of previous relevant work experience
 * Three (3) years of relevant experience in a data role working with data warehouses and business intelligence tools
 * Proven experience with dbt (data build tool) & Snowflake
 * Strong SQL skills
 * Experience with modern ELT orchestration tools like Azure Data Factory or Airflow
 * Experience with git and git-based workflows",Full-time
4024788970,19031767.0,Data Engineer,"About Us

At Hayden AI, we are on a mission to harness the power of artificial intelligence and machine learning to transform the way governments and businesses address real-world challenges.

From optimizing bus lane and bus stop enforcement to pioneering digital twin modeling and beyond, our innovative mobile perception system empowers our clients to accelerate transit, enhance street safety, and drive forward a sustainable future.

What The Job Involves

Hayden AI seeks a data generalist to support a diverse set of stakeholders with Data and Analytics needs. We are a small team, and this is a great opportunity for someone who wants to deliver a big impact: you will operate on the intersection of Data Infrastructure, Data Engineering, Analytics, Data Science, and ML Ops. You will work with transit agencies, the customer success team, finance, product, company executives, and, last but not least, engineers. You will enable all of them to get their data questions answered in a timely manner with a high accuracy.

Responsibilities


 * Design, build, and operate cloud-based data warehouse / data lake that enables large scale data analytics.
 * Operate the ETL pipelines that merge the data from multiple sources into a centralized data warehouse.
 * Build derived canonical datasets from the raw data to simplify and speed up analytical queries and make analytics accessible to less technical audiences.
 * Be the voice of the data: identify product issues using anomaly detection in various data sets, and bring it to the attention of respective stakeholders.
 * Build dashboards that track various metrics and KPIs that the company relies on.
 * Participate actively in the team's software development process, including design reviews, code reviews, and brainstorming sessions. Keep software development documents accurate and updated.
 * Proactively remove roadblocks and escalate issues when encountered.
   
   

Qualifications


 * Experience with data warehouse systems, such as Amazon Redshift, Google BigQuery, or Snowflake. From schema design to performance optimizations, and everything in between.
 * Broad knowledge of database technologies, including SQL and NoSQL (e.g. PostgreSQL, InfluxDb, Redis, DynamoDB, etc). You do not need to know all of them, but you should be comfortable in some.
 * Experience with ETL and orchestrations, such as Airbyte, DBT, Flyte, and/or Airflow.
 * Experience with Business Intelligence tooling, such as Tableau or Looker.
 * 5+ years of Software / Data Engineering experience, including hands-on coding ability in modern programming languages. We use Python and Go, but you don’t have to be an expert in both.
 * BS or MS in Computer Science, Electrical Engineering, or a related field.
 * Excellent communication, verbal and written.
   
   

Bonus


 * Experience with CI/CD automation Test Driven Development.
 * Experience with the AWS ecosystem to the extent that is needed to operate the above mentioned tools.
 * Experience with geospatial, image, and video datasets.
 * Prior experience working in startups, and desire to do that again!
   
   

Benefits And Perks

There are endless learning and development opportunities from a highly diverse and talented peer group, including experts in a wide range of fields (AI, Computer Vision, Government Contracting, Systems & Device Engineering, Operations, Communications, and more!)


 * Options for medical, dental, and vision coverage for employees and dependents (for US employees)
 * Flexible Spending Account (FSA) and Dependent Care Flexible Spending Account (DCFSA)
 * 401(k) with 3% company matching
 * Unlimited PTO
 * Daily catered lunches in our San Francisco office
   
   

At Hayden AI, we are committed to creating an inclusive and diverse workplace where everyone is treated with respect and dignity. We believe that our differences make us stronger and drive innovation. As an equal opportunity employer, we do not discriminate against any employee or applicant based on race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other legally protected status. We are dedicated to fostering a work environment that celebrates diversity and ensures that every individual has the opportunity to contribute to our mission and achieve their full potential.

Please do not forward resumes to our jobs alias, Hayden AI employees or any other company location. Hayden AI is not responsible for any fees related to unsolicited resumes.

Compensation Range: $144K - $200K

",Full-time
4120826496,10667.0,Data Analytics Engineer,"As a Data Analytics Engineer at Meta Reality Labs' Customer Experience (CX) team, you'll be part of a global team that unlocks the power of customer feedback and insights to drive business improvements. Your background and experience in analytics will help us better understand our customers' needs, preferences, and behaviors, enabling us to deliver exceptional customer experiences. You'll also contribute to the development of data governance policies, data quality standards, and data visualization best practices, ensuring that our data assets are accurate, reliable, and actionable.We’re looking for a Data Analytics Engineer with demonstrated technical skills and functional understanding and background in customer experience insights with the focus on customer support and operations. This role will partner with various functions across the end-to-end customer journey to build and scale data and advanced analytics solutions to enhance customer satisfaction and build brand loyalty, while identifying opportunities to improve data foundations and analytics maturity. By analyzing complex data sets and identifying trends, patterns, and correlations, you'll help shape the future of our products and services.To be successful in this role, you'll have a passion for data, experience managing multiple projects concurrently, and enjoy a fast-moving organization. You’ll identify ways to tell a compelling story with data and design principles. You will thrive within cross-functional teams, excel at building and managing relationships with internal partners and stakeholders, and exhibit proven organizational and presentation skills.

Data Analytics Engineer Responsibilities:


 * Design, develop, integrate, launch and maintain collections of data models, queries, reports and visualizations that support multiple use cases across customer journeys
 * Work with various data sources, including customer interactions, feedback, and behavioral data, to identify trends, patterns, and provide actionable insights
 * Build and deploy predictive models to forecast customer behavior, identify potential issues, and optimize support processes
 * Create interactive and dynamic data visualizations that communicate complex insights to stakeholders
 * Work closely with customer service and operations, product, and engineering teams to integrate data insights into business decisions and drive customer experience improvements
 * Develop and track key performance indicators to measure the effectiveness of customer experience initiatives
 * Continuously update knowledge of advanced analytics techniques, tools, and methodologies to ensure best practices are applied
   
   

Minimum Qualifications:


 * Master's degree in Computer Science, Statistics, Mathematics, or related field
 * 5+ years of experience in data analytics, Business intelligence, data science, or related fields
 * Background and knowledge of CX and VoC space
 * Proficiency in programming languages such as Python, R, or SQL
 * Experience with machine learning concepts and experience working with machine learning libraries and frameworks (e.g. scikit-learn, TensorFlow)
 * Experience creating interactive dashboards with Tableau, Power BI, and others, with proven communication and presentation skills to deliver actionable insights
 * Experience managing time-sensitive projects through to completion while balancing evolving priorities and a diverse range of stakeholders
 * Experience working with operations functions
   
   

Preferred Qualifications:


 * Knowledge of natural language processing (NLP) techniques
 * Familiarity with customer support software (e.g., Salesforce)
 * Certification in data science or related field (e.g., Certified Data Scientist)
 * Familiarity with agile development methodologies and version control systems such as Git
 * Experience working in the high-volume consumer electronics industry
 * Experience working with operations functions, preferably in the customer experience or customer support operations space
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$124,000/year to $176,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4148718999,9215489.0,Data Engineer - Abu Dhabi Hedge Fund,"We've all thought about making the jump to Dubai or Abu Dhabi for obvious reasons, but there never is the perfect opportunity to do this as a data engineer.




Well this unique hedge fund is looking to relocate talented data engineers into Abu Dhabi to join and accelerate an ever growing hedge fund.




Who do you need to be?




You're either:

 * A Data Engineer within the Hedge Fund/ Trading space
 * Coming from an outstanding educational background, and work with complex data sets




If this is you - get in touch.




Tech stack is open.",Full-time
4152485171,2139901.0,Senior Data Engineer,"We are seeking a highly motivated and experienced Senior Data Engineer to join our Security and Trust (S&T) team. In this role, you will analyze business and technical data, develop data-driven solutions, and optimize compliance and security processes through business intelligence, analytics, and automation.

The ideal candidate has strong experience with SQL, Python, BI tools, and data integration to enhance security operations and compliance tracking. You will collaborate closely with cross-functional team members within S&T and other teams to develop dashboards, manage tools, and track project progress in support of our team's overall mission and objectives.

Everlaw’s mission is to promote justice by illuminating truth. Our company culture is open and vibrant and we’re committed to the professional growth of our team members, offering an annual learning and development stipend and regular check-ins with managers regarding career goals. If you’re looking for a place that values passion, integrity, thinking big, and a desire to learn, we’d love to hear from you! Think you’re missing some of the skills and are hesitant to apply? We do not believe in the ‘perfect’ candidate and encourage you to apply if you feel you can bring value to our team.

This is a full-time position based in our Oakland, California office with a hybrid work schedule: in office M/W/Th with the option to work from home Tu/Fr.

Getting started


 * We want you to feel like part of the team early on! Our onboarding process will integrate you into the company with informative sessions on our product, policies, processes, and team structure and goals. You’ll spend meaningful time getting to know your direct reports and discover what excites and challenges them.
 * We’re excited for you to learn, grow, and contribute right away! We trust that you’ll bring experience and knowledge that will uplift and uplevel the team, but we don’t expect you to know everything on Day 1.
   
   

In your role, you'll...


 * Design and manage data architecture to track the effectiveness of InfoSec and Security & Trust initiatives.
 * Develop and maintain dashboards providing real-time insights into compliance and security program performance.
 * Streamline the aggregation and analysis of security events to improve threat detection and incident response.
 * Automate notification processes and enhance data analytics for key team workflows.
 * Analyze data trends and provide insights to management, identifying gaps and opportunities for improvement.
 * Drive program efficiency by automating manual workflows. Optimize the use of compliance and security systems to ensure they meet team needs.
 * Support the implementation and adoption of new tools.
 * Conduct periodic phishing campaigns to support security awareness objectives.
 * Automate reporting and design metrics to measure the effectiveness of security awareness training.
 * Identify and implement process improvements and automation in compliance and security workflows.
 * Collaborate across teams to enhance operational efficiency and drive process improvements.
 * Integrate with OKTA, AWS and other tools to pull audit evidence.
 * Automate and improve responses to customer RFIs related to security and compliance.
 * Streamline intake and pipeline management for greater efficiency.
 * Work closely with the senior Trust team to identify opportunities for program improvement and automation.
   
   

About You


 * You have a Bachelor's degree in Data Science, IT, IT Management, Computer Science, or a related field.
 * You have over 5 years of experience as a Data Analyst/Engineer/Scientist, with at least 3 years in building analytic tools, integration systems and pipelines.
 * You have strong SQL and/or Python skills.
 * You have strong analytical skills with the ability to interpret complex data and generate actionable insights.
 * You have a solid understanding of security concepts such as role based access, endpoint protection, etc.
 * You have proficiency in using analytics tools and software (e.g., Excel, Tableau, Power BI).
 * You have excellent communication skills, both written and verbal, with the ability to work with technical and non-technical stakeholders.
 * You are authorized to work in the United States. Please note that at this time, Everlaw is not sponsoring F-1 visas, including OPT, for this role.
   
   

Benefits


 * The expected salary range for this role is between $155,000 - $190,000 The final offered salary will be dependent upon many factors including the candidate’s experience and skills. The base pay range is subject to change in the future.
 * Equity program
 * 401(k) retirement plan with company matching
 * Health, dental, and vision
 * Flexible Spending Accounts for health and dependent care expenses
 * Paid parental leave and approximately 10 days (80 hours) per year of sick leave
 * Seventeen paid vacation days plus 11 federal holidays
 * Membership to Modern Health to help employees prioritize mental health and wellness
 * Annual allocation for Learning & Development opportunities and applicable professional membership dues
 * Company-sponsored life and disability insurance
 * Find out more about our Benefits and Perks
   
   

Perks


 * Work in Uptown Oakland, just steps from the BART line and dozens of restaurants and walking distance to Lake Merritt
 * Flexible work-from-home days on Tuesdays and Fridays
 * Monthly home internet reimbursement
 * Select your preference of hardware (Mac or PC) and customize your desk setup
 * Enjoy a wide variety of snacks and beverages in the office
 * Bond over company-wide out-of-the-box events and fun activities with your team
 * Time off for company-sponsored volunteer events and 4 paid hours per quarter to volunteer at a charitable organization of your choice
 * Take advantage of learning and career development opportunities
 * Ranked #9 on Glassdoor's Best Places to Work 2023 for US small and medium companies
 * One of Wealthfront’s 2021 Career Launching Companies, and ranked #2 on the “2022 Bay Area Best Places to Work” list by the San Francisco Business Times and the Silicon Valley Business Journal
 * One of Fast Company’s World's Most Innovative Companies for 2022 and proud contributor of free ediscovery resources to benefit the greater good through “Everlaw for Good”
   
   

Pursue Truth While Finding Yours

At Everlaw, we are deeply invested in pursuing the truth, for our clients and for our employees. We know that when you’re empowered to pursue your passions, it is reflected in the work. That’s why we’re committed to the professional growth of all our team members, offering an annual learning and development stipend and regular career check-ins with managers. If you’re looking for a place that values passion, integrity, and a desire to learn, we’d love to hear from you!

About Everlaw

We help law firms, government agencies, and corporations sift through millions of documents of evidence in big lawsuits and investigations to find the proverbial smoking gun (or needle in the haystack -- pick your metaphor). It's a multi-billion dollar space typically dominated by service-oriented vendors, and we're coming at it with cutting-edge technology and elegant design. It's working, and we've been growing very rapidly: we host hundreds of terabytes of data and work with all 50 state Attorneys General and hundreds of law firms on some of the most high-profile cases litigated today.

Everlaw is an equal opportunity employer. We pride ourselves on having a diverse workforce and we do not discriminate against any employee or applicant because of race, creed, color, religion, gender, sexual orientation, gender identity/expression, national origin, disability, age, genetic information, veteran status, marital status, pregnancy or related condition, or any other basis protected by law. We respect the gender, gender identity and gender expression of our applicants and employees, and we honor requests for pronouns. It is our policy to comply with all applicable national, state and local laws pertaining to nondiscrimination and equal opportunity, including the California Equal Pay Act. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

Everlaw requires all of its employees to be fully vaccinated for COVID-19, unless a medical or religious exemption applies. If you are hired, we will require you to prove that you have received the COVID-19 vaccine, unless you have received a medical or religious exemption.

We collect and process the personal information you provided along with your job application in accordance with our Applicants Privacy Notice and Notice at Collection.

",Full-time
4134134679,2380.0,Data Engineer,"Description

There’s never been a more exciting time to join United Airlines. We’re on a path towards becoming the best airline in the history of aviation. Our shared purpose – Connecting People, Uniting the World – is about more than getting people from one place to another. It also means that as a global company that operates in hundreds of locations around the world with millions of customers and tens of thousands of employees, we have a unique responsibility to uplift and provide opportunities in the places where we work, live and fly, and we can only do that with a truly diverse and inclusive workforce. And we’re growing – in the years ahead, we’ll hire tens of thousands of people across every area of the airline. Our careers include a competitive benefits package aimed at keeping you happy, healthy and well-traveled. From employee-run ""Business Resource Group"" communities to world-class benefits like parental leave, 401k and privileges like space available travel, United is truly a one-of-a-kind place to work. Are you ready to travel the world?

United's Digital Technology team spans the globe and is made up of individuals all working together with cutting-edge technology to build the best airline in the history of aviation. Our team designs, develops and maintains massively scaling technology solutions brought to life with innovative architectures, data analytics, and digital solutions

Job Overview And Responsibilities

Exciting opportunity to be a part of a brand new best-in-class data science & analytics team to support the advertising and technology needs for the world’s best and largest airline. An entrepreneurial and meticulous data engineer who builds underlying supporting data for measurement and reporting across United’s digital platforms.


 * Design and build scalable and reliable data infrastructure and pipelines (ingestion, integration, ETL, real-time connectors) to support data for measurement and reporting
 * Build connections with relevant endpoints for data ingestion
 * Collaborate with data scientists, analysts, and other stakeholders to understand data needs and requirements
 * Ensure data quality, performance, and security across the entire data lifecycle; developing high-quality and well-documented data sets
 * Continuously improve data infrastructure and processes to increase efficiency, scalability, and reliability
 * Stay up to date with emerging technologies and best practices in data engineering
   
   

Qualifications

What’s needed to succeed (Minimum Qualifications):


 * Bachelor’s degree in Computer Science, Engineering or a related field
 * 3-5 years hands-on industry experience in Data Engineering (or equivalent quantitative job title)
 * Deep technical knowledge of data engineering; highly skilled in SQL, relational databases, big data
 * Skilled in development of data warehousing, data flow design and development, and ETL processes
 * Proficient with Python or Scala, Azure Data Factory, Synapse
 * Proficient with cloud-based data technologies such as AWS, Azure, and/or GCP
 * Familiarity with data visualization tools (Power BI, Tableau)
 * Strong collaborator with cross-functional teams from tech, design, and business and experience leading teams in an agile setting
 * Ability to communicate and explain data and its implications to various stakeholders
 * Ability to evaluate different options proactively and to solve problems in an innovative way, developing new solutions or combining existing methods to create new approaches
 * Must be legally authorized to work in the United States for any employer without sponsorship
 * Successful completion of interview required to meet job qualification
 * Reliable, punctual attendance is an essential function of the position
   
   

What will help you propel from the pack (Preferred Qualifications):


 * Advanced Computer Engineering degree
 * Experience with advertising technology (Ad Tech), particularly in designing solutions that enhance ad targeting, measurement, and optimization.
 * Familiarity or hands-on experience with generative AI and large language models, understanding their potential impact on machine learning and ad tech innovations.
   
   

United Airlines is an equal opportunity employer. United Airlines recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, gender identity, sexual orientation, physical ability, age, veteran status and other protected status as required by applicable law. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform crucial job functions. Please contact JobAccommodations@united.com to request accommodation.

The base pay range for this role is $91,770.00 to $125,070.00.

The base salary range/hourly rate listed is dependent on job-related, non-discriminatory factors such as experience, education, and skills. This position is also eligible for bonus and/or long-term incentive compensation awards.

You may be eligible for the following competitive benefits: medical, dental, vision, life, accident & disability, parental leave, employee assistance program, commuter, paid holidays, paid time off, 401(k) and flight privileges.

United Airlines is an equal opportunity employer. United Airlines recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, gender identity, sexual orientation, physical ability, age, veteran status and other protected status as required by applicable law. Equal Opportunity Employer - Minorities/Women/Veterans/Disabled/LGBT.

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform crucial job functions. Please contact JobAccommodations@united.com to request accommodation. WHQ00024567",Full-time
4148913391,1167899.0,Data Engineer,"Double Good's mission is to create joy. We create joy with our delectable and award-winning popcorn. We create joy with our easy-to-use fundraising platform that raises a meaningful amount of money for youth sports and activities, empowering kids to pursue their dreams. We create joy through our Kids Foundation which hosts Double Good Days events across the country to bring all-ability fun to children with special needs and their families. As featured on the Today Show, Double Good is not just about the product; we have a strong social mission.

In recent years, Double Good has seen 40% year over year growth, and we're excited about our future! We're excited about the possibility of you joining our mission. We are looking for a Data Engineer to join our growing Data team.

In this pivotal role, you will be part of a world-class data team that is focused on empowering decision-makers and enhancing operations. We thrive on collaboration, creativity, problem-solving, and a drive to add value.

Location - This role will be hybrid out of our downtown Chicago office

Why Join Us:


 * Join a rockstar team and use leading technologies to make a huge impact on critical company initiatives.
 * Enjoy a stellar company culture, competitive salary and great benefits.
   
   

What the data team does: We focus on building data assets that are impactful to the business. We select and configure tools to support reliable data operations and availability of data assets to business users. We collaborate with each other and across the whole organization to connect systems, connect dots and share knowledge. We build data stores, pipelines, databases, data models, metrics, visualizations, and all the things that make it a reliable, secure, well-managed data platform.

What you'd focus on: Your role will be to help design, build and manage the data platform, pipelines and models that support strategic analysis, BI, ML and AI. As you build, you will also help make it more reliable, secure and well-managed by proactively identifying and implementing improvements in the platform.

Experience & Skills we value:


 * A solid track record with at least 5 years in data engineering.
 * Proven experience and self-motivation in taking initiative to identify needs, moving projects forward and delivering results.
 * Exceptional communication skills that promote effective teamwork.
 * Deep understanding of Kimball and OBT-style data modeling, with a complimentary drive to understand the business and create optimal models for BI and ML use cases.
 * Expertise in dbt and Airflow, with deep experience in SQL, Python, pipeline development, orchestration and deployment.
 * Experienced in Snowflake administration, with a solid understanding of performance optimization and RBAC.
 * Excellent problem-solving capabilities with a flair for analyzing the business and systems impact.
   
   

Nice to have and/or you'll learn:


 * Being comfortable developing in IaC tools, like Terraform
 * Being comfortable working with offshore DevOps teams to make requests for networking changes, AWS services, and permissions
   
   

Equal Pay Disclosure(s):

We're on a mission to create more joy in people's lives, and that includes our internal employees. We create a place people love to be a part of, where people can discover and practice their unique skill sets, a place where they can contribute and do their best work. We do this by offering our employees a competitive compensation & benefits plan.

Base Pay range for this position:


 * $90,000 - $130,000
 * 15% (% of Annualized Base Pay, paid quarterly)
   
   

The final discretionary compensation that will be offered for this role depends on a variety of factors, including job-related knowledge, skills, experience, and market location.

Tool Appendix:

Our strategy for data platform tool selection is to use hosted/SaaS tools when possible. For us, this means that the data engineer role does less with infrastructure but more with data pipelines and data models.

We work with a diverse set of tools, as shown below. While familiarity with all is beneficial, we value strong technical skills and a willingness to learn new technologies.

Category

Tool/Topic

Ingestion

Fivetran, but looking at other solutions

Data

Snowflake, Snowpark, AWS

Orchestration

Airflow

Transformation

Dbt, SQL, Python

Data modeling:

Kimball, metrics, OBT

Semantic/metrics layer:

Cube.dev

BI

Domo, but looking at other solutions

Data catalog

Looking at solutions

Observability

Elementary, Slack Notifications, Reports

CI/CD

Github Actions

IaC

Terraform, Titan for Snowflake

Other

Security, Users, Roles and Permissions in Snowflake

Team

Google Workspaces, Microsoft coming soon, Jira, Confluence, Azure DevOps, Slack for company comms

Sources

Microsoft D365 F&O, Postgres, APIs, third-parties

Benefits:


 * Double Good offers competitive benefits including medical, dental and vision coverage with plans that can fit each teammate's needs. We offer immediate vesting in our 401k plan, paid time off, company-paid leaves and other perks including a Popcorn Allowance (yup, free popcorn!).
 * Visit the Careers page on our website for more information at https://www.doublegood.com/careers.
   
   

Double Good is an Equal Opportunity and Affirmative Action employer, working in compliance with both federal and state laws. We are committed to the concept of Equal Employment opportunity. Qualified candidates will be considered for employment regardless of race, color, religion, age, sex, national origin, marital status, medical condition, or disability.  The EEO is the law and is available here. Right to Work Statement (English and Spanish).",Full-time
4092612147,1586.0,Data Engineer,"Description

We are a team of doers working passionately to apply cutting-edge advances in technology to solve real-world problems. As a Data Engineer, you will participate in developing exciting products for customers and analytics for our daily operations.

You would be joining the Device, Digital & Alexa Support (D2AS) organization which provides best in class customer support technologies for customers using Amazon products.

Key job responsibilities


 * Work closely with data scientists and business intelligence engineers to create robust data architectures and pipelines.
 * Simplify and enhance the accessibility, clarity, and usability of large or complex datasets through the development of advanced BI dashboards and applications.
 * Take ownership of the design, creation, and upkeep of metrics, reports, analyses, and dashboards to inform key business decisions.
 * Navigate ambiguous environments by evaluating various options using both data-driven insights and business expertise.
 * Develop and manage scalable, automated, and fault-tolerant data solutions using cutting-edge technologies such as Spark, EMR, Python, Redshift, Glue, and S3.
   
   

A day in the life

Data Engineers focus on managing customer requests, maintaining operational excellence, and enhancing core infrastructure. You will be collaborating closely with both technical and non-technical teams to design and execute roadmaps for essential Devices and Digital metrics.

If you are not sure that every qualification on the list above describes you exactly, we'd still love to hear from you! At Amazon, we value people with unique backgrounds, experiences, and skillsets. If you’re passionate about this role and want to make an impact on a global scale, please apply!

Benefits Summary

Amazon offers a full range of benefits that support you and eligible family members, including domestic partners and their children. Benefits can vary by location, the number of regularly scheduled hours you work, length of employment, and job status such as seasonal or temporary employment. The benefits that generally apply to regular, full-time employees include:


 * Medical, Dental, and Vision Coverage
 * Maternity and Parental Leave Options
 * Paid Time Off (PTO)
 * 401(k) Plan
   
   

About The Team

Our team manages a secure and compliant infrastructure that adapts to evolving data requirements for Devices and Digital teams. This involves solving data engineering challenges to create high-quality, reliable, accurate, consistent, and scalable data solutions that align with our business goals.

Basic Qualifications


 * 3+ years of data engineering experience
 * Experience with data modeling, warehousing and building ETL pipelines
 * Experience with one or more query language (e.g., SQL, PL/SQL, DDL, MDX, HiveQL, SparkSQL, Scala)
 * Experience with one or more scripting language (e.g., Python, KornShell)
 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with data visualization software (e.g., AWS QuickSight or Tableau) or open-source project
 * Bachelor's degree, or Master's degree
   
   

Preferred Qualifications


 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Los Angeles County applicants: Job duties for this position include: work safely and cooperatively with other employees, supervisors, and staff; adhere to standards of excellence despite stressful conditions; communicate effectively and respectfully with employees, supervisors, and staff to ensure exceptional customer service; and follow all federal, state, and local laws and Company policies. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation. Pursuant to the Los Angeles County Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com Services LLC

Job ID: A2847695",Full-time
4136952529,10801123.0,Data Engineer,"Title: Data Engineer

Location: New York, NY




About M Science:

M Science is a data-driven research and analytics firm, uncovering new insights for leading financial institutions and corporations. M Science is revolutionizing research, discovering new data sets, and pioneering methodologies to provide actionable intelligence. Our research teams have decades of experience working with massive amounts of unstructured data in near real-time to discern critical insights that help clients make smarter, more informed decisions. We combine the best of finance, data, and technology to create a truly unique value proposition for both financial services firms and major corporations.




Job Overview:

We are seeking a highly skilled Data Engineer to design and develop scalable, robust, and resilient data ingestion frameworks. The ideal candidate will have deep expertise in Databricks, Airflow, Python, and Spark, with a strong focus on building standardized data pipelines that ensure data quality, validation, anomaly detection, and resilience to vendor data issues. You will play a critical role in building a data infrastructure that enables automation, scalability, and high reliability while ensuring seamless data ingestion, transformation, and monitoring.




Responsibilities:

 * Design, develop, and optimize scalable and fault-tolerant data ingestion pipelines using Databricks, Airflow, Python, and Spark
 * Implement a standardized ingestion framework to streamline data onboarding, validation, and integration across multiple sources
 * Develop robust data quality assurance mechanisms, including schema validation, anomaly detection, and automated monitoring to detect missing, malformed, or delayed data
 * Build resilient data pipelines that handle vendor-related issues such as delayed deliveries, schema changes, incomplete records, and data corruption
 * Create automated alerting and notification systems for deviations in data quality, validation failures, or unusual patterns
 * Optimize data process performance in Spark and Databricks for scalability and cost efficiency
 * Monitor and troubleshoot production pipelines to ensure minimal downtime and timely data availability
 * Collaborate with cross-functional teams including data scientists, software engineers, and business analysts to ensure seamless data integration
 * Maintain documentation for data models, pipeline workflows, and validation rules to support operational efficiency




Qualifications:

 * 4+ years of experience in data engineering with a strong focus on data ingestion and pipeline development
 * Proficiency in Python for data processing, scripting, and automation
 * Experience with Spark and distributed data processing
 * Hands-on experience with Databricks for big data management and analytics
 * Experience in Airflow for orchestrating data pipelines
 * Strong understanding of data quality frameworks, including schema validation, anomaly detection, and data governance best practices
 * Familiarity with cloud data platforms (AWS) and cloud-based storage solutions
 * Experience handling structured and semi-structured data formats (Parquet, JSON, CSV)
 * Knowledge of SQL and NoSQL databases for data transformation and storage
 * Strong troubleshooting skills to diagnose and resolve performance bottlenecks in data pipelines




Primary Location: New York, NY

Salary Range: $100,000-140,000 USD/Annual




The salary offered will take into consideration an individual’s experience level and qualifications. In addition to salary, M Science offers, for eligible employees, an annual discretionary incentive bonus, competitive employee benefits, including: medical, dental & vision coverage; 401(k); life, accident, disability insurance; and wellness programs. M Science also offers paid time off packages that include planned time off (vacation), unplanned time off (sick leave), paid holidays and paid parental leave.",Full-time
4083292134,6125149.0,Data Engineer,"Verition Fund Management LLC (“Verition”) is a multi-strategy, multi-manager hedge fund founded in 2008. Verition focuses on global investment strategies including Global Credit, Global Convertible, Volatility & Capital Structure Arbitrage, Event-Driven Investing, Equity Long/Short & Capital Markets Trading, and Global Quantitative Trading. As a Data Engineer you would be responsible for building data pipelines and supporting Portfolio Managers and Risk teams.

Responsibilities:


 * Building data pipelines
 * Working closely with data vendors such as Bloomberg, Refinitiv, etc.
 * Taking this vendor data and normalizing/standardizing it for firm consumption
 * Taking the normalized data and customizing it to user specific needs
   
   

Qualifications:


 * 4+ years of experience in financial services
 * BS or MS in Computer Science or Computer Engineering
 * Strong technology/coding skills in Python
 * Strong design skills to build extensible configuration/data-driven platforms
 * Good Financial data, specifically security master and/or knowledge of vendor datasets
 * Strong AWS data pipeline skills
 * Strong database skills – SQL and no-SQL
 * Strong problem solving skills
 * Ability work with datasets in Excel and other productivity tools
 * Nice to Have:
    * 
       * AWS Glue
       * Spark
       * Jupyter Notebook
         

Salary Range: $120,000 USD - $200,000 USD",Full-time
3998838429,1431.0,Data Engineer,"Overview

PepsiCo operates in an environment undergoing immense and rapid change. Big-data and digital technologies are driving business transformation that is unlocking new capabilities and business innovations in areas like eCommerce, mobile experiences and IoT. The key to winning in these areas is being able to leverage enterprise data foundations built on PepsiCo’s global business scale to enable business insights, advanced analytics and new product development. PepsiCo’s Enterprise Data Operations (EDO) team is tasked with the responsibility of developing quality data collection processes, maintaining the integrity of our data foundations and enabling business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.

What PepsiCo Enterprise Data Operations (EDO) does:


 * Maintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company
 * Responsible for day-to-day data collection, transportation, maintenance/curation and access to the PepsiCo corporate data asset
 * Work cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders
 * Increase awareness about available data and democratize access to it across the company
   
   

As a member of the data engineering team, you will be the key technical expert developing and overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be an empowered member of a team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems.

Responsibilities


 * Active contributor to code development in projects and services.
 * Manage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products.
 * Build and own the automation and monitoring frameworks that captures metrics and operational KPIs for data pipeline quality and performance.
 * Responsible for implementing best practices around systems integration, security, performance and data management.
 * Empower the business by creating value through the increased adoption of data, data science and business intelligence landscape.
 * Collaborate with internal clients (data science and product teams) to drive solutioning and POC discussions.
 * Develop and optimize procedures to “productionalize” data science models.
 * Define and manage SLA’s for data products and processes running in production.
 * Support large-scale experimentation done by data scientists.
 * Prototype new approaches and build solutions at scale.
 * Research in state-of-the-art methodologies.
 * Create documentation for learnings and knowledge transfer.
 * Create and audit reusable packages or libraries.
   
   

Compensation & Benefits:


 * The expected compensation range for this position is between $100,000 - $167,500 based on a full-time schedule.
 * Location, confirmed job-related skills and experience will be considered in setting actual starting salary.
 * Bonus based on performance and eligibility; target payout is 8% of annual salary paid out annually.
 * Paid time off subject to eligibility, including paid parental leave, vacation, sick, and bereavement.
 * In addition to salary, PepsiCo offers a comprehensive benefits package to support our employees and their families, subject to elections and eligibility: Medical, Dental, Vision, Disability, Health and Dependent Care Reimbursement Accounts, Employee Assistance Program (EAP), Insurance (Accident, Group Legal, Life), Defined Contribution Retirement Plan.
   
   

Qualifications


 * 4+ years of overall technology experience that includes at least 3+ years of hands-on software development, data engineering, and systems architecture.
 * 3+ years of experience with Data Lake Infrastructure, Data Warehousing, and Data Analytics tools.
 * 3+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.).
 * 2+ years in cloud data engineering experience in Azure
 * Experience with Azure Data Factory, Azure Databricks and Azure Machine learning tools is a plus.
 * Fluent with Azure cloud services. Azure Certification is a plus.
 * Experience with integration of multi cloud services with on-premises technologies.
 * Experience with data modeling, data warehousing, and building high-volume ETL/ELT pipelines.
 * Experience with data profiling and data quality tools like Apache Griffin, Deequ, and Great Expectations.
 * Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.
 * Experience with at least one MPP database technology such as Redshift, Synapse or SnowFlake.
 * Experience with running and scaling applications on the cloud infrastructure and containerized services like Kubernetes.
 * Experience with version control systems like Github and deployment & CI tools.
 * Experience with Statistical/ML techniques is a plus.
 * Experience with building solutions in the retail or in the supply chain space is a plus
 * Understanding of metadata management, data lineage, and data glossaries is a plus.
 * Working knowledge of agile development, including DevOps and DataOps concepts.
 * Familiarity with business intelligence tools (such as PowerBI).
   
   

Education


 * BA/BS in Computer Science, Math, Physics, or other technical fields.
   
   

Skills, Abilities, Knowledge


 * Excellent communication skills, both verbal and written, along with the ability to influence and demonstrate confidence in communications with senior level management.
 * Proven track record of leading, mentoring data teams.
 * Strong change manager. Comfortable with change, especially that which arises through company growth. Able to lead a team effectively through times of change.
 * Ability to understand and translate business requirements into data and technical requirements.
 * High degree of organization and ability to manage multiple, competing projects and priorities simultaneously.
 * Positive and flexible attitude to enable adjusting to different needs in an ever-changing environment.
 * Strong leadership, organizational and interpersonal skills; comfortable managing trade-offs.
 * Foster a team culture of accountability, communication, and self-management.
 * Proactively drives impact and engagement while bringing others along.
 * Consistently attain/exceed individual and team goals
 * Ability to lead others without direct authority in a matrixed environment.
   
   

Competencies


 * Highly influential and having the ability to educate challenging stakeholders on the role of data and its purpose in the business.
 * Understands both the engineering and business side of the Data Products released.
 * Places the user in the center of decision making.
 * Teams up and collaborates for speed, agility, and innovation.
 * Experience with and embraces agile methodologies.
 * Strong negotiation and decision-making skill.
 * Experience managing and working with globally distributed teams.
   
   

EEO Statement

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.

PepsiCo is an Equal Opportunity Employer: Female / Minority / Disability / Protected Veteran / Sexual Orientation / Gender Identity

If you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy.

Please view our Pay Transparency Statement",Full-time
4092606962,1586.0,Data Engineer,"Description

We are a team of doers working passionately to apply cutting-edge advances in technology to solve real-world problems. As a Data Engineer, you will participate in developing exciting products for customers and analytics for our daily operations.

You would be joining the Device, Digital & Alexa Support (D2AS) organization which provides best in class customer support technologies for customers using Amazon products.

Key job responsibilities


 * Work closely with data scientists and business intelligence engineers to create robust data architectures and pipelines.
 * Simplify and enhance the accessibility, clarity, and usability of large or complex datasets through the development of advanced BI dashboards and applications.
 * Take ownership of the design, creation, and upkeep of metrics, reports, analyses, and dashboards to inform key business decisions.
 * Navigate ambiguous environments by evaluating various options using both data-driven insights and business expertise.
 * Develop and manage scalable, automated, and fault-tolerant data solutions using cutting-edge technologies such as Spark, EMR, Python, Redshift, Glue, and S3.
   
   

A day in the life

Data Engineers focus on managing customer requests, maintaining operational excellence, and enhancing core infrastructure. You will be collaborating closely with both technical and non-technical teams to design and execute roadmaps for essential Devices and Digital metrics.

If you are not sure that every qualification on the list above describes you exactly, we'd still love to hear from you! At Amazon, we value people with unique backgrounds, experiences, and skillsets. If you’re passionate about this role and want to make an impact on a global scale, please apply!

Benefits Summary

Amazon offers a full range of benefits that support you and eligible family members, including domestic partners and their children. Benefits can vary by location, the number of regularly scheduled hours you work, length of employment, and job status such as seasonal or temporary employment. The benefits that generally apply to regular, full-time employees include:


 * Medical, Dental, and Vision Coverage
 * Maternity and Parental Leave Options
 * Paid Time Off (PTO)
 * 401(k) Plan
   
   

About The Team

Our team manages a secure and compliant infrastructure that adapts to evolving data requirements for Devices and Digital teams. This involves solving data engineering challenges to create high-quality, reliable, accurate, consistent, and scalable data solutions that align with our business goals.

Basic Qualifications


 * 3+ years of data engineering experience
 * Experience with data modeling, warehousing and building ETL pipelines
 * Experience with one or more query language (e.g., SQL, PL/SQL, DDL, MDX, HiveQL, SparkSQL, Scala)
 * Experience with one or more scripting language (e.g., Python, KornShell)
 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with data visualization software (e.g., AWS QuickSight or Tableau) or open-source project
 * Bachelor's degree, or Master's degree
   
   

Preferred Qualifications


 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Los Angeles County applicants: Job duties for this position include: work safely and cooperatively with other employees, supervisors, and staff; adhere to standards of excellence despite stressful conditions; communicate effectively and respectfully with employees, supervisors, and staff to ensure exceptional customer service; and follow all federal, state, and local laws and Company policies. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation. Pursuant to the Los Angeles County Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com Services LLC

Job ID: A2847695",Full-time
4151876036,3255717.0,Data Engineer,"Are you looking for a fast-growing, innovative, and data-driven company? You’ve come to the right place! We are looking for a Data Engineer to join DWC’s Information Technology team.. The Data Engineer is responsible for designing, developing, and maintaining data pipelines and infrastructure to support the company's data-driven initiatives. The ideal candidate will have a strong understanding of data engineering principles and experience working with big data technologies, as well as popular data visualization tools.

What you will be doing:


 * Design and develop data pipelines to extract, transform, and load data from various sources into the company's data warehouse
 * Develop and maintain data integration processes to ensure data consistency and accuracy
 * Implement data quality checks and monitoring to identify and resolve data issues
 * Work with other DWC employees to understand their data needs and develop solutions to meet those needs
 * Optimize data pipelines for performance and scalability
 * Stay up-to-date on the latest data engineering technologies and best practices
   
   

Requirements:


 * 3+ years of experience in data engineering or a related field
 * Strong understanding of data warehousing concepts and technologies
 * Experience with data integration tools and technologies
 * Experience with data quality tools and techniques
 * Excellent written and verbal communication skills
 * Ability to understand and document technical requirements and software relationships in an organized manner
 * Ability to work well with a team or independently
 * Bachelor’s degree in Computer Science, Information Systems, or a related field preferred
 * Experience with Fivetran, Snowflake, and/or Looker preferred
   
   

Salary Range: $90,000 - $105,000 based on degree of experience

Some reasons you want to work at DWC


 * Medical, Dental, Vision Insurance
 * Company paid Life
 * Voluntary life, short- and long-term disability
 * 401k
 * Excellent time off options
 * Caring family
 * The work that you do matters
   
   

Distributor Wire & Cable is an equal opportunity employer

Powered by JazzHR

OF8RtzaVy3",Full-time
4129675524,164518.0,Data Engineer I,"If you are an internal associate, please login to Workday and apply through Jobs Hub.

Job Purpose

The Data Engineer I will be responsible for building and supporting the data platform. The Data Engineer will provide the development and automation of computing processes to detect, and respond to opportunities in business operations. The Data Engineer will work with a variety of disparate datasets that encompass many disciplines and business units. They will strive to transform and implement true business integration, leveraging top-notch data integration best practices. Merging and securing data in a way that reduces the cost to maintain and increases the utilization of enterprise-wide data as an asset and developing business intelligence.

Essential Responsibilities


 * Engineers and implements solutions that align to architecture patterns and security guidelines for data, compute and technology platforms, meeting business needs.
 * Works in partnership with business product owners, and DevSecOps to engineer and build mature scalable and robust business capabilities.
 * Follows IT architecture and IT operations guidelines and requirements while implementing optimal engineering solutions for the company.
 * Participates in engineering and planning initiatives related to capabilities, future roadmaps, operations, and strategic planning.
 * Engineers and implements business and technology innovation that drives the organization's top and bottom lines.
 * Stays current with industry trends, making recommendations of new technologies that deliver strategic business value and reduce costs.
 * Engineers and implements architecture solutions that maximize reuse and are efficient, maintainable, scalable, stable, highly available, portable, secure, and implemented correctly.
 * Strong communication competency across all levels of stakeholders, providing engineering guidance and insight into best practices.
 * Follows organizational policies and goals for IT security, change management, and operational risk.
 * Synthesizes information into clear and concise materials with thoughtful attention to detail and quality.
 * Provides engineering consulting services within domain to help achieve desired business and operational outcomes across Jackson.
 * Engineers and implements the service management processes for maintaining the technology platforms in production.
 * Acquires and maintains a working knowledge of Jackson processes and procedures across various departments.
 * Assists in researching, planning, and executing the migration of on-prem data infrastructure to Azure, including evaluating tradeoffs between cost, performance, and maintainability.
 * Develops and maintains data pipelines for complex business use cases.
 * Develops, designs, and builds solutions on a platform dedicated to large-scale processing of various data sets.
 * Collaborates with IT architecture and IT operations to identify and implement the most optimal data engineering solutions for the company.
 * Collaborates with team to execute and iterate on application development, including interfacing with
 * legacy databases, parsing raw structured and unstructured data, documenting the data warehouse, debugging, and deploying to production environments.
 * Collaborates with other teams to clarify and answer complex business questions using statistical and graphical approaches.
 * Employs exceptional problem-solving skills, with the ability to see and solve issues before applications are moved to production systems.
 * Sets, communicates, and reinforces technical standards.
 * Leads and develops best practices for larger Data Engineer Community of Practice (Data CoP).
 * Stays current with industry trends, makes recommendations of new technologies that deliver strategic business value and reduce costs.
 * Performs other duties and/or projects as assigned.
   
   

Knowledge, Skills And Abilities


 * Knowledge of industry standards, emerging technologies; and security and system best practices.
 * Excellent verbal and written communication skills including presentation creation and delivery.
 * Experience with the Microsoft Cloud ecosystem.
 * Strong organizational skills; ability to independently prioritize tasks and projects to meet deadlines.
 * Strong collaboration skills with the ability to build consensus, influencing across all levels in the organization.
 * Ability to learn and maintain a comprehensive understanding of finance/insurance business and technology.
 * Knowledge of Lean and Agile principles, systems, and tools.
 * Ability to explain and communicate technical concepts clearly.
 * Ability to conduct gap analysis and identify possible solutions for continuous improvements.
 * Basic programming skills in Python, R, Powershell and or Java with experience parsing, manipulating, and converting data to and from a wide range of formats (CSV, json, XML, html, SQL tables, etc.).
 * Good understanding of modern database concepts and SQL syntax, including experience with DB2, MongoDB, SQL Server, CosmosDB, Data Lake, Hadoop, etc.
 * Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
 * Strong analytic skills related to working with unstructured datasets.
 * Build processes supporting data transformation, data structures, metadata, dependency and workload management.
   
   

Qualifications


 * Bachelor's Degree in Computer Science/Computer Engineering and/or equivalent experience required.
 * 2+ years related IT experience required.
 * 1+ years in Data Engineering required.
 * Software development or related position experience preferred.
 * 1+ years SQL, relational database experience and unstructured datasets required.
 * 1+ years experience Azure Databricks, Azure Data Factory, Python, C# (preferred) Java, SDLC, Terraform, Spark, Config Management and Monitoring required.
 * 1+ years experience using Agile methodologies, data streaming, data as a service (REST APIs), CI/CD pipelines, Parquet, JSON preferred.
 * 1+ years experience working with Jupyter notebooks, microservices and data modeling preferred.
 * 1+ years IT infrastructure/operations role preferred.
 * Certification in Azure Fundamentals & Data Engineer upon hire preferred.
   
   

We don't just accept difference - we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Jackson is proud to be an equal opportunity workplace. The Company subscribes to and endorses federal and state laws and regulations relating to equal employment opportunity for all persons without regard to race, color, religion, gender, age, national origin, legally-recognized disability, marital status, legally-protected medical condition, citizenship, ancestry, height, weight, sexual orientation, veteran status, or any other factor not related to the needs of the job. The Company is committed to a policy of equal opportunity. Company facilities and campuses are tobacco-free environments.",Full-time
4089861426,2646.0,Data Engineer III,"Position Summary...

What you'll do...

Join us as a Data Engineer III where you'll play a pivotal role in transforming and integrating data, crafting robust data models, and developing innovative solutions. You'll work closely with stakeholders to identify data sources, ensure quality, and implement effective data governance practices. If you're passionate about leveraging data to drive business success, shaping strategic decisions, and leading the charge in data transformation, we want you on our team. Dive into a role where your expertise not only influences data architecture but also supports impactful business outcomes.

About Team

The Data Sharing & Collab Team helps Suppliers to ingest data in lowest granularity with ease of adoption and always on par with latest Tech stats exploration like Deltashare, Databricks, Snowflake etc. This team will help to grow adoption as the tech expert and share visibility on the product value add.

What You’ll Do


 * Data Transformation and Integration: Extract and transform data from databases, create data pipelines, and stay updated on analytics trends
 * Data Source and Modeling: Identify suitable data sources, perform quality checks, develop and evaluate data models, and design efficient data flows
 * Code Development and Testing: Write and test code for solutions, develop proofs of concept, deploy software, and document progress
 * Applied Business Acumen: Translate business requirements into projects, recommend solutions, develop business cases, and align projects with business strategy
 * Data Governance: Implement and document data governance practices, educate stakeholders, and provide recommendations for improvements
   
   

What You’ll Bring


 * Understanding of software development lifecycle from planning to deployment
 * High-level proficiency in Java and Spring Boot
 * You have a proven track record coding with at least one programming language (e.g., Scala, Python)
 * You’re experienced in one of cloud computing platforms (e.g., GCP, Azure)
 * You’re skilled in data modeling & data migration protocols
 * Experience with containerization technologies WCNP, Docker, and Kubernetes
 * Experience with GCP, Data warehousing, BI preferred
 * Experience with the integration tools like Automic, Airflow, Autosys
 * Experience in building highly scalable Big Data solutions and ETL ecosystems
 * Working knowledge of CI/CD pipelines
 * Strong communication skills with the ability to not only understand but also articulate the how and why of a process and solution
   
   

Preferred Qualifications And Experience


 * Knowledge of Databricks and Snowflake is an added advantage
 * Hands on knowledge in NoSQL like Cosmos DB along with RDBMS like MySQL, Postgres is plus
 * Hands on working experience in any messaging platform like Kafka is preferred
 * Increase the efficiency of the team by setting right Processes of Software Development, Requirement Intake, Effort Estimation
 * Demonstrating creative, critical thinking & troubleshooting skills
   
   

About Walmart Global Tech

Imagine working in an environment where one line of code can make life easier for hundreds of millions of people.  That’s what we do at Walmart Global Tech. We’re a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world’s leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.

Flexible, hybrid work

We use a hybrid way of working with primary in office presence coupled with an optimal mix of virtual presence. We use our campuses to collaborate and be together in person, as business needs require and for development and networking opportunities. This approach helps us make quicker decisions, remove location barriers across our global team, be more flexible in our personal lives.

Benefits

Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include a host of best-in-class benefits maternity and parental leave, PTO, health benefits, and much more.

Equal Opportunity Employer

Walmart, Inc. is an Equal Opportunity Employer – By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions – while being inclusive of all people.

The above information has been designed to indicate the general nature and level of work performed in the role.  It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎

You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎

Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For Information About Benefits And Eligibility, See One.Walmart.

‎

Sunnyvale, California US-04397:The annual salary range for this position is $117,000.00-$234,000.00

‎

Bentonville, Arkansas US-09050:The annual salary range for this position is $90,000.00-$180,000.00

‎

‎

‎

‎

‎

‎

‎

‎

‎

‎

Additional Compensation Includes Annual Or Quarterly Performance Bonuses.

‎

Additional Compensation For Certain Positions May Also Include

‎

‎


 * Stock
   
   

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelor’s degree in Computer Science and 2 years' experience in software engineering or related field. Option 2: 4 years’ experience in

software engineering or related field. Option 3: Master's degree in Computer Science.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, Master’s degree in Computer Science or related field and 2 years' experience in software engineering or related field, We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

680 West California Avenue, Sunnyvale, CA 94086-4834, United States of America",Full-time
4143538863,3015.0,Data Engineer II-R-239977,"Our Purpose

Mastercard powers economies and empowers people in 200+ countries and territories worldwide. Together with our customers, we’re helping build a sustainable economy where everyone can prosper. We support a wide range of digital payments choices, making transactions secure, simple, smart and accessible. Our technology and innovation, partnerships and networks combine to deliver a unique set of products and services that help people, businesses and governments realize their greatest potential.

Title And Summary

Data Engineer II

Overview

We believe in power of data. We think creatively, design smart, simple to use, cost-effective solutions that empower our customer with actionable insights. The Global Business Services Center (GBSC) Analytics and Automation team is built upon strong contributors with leadership abilities, innovative mindsets and with strong business and technical acumen. The team acts as an idea incubator supporting various GBSC initiatives by providing in-depth analysis and strategic guidance. The team identifies ways to leverage data for answering business questions and driving operational efficiency. We innovate using new age technologies and data analysis techniques to discover actionable insights and communicate data in new and more effective ways for influencing business decisions, encouraging long-term customer engagement, improving processes and productivity, and overall evolving the way we do business.

Technology stack


 * Our current primary tools for data analysis, data preparation and information delivery: Alteryx and Tableau
 * Core database environments: Oracle, MS SQL Server
   
   
   

Role


 * Support multiple analytics projects and initiatives within GBSC and Mastercard.
 * Identify, design and implement data and process automation solutions to support GBSC Operations and the global organization.
 * Engage with various Mastercard teams to gather requirements for the projects and execute it End-to-End in individual contributor capacity.
 * Develop new queries and Alteryx flows for extracting, transforming and analysing data to address project requirements.
 * Develop Tableau dashboards and reports that adhere to the visualization best practices and communicate a story.
 * Participate in drafting documents and presentations for communicating innovations, ideas, or discoveries.
 * Contribute to strengthening a motivated, innovative and productive team that creates next generation analytics for the shared services center and Mastercard.
 * Generate and implement ideas to continuously improve analytics and reporting services delivery.
 * Work closely with analytics community of practice and internal customers (GBSC Operations) to identify short-term and long-term objective alignment.
   
   
   

All About You

A minimum of a Bachelor’s degree in Computer Science, Information Technology, Information Systems, Data Science, Statistics, Applied Mathematics, Business Administration, or any other related field. An equivalent of this requirement in working experience is also acceptable for the position

A candidate for this position must have had at least 3-4 years of relevant work experience in a data analyst position, preferably in a fast-paced financial services environment.

Strong knowledge of SQL; ability to write, execute and optimize performance of complex queries

High proficiency in Alteryx or similar ETL tool

High proficiency in Tableau, Power BI, or similar data visualization tools

High proficiency in data preparation/ETL

Excellent problem-solving and analytical skills.

Strong communication and collaboration skills.

Ability to communicate complex quantitative analysis in a clear, precise, and actionable manner with both technical and non-technical customers;

Intellectual curiosity and enthusiasm to apply data to discover and solve business challenges and questions;

Problem solving mentality, resourcefulness and creativity in identifying solutions;

Full stack experience in data collection, aggregation, analysis, visualization, productizing and maintenance of analytics products;

Expertise with information delivery and knowledge of data visualization techniques for operational and executive dashboards;

Knowledge of basic statistical analysis techniques and data mining methodologies.

The Following Would Be a Plus

Strong understanding of the Power Platform, including Power Apps, Power Automate, and Power BI

Experience with data integration and APIs.

Mastercard is an inclusive equal opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. In the US or Canada, if you require accommodations or assistance to complete the online application process or during the recruitment process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.

Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:


 * Abide by Mastercard’s security policies and practices;
 * Ensure the confidentiality and integrity of the information being accessed;
 * Report any suspected information security violation or breach, and
 * Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.
   
   
   

In line with Mastercard’s total compensation philosophy and assuming that the job will be performed in the US, the successful candidate will be offered a competitive base salary based on location, experience and other qualifications for the role and may be eligible for an annual bonus or commissions depending on the role. Mastercard benefits for full time (and certain part time) employees generally include: insurance (including medical, prescription drug, dental, vision, disability, life insurance), flexible spending account and health savings account, paid leaves (including 16 weeks new parent leave, up to 20 paid days bereavement leave), 10 annual paid sick days, 10 or more annual paid vacation days based on level, 5 personal days, 10 annual paid U.S. observed holidays, 401k with a best-in-class company match, deferred compensation for eligible roles, fitness reimbursement or on-site fitness facilities, eligibility for tuition reimbursement, gender-inclusive benefits and many more.

Pay Ranges

O'Fallon, Missouri: $92,000 - $147,000 USD

R-239977",Full-time
4125056035,93109232.0,Data Engineer,"At Guac, we're on a mission to solve grocery food waste with predictive ML. We forecast exactly how much of each product will sell, to put an end to the millions of tons of food that goes to waste every single day due to bad inventory replenishment.




We're currently working with major supermarket chains in the US (you've probably shopped at some of them before), and we're backed by Y Combinator, 1984 Ventures, Collaborative Fund, and angels from Instacart and Citadel Securities.

We're seeking a talented Data Engineer to join our team in-person in New York to help shape the future of grocery!




About the Role




As a Data Engineer at Guac, you'll have ownership over building and maintaining our ETL infrastructure and pipelines, as well as optimizing ML systems for forecasting grocery demand. You’ll also work directly with our customers to ensure successful technical integrations. 




Around 80% of your time will be spent on engineering:




 * Designing and implementing scalable data pipelines for processing large-scale data across multiple customers
 * Optimizing machine learning systems for demand forecasting
 * Expanding our recommendation engine to meet the needs of new customers
 * Contributing to our backend services to serve our mobile and web applications




You’ll be working across languages and technologies such as: Python, FastAPI, Dagster, GCP (including BigQuery), Dask, and SQL. 




Around 20% of your time will be spent on customer facing work:




 * Collaborating directly with customers' technical teams to ensure smooth data integrations and system implementations
 * Working with customers’ internal supply chain and store operations teams to understand and then implement their unique business logic 




About You




 * At least 3 years of relevant work experience and a minimum of a Bachelor’s degree or equivalent in Computer Science
 * Strong background in data engineering and experience with large-scale distributed data processing systems
 * Proven experience in implementing and deploying machine learning models, particularly for time series forecasting
 * Excellent communication skills with experience in customer-facing technical roles
 * Familiarity with modern data infrastructure and cloud computing platforms
 * Existing background in backend development (Python/FastAPI) is a big plus




Why Work with Us




 * Intellectually challenging problems that require a lot of thinking and creativity (like how to scale ML systems across diverse grocery chains). Since we’re still a small team, you won't be pigeon-holed into one problem, product, or technology
 * Make a real-world impact: the grocery industry is enormous (in the US, it accounts for ~4% of GDP), and we're excited about the potential for a huge impact we can make with better inventory operations on both grocers' bottom-line but also on the climate and food security
 * Engage with interesting customers and see the on-the-ground operations of the grocery industry",Full-time
4107748614,33246798.0,"Data Engineer, E-Commerce","Responsibilities

TikTok is the leading destination for short-form mobile video. At TikTok, our mission is to inspire creativity and bring joy. TikTok's global headquarters are in Los Angeles and Singapore, and its offices include New York, London, Dublin, Paris, Berlin, Dubai, Jakarta, Seoul, and Tokyo.

Why Join Us

Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible.

Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day.

To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always.

At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.

Join us.

As a data engineer in the Data Platform E-Commerce team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world. You'll have the opportunity to gain hands-on experience on all kinds of systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users.

This position can be based out of our Mountain View or Seattle office.

Responsibilities - What You'll Do


 * Design and build data transformations efficiently and reliably for different purposes (e.g. reporting, growth analysis, multi-dimensional analysis);
 * Design and implement reliable, scalable, robust and extensible big data systems that support core products and business;
 * Establish solid design and best engineering practice for engineers as well as non-technical people.
   
   

Qualifications

Minimum Requirements:


 * BS or MS degree in Computer Science or related technical field or equivalent practical experience;
 * Experience in the Big Data technologies(Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc.);
 * Experience with performing data analysis, data ingestion and data integration;
 * Experience with ETL(Extraction, Transformation & Loading) and architecting data systems;
 * Experience with schema design, data modeling and SQL queries;
 * Passionate and self-motivated about technologies in the Big Data area.
   
   

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at https://shorturl.at/cdpT2

Job Information

【For Pay Transparency】Compensation Description (Annually)

The base salary range for this position in the selected city is $136000 - $280000 annually.

Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.

Benefits may vary depending on the nature of employment and the country work location. Employees have day one access to medical, dental, and vision insurance, a 401(k) savings plan with company match, paid parental leave, short-term and long-term disability coverage, life insurance, wellbeing benefits, among others. Employees also receive 10 paid holidays per year, 10 paid sick days per year and 17 days of Paid Personal Time (prorated upon hire with increasing accruals by tenure).

The Company reserves the right to modify or change these benefits programs at any time, with or without notice.

For Los Angeles County (unincorporated) Candidates

Qualified applicants with arrest or conviction records will be considered for employment in accordance with all federal, state, and local laws including the Los Angeles County Fair Chance Ordinance for Employers and the California Fair Chance Act. Our company believes that criminal history may have a direct, adverse and negative relationship on the following job duties, potentially resulting in the withdrawal of the conditional offer of employment:


 * Interacting and occasionally having unsupervised contact with internal/external clients and/or colleagues;
 * Appropriately handling and managing confidential information including proprietary and trade secret information and access to information technology systems; and
 * Exercising sound judgment.",Full-time
4143045123,20922.0,Junior Data Engineer,"Position Summary

In pursuit of Audubon's conservation mission, the Data & Technology team partners with programmatic and business teams across the organization to develop and deploy enterprise data systems and data-driven practices at the scale needed to achieve our ambitious goals. The Junior Data Engineer will play a key role in helping maintain and support software applications and data solutions within a modern-day data stack, using enterprise scale data resources to ensure that high quality data is available across the organization to support conservation and operational objectives and advance our mission for hemispheric level bird conservation.

A successful candidate will be familiar with a number of data engineering tools and methods, as well as exhibiting strong communication and time management skills. This team member will work closely with other software and data engineers and report to the Director, Data Engineering.

This is a hybrid position based in Audubon’s New York City or Washington, DC offices. We will also consider remote candidates within the United States.

Working closely with other Data team members and project stakeholders, the Junior Data Engineer will contribute to projects such as:


 * Strengthening an enterprise data architecture and strategy that includes ELT, systems integration, governance, cataloging and quality control
 * Supporting and improving operational data processes to ensure data quality and reduce technical debt in critical functional business areas such as finance and fundraising
 * Improving inclusive outreach, membership growth and advocacy engagement among prospective and current Audubon members by bringing together disparate data sets from CRM systems, census, demographic, social media and web analytics data sources
   
   

This position is funded through December 2026.

Compensation

Salary range based on geo-differentials:


 * $25.00 - $30.00 / hour = National
 * $30.00 - $35.00 / hour = Alaska, CA (not San Francisco), Connecticut, D.C., Chicago, Oyster Bay, NY
 * $35.00 - $40.00 / hour = NYC (not Oyster Bay), San Francisco, Seattle
   
   

Additional Job Description

Essential Functions


 * Support and maintain data workflows and business applications critical to Audubon’s operational success, leveraging enterprise data architecture tools and applications built in legacy tools and frameworks (such as .NET).
 * Assist in modernizing data integrations between various data systems using a light-weight Python orchestration environment (Apache Airflow).
 * Work closely with the Senior Coordinator of Data & Technology to help grow the maintainability of the technical stack by documenting support processes and systems interactions, as well as to helping to prioritize support needs and communicate solutions to stakeholders.
 * Collaborate with various members of the organization to perform ad-hoc data explorations and analysis to troubleshoot data issues and clarify business requirements.
 * Administer secure access to the data, including implementing data governance practices, user permissioning for systems and data sources, data hiding strategies such as row-level permissions and data masking.
 * Contribute to the development and implementation of risk-mitigation efforts, including a disaster recovery program and job health monitoring.
 * Contribute to initiatives that improve Audubon's data governance, documentation, and data quality standards. Implements that guidance in practice with methodology documentation, metadata, code comments, etc.
 * Convey willingness and customer orientation to train users of varying backgrounds and skillsets to utilize and partner in improving data engineering processes and practices.
 * Collaborate with Audubon staff to ensure that equity, diversity, inclusion and belonging principles are incorporated and followed in all aspects of our work.
 * Travel two or more times a year to attend in person meetings and events.
 * Perform other job-related duties as assigned.
   
   

Qualifications And Experience


 * 0-2 years of experience as a Data Engineer, or in similar roles such as Software Engineer, Data Analyst, or Database Administrator.
 * Bachelor’s Degree in Computer Science, Information Technology, Statistics, Data Science, Mathematics, or related quantitative field preferred. An equivalent combination of education and work experience will also be considered.
 * Proficiency in at least one high-level programming language such as Python, Java, or .NET.
 * Strong SQL coding ability.
 * Familiarity with software version control, such as Git.
 * Experience utilizing modern data infrastructure tools such as cloud data warehouses (Snowflake, BigQuery, etc.), data integration tools (dbt, Fivetran, Airflow, etc.), business intelligence tools (PowerBI, Sigma, etc.), CRM systems (Salesforce, Everyaction, etc.), and other enterprise data tools (such as Airtable) required.
 * Demonstrated experience applying technical coordination and project management best practices using tools such as Asana and Jira required.
 * Demonstrated ability to communicate technical information to non-technical audiences.
 * Ability to collaborate with colleagues with transparency, inclusivity and trust.
 * Self-starter who can work as part of a virtual team and remain motivated in a dynamic environment.
 * Curiosity to stay on the cusp of software and product trends in non-profits and the greater tech industry.
 * Commitment to Audubon’s organizational values of care, collaboration, change, integrity, impact, and innovation.
 * Demonstrated personal and professional commitment to and experience in advancing equity, diversity, inclusion, and belonging.
 * Genuine passion for conservation and the mission of the National Audubon Society.
 * Ability to travel at least two times a year.
   
   

This position is represented by the Communication Workers of America (CWA).

National Audubon Society Competencies: This role will also be accountable to apply and develop the following competencies.

Building Relationships: Establish and nurture meaningful connections and trust with others while fostering an environment of inclusivity and respect.

Problem Solving: Find effective solutions to challenges and support decision-making by drawing on critical thinking, creativity, and systematic approaches.

Accountability: Be reliable and trustworthy in fulfilling commitments while recognizing inequities that may impact the ability of others to fulfill responsibilities effectively.

Supporting Change: Adapt to changes and modify behavior in response to new information or unexpected obstacles while considering the diverse needs of others.

Critical Thinking: Take an active approach to analyzing, evaluating, and interpreting information or situations objectively and logically to make informed decisions or judgments.",Full-time
4142279985,72048424.0,Data Engineer,"About the Company




Forian provides a unique suite of SaaS solutions, data management capabilities, and proprietary data and analytics to optimize and measure operational, clinical, and financial performance for customers within the traditional and emerging life sciences, healthcare payer and provider segments.




Location




Position is remote; We will only consider candidates in the following states: MA, NJ, NY, PA, MD, CT







About the Role




The Healthcare Data Engineer will be responsible for building, maintaining, and improving data pipelines. The ideal candidate has strong experience with data structures and algorithms. The data engineer will work closely with the VP of Data Engineering, the Product team and occasionally with the Sales team. Attention to detail, strong intuition, problem-solving, and a customer service mindset are needed.







Responsibilities




 * Building and maintaining data pipelines
 * Monitoring data products, focusing on identifying data anomalies, and taking action to solve them
 * Optimizing existing data processes
 * Support data analysis and investigations, for both internal and external stakeholders
 * Develop and maintain documentation of data processes and products







Qualifications




 * Bachelor’s degree in Computer Science, Data Engineering, or a quantitative field
 * Minimum three years of experience working with large and complex datasets
 * Strong experience with SQL and Python
 * Minimum two years of experience with cloud platforms (eg AWS, Azure, GCP)
 * Excellent communication and interpersonal skills
 * Effective problem-solving skills
 * Strong CICD knowledge







Preferred Skills




 * Two or more years of experience working with healthcare data
 * PySpark , Linux
 * Experience with statistical inference
 * Experience with Snowflake and Databricks
 * The ability to teach and train others







Equal Opportunity Statement




Forian Inc. is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.




*** Applicants must be authorized to work for ANY employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time. ***",Full-time
4120825482,10667.0,"Data Engineer, Product Analytics","As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a world-class data engineering community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Data Engineer, Product Analytics Responsibilities:


 * Manage and execute data warehouse plans for a product or a group of products to solve well-scoped problems
 * Identify the data needed for a business problem and implement logging required to ensure availability of data, while working with data infrastructure to triage issues and resolve
 * Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights in a meaningful way
 * Build data expertise and leverage data controls to ensure privacy, security, compliance, data quality, and operations for allocated areas of ownership
 * Design, build and launch new data models and visualizations in production, leveraging common development toolkits
 * Independently design, build and launch new data extraction, transformation and loading processes in production, mentoring others around efficient queries
 * Support existing processes running in production and implement optimized solutions with limited guidance
 * Define and manage Service Level Agreements for data sets in allocated areas of ownership
   
   

Minimum Qualifications:


 * Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent
 * 2+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions
 * 2+ years of experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala or others.)
   
   

Preferred Qualifications:


 * Master's or Ph.D degree in a STEM field
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$114,000/year to $171,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4132964570,18503560.0,Data Engineer (Healthcare Data),"About Pangaea Data

Pangaea Data (Pangaea) is a South San Francisco and London based business founded by Dr Vibhor Gupta and Prof Yike Guo (Director Data Science Institute at Imperial College London; Provost, Hong Kong University of Science and Technology). They have worked in medicine and computing for over 20 years and have raised over $300 million through their academic research, including a $110 million grant focused on development work on large language models in medicine. Pangaea’s AI platform, PALLUX, is configured on clinical guidelines to find more untreated (undiagnosed, miscoded, at-risk) and under-treated patients with hard-to-diagnose conditions for screening and treatment at the point of care. Pangaea’s advisors include industry veterans from healthcare and the life sciences, including Lord David Prior (former chairman, NHS England) and Mr. Andy Palmer (former CIO, Novartis).

The Role

As Data Engineer (Healthcare Data), you will join Pangaea’s team to lead and support the development of reliable, scalable, and secure data solutions. The ideal candidate will be experienced with healthcare data standards (e.g. FHIR, OMOP), possess a strong understanding of data privacy regulations (e.g., HIPAA, GDPR), and have technical expertise to design and implement data pipelines, storage systems, and integrations.

This role will continue to evolve as the business grows, but in the short term it will also involve development of the software product and collaboration with the clinical and scientific team. A strong software engineering background and knowledge in AI, especially Machine Learning and Natural Language Processing, is essential. For the right candidate, this is a senior technical position with scope to grow into a leadership role.

Key Technical Responsibilities Will Include


 * Design, implement, and maintain ETL pipelines to collect, clean, and transform healthcare data from various sources such as EHR systems, APIs, and databases
 * Ensure data quality and integrity through robust testing and validation processes
 * Optimize storage solutions for structured and unstructured healthcare data using databases (e.g., MongoDB) and cloud-based data warehouses (e.g., Azure Cosmos, Azure Fabric)
 * Maintain strict compliance with data privacy regulations such as HIPAA, GDPR, and other local healthcare policies
 * Work closely with the clinical team to understand data requirements and translate them into technical solutions
 * Collaborate with the AI team to provide clean, well-structured datasets for research, and AI/ML models
 * Stay up-to-date with the latest data engineering technologies and best practices
   
   

Mandatory Requirements

Technical Skills


 * Experience working with Electronic Health Records (EHR) systems (e.g. Epic, Cerner)
 * A university qualification (Bachelors, Masters, Doctorate) with at least two years of university study in Computer Science, Informatics, Data Science, Engineering, or related
 * Experience in data engineering, with a focus on healthcare data preferred
 * Familiarity with NoSQL databases (e.g., MongoDB) and relational databases (e.g., PostgreSQL, MySQL)
 * 5+ years in Python and SQL work
 * Knowledge of ETL tools (e.g., Apache Airflow) and cloud platforms (e.g., AWS, Azure, GCP).
 * Understand data modelling concepts and best practices. Experience with healthcare data standards (e.g., HL7, FHIR, ICD, SNOMED, DICOM) preferred
 * Excellent problem-solving and communication skills
   
   

Personal Traits


 * Ability to communicate complex ideas effectively, both verbally and written
 * Ability to engage all levels of the company and the customers’ organizations
 * Ability to work collaboratively in a team environment
   
   

Nice to Have


 * 3-5 years experience of managing teams
 * Experience working on large-scale, commercial software development projects is a plus
 * Experience with research communities and/or efforts, including having published papers (being listed as author) at AI/ML/NLP/CV conferences (e.g. Bio-IT, NeuraIPS, ICML, ICLR, ACL, CVPR and KDD) and journals
 * Experience and knowledge of deploying AI and Data solutions for healthcare and pharmaceuticals at scale is desirable
   
   

Perks and Benefits


 * Flexible working hours
 * Salary dependent on experience
 * Package of attractive benefits including private medical insurance and monthly travel card
 * You will join a dedicated highly renowned team offering you the opportunity to grow and develop your professional skills and profile
 * You will have the opportunity to learn about building a startup business from experienced professionals and serial entrepreneurs
   
   

Application Contact Information

Your application should include a CV and cover letter highlighting your relevant experiences and motivations. Please send this to careers@pangaeadata.ai

General Information

Pangaea Data is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances.",Full-time
4145412381,36094.0,Data Engineer,"About GAINSystems:

GAINS is a leading provider of cloud Supply Chain solutions based in the Chicago neighborhood of Wicker Park. As part of the Francisco Partners portfolio of specialized companies, we are rapidly growing and expanding our global teams to drive innovation, deliver customer value, and accelerate market leadership.

Supply chain volatility has made it difficult for businesses to plan and keep their customer promises. GAINS helps companies address these challenges with innovative solutions leveraging proven AI and ML techniques. Our team of industry and technology experts rapidly delivers transformational value resulting in sustainable and measurable ROI-based impact for our global customers. If you are a technology enthusiast who wants to make an impact, then GAINS is for you.

Description:

We are seeking a Data Engineer to join our dynamic team and play a key role in designing, building, and optimizing our data pipelines, ML operations and streaming architectures. The ideal candidate will have strong expertise in Python, PySpark, Databricks, and Kafka, with experience in handling large-scale data processing, real-time data streaming, and cloud-based data solutions.

Key Responsibilities


 * Design, develop, and maintain scalable ETL/ELT pipelines using Python, PySpark and Databricks
 * Implement real-time data streaming solutions using Apache Kafka
 * Optimize data ingestion, processing, and transformation workflows for performance and reliability
 * Work closely with data scientists, analysts, and business stakeholders to provide high-quality data solutions
 * Ensure data integrity, security, and compliance with industry best practices
 * Monitor and troubleshoot data pipeline performance and real-time streaming issues
 * Implement DevOps and CI/CD practices for data engineering workflows
 * Collaborate with cross-functional teams to support business intelligence, machine learning, and analytics initiatives
   
   

Required Skills & Qualifications


 * Proven experience as a Data Engineer or similar role with 3 or more years of industry experience
 * Strong proficiency in Python for data processing and automation
 * Hands-on experience with Databricks for big data processing and analytics
 * Expertise in Apache Kafka for building scalable real-time data streaming solutions
 * Experience with SQL and NoSQL databases for structured and unstructured data storage
 * Familiarity with cloud platforms (AWS, Azure, or GCP) and their data services
 * Knowledge of CI/CD pipelines, containerization (Docker, Kubernetes), and orchestration tools like Airflow
 * Strong problem-solving and debugging skills in distributed computing environments
 * Strong understanding of Data Ops principles
   
   

Preferred Qualifications


 * Experience with Microsoft Azure, Delta Lake, and Lakehouse architecture
 * Experience with ML and specifically MlFlow
   
   

At GAINS, we recognize that diversity and inclusion make our teams stronger. We are committed to equal employment opportunity and welcome everyone regardless of race, color, ancestry, religion, national origin, age, sex, gender identity, sexual orientation, disability, marital status, domestic partner status, veteran status or medical condition. We encourage people from all backgrounds to apply.

Powered by JazzHR

r1SvbeP233",Full-time
4149980852,1035.0,Data Engineer,"Do you want to help revolutionize how Microsoft measures, monitors, and manages its multi-billion business portfolio? Do you want to design and build the next generation of user experiences and analytics platforms using cutting-edge technology? Do you want to influence product engineering teams to shape the next generation of data and analytics capabilities available to millions of Microsoft customers worldwide?

The Finance Data and Experiences Team is seeking a highly motivated Data Engineer to support the OneTax Data Management and Engineering team. This team is dedicated to executing business operations and data management of the OneTax system, which includes delivering business-relevant initiatives and driving tool strategy. OneTax is an enterprise reporting application that encompasses all of Microsoft’s Indirect Tax data and supports tax compliance, audits, and planning. It is a cloud-built big data solution leveraging the latest Azure technologies to process hundreds of millions of rows of data per month. OneTax has a worldwide user base, and the team’s mission is to serve those users by enabling compliant tax filings, audit support, and data insights through trusted and timely tax data.

We pride ourselves on a culture of customer centricity, innovation, agility, transparency, and flexibility. We are always eager to hear new ideas and promote out of the box thinking when addressing complex process, architecture, or technology challenges.

Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.

In alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day.

Responsibilities

As a Data Engineer, you will have the opportunity to partner with the Tax organization as well as multiple Engineering teams to design, develop and implement tax reporting solutions for all of Microsoft. In this role, you will work with Azure, SQL, Synapse, Fabric and other cloud-native platforms to help architect and develop a suite of future-state analytics capabilities.

To be successful in this role, you will be able to do the following:


 * Apply standard modification techniques and operations (e.g., inserting, aggregating, joining) to transform raw data into compatible formats for downstream data sources and databases, employing software, query languages, and computing tools to assess and enhance data quality and completeness.
 * Follow data modeling and data handling procedures to maintain compliance with applicable laws and policies across assigned workstreams.
 * Understand security initiatives and implement security standards in the solutioning.
 * Perform root cause analysis to identify reasons for detected problems and anomalies, implementing basic solutions to minimize points of failure to ensure data quality and optimal performance throughout the data lifecycle.
 * Collaborate with stakeholders to understand and capture the business challenge, evaluate feasibility, and rapidly develop streamlined dashboards and reporting solutions.
 * Understand dependencies across multiple systems and provide data-based insights into the health of data products owned by the team according to service level agreements (SLAs).
 * Engage fully in all components of the SDLC release cycle with Engineering and prepare and execute end-to-end test scenarios.
 * Investigate and manage user support inquiries and escalation inquiries about Microsoft data, tools, and processes.
 * Be available outside of business hours to support financial close procedures and attend calls to support technical incidents.
 * Leverage AI technologies, including Microsoft Fabric and OpenAI, to enhance data processing, analysis, and reporting capabilities.
 * Embody our culture and values
   
   

Qualifications

Required/Minimum Qualifications


 * Bachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering , or related field AND 2+ years experience in business analytics, data science, software development, data modeling or data engineering work
    * OR Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering or related field AND 1+ year(s) experience in business analytics, data science, software development, or data engineering work
    * OR equivalent experience.

 * This role does require you to be onsite 3+ days a week.
   

Additional Or Preferred Qualifications


 * 5-7 years of data engineering experience with big data processing systems or online services.
 * 5-7 years of experience with any of the following: (SQL, Python, DAX, Power BI, Power Query, Tableau).
 * Advanced experience and skills in SQL, Azure Synapse, Azure Data Lake, Azure Databricks, and other leading-edge technologies.
 * Effective problem-solving skills and the ability to utilize experience to improve processes.
 * The ability to multi-task and deal effectively with ambiguity.
 * Experience in analyzing large volumes of data, extracting insights, and processing large data sets.
 * Proven process improvement/automation experience.
 * Knowledge of AI technologies, including Microsoft Fabric and OpenAI.
 * Knowledge of tax and revenue financial reporting.
 * Ability to ramp up quickly on new technologies.
   
   

Data Engineering IC3 - The typical base pay range for this role across the U.S. is USD $98,300 - $193,200 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $127,200 - $208,800 per year.

Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay

Microsoft will accept applications for the role until February 18, 2025.

#FD&E #CFT #Finance

Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",Full-time
4152194959,4030.0,Data Analytics Engineer Co-op,"You know the moment. It’s the first notes of that song you love, the intro to your favorite movie, or simply the sound of someone you love saying “hello.” It’s in these moments that sound matters most.

At Bose, we believe sound is the most powerful force on earth. We’ve dedicated ourselves to improving it for nearly 60 years. And we’re passionate down to our bones about making whatever you’re listening to a little more magical.

The Corporate Strategy team at Bose works on some of the company’s most important business and growth initiatives. We work closely with executive leadership and cross-functional teams across the company to analyze market opportunities, create winning strategies, and inform important decisions with insightful, data-driven recommendations based on a deep knowledge of the business, customers, and external market factors.

Job Description

About the Role:

We are looking for a Data Analytics Engineering Co-op to join our Data and Analytics Center of Excellence (D&A CoE). This role provides an exciting opportunity to gain hands-on experience in the data and analytics engineering work that drives a multi-billion dollar business like Bose. You will work alongside experienced professionals to develop and support data-driven solutions that enhance business strategies and improve customer experiences.

As a Data Analytics Engineering Co-op, you will assist in transforming raw, diverse datasets into meaningful insights. This includes data pipeline development and modeling work that supports business analysts as well as data scientists who are creating AI solutions. Applications include marketing, engineering, product development, supply chain, and finance. You will work with a modern technology stack, including AWS and Snowflake, and write code using engineering best practices. This role is ideal for someone who is eager to learn, detail-oriented, and passionate about leveraging data to drive decision-making. Quality data models are the foundation of what we do in the D&A CoE, from executive level reporting to AI models that optimize our business.

Key Responsibilities


 * Assist in the development and maintenance of business-critical data pipelines, typically built in SQL and Python
 * Support the design and implementation of logical and physical data models to enhance data accessibility.
 * Conduct data wrangling and preprocessing to clean and structure datasets for analysis.
 * Help build and maintain semantic layers to enable dashboard development and data science work.
 * Contribute to new tools and techniques that make data analytics engineering more efficient and effective.
 * Work with cross-functional teams to understand business requirements and translate them into data solutions.
 * Assist in creating dashboards and reports that provide actionable insights for business teams.
 * Learn and apply best practices for data governance, security, and quality assurance.
   
   

Bose is an equal opportunity employer that is committed to inclusion and diversity. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, genetic information, national origin, age, disability, veteran status, or any other legally protected characteristics. For additional information, please review: (1) the EEO is the Law Poster (http://www.dol.gov/ofccp/regs/compliance/posters/pdf/OFCCP_EEO_Supplement_Final_JRF_QA_508c.pdf); and (2) its Supplements (http://www.dol.gov/ofccp/regs/compliance/posters/ofccpost.htm). Please note, the company's pay transparency is available at http://www.dol.gov/ofccp/pdf/EO13665_PrescribedNondiscriminationPostingLanguage_JRFQA508c.pdf. Bose is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the application or employment process, please send an e-mail to Wellbeing@bose.com and let us know the nature of your request and your contact information.

Our goal is to create an atmosphere where every candidate feels supported and empowered in the interviewing process. Diversity and inclusion are integral to our success, and we believe that providing reasonable accommodation is not only a legal obligation but also a fundamental aspect of our commitment to being an employer of choice. We recognize that individuals may have different needs and requirements based on their abilities, and we provide reasonable accommodations to ensure ideal conditions are met during the application process.

If you believe you need a reasonable accommodation, please send a note to wellbeing@bose.com",Full-time
4141579029,52160608.0,Data Engineer,"🚀 Join the Future of Commerce with Whatnot!

Whatnot is the largest livestream shopping platform in North America and Europe to buy, sell, and discover the things you love. We’re re-defining e-commerce by blending community, shopping, and entertainment into a community just for you. As a remote co-located team, we’re inspired by innovation and anchored in our values. With hubs in the US, UK, Ireland, Poland, and Germany, we’re building the future of online marketplaces—together.

From fashion, beauty, and electronics to rare collectibles like trading cards, comic books, and even live plants, our live auctions have something for everyone.

And we’re just getting started! As one of the fastest growing marketplaces, we’re looking for bold, forward-thinking problem solvers across all functional areas. Check out the latest Whatnot updates on our news and engineering blogs and join us as we enable anyone to turn their passion into a business, and bring people together through commerce.

💻 Role

Data is a crucial part of Whatnot’s mission to bring people together through commerce. The Data Platforms team creates solutions that improve our core product experience and enable stakeholders across the organization to act with confidence.

As our newest Data Engineer, you will build partnerships across the company and design scalable solutions to pressing business goals. You will build on our data architecture, unlock critical new use cases, and drive end-to-end initiatives leveraging software, data & analytics.

On any given day, you will:


 * Make key decisions about how we build data systems at Whatnot – and then make it happen.
 * Contribute to the design and implementation of our data platform architecture. You will help craft best practices and roll outs to steer the direction of the team.
 * Work with key stakeholders to design data applications for both internal and external audiences and a variety of use cases, including machine learning, experimentation, and real-time analytics.
 * Support efforts to optimize the entire data platform, including our real-time logging solutions, analytics databases, data warehouse, metrics store, and more.
   
   

US Based:

Team members in this role are required to be within commuting distance of our San Francisco, Los Angeles, Seattle, or New York City hubs.

👋 You

Curious about who thrives at Whatnot? We’ve found that embodying a low ego, growth mindset, and high-impact drive goes a long way here.

As our next Data Engineer you should have 3+ years of experience, plus:


 * Track record in transforming large amounts of complex data into insights through the end-to-end creation of data products.
 * Experience implementing real-time and batch data pipelines with tight SLOs and complex transformation requirements
 * Proficiency in data architecture and modeling concepts, such as Kimball or Data Vault
 * Expertise in data engineering tooling, such as ingesting, testing, transformations, lineage, orchestration, and/or semantic layers.
 * Experience managing cloud data warehouses (Snowflake, BigQuery, Redshift, etc.) for processing and serving data products.
 * Skill at cultivating strong partnerships and the ability to coach and influence others to up-level the craft of data engineering.
   
   

In addition to these role-specific qualifications, you’ll also possess:


 * Understanding of the cloud, and experience with at least one of the major cloud providers (e.g. AWS).
 * Proficiency in at least one server-side programming language (preferably Python), common algorithms and data structures, and software design principles.
 * Comfort with infrastructure-as-code approaches (e.g. Terraform).
 * Self-starter ethic, thriving under a high level of autonomy.
 * Exceptional interpersonal and communication skills.
   
   

💰Compensation

$158,000/year to $205,000/year + benefits + equity

The salary range may be inclusive of several levels that would be applicable to the position. Final salary will be based on a number of factors including, level, relevant prior experience, skills, and expertise. This range is only inclusive of base salary, not benefits (more details below) or equity.

🎁 Benefits


 * Flexible Time off Policy and Company-wide Holidays (including a spring and winter break)
 * Health Insurance options including Medical, Dental, Vision
 * Work From Home Support
    * Home office setup allowance
    * Monthly allowance for cell phone and internet

 * Care benefits
    * Monthly allowance for wellness
    * Annual allowance towards Childcare
    * Lifetime benefit for family planning, such as adoption or fertility expenses

 * Retirement; 401k offering for Traditional and Roth accounts in the US (employer match up to 4% of base salary) and Pension plans internationally
 * Monthly allowance to dogfood the app
 * Parental Leave
    * 16 weeks of paid parental leave + one month gradual return to work *company leave allowances run concurrently with country leave requirements which take precedence.
      

💛 EOE

Whatnot is proud to be an Equal Opportunity Employer. We value diversity, and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, parental status, disability status, or any other status protected by local law. We believe that our work is better and our company culture is improved when we encourage, support, and respect the different skills and experiences represented within our workforce.",Full-time
4131606335,26793.0,Data Engineer,"About Apexon:




Apexon is a digital-first technology services firm specializing in accelerating business transformation and delivering human-centric digital experiences. We have been meeting customers wherever they are in the digital lifecycle and helping them outperform their competition through speed and innovation.




Apexon brings together distinct core competencies – in AI, analytics, app development, cloud, commerce, CX, data, DevOps, IoT, mobile, quality engineering and UX, and our deep expertise in BFSI, healthcare, and life sciences – to help businesses capitalize on the unlimited opportunities digital offers. Our reputation is built on a comprehensive suite of engineering services, a dedication to solving clients’ toughest technology problems, and a commitment to continuous improvement.




Backed by Goldman Sachs Asset Management and Everstone Capital, Apexon now has a global presence of 15 offices (and 10 delivery centers) across four continents.



We enable #HumanFirstDIGITAL



Role Description:



You’ll be responsible for (Responsibilities):

We are looking for a Data Engineer to join our fast growing team.

 * This person will be responsible for expanding and optimizing our current cloud based data pipeline architecture for the various cross functional teams.
 * The ideal candidate has experience building robust data pipelines and reporting tools. However, someone with a strong application development background with keen interest in data engineering would be considered.
 * The candidate will be collaborating extensively with Engineering, Analytics and Product teams to support functional use-cases and take data driven decisions.

Who we are looking for

 * Strong background in data processing & software engineering and can build high-quality, scalable data oriented products.
 * Industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, EMR, etc..) for building efficient, large-scale data pipelines.
 * Strong Software Engineering experience with in depth understanding of Python, Scala, Java or equivalent
 * Strong understanding of data architecture, modeling and infrastructure
 * Experience with building workflows (ETL pipelines)
 * Experience with SQL and optimizing queries
 * Problem solver with attention to detail who can see complex problems in the data space through end to end
 * Willingness to work in a fast paced environment
 * MS/BS in Computer Science or relevant industry experience.
 * Strongly recommended (but optional)
 * Experience building scalable applications on the Cloud (Amazon AWS, Google Cloud, etc..)
 * Experience building stream-processing applications (Spark streaming, Apache-Flink, Kafka, etc..)
 * Experience with Databricks and Snowflake






You’ll have (Qualification & Experience):

 * Bachelor's Degree in related field is required.



Don’t worry if you don’t check all the boxes; we’d still love to hear from you.




Our Commitment to Diversity & Inclusion:




Did you know that Apexon has been Certified™ by Great Place To Work®, the global authority on workplace culture, in each of the three regions in which it operates: USA (for the fourth time in 2023), India (seven consecutive certifications as of 2023), and the UK.

Apexon is committed to being an equal opportunity employer and promoting diversity in the workplace. We take affirmative action to ensure equal employment opportunity for all qualified individuals. Apexon strictly prohibits discrimination and harassment of any kind and provides equal employment opportunities to employees and applicants without regard to gender, race, color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law.




You can read about our Job Applicant Privacy policy here Job Applicant Privacy Policy (apexon.com)




Our Perks and Benefits:

Our benefits and rewards program has been thoughtfully designed to recognize your skills and contributions, elevate your learning/upskilling experience and provide care and support for you and your loved ones.




As an Apexon Associate, you get continuous skill-based development, opportunities for career advancement, and access to comprehensive health and well-being benefits and assistance.




We also offer:

 1. Health Insurance with Dental & Vision
 2. 401K Plan
 3. Life Insurance, STD & LTD
 4. Paid Vacations & Holidays
 5. Paid Parental Leave
 6. FSA Dependent & Limited Purpose care
 7. Learning & Development

",Full-time
4045410894,66321745.0,Junior Data Engineer (Remote),"Since 2010 and almost 14 years SynergisticIT has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients.

Post Covid the tech Layoffs have been massive—In 2022 there were 165,269 tech layoffs, In 2023 there were 264,220 tech layoffs and so far in 2024 there have been 126,382 tech layoffs. (Source Layoffs.fyi ) -Total layoffs as per this 555,871 tech layoffs.

Client, Dell and Cisco have announced 15,000/12,500 and 4000 tech layoffs respectively in August.

The Job market is Hyper Competitive. For 1 position 500-2000 candidates or more are applying and laid off job seekers are also competing for entry level Job positions.

Acquiring the right technology skillsets which are being demanded by clients and getting yourself in front of clients is the way to get to get Interviews and eventually a Job Offer. Survival of the Fittest is the only way to get a tech Job in this job market.

In this Layoffs fueled market also SynergisticIT's candidates are able to achieve multiple job offers and $100k &plus; salaries once they acquire the required skills.

please check the below links to see success outcomes, salaries of our candidates .

https://www.synergisticit.com/candidate-outcomes/

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please visit the below videos exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, we are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Data Engineers, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

Required Skills

REQUIRED SKILLS For Java /Full stack/Devops Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Knowledge of Core Java , javascript , C&plus;&plus; or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

For data Science/Data Analyst/AI/Machine learning Positions

Required Skills

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude

Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidate.",Full-time
4146427912,3876753.0,Data Engineer,"PILYTIX brings Explainable Artificial Intelligence (XAI) to sales and fundraising teams with software-as-a-service products that enable them to be more effective throughout their entire sales funnel. Data Engineers will assist in the development of PILYTIX's cutting-edge zeroG™ platform by maintaining and enhancing the data pipelines that ingest, transform, and archive client data. They will design connections to new sources of data, optimize existing integrations, and develop scalable workflows as data management specialists. They will also build internal tools to support our team of Data Scientists and Software Engineers, powering the PILYTIX products to help our clients win more revenue, faster.

Responsibilities:


 * Design workflows using SQL, internal and external APIs, and other tools for data wrangling and customized, client-focused operations
 * Develop and adapt code to facilitate Master Data Management (MDM)
 * Author and monitor directed acyclic graphs (DAGs) in Apache Airflow to ingest and transform data
 * Build connections for new sources of data including from sales, marketing, sports and entertainment event ticketing, and social media platforms
 * Maintain and improve internal Python packages to streamline ingest processes
 * Work collaboratively with the app development team to add new data-driven features to our software-as-a-service product
 * Work collaboratively with the data science team to enhance our AI and machine learning capabilities
 * Participate in Agile / Kanban processes on a daily basis
 * Execute tasks with adherence to high standards of data governance and stewardship
 * Comply with change management policies and code reviews to ensure data integrity and system stability
   
   
   

Requirements


 * BS or higher in a STEM field and 2-4 years of hands-on industry experience programming and working directly with moderate-sized datasets as an analyst, engineer, consultant, database administrator or other
 * Exceptional understanding of data architecture and software engineering best practices including fundamental knowledge of object-oriented design and data structures
 * 2+ years professional experience with SQL (PostgreSQL & BigQuery preferred)
 * 2+ years professional experience with Python
 * Proficiency using REST APIs and writing code to optimize data queries, implement ETL/ELT processes, and perform data wrangling
 * Familiarity with Apache Airflow or similar data pipeline systems
 * Experience working with Salesforce Sales Cloud or similar CRM systems
 * Experience working with Salesforce Marketing Cloud or similar marketing and customer engagement platforms
 * Proficiency with Git or other DVCS, including in a team environment
 * Knowledge of Agile / Kanban processes
 * Entrepreneurial spirit and highly self-motivated
   
   

Nice to Have:


 * Familiarity with Google Cloud Platform (GCP) infrastructure and microservices
 * Exposure to CI/CD and containerized deployment via Docker / Kubernetes
   
   

Job is based in Austin TX, but extraordinarily qualified remote candidates (willing to travel to Austin semi-regularly) may apply.

Benefits


 * Competitive base salary with ability to earn bonuses
 * Professional development and entrepreneurial opportunities
 * Paid time off
 * 401(k)
 * Medical and dental plans",Full-time
4150472828,93246786.0,Data Engineer,"Data Engineer will design, implement, and maintain data infrastructure solutions using Databricks

Load and manage data products in Databricks

Collaborate with the team to eliminate repetitive data using Power Automate, starting with Finance

As a Data Engineer, you will support UAT testing and data consumption phases

Work on AI-enabled upselling and predictive ordering projects",Contract
4136864033,401618.0,Data Engineer,"Data Engineer




$135K - $155K




US Remote




Permanent Hire – no C2C




A product-focused technology company headquartered in the Midwest is actively hiring a Data Engineer to join the team, working remotely.




The business is hiring significantly, and with huge plans for 2025, they are seeking a Data Engineer with strong commercial experience in Python, ETL processes and AWS to join the team. You will be responsible for designing, developing and maintaining data pipelines, alongside working collaboratively with the wider tech function.




Responsibilities:

 * Collaborate with the wider team to define requirements.
 * Develop efficient ETL data pipelines.
 * Able to mentor junior engineers when required.
 * Unit & functional testing.




Skills:

 * Python
 * SQL
 * ETL
 * AWS (any experience with AWS IoT would be highly desirable)




Benefits:

 * Medical / Dental & Vision
 * Matched 401K
 * Generous PTO




If you’re an experienced Data Engineer who’s looking to enhance your career, please apply now for immediate consideration.

",Full-time
4130662149,74615750.0,Data Engineer,"Who We Are

Imprint is building a next-generation co-branded credit card company to serve America’s great brands. Some of our partners include H-E-B, Turkish Airlines, Brooks Brothers, and Eddie Bauer. Imprint is backed by Khosla Ventures, Kleiner Perkins, and Thrive Capital. We are focused on building a brilliant team who want to change payments and who embody our Operating Principles.

The Team

The Data Analytics team at Imprint is dedicated to building a robust data foundation that drives smarter decision-making across the organization. The team is responsible for developing and maintaining Imprint’s data infrastructure, which includes not only the data warehouse and data pipelines but also comprehensive analytics systems that support both daily operations and strategic initiatives. By efficiently managing data flows, ensuring data quality, and optimizing performance, the Data Analytics team enables accessible, high-quality data that fuels insights into customer behavior, operational efficiency, and market trends. Leveraging these actionable insights, the team plays a crucial role in guiding Imprint's growth and profitability, empowering cross-functional teams to make well-informed, data-driven decisions.

Location

Our offices are located in New York City and San Francisco. This role will be able to work remotely or hybrid from one of our offices

What You'll Do

Build and Manage Data Pipelines


 * Create and maintain data pipelines to bring data from various sources into our systems, ensuring it’s clean, organized, and ready for use
 * Keep data flowing smoothly, making it available when needed by different teams
   
   

Support Data Modeling


 * Work with teams to design and maintain data structures for reporting and analysis
 * Ensure data is structured in a way that answers key business questions
   
   

Ensure Data Quality


 * Maintain data accuracy and integrity, quickly addressing any data issues
 * Monitor data processes and perform routine checks to ensure reliability
   
   

Optimize Data Storage


 * Design and manage cloud-based data storage solutions, optimizing for speed, accuracy, and cost-efficiency
 * Regularly improve the performance of our data systems
   
   

Collaborate Across Teams


 * Partner with data scientists, analysts, and other teams to understand their data needs.
 * Support others in accessing and effectively using data for their projects
   
   

What We Look For


 * 4+ years of experience working in data architecture, data pipeline, data warehouse modeling, master data management
 * Bonus points for Master’s degree in Computer Science, Engineering, Mathematics, Analytics or related field
 * Experience in scaling and optimizing schemas, data warehouse modeling in dbt, performance tuning SQL in Snowflake, data pipeline management in Airflow, working with AWS cloud platforms, manage code changes in Github, manage data infrastructure in Terraform, and understand CI/CD concepts
 * Advanced knowledge and extensive experience in SQL
 * Experience designing, developing, and maintaining large-scale and well-documented data marts to drive data insights
 * Excellent written and verbal communication and interpersonal skills, and ability to effectively collaborate with technical and business teams
   
   

Bonus Points


 * Experience in banking, financial services, credit card, fintech in a start-up environment
   
   

Perks & Benefits


 * Competitive compensation and equity packages
 * Leading configured work computers of your choice
 * Flexible paid time off policy
 * Fully covered, high-quality healthcare including fully covered dependent coverage
 * Additional health coverage includes access to One Medical and option to enroll in an FSA
 * 16 weeks of paid parental leave for the primary caregiver and 8 weeks for all new parents
 * An understanding that successful remote work requires flexibility and an appreciation for asynchronous work
 * Access to industry-leading technology across all of our business units — stemming from our philosophy that we should invest in resources for our team that foster innovation, optimization, and productivity
   
   

Imprint is committed to a diverse and inclusive workplace. Imprint is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. Imprint welcomes talented individuals from all backgrounds who want to build the future of payments and rewards. If you are passionate about FinTech and eager to grow, let’s move the world forward, together.

Compensation Range: $120K - $180K

",Full-time
4066233818,1586.0,Data Engineer,"Description

Data Engineer

Come build the future as a Data Engineer at Amazon, where you will be inspired working along best-in-class inventors and innovators! You will have the opportunity to create meaningful experiences that deliver on the ever-evolving needs of our customers, and your work will impact millions of people around the world.

As an Amazon Data Engineer, you will solve unique and complex problems at a rapid pace, utilizing the latest technologies to create solutions that are highly scalable. You will find that there is an unlimited number of opportunities within Amazon, where developing your career across a wide range of teams is highly supported. We are committed to making your work experience as enjoyable as the experiences you’ll be creating for our customers.

Apply now and you will be eligible for Amazon Data Engineer positions that are based on your preferred location, team, and more. We’re hiring across Amazon Stores in the United States and Canada.

Teams with available positions include, but are not limited to:


 * Consumer Technology: Build new generation features and products for amazon.com, constantly improving the Customer and Seller experience for billions around the globe. Whether building site wide features such as reviews and recommendations, category specific software for the likes of Pharmacy, Electronics, Digital Software and Video Games or seller infrastructure, there are a variety of complex problems to tackle using a range of technologies in the design of your technical solutions.
 * Operations Technology: Shape the future of transportation planning and execution on a global scale, that impacts hundreds of fulfillment centers, thousands of Amazonians, and millions of customers across the world. Your technology will support thousands of operators worldwide to design, build and run the best-in-class Amazon transportation network. We are building intelligent software to make transportation more reliable, faster, and less costly, providing a better and less expensive experience for our customers.
 * Human Resources Technology: Create a seamless experience for millions of Amazonians and/or candidates. Whether supporting technologies for onboarding, time and attendance, compensation, amazon.jobs, or recruiting, you’ll deliver robust feature sets, elegant designs, intuitive user interfaces and systems that make it easy for Amazonians to excel at performing critical business functions.
   
   

About Us

Work/Life Balance

Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth

Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign opportunities based on what will help each team member develop into a better-rounded contributor.

Inclusive Team Culture

Here at Amazon, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Key job responsibilities


 * Design, implement, and support a platform providing secured access to large datasets.
 * Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.
 * Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation.
 * Tune application and query performance using profiling tools and SQL.
 * Analyze and solve problems at their root, stepping back to understand the broader context.
 * Learn and understand a broad range of Amazon’s data resources and know when, how, and which to use and which not to use.
 * Keep up to date with advances in big data technologies and run pilots to design the data architecture to scale with the increased data volume using AWS.
 * Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for datasets.
 * Triage many possible courses of action in a high-ambiguity environment, making use of both quantitative analysis and business judgment.
   
   

Basic Qualifications


 * 3+ years of data engineering experience
 * Proficient in SQL
 * Experience with data modeling, warehousing and building ETL pipelines
 * Experience in at least one modern scripting or programming language, such as Python, Java, Scala, or NodeJS
   
   

Preferred Qualifications


 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
 * Experience with big data technologies such as: Hadoop, Hive, Spark, EMR
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com LLC - A03

Job ID: A2820515",Full-time
4056191928,2646.0,Data Engineer III,"Position Summary...

What you'll do...

Immigration sponsorship is not available in this role.

Join us as a Software Engineer III where you'll play a pivotal role in transforming and integrating data, crafting robust data models, and developing innovative solutions. You'll work closely with stakeholders to identify data sources, ensure quality, and implement effective data governance practices. If you're passionate about leveraging data to drive business success, shaping strategic decisions, and leading the charge in data transformation, we want you on our team. Dive into a role where your expertise not only influences data architecture but also supports impactful business outcomes.

About Team

The Data Sharing & Collab Team helps Suppliers to ingest data in lowest granularity with ease of adoption and always on par with latest Tech stats exploration like Deltashare, Databricks, Snowflake etc. This team will help to grow adoption as the tech expert and share visibility on the product value add.

What You’ll Do


 * Data Transformation and Integration: Extract and transform data from databases, create data pipelines, and stay updated on analytics trends
 * Data Source and Modeling: Identify suitable data sources, perform quality checks, develop and evaluate data models, and design efficient data flows
 * Code Development and Testing: Write and test code for solutions, develop proofs of concept, deploy software, and document progress
 * Applied Business Acumen: Translate business requirements into projects, recommend solutions, develop business cases, and align projects with business strategy
 * Data Governance: Implement and document data governance practices, educate stakeholders, and provide recommendations for improvements
   
   

What You’ll Bring


 * Understanding of software development lifecycle from planning to deployment
 * High-level proficiency in Java and Spring Boot
 * You have a proven track record coding with at least one programming language (e.g., Scala, Python)
 * You’re experienced in one of cloud computing platforms (e.g., GCP, Azure)
 * You’re skilled in data modeling & data migration protocols
 * Experience with containerization technologies WCNP, Docker, and Kubernetes
 * Experience with GCP, Data warehousing, BI preferred
 * Experience with the integration tools like Automic, Airflow, Autosys
 * Experience in building highly scalable Big Data solutions and ETL ecosystems
 * Working knowledge of CI/CD pipelines
 * Strong communication skills with the ability to not only understand but also articulate the how and why of a process and solution
   
   

Preferred Qualifications And Experience


 * Knowledge of Databricks and Snowflake is an added advantage
 * Hands on knowledge in NoSQL like Cosmos DB along with RDBMS like MySQL, Postgres is plus
 * Hands on working experience in any messaging platform like Kafka is preferred
 * Increase the efficiency of the team by setting right Processes of Software Development, Requirement Intake, Effort Estimation
 * Demonstrating creative, critical thinking & troubleshooting skills
   
   

The above information has been designed to indicate the general nature and level of work performed in the role.  It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

About Walmart Global Tech

Imagine working in an environment where one line of code can make life easier for hundreds of millions of people.  That’s what we do at Walmart Global Tech. We’re a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world’s leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.

Flexible, hybrid work

We use a hybrid way of working with primary in office presence coupled with an optimal mix of virtual presence. We use our campuses to collaborate and be together in person, as business needs require and for development and networking opportunities. This approach helps us make quicker decisions, remove location barriers across our global team, be more flexible in our personal lives.

Benefits

Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include a host of best-in-class benefits maternity and parental leave, PTO, health benefits, and much more.

Equal Opportunity Employer

Walmart, Inc. is an Equal Opportunity Employer – By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions – while being inclusive of all people.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎

You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎

Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For Information About Benefits And Eligibility, See One.Walmart.

‎

Sunnyvale, California US-04397:The annual salary range for this position is $117,000.00-$234,000.00

‎

Bentonville, Arkansas US-09050:The annual salary range for this position is $90,000.00-$180,000.00

‎

‎

‎

‎

‎

‎

‎

‎

‎

‎

Additional Compensation Includes Annual Or Quarterly Performance Bonuses.

‎

Additional Compensation For Certain Positions May Also Include

‎

‎


 * Stock
   
   

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelor’s degree in Computer Science and 2 years' experience in software engineering or related field. Option 2: 4 years’ experience in

software engineering or related field. Option 3: Master's degree in Computer Science.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, Master’s degree in Computer Science or related field and 2 years' experience in software engineering or related field, We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

680 West California Avenue, Sunnyvale, CA 94086-4834, United States of America

",Full-time
4147567410,66321745.0,Data Engineer - Entry/Remote,"SYNERGISTICIT is aware that the Job Market is Challenging due to almost 600,000 Tech Layoffs within the past 2 years due to which The Job market is flooded with thousands of laid off Techies who are competing with existing Jobseekers. For entry level Job seekers to get client interviews and jobs they need to differentiate themselves by ensuring they have exceptional skills and technologies to be noticed by clients.

Since 2010 we have helped Jobseekers differentiate themselves by providing the clients with candidates who have the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.

All Positions are open for all visas and US citizens

We are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this economy no client wants or has the resources to take an entry level person and spend resources on upgrading their skills and on top of that pay the jobseeker. That's the specific reason there are so many techies both experience and freshers who are unemployed.

Clients have now the option to hire remote workers from anywhere so for a Jobseeker its important to introspect and see how they can become better and have the skills and technologies to meet client requirements.

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates looking to make their careers in IT Industry

We welcome candidates with all visas and citizens to apply.

If you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.

please check the below links to see success outcomes of our candidates

Synergisticit Pics /Salaries of Successful Candidates

Synergisticit at Oracle Cloudworld 2023

Synergisticit at Gartner Data & Analytics summit

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

If you have relevant skills and industry experience, please apply

For preparing for interviews please visit

https://www.synergisticit.com/interview-questions/

REQUIRED SKILLS For Java /Software Programmers


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Project work on the skills
 * Knowledge of Core Java , javascript , C&plus;&plus; or software programming
 * Spring boot, Microservices, Docker, Jenkins and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Project work on the technologies needed
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, PowerBI, Time series analysis

Please understand skills and relevant experience on real world projects are required by clients for selection even if its Junior or entry level position the additional skills and Project work with hands on experience building projects at client site are the only way a candidate can be picked by clients.

No third party candidates or c2c candidates

please only apply to the posting

If you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.

No phone calls please. Shortlisted candidates would be reached out.",Full-time
4149737949,1283.0,Data Engineer - Python with Data Structure,"Infosys is seeking a Python Developer, skilled in Data Structure. Candidate should have strong background in designing and deploying Machine Learning models using Python. Ideal candidate will work with clients to understand the issues they face, diagnose problems, design solutions and facilitate solution deployment on Cloud Platform. One will also have the opportunity to shape value-adding consulting solutions for clients by connecting various functions of cloud components. Ideally the candidate uses understanding of the problem to arrive at multiple solution alternatives keeping in mind the various stakeholders and assess the pros and cons of all the alternatives to arrive at the optimal solution.




Required Qualifications:

 * Bachelor’s degree or foreign equivalent required from an accredited institution. Will also consider three years of progressive experience in the specialty in lieu of every year of education.
 * All applicants authorized to work in the United States are encouraged to apply
 * Candidate must live within commuting distance of Richmond, VA OR Pennington, NJ OR Plano, Tx OR Charlotte, NC OR be willing to relocate. This is an onsite position. Travel within the US may be required.
 * At least 4 years of experience in Information Technology
 * At least 3 years of experience as Core Python Developer with Data Structures, Stacks, Queues, Linked list OOPS concepts,
 * At least 3 years of experience in Creating large-scale data processing pipelines to help developers build and train novel machine learning algorithms.
 * At least 3 years of experience in developing, test and maintain high-quality software using Python programming language.
 * At least 3 years of experience in Cloud platforms (e.g., GCP, Azure) and their AI services.
 * At least 2 years of experience in developing ML, NLP Deep learning models
 * At least 2 years of Experience in working With Derivatives and Capital Markets
 * Ability to write clean and reusable code that can be easily maintained and scaled.

Preferred Qualifications:

 * Experience in LLM, Generative AI (developing capabilities or Dev/Ops)
 * Participation experience in code reviews, ensure code quality and identify areas for improvement to implement practical solutions.
 * Debugging codes when required and troubleshooting any Python-related queries.
 * Experience in working with Multi cloud environment such as, GCP, AWS, Azure
 * Excellent problem-solving skills and ability to address complex technical challenges.
 * Effective communication skills to collaborate with cross-functional teams and stakeholders.
 * High Impact client communication
 * Domain experience in Banking, Finance, Capital Markets




The job may entail extensive travel. The job may also entail sitting as well as working at a computer for extended periods of time. Candidates should be able to effectively communicate by telephone, email, and face to face.

EEO/About Us :

About Us

Infosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem.




Infosys provides equal employment opportunities to applicants and employees without regard to race; color; sex; gender identity; sexual orientation; religious practices and observances; national origin; pregnancy, childbirth, or related medical conditions; status as a protected veteran or spouse/family member of a protected veteran; or disability.",Full-time
4150917785,5279801.0,"Software Engineer Co-op, AI/ML","Company Overview:

Bose Professional is a leader in the professional audio industry, specializing in the design and manufacturing of cutting-edge audio solutions including loudspeakers, amplifiers, signal processing devices, controls, software, and accessories. As we continue to expand our team, we are seeking a Software Engineer Co-op, AI/ML to join us on our journey.

We have organized ourselves culturally around a set of shared values. We are a team first, which means we are collaborative and support each other toward our common goals. We start everything from the outside in, starting with the customer and solving from there. We value trust, so we are a company of people who are open and direct, avoid politics, and who do what it takes to deliver on our commitments. And as we work together, we are empathetic, courteous, and fair, because we respect each other. Finally, we believe that creativity and innovation belong in all parts of the company to drive excellence in everything we do.

Position Overview:

Do you love great sounding music with quality that brings joy to people’s lives? Would you love to work with a team that helps develop the best sounding Digital Signal processors, amplifiers, subwoofers, and loudspeakers in the world? Bose Professional is looking for an intern with a working knowledge of software development and an interest in gaining real-world software engineering experience at an innovative and thriving high-technology company.

You will work in a tight-knit team of Software Engineers to develop best-in-class professional audio software applications used to design, configure, and control Bose Professional audio amplifiers and signal processors that are used to drive our award-winning loudspeakers.   

Using your programming skills, you will be creating software for our next generation software middleware that would drive best-in-class digital signal processors, amplifiers and controls. 

Key Responsibilities:


 * Assist in collecting, preprocessing, and analyzing audio datasets for ML training and validation.
 * Train, fine-tune, and evaluate machine learning models using frameworks like TensorFlow, PyTorch, or Scikit-Learn.
 * Implement and optimize model validation techniques, including cross-validation, hyperparameter tuning, and performance metrics assessment.
 * Develop scripts and automation tools for training pipeline optimization.
 * Conduct error analysis to improve model robustness and generalization.
 * Collaborate with the AI/ML team to experiment with novel architecture and techniques.
 * Document findings, methodologies, and results for internal and external reporting.
 * Assist in deploying and testing models in real-world scenarios, ensuring efficiency and reliability.
   
   

Qualifications:


 * The ideal candidate will be either in a Master’s program or in their Junior or Senior year of study in the 2025 calendar year with emphasis in Computer Science, Electrical Engineering or a related STEM field such as math or physics.
 * Demonstrate an understanding of basic algorithms, data science, and design principles.
 * Experience with frameworks/libraries like TensorFlow, PyTorch & NumPy.
 * Substantial academic project work or some industry experience in collecting, preprocessing, and analyzing datasets for ML training and validation
 * Model tuning and model evaluation experience is desirable
 * Have clear verbal and written communication skills.
   
   

Bose Professional is an equal opportunity employer and values diversity in the workplace. We encourage all qualified individuals to apply.

Position/Title: Software Engineer Co-op, AI/ML

Location: Hopkinton, MA - Hybrid

Reports to: Director of Software Engineering

Department: Engineering

Powered by JazzHR

9Pr9soePeD",Internship
4137483462,166658.0,Data Engineer,"Job Description

Join our dynamic team at the University of Notre Dame Investment Office as a Data Engineer. You will partner with us on the ground floor of a pivotal project to transform and streamline our data infrastructure within Microsoft’s Azure platform and help shape the future of data strategy, growth, and innovation in our office. The Data Engineer will play a comprehensive role in understanding end customer needs; designing, building, and maintaining data pipelines; and creating end-user analytics across all Investment Office functions.

The 40-person Investment Office is responsible for investing the ~$20 billion Notre Dame Endowment and other financial assets of the University. If you’re passionate about data, skilled in SQL , Python, and Power BI, and enjoy creating end-to-end solutions, we’d love to hear from you!

Responsibilities Include


 * Collaborate with cross-functional teams to understand data requirements, design efficient solutions, and ensure data quality
 * Build and maintain data pipelines ( ETL ) from APIs, databases, and files
 * Interpret and write SQL and Python code
 * Create dashboards and reports using Power BI
 * Document your work comprehensively to enable knowledge sharing and facilitate maintenance
 * Implement and follow data security practices to protect sensitive information
 * Collaborate with Analytics team members to ensure data quality and foster team capability and support
 * Communicate technical concepts to non-technical stakeholders effectively
   
   

Why join us?


 * Work on exciting projects with cutting-edge technologies in investment management (stocks, bonds, private equity, digital assets)
 * Grow your career in data engineering
 * Work closely with a high-impact, tight-knit Investment Office team
 * Enjoy a collaborative work environment at a top university with a unique mission
 * Competitive compensation and comprehensive benefits package
 * Generous professional development opportunities
   
   

Minimum Qualifications


 * Bachelor’s degree in Computer Science, Information Systems, or related field (or equivalent experience)
 * 2+ years of proven experience in data engineering or related role
 * Experienced with data pipelines and ETL processes
 * Strong SQL and Python programming skills
 * Proficient in Python for data manipulation and API integration
 * Familiar with data modeling and semantic layers
 * Cloud platform data engineering knowledge
 * Excellent problem-solving skills and attention to detail
 * Ability to work in the United States without visa sponsorship
   
   

Preferred Qualifications


 * Git proficiency managing source code repositories, such as GitHub or Azure DevOps, for version control and collaboration
 * Knowledge of Microsoft Power BI to create interactive dashboards
 * Microsoft Azure Data Engineering certification or interest in pursuing this certification (sponsored by Notre Dame)
 * Experience working with investment-related datasets
   
   

Special Instructions to Applicants

Department Investment Office (45000)

Department Website https://investment.nd.edu/

Family / Sub-Family IT / Business Intelligence

Career Stream/Level EIC 2 Professional

FLSA Status S1 - FT Exempt",Full-time
4077944881,2684737.0,Experienced Data Engineer - Data Engineering,"We believe that the way people interact with their finances will drastically improve in the next few years. We’re dedicated to empowering this transformation by building the tools and experiences that thousands of developers use to create their own products. Plaid powers the tools millions of people rely on to live a healthier financial life. We work with thousands of companies like Venmo, SoFi, several of the Fortune 500, and many of the largest banks to make it easy for people to connect their financial accounts to the apps and services they want to use. Plaid’s network covers 12,000 financial institutions across the US, Canada, UK and Europe. Founded in 2013, the company is headquartered in San Francisco with offices in New York, Washington D.C., London and Amsterdam.

The main goal of the DE team in 2024-25 is to build robust golden data sets to power our business goals of creating more insights based products. Making data-driven decisions is key to Plaid's culture. To support that, we need to scale our data systems while maintaining correct and complete data. We provide tooling and guidance to teams across engineering, product, and business and help them explore our data quickly and safely to get the data insights they need, which ultimately helps Plaid serve our customers more effectively. Data Engineers heavily leverage SQL and Python to build data workflows. We use tools like DBT, Airflow, Redshift, ElasticSearch, Atlanta, and Retool to orchestrate data pipelines and define workflows. We work with engineers, product managers, business intelligence, data analysts, and many other teams to build Plaid's data strategy and a data-first mindset. Our engineering culture is IC-driven -- we favor bottom-up ideation and empowerment of our incredibly talented team. We are looking for engineers who are motivated by creating impact for our consumers and customers, growing together as a team, shipping the MVP, and leaving things better than we found them.

You will be in a high impact role that will directly enable business leaders to make faster and more informed business judgements based on the datasets you build. You will have the opportunity to carve out the ownership and scope of internal datasets and visualizations across Plaid which is a currently unowned area that we intend to take over and build SLAs on. You will have the opportunity to learn best practices and up-level your technical skills from our strong DE team and from the broader Data Platform team. You will collaborate with and have strong and cross functional partnerships with literally all teams at Plaid from Engineering to Product to Marketing/Finance etc.

Responsibilities


 * Understanding different aspects of the Plaid product and strategy to inform golden dataset choices, design and data usage principles.
 * Have data quality and performance top of mind while designing datasetsLeading key data engineering projects that drive collaboration across the company.
 * Advocating for adopting industry tools and practices at the right timeOwning core SQL and python data pipelines that power our data lake and data warehouse.
 * Well-documented data with defined dataset quality, uptime, and usefulness.
   
   

Qualifications


 * 4+ years of dedicated data engineering experience, solving complex data pipelines issues at scale.
 * You’ve have experience building data models and data pipelines on top of large datasets (in the order of 500TB to petabytes)
 * You value SQL as a flexible and extensible tool, and are comfortable with modern SQL data orchestration tools like DBT, Mode, and Airflow.
 * You have experience working with different performant warehouses and data lakes; Redshift, Snowflake, Databricks.
 * You have experience building and maintaining batch and realtime pipelines using technologies like Spark, Kafka.
 * You appreciate the importance of schema design, and can evolve an analytics schema on top of unstructured data.
 * You are excited to try out new technologies. You like to produce proof-of-concepts that balance technical advancement and user experience and adoption.
 * You like to get deep in the weeds to manage, deploy, and improve low level data infrastructure.
 * You are empathetic working with stakeholders. You listen to them, ask the right questions, and collaboratively come up with the best solutions for their needs while balancing infra and business needs.
 * You are a champion for data privacy and integrity, and always act in the best interest of consumers.
   
   

$182,250 - $243,000 a year

Target base Salary for this role is $182,250 - $297,640 per year. Additional compensation in the form(s) of equity and/or commission are dependent on the position offered. Plaid provides a comprehensive benefit plan, including medical, dental, vision, and 401(k). Pay is based on factors such as (but not limited to) scope and responsibilities of the position, candidate's work experience and skillset, and location. Pay and benefits are subject to change at any time, consistent with the terms of any applicable compensation or benefit plans.

Our mission at Plaid is to unlock financial freedom for everyone. To support that mission, we seek to build a diverse team of driven individuals who care deeply about making the financial ecosystem more equitable. We recognize that strong qualifications can come from both prior work experiences and lived experiences. We encourage you to apply to a role even if your experience doesn't fully match the job description. We are always looking for team members that will bring something unique to Plaid! Plaid is proud to be an equal opportunity employer and values diversity at our company. We do not discriminate based on race, color, national origin, ethnicity, religion or religious belief, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, military or veteran status, disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state, and local laws. Plaid is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance with your application or interviews due to a disability, please let us know at accommodations@plaid.com

Please review our Candidate Privacy Notice here .

",Full-time
4143934304,529693.0,Data Engineer,"We believe communication belongs to everyone. We exist to democratize phone service.  TextNow is evolving the way the world connects, and that's because we're made up of people with curious minds who bring an optimistic yet critical lens into the work we do.   We're the largest provider of free phone service in the nation. And we're just getting started.

Join us in our mission to break down barriers to communication and free the flow of conversation for people everywhere.

TextNow is looking for an experienced Data Engineer with hands-on experience designing and developing data platforms. You will own the design, development, and maintenance of TextNow's data platform , enabling us to make effective data-informed decisions. You will be part of cross-functional efforts to build scalable and reliable frameworks that support all of TextNow's business and data products. In this role, you can interact with different functional areas within the business and influence decision-making in a fast-growing mobile communications start-up.  

What You'll Do


 * Own TextNow's data warehouse, pipeline, and integration points between various business systems.  
 * Explore available technologies and develop solutions to build and improve our identity resolution solutions.
 * Design, Develop and support new and existing batch and real-time data pipelines and recommend improvements and modifications.  
 * Manage data to manage our AI/ML data products.  
 * Be a champion of TextNow's data ecosystem by working with engineering and infrastructure to implement data strategy for governance, security, privacy, quality, and retention that will satisfy business policies and requirements.  
 * Communicate strategies and processes around data modeling and architecture to cross-functional groups.  Identify, design, and implement internal process improvements.  
   
   

Who You Are


 * Have 3-8 years of experience working with data warehouse/data lake and ETL architectures, cloud data warehouses (Snowflake), and experience in Python and SQL, preferably at companies with fast-growing and evolving data needs.
 * Have at least 1-2+ years of experience with Airflow, Iceberg, Spark and Flink.
 * Exposure to AWS cloud data/ML services such as EKS, MWAA and Sagemaker.
 * Developed scalable data pipelines using Python/Scala, SQL, and distributed processing frameworks like Spark or Flink.
 * Experience driving technical vision for user identity resolution and data quality in previous roles is preferred.
 * Hands on experience working with building data features using Snowflake, dbt, and Python to power real-time AI/ML inference.
 * Respectfully candid with the ability to initiate and drive projects to completion.
 * Highly organized, structured work approach and dependable.
   
   

More about TextNow...

Our Values


 * Customer Obsessed (We strive to have a deep understanding of our customers)
 * Do Right By Our People (We treat each other with fairness, respect, and integrity)
 * Accept the Challenge (We adopt a ""Yes, We Can"" mindset to achieve ambitious goals)
 * Act Like an Owner (We treat this company like it's our own... because it is!)
 * Give a Damn! (We are deeply commited and passionate about our work and achieving results)
   
   

Benefits, Culture, & More


 * Strong work life blend
 * Flexible work arrangements (wfh, remote, or access to one of our office spaces)
 * Employee Stock Options
 * Unlimited vacation
 * Competitive pay and benefits
 * Parental leave
 * Benefits for both physical and mental well being (wellness credit and L&D credit)
 * We travel a few times a year for various team events, company wide off-sites, and more
   
   

Diversity And Inclusion

At TextNow, our mission is built around inclusion and offering a service for EVERYONE, in an industry that traditionally only caters to the few who have the means to afford it. We believe that diversity of thought and inclusion of others promotes a greater feeling of belonging and higher levels of engagement. We know that if we work together, we can do amazing things, and that our differences are what make our product and company great.

TextNow Candidate Policy

By submitting an application to TextNow, you agree to the collection, use, and disclosure of your personal information in accordance with the TextNow Candidate Policy",Full-time
4151641938,18048544.0,Data Engineer,"$124,000 - $152,000 a yearThis role requires an individual with an obsession for data quality, who is comfortable writing Python scripts and libraries, experienced in dealing with financial datasets, and proficient in SQL and database management.

Responsibilities- Serve as a key point of contact for our clients, managing their expectations effectively and delivering top-notch service.- Develop and maintain ETL pipelines, ensuring data integrity, quality, and timeliness.- Write, debug, and optimize Python scripts and libraries to automate data processes.- Handle complex financial datasets, extracting meaningful insights that drive business value.- Utilize your strong SQL and database skills to design and implement robust data structures according to client demands.- Employ data ingestion patterns, including FTP, APIs, and web scraping, to fetch and process data from various sources.- Collaborate with the broader team to meet project goals, maintaining a high level of communication, documentation, and cooperation.- Leverage your knowledge of Google Cloud Platform (or similar cloud technologies) to implement scalable solutions.- Stay current with industry trends and emerging technologies in data engineering.- Strictly adhere to best practices and promote strong SDLC and DevOps culture using a modern cloud data engineering technology stack.

Qualifications

Education:- Bachelor's or Master's degree in Computer Science, Data Science, or a related field.- 3-5 years of proven experience as a Data Engineer or similar role, preferably in the financial sector (or an equivalent combination of education and experience).

Experience:- 2+ years of client-facing skills with a background in managed services.- 3+ years of experience with Python for writing scripts and libraries.- Experience working with financial datasets.

Technical Skills:- Strong knowledge of data architecture, data modeling, and data management principles.- Strong SQL and database management skills.- Proficiency with Git or similar version control systems.- Proficiency in database technologies, ETL processes, and data ingestion methods (FTP, APIs, and web scraping).- Experience with at least one cloud platform (e.g., AWS, Azure, Google Cloud).- Knowledge and hands-on expertise in the following technologies:- Data lake architectures- Distributed computing- Data modeling for relational and non-relational data stores- Prior hands-on experience using a workflow orchestration system like Apache Airflow, Kestra, Prefect, or Mage at scale.- Experience with cloud data warehouses like Snowflake, Redshift, Azure Synapse, and Google BigQuery.- Hands-on coding proficiency in modern Python, Java, JSON, and YAML.

Soft Skills:- Expertise in managing and delivering on client expectations.- Sense of ownership and responsibility, with the ability to work independently with minimal supervision.- Demonstrable obsession with data quality and attention to detail.- Excellent communication and interpersonal skills.

Location Requirement:- Must be within commuting distance to NYC for regular client meetings.",Full-time
4045414243,66321745.0,Junior/Entry Data Engineer (Remote),"Since 2010 and almost 14 years SynergisticIT has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients.

Post Covid the tech Layoffs have been massive—In 2022 there were 165,269 tech layoffs, In 2023 there were 264,220 tech layoffs and so far in 2024 there have been 126,382 tech layoffs. (Source Layoffs.fyi ) -Total layoffs as per this 555,871 tech layoffs.

Client, Dell and Cisco have announced 15,000/12,500 and 4000 tech layoffs respectively in August.

The Job market is Hyper Competitive. For 1 position 500-2000 candidates or more are applying and laid off job seekers are also competing for entry level Job positions.

Acquiring the right technology skillsets which are being demanded by clients and getting yourself in front of clients is the way to get to get Interviews and eventually a Job Offer. Survival of the Fittest is the only way to get a tech Job in this job market.

In this Layoffs fueled market also SynergisticIT's candidates are able to achieve multiple job offers and $100k &plus; salaries once they acquire the required skills.

please check the below links to see success outcomes, salaries of our candidates.

https://www.synergisticit.com/candidate-outcomes/

https://www.synergisticit.com/roi-of-computer-science-degree-colleges-vs-synergisticit/

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please visit the below videos exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, we are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Data Engineers, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

REQUIRED SKILLS For Java /Full Stack/Devops Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Knowledge of Core Java , javascript , C&plus;&plus; or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

For data Science/Data Analyst/AI/Machine learning Positions

Required Skills

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude

Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Full-time
4066237448,1586.0,Data Engineer,"Description

Data Engineer

Come build the future as a Data Engineer at Amazon, where you will be inspired working along best-in-class inventors and innovators! You will have the opportunity to create meaningful experiences that deliver on the ever-evolving needs of our customers, and your work will impact millions of people around the world.

As an Amazon Data Engineer, you will solve unique and complex problems at a rapid pace, utilizing the latest technologies to create solutions that are highly scalable. You will find that there is an unlimited number of opportunities within Amazon, where developing your career across a wide range of teams is highly supported. We are committed to making your work experience as enjoyable as the experiences you’ll be creating for our customers.

Apply now and you will be eligible for Amazon Data Engineer positions that are based on your preferred location, team, and more. We’re hiring across Amazon Stores in the United States and Canada.

Teams with available positions include, but are not limited to:


 * Consumer Technology: Build new generation features and products for amazon.com, constantly improving the Customer and Seller experience for billions around the globe. Whether building site wide features such as reviews and recommendations, category specific software for the likes of Pharmacy, Electronics, Digital Software and Video Games or seller infrastructure, there are a variety of complex problems to tackle using a range of technologies in the design of your technical solutions.
 * Operations Technology: Shape the future of transportation planning and execution on a global scale, that impacts hundreds of fulfillment centers, thousands of Amazonians, and millions of customers across the world. Your technology will support thousands of operators worldwide to design, build and run the best-in-class Amazon transportation network. We are building intelligent software to make transportation more reliable, faster, and less costly, providing a better and less expensive experience for our customers.
 * Human Resources Technology: Create a seamless experience for millions of Amazonians and/or candidates. Whether supporting technologies for onboarding, time and attendance, compensation, amazon.jobs, or recruiting, you’ll deliver robust feature sets, elegant designs, intuitive user interfaces and systems that make it easy for Amazonians to excel at performing critical business functions.
   
   

About Us

Work/Life Balance

Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth

Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign opportunities based on what will help each team member develop into a better-rounded contributor.

Inclusive Team Culture

Here at Amazon, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Key job responsibilities


 * Design, implement, and support a platform providing secured access to large datasets.
 * Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.
 * Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation.
 * Tune application and query performance using profiling tools and SQL.
 * Analyze and solve problems at their root, stepping back to understand the broader context.
 * Learn and understand a broad range of Amazon’s data resources and know when, how, and which to use and which not to use.
 * Keep up to date with advances in big data technologies and run pilots to design the data architecture to scale with the increased data volume using AWS.
 * Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for datasets.
 * Triage many possible courses of action in a high-ambiguity environment, making use of both quantitative analysis and business judgment.
   
   

Basic Qualifications


 * 3+ years of data engineering experience
 * Proficient in SQL
 * Experience with data modeling, warehousing and building ETL pipelines
 * Experience in at least one modern scripting or programming language, such as Python, Java, Scala, or NodeJS
   
   

Preferred Qualifications


 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
 * Experience with big data technologies such as: Hadoop, Hive, Spark, EMR
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com LLC - A03

Job ID: A2820515",Full-time
4117095907,66321745.0,Data Engineer (Entry Level),"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you need

Position open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, IT enthusiasts, Python/Java developers, Data analysts/ Data Scientists.

We welcome candidates with all visas and citizens to apply.

Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates looking to make their careers in IT Industry

Candidates who are serious about their future in the IT Industry and have set big goals for themselves.

Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience which our clients need with great outcomes

Candidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancement

Candidates Who Lack Experience

Have had a break in careers

Lack Technical Competency

Different visa candidates who want to get employed and settle down in the USA

Please Also Check The Below Links

Synergisticit Pics /Salaries of Successful Candidates

Synergisticit at Oracle Cloudworld 2023

Synergisticit at Gartner Data & Analytics summit

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

If not a match candidates can opt for Skill enhancement.

REQUIRED SKILLS For Java/Software Programmers


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Core Java , javascript , C&plus;&plus; or software programming
 * Spring boot, Microservices and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, Python, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, Time series analysis

Please understand skills are required by clients for selection even if its Junior or entry level position the additional skills are the only way a candidate can be picked by clients.

No third party candidates or c2c candidates

Please understand skills are required by clients for selection even if its Junior or entry level position the additional skills are the only way a candidate can be picked by clients.

Please apply to the posting

No phone calls please. Shortlisted candidates would be reached out",Full-time
4066232907,1586.0,Data Engineer,"Description

Data Engineer

Come build the future as a Data Engineer at Amazon, where you will be inspired working along best-in-class inventors and innovators! You will have the opportunity to create meaningful experiences that deliver on the ever-evolving needs of our customers, and your work will impact millions of people around the world.

As an Amazon Data Engineer, you will solve unique and complex problems at a rapid pace, utilizing the latest technologies to create solutions that are highly scalable. You will find that there is an unlimited number of opportunities within Amazon, where developing your career across a wide range of teams is highly supported. We are committed to making your work experience as enjoyable as the experiences you’ll be creating for our customers.

Apply now and you will be eligible for Amazon Data Engineer positions that are based on your preferred location, team, and more. We’re hiring across Amazon Stores in the United States and Canada.

Teams with available positions include, but are not limited to:


 * Consumer Technology: Build new generation features and products for amazon.com, constantly improving the Customer and Seller experience for billions around the globe. Whether building site wide features such as reviews and recommendations, category specific software for the likes of Pharmacy, Electronics, Digital Software and Video Games or seller infrastructure, there are a variety of complex problems to tackle using a range of technologies in the design of your technical solutions.
 * Operations Technology: Shape the future of transportation planning and execution on a global scale, that impacts hundreds of fulfillment centers, thousands of Amazonians, and millions of customers across the world. Your technology will support thousands of operators worldwide to design, build and run the best-in-class Amazon transportation network. We are building intelligent software to make transportation more reliable, faster, and less costly, providing a better and less expensive experience for our customers.
 * Human Resources Technology: Create a seamless experience for millions of Amazonians and/or candidates. Whether supporting technologies for onboarding, time and attendance, compensation, amazon.jobs, or recruiting, you’ll deliver robust feature sets, elegant designs, intuitive user interfaces and systems that make it easy for Amazonians to excel at performing critical business functions.
   
   

About Us

Work/Life Balance

Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth

Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign opportunities based on what will help each team member develop into a better-rounded contributor.

Inclusive Team Culture

Here at Amazon, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Key job responsibilities


 * Design, implement, and support a platform providing secured access to large datasets.
 * Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.
 * Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation.
 * Tune application and query performance using profiling tools and SQL.
 * Analyze and solve problems at their root, stepping back to understand the broader context.
 * Learn and understand a broad range of Amazon’s data resources and know when, how, and which to use and which not to use.
 * Keep up to date with advances in big data technologies and run pilots to design the data architecture to scale with the increased data volume using AWS.
 * Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for datasets.
 * Triage many possible courses of action in a high-ambiguity environment, making use of both quantitative analysis and business judgment.
   
   

Basic Qualifications


 * 3+ years of data engineering experience
 * Proficient in SQL
 * Experience with data modeling, warehousing and building ETL pipelines
 * Experience in at least one modern scripting or programming language, such as Python, Java, Scala, or NodeJS
   
   

Preferred Qualifications


 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
 * Experience with big data technologies such as: Hadoop, Hive, Spark, EMR
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com LLC - A03

Job ID: A2820515",Full-time
4134210028,33246798.0,Data Engineer - Data Platform,"Responsibilities
TikTok is the leading destination for short-form mobile video. At TikTok, our mission is to inspire creativity and bring joy. TikTok's global headquarters are in Los Angeles and Singapore, and its offices include New York, London, Dublin, Paris, Berlin, Dubai, Jakarta, Seoul, and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our products are built to help imaginations thrive. This is doubly true of the teams that make our innovations possible. Together, we inspire creativity and enrich life - a mission we aim towards achieving every day. To us, every challenge, no matter how ambiguous, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. At TikTok, we create together and grow together. That's how we drive impact-for ourselves, our company, and the users we serve. Join us.

As a data engineer in the data platform team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world. You'll have the opportunity to gain hands-on experience on all kinds of systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users.

Responsibilities - What You'll Do
• Design and build data transformations efficiently and reliably for different purposes (e.g. reporting, growth analysis, multi-dimensional analysis);
• Design and implement reliable, scalable, robust and extensible big data systems that support core products and business;
• Establish solid design and best engineering practice for engineers as well as non-technical people.



Qualifications
Minimum qualification:
• BS or MS degree in Computer Science or related technical field or equivalent practical experience;
• Experience in the Big Data technologies(Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc.);
• Experience with performing data analysis, data ingestion and data integration;
• Experience with ETL(Extraction, Transformation & Loading) and architecting data systems;
• Experience with schema design, data modeling and SQL queries;
• Passionate and self-motivated about technologies in the Big Data area.

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at https://shorturl.at/cdpT2



Job Information
【For Pay Transparency】Compensation Description (Annually)
The base salary range for this position in the selected city is $145000 - $355000 annually.
Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.
Benefits may vary depending on the nature of employment and the country work location. Employees have day one access to medical, dental, and vision insurance, a 401(k) savings plan with company match, paid parental leave, short-term and long-term disability coverage, life insurance, wellbeing benefits, among others. Employees also receive 10 paid holidays per year, 10 paid sick days per year and 17 days of Paid Personal Time (prorated upon hire with increasing accruals by tenure).
The Company reserves the right to modify or change these benefits programs at any time, with or without notice.
For Los Angeles County (unincorporated) Candidates:
Qualified applicants with arrest or conviction records will be considered for employment in accordance with all federal, state, and local laws including the Los Angeles County Fair Chance Ordinance for Employers and the California Fair Chance Act. Our company believes that criminal history may have a direct, adverse and negative relationship on the following job duties, potentially resulting in the withdrawal of the conditional offer of employment:
1. Interacting and occasionally having unsupervised contact with internal/external clients and/or colleagues;
2. Appropriately handling and managing confidential information including proprietary and trade secret information and access to information technology systems; and
3. Exercising sound judgment.",Full-time
4117848871,65137.0,Data Engineer,"As passionate about our people as we are about our mission.

What We’re All About

Q2 is proud of delivering our mobile banking platform and technology solutions, globally, to more than 22 million end users across our 1,300 financial institutions and fintech clients. At Q2, our mission is simple: Build strong, diverse communities by strengthening their financial institutions. We accomplish that by investing in the communities where both our customers and employees serve and live.

What Makes Q2 Special?

Being as passionate about our people as we are about our mission. We celebrate our employees in many ways, including our “Circle of Awesomeness” award ceremony and day of employee celebration among others! We invest in the growth and development of our team members through ongoing learning opportunities, mentorship programs, internal mobility, and meaningful leadership relationships. We also know that nothing builds trust and collaboration like having fun. We hold an annual Dodgeball for Charity event at our Q2 Stadium in Austin, inviting other local companies to play, and community organizations we support to raise money and awareness together.

The Job At-A-Glance

Q2 is seeking a Data Engineer to join our Data Insights organization. As part of the Data Engineering team, you will build and maintain the Cloud infrastructure for streaming data pipelines and messaging solutions. Our team collaborates closely with cross-functional teams to integrate Kafka into various applications and ensures optimal performance and reliability of the data infrastructure.

A Typical Day


 * Design, implement, and manage Kafka-based data pipelines and messaging solutions to support critical business operations and enable real-time data processing.
 * Configure, deploy, and maintain Kafka clusters, ensuring high availability and scalability to maximize uptime and support business growth.
 * Monitor Kafka performance and troubleshoot issues to minimize downtime and ensure uninterrupted data flow, enhancing decision-making and operational efficiency.
 * Collaborate with development teams to integrate Kafka into applications and services.
 * Develop and maintain Kafka connectors such as JDBC, MongoDB, and S3 connectors, along with topics and schemas, to streamline data ingestion from databases, NoSQL data stores, and cloud storage, enabling faster data insights.
 * Implement security measures to protect Kafka clusters and data streams, safeguarding sensitive information and maintaining regulatory compliance.
 * Optimize Kafka configurations for performance, reliability, and scalability.
 * Automate Kafka cluster operations using infrastructure-as-code tools like Terraform or Ansible to increase operational efficiency and reduce manual overhead.
   
   

Bring Your Passion, Do What You Love. Here’s What We’re Looking For:


 * Degree in Computer Science, Information Systems, or equivalent experience
 * 3-5 years of related professional experience 
 * Advanced knowledge in multiple areas of 
 * data transformations, data pipelines, workflow automation, and scheduling systems  
 * data-centric systems architecture 
 * software engineering and distributed software design 
 * database systems, data warehouses, distributed file storage and compute platforms 
 * Experience with several of the technologies we currently use: 
 * Cloud Providers: AWS, Azure 
 * Data Movement Tools: Kafka, Redis, Kinesis
 * Data Pipelines: Apache Airflow, dbt
 * Data Tools: Pyspark, Snowpark, AWS Glue, Pandas, Databricks, SageMaker
 * Databases: Snowflake, SqlServer, Postgresql 
 * Containerization: Kubernetes, Docker 
 * Languages: Python, C#, Golang, Bash, SQL 
 * CI/CD: GitLab, Azure DevOps
 * SCM: Git, Github, GitLab 
   
   

 

We look for engineers that are comfortable working in a team setting as well as working individually under their own responsibility. Regardless of experience level, all our engineers strive to learn more than they knew yesterday. We pride ourselves on elevating the folks around us. We grow leaders and encourage engineers at all levels of experience to take ownership of challenging work.  

 

This position requires fluent written and oral communication in English.

Applicants must be authorized to work for any employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time.

Health & Wellness


 * Hybrid Work Opportunities
 * Flexible Time Off
 * Career Development & Mentoring Programs
 * Health & Wellness Benefits, including competitive health insurance offerings and generous paid parental leave for eligible new parents
 * Community Volunteering & Company Philanthropy Programs
 * Employee Peer Recognition Programs – “You Earned it”
   
   

Click here to find out more about the benefits we offer.

How We Give Back To The Community

You can learn more about our Q2 Spark Program, Q2 Philanthropy fund, and our employee volunteering programs on our Q2 Community page. Q2 supports dozens of wide-reaching organizations, such as the African American Leadership Institute, and The Trevor Project, promoting diversity and success in leadership and technology. Other deserving beneficiaries include Resource Center helping LGBTQ communities, JDRF, and Homes for our Troops, a group helping veterans rebuild their lives with specially adapted homes.

At Q2, our goal is to be a diverse and inclusive workforce that fosters mutual respect for our employees and the communities we serve. Q2 is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.",Full-time
4098430188,7971559.0,Data Engineer II,"Are you interested in building the future of healthcare and transforming the patient experience? Are you hopeful about what data and medical research can do to improve medicine? We're looking for a Data Engineer to ensure PatientIQ remains at the forefront of using data to drive positive healthcare outcomes.

As a core member of the Data Engineering department, you will be in a dynamic environment that works cross-functionally with all other departments, such as Engineering, Product, Customer Success, and Marketing. You will work on a broad array of problems that rely on data to derive insights for our business and customers. We heavily value diligence, curiosity, and initiative, which are key to unlocking the value of PatientIQ's data for our users and decision-making. Your work will be impactful across the entire organization.

Role Responsibilities


 * Clean and process large, complex datasets using tools such as SQL and Python
 * Migrate client data into PatientIQ's platform per established service level agreements (SLA)
 * Develop rigorous data quality assurance checks throughout the ETL process
 * Design, develop, maintain, and streamline scalable data pipelines to support healthcare data analysis
 * Work closely with data analysts to understand their data needs and develop solutions to meet those needs
 * Monitor and optimize the performance of data pipelines and systems
 * Collaborate with other teams to integrate data from multiple sources
   
   
   

Requirements

Ideal Qualifications


 * BS/MS in Computer Science, Engineering, Mathematics, or a related field
 * 2+ years of experience as a Data Engineer
 * Experience designing, building, and maintaining ETL infrastructure in a production setting
 * Experience working with large, complex datasets
 * Deep knowledge of SQL and at least one programming language (e.g., Python, Java, Ruby, etc.)
 * Experience with Data Warehousing (Redshift, BigQuery, Snowflake)
 * Experience with cloud technologies such as AWS, Google Cloud Platform, or Azure
 * Experience with version control systems (e.g., Git) and writing reusable and extensible code
 * Highly self-motivated with strong analytical problem-solving skills and attention to detail
   
   
   

Nice to Haves


 * Experience working in Healthcare, Finance, or another regulated industry
 * Experience with workflow management systems such as Airflow
 * Experience in machine learning and/or business intelligence
   
   
   

Benefits


 * Great Benefits - top-notch health, dental and vision insurance. Additional perks available including 401K
 * We are Mission Driven - our team is motivated to solve complex problems, drive medicine forward, and ultimately improve patient outcomes
 * True Idea Meritocracy - great ideas win out. We encourage all team members to challenge the status quo because our mission demands this
 * Flexible Time Off - we trust you to take the time you need when you feel it is appropriate, given your workload and responsibilities. No need to track it or save up
 * World-Class Team - we're at the top of our industry because of our employees. They're the best investment we can make, and we never forget that
 * Fast Growing - we are building the largest platform for healthcare providers, industry partners, researchers, and others to collaborate on the mission to improve patient outcomes",Full-time
4145181032,28619152.0,Data Engineer,"The Role We Need:



PadSplit is hiring for a Data Engineer to build and maintain scalable data infrastructure that drives analytics, reporting, and decision-making across the organization. This role is critical to optimizing data pipelines, ensuring data reliability, and enabling cross-functional teams to unlock valuable insights in a remote, high-growth environment.



The Person We Are Looking For:



PadSplit is looking for a highly skilled Data Engineer with expertise in building and maintaining scalable data infrastructure using tools like PostgreSQL, AWS, Snowflake, and dbt. The ideal candidate is a collaborative problem-solver who is eager to optimize data pipelines, enhance query performance, and drive reliable, data-informed decision-making across the organization.








Here’s What You’ll Do Day-to-Day:
 * Design, build, and optimize scalable ETL/ELT pipelines to facilitate seamless data ingestion and transformation processes.
 * Develop and maintain data models to enable self-service analytics and reporting across the organization.
 * Optimize database performance in PostgreSQL, ensuring efficient data storage, retrieval, and query execution.
 * Implement and enhance search capabilities using NoSQL technologies like ElasticSearch or Solr to improve data discovery.
 * Collaborate with data analysts to create insightful dashboards that support data-driven decision-making.
 * Ensure data quality, governance, and security by adhering to best practices in cloud-based data environments.
 * Monitor and troubleshoot issues within data pipelines, focusing on optimizing efficiency and reliability.
 * Work closely with software engineers and product teams to integrate data solutions into operational workflows and product development.




Here’s What You’ll Need to Be Successful:
 * 5+ years of experience in data engineering or a similar role, with a proven track record of designing scalable data solutions.
 * Expertise in PostgreSQL, including database management, query optimization, and performance tuning.
 * Hands-on experience with AWS cloud services such as S3, Lambda, Glue, Redshift, and IAM.
 * Proficiency in data warehousing technologies like Snowflake, Redshift, or BigQuery for cloud-based data storage and analysis.
 * Strong skills in data transformation, modeling, and building efficient ETL/ELT pipelines.
 * Experience with data visualization tools like Mode, Looker, Tableau, or Hex to support analytics and reporting.
 * Knowledge of ElasticSearch or Solr for implementing search indexing and query capabilities.
 * Proficiency in SQL and Python, with experience in automation, scripting, and workflow orchestration (e.g., Airflow).
 * Understanding of CI/CD pipelines, infrastructure-as-code principles, and cloud-based deployment practices.
 * Strong analytical and problem-solving abilities, with a passion for leveraging data-driven insights to inform decisions.
 * Nice-to-Have: Experience with streaming data solutions like Kafka or Kinesis, knowledge of machine learning pipelines, and familiarity with data privacy regulations such as GDPR or CCPA.




The Interview Process:
 * Your application will be reviewed for possible next steps by the Hiring Manager.
 * If you meet eligibility requirements, the next step would be a video screen with a member of the PeopleOps team for about thirty (30) minutes.
 * If warranted, the next step would be a video interview with our CTO for forty-five (45) minutes.
 * If warranted, the next step would be a video panel interview with key stakeholders at PadSplit for one-and-a-half (1.5) hour.
 * The panel interview will require a candidate to work on a technical assessment where you will showcase your engineering skills to the panel for discussion. 
 * If warranted, then we move to offer!




Compensation, Benefits, and Perks:
 * Fully remote position - we swear!
 * Competitive compensation package including an equity incentive plan
 * National medical, dental, and vision healthcare plans
 * Company provided life insurance policy
 * Optional accidental insurances, FSA, and DCFSA benefits
 * Unlimited paid-time (PTO) policy with eleven (11) company-observed holidays
 * 401(k) plan 
 * Twelve (12) weeks of paid time off for both birth and non-birth parents
 * The opportunity to do what you love at a company that is at the forefront of solving the affordable housing crisis








Compensation is based on the role's scope, market benchmarks, the person's expertise and experience, and the impact of their contributions to our business goals.",Full-time
4151647211,532234.0,Data Engineer,"Mmg Insurance Company

Job Description

Job Title: Data Engineer

Department: Data, Analytics, and Insights

Reports To: Data, Analytics, and Insights Director

FLSA Status: Exempt

Summary

Facilitates the utilization of enterprise data for helping decision makers. Develops pipelines to transform raw data into reliable and usable information for analysis. Incorporates best practices for data transformation, utilizing automated delivery. Ensures data quality standards are maintained throughout the transformation process. Works with the project team to ensure data deliverables are both timely and meet specifications.

Essential Duties And Responsibilities


 * Plans and creates data pipelines supporting business intelligence.
 * Builds data migration scripts and procedures using tools such as SSIS.
 * Participates in data lake architecture design and decision making.
 * Understands and utilizes Microsoft Azure cloud platform and tools.
 * Collaborates on data model design.
 * Maintains technical documentation of data systems including but not limited to the MMG Data Catalog
 * Facilitates importing of third-party data into data lake.
 * Investigates exceptions in data migrations.
 * Supports and performs data masking activities using tools such as Delphix.
 * Collaborates on sub-production environment data refresh strategy.
 * Executes sub-production environment data refreshes.
 * Builds validations and checks for examining and maintaining data quality.
 * Creates queries to support data delivery including reports, dashboards and other visualizations.
 * Evaluates data migration approaches and technologies and recommends process improvements as needed.
 * Work with data and analytics experts to strive for greater functionality in our data systems.
 * Stays current with business operations and business intelligence technologies
 * Develops scripts for data patches as needed.
 * Maintains good working relationships and strong communication with other members of the team.
 * Travels as required to perform the duties and responsibilities of the position and to fulfill educational requirements. (May include overnight stays.)
 * Other duties may be assigned.
   
   

Other Skills And Abilities


 * Demonstrates leadership by exhibiting confidence in self and others; Inspires and motivates others to perform well; effectively influences actions and opinions of others; Accepts feedback from others; Gives appropriate recognition to others. Possesses above-average telephone skills.
 * Possesses above-average interpersonal and relationship skills.
 * Customer Service – Manages difficult or emotional customer situations; Responds promptly to customer needs.
 * Solicits customer feedback to improve service; Responds to request for service and assistance; Meets commitments.
 * Professionalism – Approaches others in a tactful manner; Reacts well under pressure; Treats others with respect and consideration regardless of their status or position; Accepts responsibility for own actions; Follows through on commitments.
 * Demonstrates the ability to consistently maintain a positive attitude.
 * Works cooperatively and productively with employees.
 * Is self-motivated with strong organizational skills.
 * Demonstrates the ability to multi-task effectively and efficiently.
   
   

EDUCATION And/or EXPERIENCE

Bachelor's degree in a field with an emphasis on analytical skills, such as mathematics, engineering, computer science or a Bachelor’s degree in business administration with an ability to demonstrate SQL skills. 2-4 experience in the same or related role.",Full-time
4139248930,10788836.0,Data Engineer,"Are you interested in leading the transformation of cancer care through putting world-leading scientific data and knowledge in the hands of doctors and other members of the medical team? Do you have a passion for solutions that empower patients to take charge of their care and bring world-class solutions to winning the cancer battle? If so, join our team at VieCure, the company that promises to revolutionize the way cancer care is delivered.




At VieCure, we are dedicated to transforming the oncology space through innovative technology solutions. Our mission is to empower clinicians and patients with data-driven insights, supporting personalized cancer care. Join our team of passionate professionals working to make a difference in people’s lives.




We are seeking a skilled and collaborative Data Engineer to join our team in Denver, CO. The ideal candidate will work alongside our DBA and API/Services team to design, build, and maintain scalable data solutions that support the company's growing needs. This role is critical in ensuring the seamless flow, transformation, and quality of data across systems to drive operational and analytical excellence.




Key Responsibilities:

 * Data Pipeline Development: Design, build, and maintain scalable and reliable ETL/ELT pipelines to support data ingestion, transformation, and loading into Azure SQL and SQL Server databases.
 * Data Integration: Collaborate with the API/Services team to develop seamless integrations between APIs, microservices, and database systems, ensuring efficient data exchange and synchronization.
 * Data Modeling: Work with the DBA to design and implement optimized database schemas and data models that align with application and reporting requirements.
 * Data Quality Assurance: Implement processes and tools to monitor, validate, and ensure the quality and integrity of the data across the pipeline.
 * Cross-Team Collaboration: Act as a liaison between the DBA, API/Services team, and business stakeholders to understand data requirements and deliver solutions that support business goals.
 * Documentation: Maintain comprehensive documentation for pipelines, data models, and processes to ensure smooth knowledge transfer and onboarding.
 * Security & Compliance: Ensure data engineering practices adhere to data security, privacy, and compliance regulations, working alongside the DBA to enforce database-level policies.
 * Data Insights Enablement: Enable analytics and reporting by preparing data for visualization and analysis (e.g., aggregating or transforming data for Power BI, dashboards, etc.).




Experience & Skills:

 * Proven experience with Azure SQL and SQL Server.
 * Hands-on experience building and maintaining ETL/ELT pipelines.
 * Familiarity with data integration best practices and tools.
 * Knowledge of Power BI or similar visualization tools.
 * Strong understanding of relational database design and data modeling.
 * Experience in cross-functional collaboration and stakeholder communication.
 * Understanding of data security, privacy, and compliance considerations.
 * Strong analytical and problem-solving skills.




Preferred Qualifications:

 * Familiarity with tools such as Azure Data Factory or SSIS.
 * Experience working in a healthcare or regulated environment.
 * Certifications such as Azure Data Engineer Associate (preferred but not required).




Work Environment:

This position is full-time, on-site at our Denver, CO office. We value collaboration and teamwork, and our office culture is designed to foster innovation and creativity.




Why Join Us?

 * Competitive salary and benefits package.
 * Opportunity to work on impactful projects in the healthcare technology space.
 * Collaborative and supportive work environment.
 * A chance to make a tangible difference in patients’ lives.




How to Apply: If you are passionate about data engineering and want to contribute to a meaningful mission, we want to hear from you! Please submit your resume and a brief cover letter detailing your experience and interest in the role.",Full-time
4120825524,10667.0,Data Engineer,"At Meta, we have many opportunities to work with data each and every day. In this role as a Data Engineer on the Meta Data Center’s Data Science team, your primary responsibility will be to partner with key stakeholders, data scientists and software engineers to support and enable the continued growth critical to Meta's Data Center organization. You will be responsible for creating the technology and data architecture that moves and translates data used to inform our most critical strategic and real-time decisions. You will also help translate business needs into requirements and identify efficiency opportunities. In addition to extracting and transforming data, you will be expected to use your expertise to build extensible data models, provide meaningful recommendations and actionable strategies to partnering data scientist for performance enhancements and development of best practices, including streamlining of data sources and related programmatic initiatives. The ideal candidate will have a passion for working in white space and creating impact from the ground up in a fast-paced environment. This position is part of the Infrastructure Data Center team.

Data Engineer Responsibilities:


 * Partner with leadership, engineers, program managers and data scientists to understand data needs
 * Apply proven expertise and build high-performance scalable data warehouses
 * Design, build and launch efficient & reliable data pipelines to move and transform data (both large and small amounts)
 * Securely source external data from numerous partners
 * Intelligently design data models for optimal storage and retrieval
 * Deploy inclusive data quality checks to ensure high quality of data
 * Optimize existing pipelines and maintain of all domain-related data pipelines
 * Ownership of the end-to-end data engineering component of the solution
 * Support on-call shift as needed to support the team
 * Design and develop new systems in partnership with software engineers to enable quick and easy consumption of data
   
   

Minimum Qualifications:


 * BS/MS in Computer Science or a related technical field
 * 5+ years of Python or other modern programming language development experience
 * 5+ years of SQL and relational databases experience
 * 5+ years experience in custom ETL design, implementation and maintenance
 * 3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, Digdag, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M)
 * 3+ years experience with Data Modeling
 * Experience working with cloud or on-premises Big Data/MPP analytics platform (i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar)
 * 2+ years experience working with enterprise DE tools and experience learning in-house DE tools
 * Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.
   
   

Preferred Qualifications:


 * Experience with more than one coding language
 * Experience designing and implementing real-time pipelines
 * Experience with data quality and validation
 * Experience with SQL performance tuning and end-to-end process optimization
 * Experience with anomaly/outlier detection
 * Experience with notebook-based Data Science workflow
 * Experience with Airflow
 * Experience querying massive datasets using Spark, Presto, Hive, Impala, etc.
 * Experience building systems integrations, tooling interfaces, implementing integrations for ERP systems (Oracle, SAP, Saleforce etc).
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$145,000/year to $204,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4108550319,66321745.0,Junior Data Engineer,"Since 2010 SynergisticIT has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients.

The Tech Job market has been affected by massive layoffs and since 2021 there have been more than 600,000.00 tech layoffs.

The Job market is Hyper Competitive. For 1 position 500-1000 candidates or more are applying and laid off job seekers are also competing for entry level Job positions.

Please see the below links to know more about Synergisticit and some useful tips

https://www.synergisticit.com/candidate-outcomes/

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://www.youtube.com/playlist?list=PLJgkOBQ51j5AHT5I6n29glr0q6trzkxYD

https://synergisticit.wistia.com/medias/k6t6a1n4kb

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

We regularly interact with the Top Tech companies to give our candidates a competitive advantage.

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

We are continuously looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Data Engineers, Machine Learning engineers for full time positions with clients.

Who Should Apply? Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We need Data Science/Machine learning/Data Analyst and Java Full stack candidates

Preferred SKILLS For Java /Full Stack/Devops Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Knowledge of Core Java , javascript , C++ or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

For data Science/Data Analyst/AI/Machine learning Positions

Preferred SKILLS

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude

Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools

Candidates lacking technical skills can research our other programs which can assist in landing a Job

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Contract
4108503387,66321745.0,Junior Data Engineer,"Since 2010 SynergisticIT has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients.

The Tech Job market has been affected by massive layoffs and since 2021 there have been more than 600,000.00 tech layoffs.

The Job market is Hyper Competitive. For 1 position 500-1000 candidates or more are applying and laid off job seekers are also competing for entry level Job positions.

Please see the below links to know more about Synergisticit and some useful tips

Synergisticit Pics /Salaries of Successful Candidates

Synergisticit at Oracle Cloudworld 2023

Synergisticit at Gartner Data & Analytics summit

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

We regularly interact with the Top Tech companies to give our candidates a competitive advantage.

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

We are continuously looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Data Engineers, Machine Learning engineers for full time positions with clients.

Who Should Apply? Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We need Data Science/Machine learning/Data Analyst and Java Full stack candidates

Preferred SKILLS For Java /Full Stack/Devops Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Knowledge of Core Java , javascript , C++ or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

For data Science/Data Analyst/AI/Machine learning Positions

Preferred SKILLS

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude

Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools

Candidates lacking technical skills can research our other programs which can assist in landing a Job

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Contract
4052423502,66321745.0,Junior Data Engineer,"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you need

Position open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, IT enthusiasts, Python/Java developers, Data analysts/ Data Scientists.

We welcome candidates with all visas and citizens to apply.

Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates looking to make their careers in IT Industry

We assist in filing for STEM extension and also for H1b and Green card filing.

Candidates who are serious about their future in the IT Industry and have set big goals for themselves.

Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience which our clients need with great outcomes

Candidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancement

Candidates Who Lack Experience

Have had a break in careers

Lack Technical Competency

Different visa candidates who want to get employed and settle down in the USA

Please Also Check The Below Links

https://www.synergisticit.com/candidate-outcomes/

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

How Can Recently Laid Off Tech People Get Employed Again? | SynergisticIT

If not a match candidates can opt for Skill enhancement.

REQUIRED SKILLS For Java/Software Programmers


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Core Java , javascript , C&plus;&plus; or software programming
 * Spring boot, Microservices and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, Python, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, Time series analysis

Please understand skills are required by clients for selection even if its Junior or entry level position the additional skills are the only way a candidate can be picked by clients.

No third party candidates or c2c candidates

Please understand skills are required by clients for selection even if its Junior or entry level position the additional skills are the only way a candidate can be picked by clients.

Please apply to the posting

No phone calls please. Shortlisted candidates would be reached out.",Full-time
4139526575,85677.0,Data Engineer,"Georgia Pacific’s BI and Data Analytics group supporting key segments including Packaging & Cellulose and Building Products is looking for a Data Engineer to join our team. We are looking for entrepreneurial minded innovators and leaders who can help us further develop this service of exceptionally high value to our business, improve the capabilities and delivery of the team.

LOCATION: ATLANTA, GA

What You Will Do

A successful candidate will bring knowledge of best-in-class BI development standards, practices. You must be enthusiastically collaborative, passion for working with people, value seeking, open to challenge and be challenged with new ideas and established approaches with an appetite for learning and innovation. Ideal candidate would have strong technical experience to design and develop BI Solutions and partner across cross functional business and technology teams across the globe to co deliver impactful solutions.


 * Design, Develop, Test, and deploy Pipelines from a wide variety of sources with Batch, Real-time and Near Real-time capabilities across our Segments.
 * Demonstrate strong conceptual, analytical, and problem-solving skills and ability to articulate ideas and technical solutions effectively to external IT partners as well as internal data team members.
 * Work with cross-functional teams, on-shore/off-shore, development/QA teams/Vendors in a matrixed environment for data delivery.
 * Maintain, monitor, troubleshoot, fix, and explain failures/errors in existing ETL jobs, BI models, dashboards, and reports.
 * Work with users and BI team to develop business requirements and documentation.
 * Update and maintain key data cloud solution deliverables and diagrams.
 * Ensure conformance and compliance using Georgia-Pacific data architecture guidelines and enterprise data strategic vision.
   
   

Who You Are (Basic Qualifications)


 * Experience with overall all IT experience.
 * Experience in PySpark, Glue, Lambda, S3 and other AWS tool sets.
 * Develop data pipeline from Enterprise data lake using PySpark, Glue and other AWS tools.
 * Hands-on experience in designing, implementing, managing large-scale data and ETL solutions with AWS IaaS and PaaS Compute, Storage, and Database services (S3, RDS, Lambda, IAM, RedShift, Glue, EMR, Kinesis, Athena).
 * Hands on experience in Cloud monitoring stack like CloudTrail, CloudWatch and AWS Event-bridge trigger service.
 * Working experience in building Data Marts and Data Modeling.
 * Good understanding of Data warehouse, ETL, AWS architecture and Redshift.
   
   

What Will Put You Ahead


 * AWS certifications: Solution Architect (SAA/SAP) or Data Analytics Specialty (DAS).
 * Full life cycle project experience in building a data solution in AWS
 * Understanding of common DevSecOps/DataOps and CICD processes, methodologies, and technologies.
 * Strong knowledge in PySpark, Redshift store procedures, Kinesis and AWS Glue service.
 * Experience in working with Infor and SAP S/4 Hana.
   
   

At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.

Hiring Philosophy

All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here.

Who We Are

As a Koch company and a leading manufacturer of bath tissue, paper towels, paper-based

packaging, cellulose, specialty fibers, building products and much more, Georgia-Pacific works to meet evolving needs of customers worldwide with quality products. In addition to the products we make, we operate one of the largest recycling businesses. Our more than 30,000 employees in over 150 locations are empowered to innovate every day – to make everyday products even better.

At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.

Our Benefits

Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength - focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes - medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.

Additionally, everyone has individual work and personal needs. We seek to enable the best work environment that helps you and the business work together to produce superior results.

Equal Opportunities

Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, some offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please click here for additional information.",Full-time
4151640169,361843.0,Big Data Engineer,"Job Responsibilities


 * Work with tech and product teams to develop new tools and systems to support the growth of the business
 * Create and optimize our data pipeline architecture
 * Build data access platform for our data science and tech teams
 * Design and implement modernized ETL through cloud-based solutions
 * Design and develop large-scale data structures for business intelligence analytics by using data mining tools
 * Write reliable software to ingest, transform and distribute data into our internal applications.
 * Support infrastructure and database processes
 * Add and improve logging and monitoring to current solutions
 * Provide ad-hoc queries and analysis as needed.
   
   

Job Skills


 * Similar and 5+ years of professional experience, or MS and 3+ years
 * Strong experience with databases, SQL, writing and debugging
 * Professional experience with Python development
 * Working knowledge of bash scripting and/or JavaScript
 * Experience working with MongoDB, Redis, and PostgreSQL
 * Experience with cloud-based data solutions (AWS preferred)
 * Experience with automation/configuration management/enterprise schedulers
 * System monitoring and alerting, dashboarding experience
 * Working understanding of code and script (Java, Python, JavaScript, bash)",Full-time
4011556532,5045143.0,Data Engineer,"StackAdapt is a self-serve advertising platform that specializes in multi-channel solutions including native, display, video, connected TV, audio, in-game, and digital out-of-home ads. We empower hundreds of digitally-focused companies to deliver outcomes and exceptional campaign performance everyday. StackAdapt was founded with a vision to be more than an advertising platform, it’s a hub of innovation, imagination and creativity.

We're looking to add Data Engineers to our data science team! This team works on solving complex problems for StackAdapt's digital advertising platform. You'll be working directly with our data scientists, data engineers, Engineering team, and CTO on building pipelines and ad optimization models. With databases that process millions of requests per second, there's no shortage of data and problems to tackle.

Want to learn more about our Data Science Team: https://alldus.com/ie/blog/podcasts/aiinaction-ned-dimitrov-stackadapt/

Learn more about our team culture here: https://www.stackadapt.com/careers/data-science

Watch our talk at Amazon Tech Talks: https://www.youtube.com/watch?v=lRqu-a4gPuU

StackAdapt is a Remote First company, and we are open to candidates located anywhere in the US for this position.

What you'll be doing:


 * Design modular and scalable real time data pipelines to handle huge datasets
 * Understand and implement custom ML algorithms in a low latency environment
 * Work on microservice architectures that run training, inference, and monitoring on thousands of ML models concurrently
   
   

What you'll bring to the table:


 * Have the ability to take an ambiguously defined task, and break it down into actionable steps
 * Have deep understanding of algorithm and software design, concurrency, and data structures
 * Experience in implementing probabilistic or machine learning algorithms
 * Interest in designing scalable distributed systems
 * A high GPA from a well-respected Computer Science program
 * Enjoy working in a friendly, collaborative environment with others
   
   

StackAdapters enjoy:


 * Competitive salary + equity
 * 401K matching
 * 3 weeks vacation + 3 personal care days + 1 Culture & Belief day + birthdays off
 * Access to a comprehensive mental health care platform
 * Health benefits from day one of employment
 * Work from home reimbursements
 * Optional global WeWork membership for those who want a change from their home office
 * Robust training and onboarding program
 * Coverage and support of personal development initiatives (conferences, courses, etc)
 * Access to StackAdapt programmatic courses and certifications to support continuous learning
 * Mentorship opportunities with industry leaders
 * An awesome parental leave policy
 * A friendly, welcoming, and supportive culture
 * Our social and team events!
   
   

If this role speaks to you then please apply - we'd love to speak with you. Due to a high volume of interest, only those shortlisted for interview will be contacted.

StackAdapt is a diverse and inclusive team of collaborative, hardworking individuals trying to make a dent in the universe. No matter who you are, where you are from, who you love, follow in faith, disability (or superpower) status, ethnicity, or the gender you identify with (if you’re comfortable, let us know your pronouns), you are welcome at StackAdapt. If you have any requests or requirements to support you throughout any part of the interview process, please let our Talent team know.

About StackAdapt

We've been recognized for our diverse and supportive workplace, high performing campaigns, award-winning customer service, and innovation. We've been awarded:

Ad Age Best Places to Work 2024

G2 Top Software and Top Marketing and Advertising Product for 2024

Campaign’s Best Places to Work 2023 for the UK

2024 Best Workplaces for Women and in Canada by Great Place to Work®

#1 DSP on G2 and leader in a number of categories including Cross-Channel Advertising

",Full-time
4148682774,28868872.0,Data Engineer II,"Department: Data - Analytics

Location: 1668 S. Garfield Ave. 2nd Floor, Alhambra, CA 91801

Compensation: $105,000 - $120,000 / year



Description

We are currently seeking a highly motivated Data Engineer II. This role will report to the Manager of Data Integration and work closely with data analysts, data engineers, data scientists, and clinical leaders to produce deliverables for internal and external clients. With over a million managed lives across the country and terabytes of data generated, our teams need to be continuously equipped with the tools and insights to drive strategy and innovation to further our core values of improving patient outcomes and empowering our providers.

Our Values:

   
   
 * Patients First
   
   
 * Empowering the Independent Provider
   
   
 * Be Innovative
   
   
 * Operate with Integrity & Deliver Excellence
   
   
 * Team of One
   
   
   
   
   
   

What You'll Do


   
   
 * Use data engineering best practices to produce high quality, maximally available data models which are intuitive to data analysts and trusted by stakeholders
   
   
 * Develop deep domain knowledge in healthcare operations, tracking regulatory developments related to analytics products you maintain
   
   
 * Apply quality measures and other metrics to datasets originating from internal and external clients
   
   
 * Build scalable ELT pipelines and business intelligence dashboards as needed, embracing automation wherever possible
   
   
 * Implement data quality checks which proactively identify data issues and distributional shifts to ensure accuracy of downstream analytical products
   
   
   
   
   
   

Qualifications


   
   
 * Bachelor's degree required in healthcare, analytics, statistics, finance, business, or related field; Master's degree (MBA, MPH) preferred.
   
   
 * Experience with relational databases.
   
   
 * Strong understanding of database structures, theories, principles, and practices
   
   
 * Working knowledge with programming or scripting languages such as Python, Spark, and SQL.
   
   
 * Knowledge of professional software engineering practices and best practices for the full software development life cycle (SDLC), including documentation, coding standards, code reviews, source control management, build processes, testing, and operations.
   
   
 * Familiarity with normalized, dimensional, star schema and snowflake schematic models
   
   
 * Working experience with Databricks preferred
   
   
 * Familiarity with business intelligence exploratory or visualization tools (e.g., Tableau, PowerBI.) preferred
   
   
 * Strong written and oral communication skills.
   
   
 * Experience with Excel.
   
   
   
   

You're a great for this role if:

   
   
 * 2+ years of experience working in the data and analytics landscape
   
   
 * 2+ years of experience using version control to manage code changes
   
   
 * 2+ years of experience in managed care or other healthcare data field preferred
   
   
 * 1+ years' using cloud-based services from AWS, GCP, or Azure
   
   
   
   
   
   

Environmental Job Requirements and Working Conditions


   
   
 * This position is remotely based in the U.S.
   
   
 * The total compensation target pay range for this role is: $105,000 - $120,000. The salary range represents our national target range for this role.
   
   
   
   
   
   

Astrana Health is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based on race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. All employment is decided based on qualifications, merit, and business need. If you require assistance in applying for open positions due to a disability, please email us at humanresourcesdept@astranahealth.com to request an accommodation.

Additional Information:
The job description does not constitute an employment agreement between the employer and employee and is subject to change by the employer as the needs of the employer and requirements of the job change.",Full-time
4137189322,1586.0,"Data Engineer, F3 DASH","Description

Are you interested in being a part of Amazon’s fastest growing business? Are you excited to work on cutting edge Big Data technologies to help shape the future of Grocery data? If the answer to both these questions is Yes, then come be a part of Amazon Fresh’s Central Data Infrastructure team (DASH). Our vision is to build a world class, centralized and secure data infrastructure for Amazon’s Worldwide Omnichannel Grocery Business. Our mission is to make it extremely convenient for Internal stakeholders, 3P partners and the Grocery engineering community to access timely and accurate data for all their reporting and analytics needs. The scale and the complexity of the data we manage requires constant innovation and pushing the boundaries on what’s possible. This role offers you an opportunity to work on VP level visibility initiatives and make a lasting impression on how grocery data is managed and distributed across the globe.

Key job responsibilities

In This Role You Will


 * Help build the infrastructure to answer questions with data, using software engineering best practices, data management fundamentals, data storage principles, and recent advances in distributed systems
 * Manage AWS resources.
 * Collaborate with Business Intelligence Engineers to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation
 * Collaborate with Data Scientists to implement advanced analytics algorithms that exploit our rich data sets for statistical analysis, prediction, clustering and machine learning
 * Drive the architecture and technology choices that enable a world-class user experience
 * Develop expertise in a broad range of Amazon’s data resources and know when, how, and which to use and which not to use
 * Encourage the organization to adopt next-generation data architecture strategies, proposing both data flows and storage solutions
 * be comfortable with a degree of ambiguity and willing to develop quick proof of concepts, iterate and improve
 * Create extensible designs and easy to maintain solutions with the long term vision in mind
 * Have an understanding and empathy for business objectives, and continually align your work with those objectives and seek to deliver business value. You listen effectively.
   
   

A day in the life

Successful candidate would have extensive experience working with big data, building data warehouses and data processing services. They are effective at seeing data patterns and building generic data solutions to improve user experience. Proficiency in SQL and data modelling allows to create data warehouses and tables conforming to wide range of business needs. Previous ETL and MPP experience enables candidate to build extensible and scalable pipelines capable of processing large amounts of data in a short time, ex. >1T rows within few hours. Wide industry experience helps detect inefficiencies in existing designs and address them with minimal effort.

About The Team

F3 DASH is Amazon Fresh central data team responsible for the creation and maintenance of Amazon Grocery’s global data infrastructure. Our mission is to make all of grocery data easily accessible across multiple businesses by all users from a single location without any restrictions for all their reporting and analytics needs. Our long-term vision is to build a best-in-class data infrastructure to support worldwide grocery data to enable timely reporting and automated decision-making with standardized metrics to deliver top-line and bottom-line impact to Amazon’s grocery business.

Basic Qualifications


 * 1+ years of data engineering experience
 * Experience with data modeling, warehousing and building ETL pipelines
 * Experience with one or more query language (e.g., SQL, PL/SQL, DDL, MDX, HiveQL, SparkSQL, Scala)
 * Experience with one or more scripting language (e.g., Python, KornShell)
   
   

Preferred Qualifications


 * Experience with big data technologies such as: Hadoop, Hive, Spark, EMR
 * Experience with any ETL tool like, Informatica, ODI, SSIS, BODI, Datastage, etc.
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $91,200/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com Services LLC

Job ID: A2872706",Full-time
4146251839,1353.0,Python SQL Data Engineer," * Skill set requirement: Python lead – Strong Python API development experience . experience SQL in building complex data logic at the back-end layer.
 * Very good at complex problem-solving skills and applying them using Python and SQL like Customer Identity resolution, Fuzzy Matching logic implementation..etc
 * Experience with relational and NoSQL databases like Postgres, BigQuery
 * Exposure to containerization, serverless architecture, and Cloud Native development. (GKE, AWSLambda / GCP Cloud run / GCP Cloud functions..etc)
 * Hands-on expertise in software development practices and with data engineering tools like Airflow, Apache Beam, and Streaming through pub/sub, NoSQL..etc
 * Preferred experience with Google Cloud.
   
   

Salary Range - $120,000-$140,000 a year",Full-time
4120910711,1586.0,"Data Engineer , Amazon Pharmacy","Description

Innovation is at the core of what we do. We believe that by removing and reducing the barriers that prevent people from taking their medications, we can help customers conveniently get the medications they need, when they need them and take them as prescribed.

We have provided customers with the ability to find transparent and simple pricing, receive 24/7 customer service support, and have their meds delivered to their doorsteps while creating programs and products that embody our mission and position ourselves in becoming the world’s safest and fastest online pharmacy.

We are looking for a Data Engineer to join us on our journey to make it drastically easier for customers to find, choose, afford, and engage with the services, products, and professionals they need to get and stay healthy!

As a Data Engineer in Pharmacy team, you will partner with Software Engineers, Business Intelligence Engineers and product managers. You will design, implement, and maintain next generation BI solutions for large scale, highly secure and complex data structures to ensure the data is auditable, available and accessible. You will gain a deep understanding of our services and the data they produce, and become our resident expert in how to transform that data into a format that is useful for analytics and business intelligence. You will proactively help to identify new data for integration with our platform, and propose and implement new technologies to help us better understand our data.

#everydaybetter

Key job responsibilities


 * Design, implement, maintain and support a secure and robust data lake in native AWS with 300+ datasets which contain both PII and PHI data.
 * Implement ingestion routines both real time and batch using best practices in modeling, ETL/ELT processes by leveraging AWS technologies and big data tools.
 * Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL, Python and AWS big data technologies.
 * Gather business and functional requirements and translate into secure, robust, scalable,
   
   

operable solutions with a flexible and adaptable architecture.


 * Collaborate with engineers to help adopt best practices in system creation, integrity, test design, analysis, validation, and documentation.
 * Help continually improve ongoing reporting and analysis processes, automating or simplifying
   
   

self-service tools for customers.


 * Explore and learn the latest AWS technologies to provide new capabilities and increase
   
   

efficiency

Basic Qualifications


 * 3+ years of data engineering experience
 * Experience with data modeling, warehousing and building ETL pipelines
 * 3+ years of analyzing and interpreting data with Redshift, Oracle, NoSQL etc. experience
 * Experience with big data technologies such as: Hadoop, Hive, Spark, EMR
 * Bachelor's degree
 * 3+ years of experience in at least one of the programming languages like Python, Java etc.
 * Experience in working and delivering end-to-end projects independently.
 * Excellent written and verbal communication skills Amazon is committed to a diverse and
 * inclusive workplace.
   
   

Preferred Qualifications


 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
 * Experience providing technical leadership and mentoring other engineers for best practices on data engineering
 * Experience working with secure medical data, pipeline, services and HIPAA compliant environment,.
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com Services LLC

Job ID: A2832739",Full-time
4149381337,34072.0,Data Engineer,"If you’re looking for a full-service agency that’s shaking up the marketing landscape and creating momentum– you’re in the right place. At Hiebing, we’re a passionate, full-service crew fueled by curiosity, dedicated to doing great work and good deeds. Collaboration is second nature for our teams in both Madison and Austin. They work together to craft meaningful stories for brands we love and pro bono causes we believe in across the country. We believe in the power of our “We Before Me” credo, where the team always has your back and your voice is amplified by others building on your great ideas with a “Yes And”. Think you’d thrive here? Come join the vibe!

We are seeking a skilled and motivated Data Engineer to join our data science team. The ideal candidate will possess a strong background in data engineering with the ability to build scalable data pipelines using software, develop machine learning models, and implement data-driven solutions to complex business problems.

Required Skills & Job Responsibilities:

Data Pipeline Development:


 * Design, develop, and maintain scalable and efficient data pipelines for collecting, processing, and storing large volumes of structured and unstructured data
 * Ensure data quality and integrity by implementing robust data validation and cleansing processes
   
   

Data Infrastructure Management:


 * Work closely with the marketing science and IT teams to build and maintain the data infrastructure, including databases, data warehouses, and cloud-based solutions
 * Implement data governance and security best practices to ensure data compliance and privacy
   
   

Performance Optimization:


 * Optimize the performance of data processing and machine learning workflows to ensure efficiency and scalability
 * Troubleshoot and resolve issues related to data pipelines, model deployment, and infrastructure
   
   

Research and Innovation:


 * Stay up-to-date with the latest advancements in data science, artificial intelligence, and data engineering technologies
 * Propose and explore new methodologies and tools to enhance the capabilities of the data science team
   
   

Collaboration and Communication:


 * Collaborate with cross-functional teams, including data scientists, software engineers, and business analysts, to understand business requirements and deliver data-driven solutions
 * Communicate complex technical concepts and results to non-technical stakeholders in a clear and concise manner
   
   

The most qualified candidates will also have the following skills:

Machine Learning Model Development:


 * Develop, train, and deploy machine learning models to address various business challenges such as predictive analytics, classification, clustering, and recommendation systems
 * Continuously monitor and improve model performance through regular evaluation and tuning
   
   

Software Development:


 * Develop and maintain high-quality, production-ready code for data science applications and tools
 * Implement and follow software development best practices, including version control, testing, and documentation
   
   

Qualifications:


 * Bachelor’s or Master’s degree in Computer Science, Data Science, Engineering, or a related field
 * Proven experience as a Data Science Engineer, Data Engineer, or a similar role
 * Experience with data ELT software
 * Proficiency in SQL and experience with database technologies, preferably Snowflake
 * Experience with big data technologies and cloud platforms (e.g., AWS, Google Cloud, Azure)
 * Sufficient programming skills in Python
 * Familiarity with data visualization tools (e.g., Tableau, Power BI)
 * Solid understanding of machine learning algorithms, data structures, and software development principles
 * Knowledge of continuous integration and continuous deployment (CI/CD) practices
 * Understanding of data privacy regulations and best practices
 * Strong problem-solving skills and ability to work independently as well as part of a team
 * Excellent communication and interpersonal skills
 * Ability to work independently as well as part of a team
 * Ability to work on-site Monday, Tuesday & Wednesday weekly in an open-office environment
 * Ability to work in the United States without requiring sponsorship now or in the future
   
   

Preferred Qualifications:


 * Snowflake SnowPro Advanced Data Engineer certification
 * Microsoft Azure Security Engineer Associate certification
   
   

Powered by JazzHR

Qeaf7a0ZkT",Full-time
4120825493,10667.0,"Data Engineer, Product Analytics","As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a world-class data engineering community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Data Engineer, Product Analytics Responsibilities:


 * Manage and execute data warehouse plans for a product or a group of products to solve well-scoped problems
 * Identify the data needed for a business problem and implement logging required to ensure availability of data, while working with data infrastructure to triage issues and resolve
 * Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights in a meaningful way
 * Build data expertise and leverage data controls to ensure privacy, security, compliance, data quality, and operations for allocated areas of ownership
 * Design, build and launch new data models and visualizations in production, leveraging common development toolkits
 * Independently design, build and launch new data extraction, transformation and loading processes in production, mentoring others around efficient queries
 * Support existing processes running in production and implement optimized solutions with limited guidance
 * Define and manage Service Level Agreements for data sets in allocated areas of ownership
   
   

Minimum Qualifications:


 * Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent
 * 2+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions
 * 2+ years of experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala or others.)
   
   

Preferred Qualifications:


 * Master's or Ph.D degree in a STEM field
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$114,000/year to $171,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4133245417,3067.0,ETL Data Engineer,"The position demands a professional with 10+ years of overall experience, including 3-5years of hands-on current experience with the tool.




Primary Skills:

 * Extensive Experience in ETL Tool – Pentaho
 * Expert in creating data flows
 * Modification of existing complex data flows leading to optimization
 * Hands on experience of formulating, executing, and debugging SQL queries
 * Knowledge of reading data for APIs
 * Experience in creating data models




Additional skills:

 * Extensive experience in Extract Transform Load methodology
 * Knowledge of data sources, transform maps to push data to ServiceNow
 * Prior experience of working in regulatory reporting / remediation / banking industry




Tasks:

The role involves

 * analysing the source data feeds,
 * identifying gaps and inconsistencies in the data reporting,
 * provide detailed insights on how the source data is processed and reported,
 * coordinating with technology owners to analyse and implement the required changes in source feeds,
 * and collaborating with the Patch management reporting teams to ensure seamless data integration and enhanced report quality.

The pay range for this role is $130k - $150k per annum including any bonuses or variable pay. Tech Mahindra also offers benefits like medical, vision, dental, life, disability insurance and paid time off (including holidays, parental leave, and sick leave, as required by law). Ask our recruiters for more details on our Benefits package. The exact offer terms will depend on the skill level, educational qualifications, experience, and location of the candidate.




Thanks & Regards




Tech Mahindra is an Equal Employment Opportunity employer. We promote and support a diverse workforce at all levels of the company. All qualified applicants will receive consideration for employment without regard to race, religion, color, sex, age, national origin or disability. All applicants will be evaluated solely on the basis of their ability, competence, and performance of the essential functions of their positions with or without reasonable accommodations. Reasonable accommodations also are available in the hiring process for applicants with disabilities. Candidates can request a reasonable accommodation by contacting the company ADA Coordinator at ADA_Accomodations@TechMahindra.com.”",Full-time
4120822651,10667.0,"Data Engineer, Product Analytics","As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a world-class data engineering community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Data Engineer, Product Analytics Responsibilities:


 * Manage and execute data warehouse plans for a product or a group of products to solve well-scoped problems
 * Identify the data needed for a business problem and implement logging required to ensure availability of data, while working with data infrastructure to triage issues and resolve
 * Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights in a meaningful way
 * Build data expertise and leverage data controls to ensure privacy, security, compliance, data quality, and operations for allocated areas of ownership
 * Design, build and launch new data models and visualizations in production, leveraging common development toolkits
 * Independently design, build and launch new data extraction, transformation and loading processes in production, mentoring others around efficient queries
 * Support existing processes running in production and implement optimized solutions with limited guidance
 * Define and manage Service Level Agreements for data sets in allocated areas of ownership
   
   

Minimum Qualifications:


 * Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent
 * 2+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions
 * 2+ years of experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala or others.)
   
   

Preferred Qualifications:


 * Master's or Ph.D degree in a STEM field
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$114,000/year to $171,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4148243135,2433416.0,Data Engineer II,"Our Opportunity

Chewy is seeking a Data Engineer II to join the growing Transportation Systems team. You will be a part of a team responsible for strategic system design, research initiatives, and financial data cataloging centered around our transportation planning and execution. This includes building enterprise data pipelines that drive analytic solutions and creating data products for analytics and data scientist team members to improve their productivity. The Transportation team operates in a fast-paced environment where every day brings new challenges and opportunities. You will be responsible for building and implementing data products and technologies which will handle the growing business needs and play a key role in redefining what it means to be a world-class ecommerce organization.

What You’ll Do


 * Own the design, development, and maintenance of our end to end data pipelines!
 * Tackle complex data issues to provide insights needed to accomplish our business goals
 * Develop data products for analytics and data scientist Team Members to boost their efficiency
 * Assist in crafting Proof of Concepts and advise, consult, mentor and coach other data and analytic professionals on data standards and practices
 * Lead the evaluation, implementation and deployment of emerging tools and process for analytic data engineering to improve our efficiency as a team
 * Develop and deliver communication and education plans on analytic data engineering capabilities, standards, and processes
 * Code, test, and detail new or modified data systems to build robust and scalable applications for data analytics
 * Actively contribute to team discussions and initiatives, valuing diverse perspectives and encouraging a cooperative work atmosphere.
 * Data cataloging & documentation of data sources
 * Regularly meet with business partners and analytics teams to understand and solve data needs, short-term and medium-term
 * Build trust with internal collaborators to encourage data-driven decision-making
 * Partner with data engineering to grow the value of our data products by onboarding new data from our backend and 3rd party systems
   
   

What You’ll Need


 * Bachelor of Science or Master's degree in Computer Science, Engineering, Information Systems or related field.
 * 5+ years of experience in Data Engineering or Business Intelligence roles working with ETL, Data Modeling, and Data Architecture, developing modem data pipelines and applications for analytics (e.g., BI, reporting, dashboards) and advanced analytics (e.g., machine learning, deep learning) use cases.
 * Current permanent U.S. work authorization is required
 * Expertise crafting and implementing enterprise data pipelines using modern data engineering approach and tools: Spark, PySpark, Scala, Docker, Databricks, Glue, cloud-native EDW (Snowflake, Redshift), Kafka/Confluence, Presto/Dremio/Athena
 * Proficiency in AWS ecosystem, Java, Python, SQL
 * Proficiency in data warehouse methodologies and techniques from transactional databases to dimensional data modeling, to wide denormalized data marts.
 * Experience with writing and reviewing version-controlled code (GitHub).
 * Experience with building statistical and predictive models from scratch.
 * Experience effectively presenting insights and summarizing complex data to diverse audiences through visualizations.
 * To be a self-starter with the ability to take initiative and drive projects forward independently.
 * Familiarity with supply chain and logistics a plus
 * Demonstrated experience working with and delivering to various key Team Members from different parts of the company (Finance, Engineering, Human Resources, Supply Chain etc.)
 * Excellent written and oral communication skills
 * This role requires 5% domestic travel
   
   

Chewy values diversity and inclusion. Contact CAAR@chewy.com for accommodations related to disabilities or religion.

If you have a question regarding your application, please contact HR@chewy.com.

To access Chewy's Customer Privacy Policy, please click here. To access Chewy's California CPRA Job Applicant Privacy Policy, please click here.

Chewy is committed to equal opportunity. We value and embrace diversity and inclusion of all Team Members. If you have a disability under the Americans with Disabilities Act or similar law, and you need an accommodation during the application process or to perform these job requirements, or if you need a religious accommodation, please contact CAAR@chewy.com.

If you have a question regarding your application, please contact HR@chewy.com.

To access Chewy's Customer Privacy Policy, please click here. To access Chewy's California CPRA Job Applicant Privacy Policy, please click here.",Full-time
4066233825,1586.0,Data Engineer,"Description

Data Engineer

Come build the future as a Data Engineer at Amazon, where you will be inspired working along best-in-class inventors and innovators! You will have the opportunity to create meaningful experiences that deliver on the ever-evolving needs of our customers, and your work will impact millions of people around the world.

As an Amazon Data Engineer, you will solve unique and complex problems at a rapid pace, utilizing the latest technologies to create solutions that are highly scalable. You will find that there is an unlimited number of opportunities within Amazon, where developing your career across a wide range of teams is highly supported. We are committed to making your work experience as enjoyable as the experiences you’ll be creating for our customers.

Apply now and you will be eligible for Amazon Data Engineer positions that are based on your preferred location, team, and more. We’re hiring across Amazon Stores in the United States and Canada.

Teams with available positions include, but are not limited to:


 * Consumer Technology: Build new generation features and products for amazon.com, constantly improving the Customer and Seller experience for billions around the globe. Whether building site wide features such as reviews and recommendations, category specific software for the likes of Pharmacy, Electronics, Digital Software and Video Games or seller infrastructure, there are a variety of complex problems to tackle using a range of technologies in the design of your technical solutions.
 * Operations Technology: Shape the future of transportation planning and execution on a global scale, that impacts hundreds of fulfillment centers, thousands of Amazonians, and millions of customers across the world. Your technology will support thousands of operators worldwide to design, build and run the best-in-class Amazon transportation network. We are building intelligent software to make transportation more reliable, faster, and less costly, providing a better and less expensive experience for our customers.
 * Human Resources Technology: Create a seamless experience for millions of Amazonians and/or candidates. Whether supporting technologies for onboarding, time and attendance, compensation, amazon.jobs, or recruiting, you’ll deliver robust feature sets, elegant designs, intuitive user interfaces and systems that make it easy for Amazonians to excel at performing critical business functions.
   
   

About Us

Work/Life Balance

Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth

Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign opportunities based on what will help each team member develop into a better-rounded contributor.

Inclusive Team Culture

Here at Amazon, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Key job responsibilities


 * Design, implement, and support a platform providing secured access to large datasets.
 * Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.
 * Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation.
 * Tune application and query performance using profiling tools and SQL.
 * Analyze and solve problems at their root, stepping back to understand the broader context.
 * Learn and understand a broad range of Amazon’s data resources and know when, how, and which to use and which not to use.
 * Keep up to date with advances in big data technologies and run pilots to design the data architecture to scale with the increased data volume using AWS.
 * Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for datasets.
 * Triage many possible courses of action in a high-ambiguity environment, making use of both quantitative analysis and business judgment.
   
   

Basic Qualifications


 * 3+ years of data engineering experience
 * Proficient in SQL
 * Experience with data modeling, warehousing and building ETL pipelines
 * Experience in at least one modern scripting or programming language, such as Python, Java, Scala, or NodeJS
   
   

Preferred Qualifications


 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
 * Experience with big data technologies such as: Hadoop, Hive, Spark, EMR
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com LLC - A03

Job ID: A2820515",Full-time
4141159029,15259345.0,Data Engineer,"Role Overview

Data Research Engineers in Citadel Securities are responsible for the curation of large-scale structure and unstructured data and for data assimilation across a multitude of sources. They focus on the translation of high-level conceptual queries to efficient back-end queries on extremely large-scale data collections. Our data science is supported by state-of-the-art cloud-based services that scale out. The advanced queries will be crucial in enriching alpha signals for our multi-billion-dollar Systematic Business and research function, enabling us to deliver a competitive edge against competitors.

Our team of talented Data Research Engineers works hand-in-hand with the QR teams to design the most insightful queries. In addition, they closely work with business operations and QRs in order to identify and evaluate the most promising datasets from anywhere in the world and available in numerous modalities. We are looking for individuals passionate about driving business impact through data!

Responsibilities

 * Act as data owner of several datasets each with its own unique schema and delivery frequency
 * Partner with researchers to produce high-value datasets
 * Design, create, automate, and maintain custom data pipelines
 * Extract the raw data
 * Clean and normalize the data
 * Translate high-level market research concepts into scalable processes that further transform the data
 * Handle all edge cases
 * Develop high-performance schemas and queries
 * Setup “data checks” and alerts to determine when the data is “bad”'
 * Load the processed dataset to a format easily digested by quantitative researchers and models
 * Develop tooling to facilitate the development and monitoring of custom data pipelines
 * Setup analytical infrastructure to facilitate exploration and visualization of datasets
 * Large scale cloud development of applications as a service

Skills and Qualifications

Required:

 * Demonstrated experience driving meaningful business outcomes through data engineering
 * Prior ownership of a data project (or at least a large part of it)
 * Strong attention to detail
 * Good analytical and quantitative abilities
 * Demonstrated ability to quickly learn new technologies and skills
 * Experience with ETL dev

Preferred:

 * BigQuery
 * Experience with data manipulation and query design and optimization
 * Experience in time series forecasting and machine learning techniques
 * Strong data science skills
 * Strong coding skills: proficiency in Python, SQL DBs, Cloud, schedulers, containers, CI/CD, software packaging
 * Strong ability to communicate with other stakeholders (e.g., data vendors, QRs, etc.)
 * Data Build Tool (DBT)
 * Education: BS degree in Computer Science, Mathematics, or related Computer Engineering or Science curriculum

About Citadel Securities

Citadel Securities is the next-generation capital markets firm and a leading global market maker. We provide institutional and retail investors with the liquidity they need to trade a broad array of equity and fixed income products in any market condition. The brightest minds in finance, science and technology use powerful, advanced analytics to solve the market’s most critical challenges, turning big ideas into real-world outcomes.


",Full-time
4052854724,66321745.0,Junior Data Engineer,"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you need

Position open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, IT enthusiasts, Python/Java developers, Data analysts/ Data Scientists.

We welcome candidates with all visas and citizens to apply.

Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates looking to make their careers in IT Industry

We assist in filing for STEM extension and also for H1b and Green card filing.

Candidates who are serious about their future in the IT Industry and have set big goals for themselves.

Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience which our clients need with great outcomes

Candidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancement

Candidates Who Lack Experience

Have had a break in careers

Lack Technical Competency

Different visa candidates who want to get employed and settle down in the USA

Please Also Check The Below Links

https://www.synergisticit.com/candidate-outcomes/

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

How Can Recently Laid Off Tech People Get Employed Again? | SynergisticIT

If not a match candidates can opt for Skill enhancement.

REQUIRED SKILLS For Java/Software Programmers


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Core Java , javascript , C++ or software programming
 * Spring boot, Microservices and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, Python, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, Time series analysis

Please understand skills are required by clients for selection even if its Junior or entry level position the additional skills are the only way a candidate can be picked by clients.

No third party candidates or c2c candidates

Please understand skills are required by clients for selection even if its Junior or entry level position the additional skills are the only way a candidate can be picked by clients.

Please apply to the posting

No phone calls please. Shortlisted candidates would be reached out.",Full-time
4151624925,28987090.0,Data Engineer,"Abridge was founded in 2018 with the mission of powering deeper understanding in healthcare. Our AI-powered platform was purpose-built for medical conversations, improving clinical documentation efficiencies while enabling clinicians to focus on what matters most—their patients.

Our enterprise-grade technology transforms patient-clinician conversations into structured clinical notes in real-time, with deep EMR integrations. Powered by Linked Evidence and our purpose-built, auditable AI, we are the only company that maps AI-generated summaries to ground truth, helping providers quickly trust and verify the output. As pioneers in generative AI for healthcare, we are setting the industry standards for the responsible deployment of AI across health systems.

We are a growing team of practicing MDs, AI scientists, PhDs, creatives, technologists, and engineers working together to empower people and make care make more sense.

The Role

Our generative AI-powered products are revolutionizing the practice of medicine, and we’re looking for a highly motivated Data Engineer to join our growing US-based Data Engineering team. In this crucial role, you will build and optimize large scale data infrastructure to drive business decisions and machine learning research.

What You'll Do


 * Build and maintain scalable data services, pipelines and storage solutions for the feedback of unstructured application data for ML training and evaluation purposes.
 * Build and manage OLAP databases, ELTs and general data tooling for analytics , business decisions and products features.
 * Work closely with a team of frontend and backend engineers, product managers, and analysts.
 * Optimize data infrastructure to enhance the throughput, latency and reliability of the data system.
 * Investigate and correct issues identified through data operations monitors, tools, and reports.
 * Designs data integrations and data quality framework.
   
   

Who You Are


 * 5+ years of experience in Data Engineering or Backend Engineering with a focus on data systems.
 * Proficient in at least one general purpose programming language (e.g., Python, Java, Scala) and SQL (any variant)
 * Proficiency with at least one modern cloud provider (GCP, AWS, Azure) and accompanying data services
 * Experience in building systems that manage the ingest, transformation, and management of both structured and unstructured data types
 * Deep knowledge of modern data infrastructure best practices
 * Experience with distributed systems and different distributed processing frameworks
 * Experience with Terraform, Kubernetes, and containerization technologies.
 * Familiarity with the deploying ML models at scale a bonus
 * Experience in building data products that are well-modeled, documented and easy to understand and maintain.
 * Ability to prioritize amidst changing priorities in a fast moving environment
   
   

Base Salary: $200,000 USD - $265,000+ USD per year + Equity

The salary range provided is based on transparent pay guidelines and is an estimate for candidates residing in the San Francisco and New York City metro areas. The actual base salary will vary depending on the candidate's location, relevant experience, skills, qualifications, and other job-related factors. Additionally, this role may include the opportunity to participate in a company stock option plan as part of the total compensation package.

Must be willing to work from our SF office at least 3x per week

This position requires a commitment to a hybrid work model, with the expectation of coming into the office a minimum of (3) three times per week. Relocation assistance is available for candidates willing to move to San Francisco.

Must be willing to travel up to 10%

Abridge typically hosts a three-day builder team retreat every 3-6 months. These retreats often feature internal hackathons, collaborative project sessions, and social events that allow the team to connect in person.

We value people who want to learn new things, and we know that great team members might not perfectly match a job description. If you’re interested in the role but aren’t sure whether or not you’re a good fit, we’d still like to hear from you.

Why Work at Abridge?


 * Be a part of a trailblazing, mission-driven organization that is powering deeper understanding in healthcare through AI!
 * Opportunity to work and grow with talented individuals and have ownership and impact at a high-growth startup.
 * Flexible/Unlimited PTO — Salaried team members can take off as much approved time off as they need, plus 13 paid holidays
 * Equity — For all salaried team members
 * Medical insurance — We pay 100% of the premium for you + 75% for dependents. 3 Aetna plans to choose from.
 * Dental & Vision insurance — We pay 100% of the premium for you + 75% for dependents. 2 Aetna plans to choose from.
 * Flexible Spending (FSA) & Health Savings (HSA) Accounts
 * Learning and Development budget — $3,000 per year for coaching, courses, workshops, conferences, etc.
 * 401k Plan — Contribute pre-tax dollars toward retirement savings.
 * Paid Parental Leave — 16 weeks paid parental leave, for all full-time employees
 * Flexible working hours — We care more about what you accomplish than what specific hours you’re working.
 * Home Office Budget — We provide up to $1,600 in a one-time reimbursement to set up your home office.
 * Sabbatical Leave — 30 days of paid Sabbatical Leave after 5 years of employment.
 * ...Plus much more!
   
   

Life at Abridge

At Abridge, we’re driven by our mission to bring understanding and follow-through to every medical conversation. Our culture is founded on doing things the “inverse” way in a legacy system—focusing on patients, instead of the system; focusing on outcomes, instead of billing; and focusing on the end-user experience, instead of a hospital administrator's mandate.

Abridgers are engineers, scientists, designers, and health policy experts from a diverse set of backgrounds—an experiment in alchemy that helps us transform an industry dominated by EHRs and enterprise into a consumer-driven experience, one recording at a time. We believe in strong ideas, loosely held, and place a high premium on a growth mindset. We push each other to grow and expose each other to the latest in our respective fields. Whether it’s holding a PhD-level deep dive into understanding fairness and underlying bias in machine learning models, debating the merits of a Scandinavian design philosophy in our UI/UX, or writing responses for Medicare rules to influence U.S. health policy, we prioritize sharing our findings across the team and helping each other be successful.

Diversity & Inclusion

Abridge is an equal opportunity employer. Diversity and inclusion is at the core of what we do. We actively welcome applicants from all backgrounds (including but not limited to race, gender, educational background, and sexual orientation).

Staying Safe - Protect Yourself From Recruitment Fraud

We are aware of individuals and entities fraudulently representing themselves as Abridge recruiters and/or hiring managers. Abridge will never ask for financial information or payment, or for personal information such as bank account number or social security number during the job application or interview process. Any emails from the Abridge recruiting team will come from an @abridge.com email address. You can learn more about how to protect yourself from these types of fraud by referring to this article. Please exercise caution and cease communications if something feels suspicious about your interactions.",Full-time
4126534681,76262108.0,Data Engineer,"Come and change the world of AI with the Kumo team!

Companies spend millions of dollars to store terabytes of data in data lakehouses, but only leverage a fraction of it for predictive tasks. This is because traditional machine learning is slow and time consuming, taking months to perform feature engineering, build training pipelines, and achieve acceptable performance.

At Kumo, we are building a machine learning platform for data lakehouses, enabling data scientists to train powerful Graph Neural Net models directly on their relational data, with only a few lines of declarative syntax known as Predictive Query Language. The Kumo platform enables users to build models a dozen times faster, and achieve better model accuracy than traditional approaches.

We're seeking intellectually curious and highly motivated Data Engineers to become foundational members of our Machine Learning and Data Platform team.

Your Foundation:


 * 1+ years of professional experience in SaaS/Enterprise companies
 * Strong experience with data ingestion and connectors
 * Experience in building end-to-end production-grade data solutions on AWS or GCP
 * Experience in building scalable ETL pipelines.
 * Ability to plan effective data storage, security, sharing, and publishing within an organization.
 * Experience in developing batch ingestion and data transformation routines using ETL tools.
 * Familiarity with AWS services such as S3, Kinesis, EMR, Lambda, Athena, Glue, IAM, RDS.
 * Proficiency in several programming languages (Python, Scala, Java).
 * Familiarity with orchestration tools such as Temporal, Airflow, Luigi, etc.
 * Self-starter, motivated, with the ability to structure complex problems and develop solutions.
 * Excellent communication skills and ability to explain data and analytics strengths and weaknesses to both technical and senior business stakeholders.
   
   

Your Extra Special Sauce:


 * Deep familiarity with Spark and/or Hive
 * Understanding of different storage formats like Parquet, Avro, Arrow, and JSON and when to use each
 * Understanding of schema designs like normalization vs. denormalization.
 * Proficiency in Kubernetes, and Terraform.
 * Azure, ADF and/or Databricks skills
 * Experience with integrating, transforming, and consolidating data from various data systems into analytics solutions
 * Good understanding of databases, SQL, ETL tools/techniques, data profiling and modeling
 * Strong communications skills and client engagement
   
   

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",Full-time
4149943363,51634180.0,Data Engineer,"Role: Data Engineer

Location: Bentonville is primary location where they need to sit


 * Spark,
 * Kafka
 * Data design,
 * Data services,
 * Data warehousing
 * Sql - creating structures, tables, building services around that
 * R
 * SSAS
 * Azure aql,
 * Google bigquery
 * DBA type of work
   
   

Requirement: Bachelor’s degree in Computer Science or related field or equivalent combination of industry-related professional experience and education.",Contract
4120827290,10667.0,"Data Engineer, Product Analytics","As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a world-class data engineering community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Data Engineer, Product Analytics Responsibilities:


 * Manage and execute data warehouse plans for a product or a group of products to solve well-scoped problems
 * Identify the data needed for a business problem and implement logging required to ensure availability of data, while working with data infrastructure to triage issues and resolve
 * Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights in a meaningful way
 * Build data expertise and leverage data controls to ensure privacy, security, compliance, data quality, and operations for allocated areas of ownership
 * Design, build and launch new data models and visualizations in production, leveraging common development toolkits
 * Independently design, build and launch new data extraction, transformation and loading processes in production, mentoring others around efficient queries
 * Support existing processes running in production and implement optimized solutions with limited guidance
 * Define and manage Service Level Agreements for data sets in allocated areas of ownership
   
   

Minimum Qualifications:


 * Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent
 * 2+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions
 * 2+ years of experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala or others.)
   
   

Preferred Qualifications:


 * Master's or Ph.D degree in a STEM field
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$114,000/year to $171,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4143019026,210064.0,Data Engineer,"Genpact (NYSE: G) is a global professional services and solutions firm delivering outcomes that shape the future. Our 125,000+ people across 30+ countries are driven by our innate curiosity, entrepreneurial agility, and desire to create lasting value for clients. Powered by our purpose – the relentless pursuit of a world that works better for people – we serve and transform leading enterprises, including the Fortune Global 500, with our deep business and industry knowledge, digital operations services, and expertise in data, technology, and AI.




Inviting applications for the role of Principal Consultant- Databricks Developer!




We are seeking a highly skilled and experienced Databricks Platform Architect to lead the design, implementation, and optimization of our Databricks platform. The ideal candidate will have a strong background in cloud-based data processing systems, data warehousing, and big data technologies. They will work closely with our data engineering team to ensure that our Databricks platform is optimized for performance, scalability, and reliability.




Responsibilities

 * Architect and design solutions to meet functional and non-functional requirements.
 * Lead the design, implementation, and optimization of our Databricks platform.
 * Work closely with our data engineering team to ensure that our Databricks platform is optimized for performance, scalability, and reliability.
 * Develop and maintain a comprehensive understanding of our data pipeline and data architecture.
 * Collaborate with other teams to ensure that our Databricks platform is integrated with our other systems and technologies.
 * Develop and maintain documentation for our Databricks platform, including architecture diagrams, deployment guides, and operational procedures.
 * Provide guidance and support to our data engineering team on Databricks-related issues.
 * Create and review architecture and solution design artifacts.
 * Evangelize re-use through the implementation of shared assets.
 * Enforce adherence to architectural standards/principles, global product-specific guidelines, usability design standards, etc.
 * Proactively guide engineering methodologies, standards, and leading practices.
 * Guidance of engineering staff and reviews of as-built configurations during the construction phase.
 * Provide insight and direction on roles and responsibilities required for solution operations.
 * Identify, communicate and mitigate Risks, Assumptions, Issues, and Decisions throughout the full lifecycle.
 * Considers the art of the possible, compares various architectural options based on feasibility and impact, and proposes actionable plans.
 * Demonstrate strong analytical and technical problem-solving skills.
 * Ability to analyze and operate at various levels of abstraction.
 * Ability to balance what is strategically right with what is practically realistic.
 * Growing the Data Engineering business by helping customers identify opportunities to deliver improved business outcomes, designing and driving the implementation of those solutions.
 * Supporting and developing our people, including learning & development, certification & career development plans
 * Providing technical governance and oversight for platform design and implementation
 * Should have technical foresight to understand new technology and advancement.
 * Leading team in the definition of best practices & repeatable methodologies in Cloud Data Engineering, including Data Storage, ETL, Data Integration & Migration, Data Warehousing and Data Governance
 * Should have Technical Experience in Azure, AWS & GCP Cloud Data Engineering services and solutions.
 * Contributing to Sales & Pre-sales activities including proposals, pursuits, demonstrations, and proof of concept initiatives
 * Evangelizing the Data Engineering service offerings to both internal and external stakeholders
 * Development of Whitepapers, blogs, webinars and other though leadership material
 * Development of Go-to-Market and Service Offering definitions for Data Engineering
 * Working with Learning & Development teams to establish appropriate learning & certification paths for their domain.
 * Expand the business within existing accounts and help clients, by building and sustaining strategic executive relationships, doubling up as their trusted business technology advisor.
 * Position differentiated and custom solutions to clients, based on the market trends, specific needs of the clients and the supporting business cases.
 * Build new Data capabilities, solutions, assets, accelerators, and team competencies.
 * Manage multiple opportunities through the entire business cycle simultaneously, working with cross-functional teams as necessary.




Qualifications we seek in you!

Minimum qualifications

 * Proven experience, as a Data Architect, Data Solutions Architect, or similar role in a consulting environment.
 * Hands-on Experience to design platform and build Databricks based solution on cloud platform (Azure, AWS).
 * Excellent technical architecture skills, enabling the creation of future-proof, complex global Platform solutions on Databricks.
 * Excellent interpersonal communication and organizational skills are required to operate as a leading member of global, distributed teams that deliver quality services and solutions.
 * Ability to rapidly gain knowledge of the organizational structure of the firm to facilitate work with groups outside of the immediate technical team.
 * Knowledge and experience in IT methodologies and life cycles that will be used.
 * Familiar with solution implementation/management, service/operations management, etc.
 * Leadership skills – ability to inspire others and persuade.
 * Maintains close awareness of new and emerging technologies and their potential application for service offerings and products.
 * Bachelor’s Degree or equivalency (CS, CE, CIS, IS, MIS, or engineering discipline) or equivalent work experience.
 * Experience in a Platform architecture role using service and hosting solutions such as private/public cloud IaaS, PaaS, and SaaS platforms.
 * Experience in architecting and designing technical solutions for cloud-centric solutions based on industry standards using IaaS, PaaS, and SaaS capabilities.
 * Must have strong hands-on experience on various cloud services like ADF/Lambda, ADLS/S3, Security, Monitoring, Governance & Compliance.
 * Must have experience to design platform on Databricks.

hands-on Experience to design and build Databricks based solution on any cloud platform. hands-on experience to design and build solution powered by DBT models and integrate with databricks.

 * Must be very good designing End-to-End solution on cloud platform.
 * Must have good knowledge of Data Engineering concept and related services of cloud.
 * Must have good experience in Python and Spark.
 * Must have good experience in setting up development best practices.
 * Good to have knowledge of docker and Kubernetes.
 * Experience with claims-based authentication (SAML/OAuth/OIDC), MFA, RBAC, SSO etc.
 * Knowledge of cloud security controls including tenant isolation, encryption at rest, encryption in transit, key management, vulnerability assessments, application firewalls, SIEM, etc.
 * Experience building and supporting mission-critical technology components with DR capabilities.
 * Experience with multi-tier system and service design and development for large enterprises
 * Extensive, real-world experience designing technology components for enterprise solutions and defining solution architectures and reference architectures with a focus on cloud technologies.
 * Exposure to infrastructure and application security technologies and approaches
 * Familiarity with requirements gathering techniques.







""The approximate annual base compensation range for this position is $100k to $115k. The actual offer, reflecting the total compensation package plus benefits will be determined by a number of factors which include but are not limited to the applicant's experience, knowledge, skills, and abilities; geographic location; and internal equity.""




“Los Angeles, California based candidates are not eligible for this role. New York area candidates are eligible for this role only.”




Genpact is an Equal Opportunity Employer and considers applicants for all positions without regard to race, color, religion or belief, sex, age, national origin, citizenship status, marital status, military/veteran status, genetic information, sexual orientation, gender identity, physical or mental disability or any other characteristic protected by applicable laws. Genpact is committed to creating a dynamic work environment that values diversity and inclusion, respect and integrity, customer focus, and innovation. Get to know us at genpact.com and on LinkedIn, X, YouTube, and Facebook.




Furthermore, please do note that Genpact does not charge fees to process job applications and applicants are not required to pay to participate in our hiring process in any other way. Examples of such scams include purchasing a 'starter kit,' paying to apply, or purchasing equipment or training.",Full-time
4137505474,15191764.0,"Data Engineer, 1+ Years of Experience","Snap Inc is a technology company. We believe the camera presents the greatest opportunity to improve the way people live and communicate. Snap contributes to human progress by empowering people to express themselves, live in the moment, learn about the world, and have fun together. The Company’s three core products are Snapchat, a visual messaging app that enhances your relationships with friends, family, and the world; Lens Studio, an augmented reality platform that powers AR across Snapchat and other services; and its AR glasses, Spectacles.

Snap Engineering teams build fun and technically sophisticated products that reach hundreds of millions of Snapchatters around the world, every day. We’re deeply committed to the well-being of everyone in our global community, which is why our values are at the root of everything we do. We move fast, with precision, and always execute with privacy at the forefront.

We’re looking for a Data Engineer to join our Decision & Insights Team!

What you’ll do:


 * Work closely with stakeholders in engineering, product, data science, and governance to make high quality datasets available to consumers in a timely manner
 * Develop scalable data ETL pipelines that automate manual data processes, optimize data delivery, and adhere with privacy and governance principles
 * Implement and manage data warehousing solutions and ensure data integrity and quality through rigorous testing and validation
 * Build tooling and implement systems to overcome limitations of the data consumption portals when appropriate
 * Implement and maintain data security practices to ensure data privacy and protection, and compliance with data governance policies and regulations.
   
   

Knowledge, Skills & Abilities:


 * Experience in building data pipelines to serve reporting needs
 * Experience owning all or part of a team roadmap
 * Ability to prioritize requests from multiple stakeholders in disparate domains
 * Ability to effectively communicate complex projects to non-technical stakeholders
   
   

Minimum Qualifications:


 * BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
 * 1+ year experience in SQL or similar languages
 * 1+ years development experience in at least one object-oriented or scripting language (Python, Java, Scala, etc)
   
   

Preferred Qualifications:


 * Hands-on experience with Google BigQuery, Spark, and Hadoop
 * Experience in version control systems such as Git, and workflow management tools such as Airflow
 * Experience in ETL tools and data architecture and warehousing experience
 * Experience leading a small team of data or software engineers
 * Strong analytical and problem-solving skills
 * Excellent communication and teamwork abilities
 * Attention to detail and commitment to data quality
   
   

If you have a disability or special need that requires accommodation, please don’t be shy and provide us some information.

""Default Together"" Policy at Snap: At Snap Inc. we believe that being together in person helps us build our culture faster, reinforce our values, and serve our community, customers and partners better through dynamic collaboration. To reflect this, we practice a “default together” approach and expect our team members to work in an office 4+ days per week.

At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets.

Our Benefits: Snap Inc. is its own community, so we’ve got your back! We do our best to make sure you and your loved ones have everything you need to be happy and healthy, on your own terms. Our benefits are built around your needs and include paid parental leave, comprehensive medical coverage, emotional and mental health support programs, and compensation packages that let you share in Snap’s long-term success!

Compensation

In the United States, work locations are assigned a pay zone which determines the salary range for the position. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. The starting pay may be negotiable within the salary range for the position. These pay zones may be modified in the future.

Zone A (CA, WA, NYC):

The base salary range for this position is $118,000-$176,000 annually.

Zone B:

The base salary range for this position is $112,000-$167,000 annually.

Zone C:

The base salary range for this position is $100,000-$150,000 annually.

This position is eligible for equity in the form of RSUs.",Full-time
3875375343,46623.0,Data Engineer,"Description

Your role at GEI.

GEI Consultants has an opening in our Operational Development Team for a qualified Data Engineer to support a variety of systems and data engineering tasks focused on data flow activities. The majority of our systems are based in MS SQL Server, Tableau Server, Azure, and FastField Forms. This person will primarily work closely with members of the Operational Development Team and with members of our IT staff. The ideal candidate will be focused, detail-oriented, and driven to attain and maintain very high standards for efficiency and accuracy in data acquisition and integration into our systems. The ideal candidate will have more than 3 years of data engineering experience in the AEC industry or in similar science and/or engineering environments. GEI seeks a committed, self-motivated, organized and detail-oriented individual who anticipates issues and thrives on creative, independent problem solving within a rapid, deadline-driven environment.

Essential Responsibilities & Duties


 * ETL of data from a wide variety of sources
 * Database and Data Warehouse design/expansion/backup & recovery
 * Index management and optimization
 * Support data sources for Tableau Server, Power BI, and ArcGIS
 * Stored procedure development and maintenance
 * Identify new opportunities within GEI where existing business approaches to data can be replaced with a more efficient/automated data flow and presentation of data for analysis
 * Develop and optimize ETL/SSIS packages to facilitate data transfer between FTP, remote data loggers, Azure, and on-premises databases
 * Troubleshoot SSIS package permission issues related to execute-as/data source read/write access
 * SQL Agent Job development and monitoring
 * Develop data reporting and visualizations as specified by clients using Tableau, SSRS, etc
 * Perform DML and DDL via tsql/stored procedures executed directly within SSMS and remotely via SSIS
 * Develop test plans, implementation plans, and project timelines for various data engineering projects
 * Define, prioritize, communicate, and foster shared understanding of project objectives and scope
 * Coordinate the development of standard operating procedures (SOPs), technical training programs, and QA/QC procedures for staff and work product
 * Team with all staff necessary to complete assignments
 * Collaborate with technical team members to ensure the solution design satisfies project objectives and business requirements
 * Other duties as assigned
   
   

Minimum Qualifications


 * 3+ years of experience in a position performing similar data engineering tasks
 * Proven record of ability to design, manage, and support MS SQL Server and Azure databases
 * Ability to work with the following programming/mark-up/scripting languages preferred: VB.net, python, XML, javascript, and R
 * Bachelor's Degree, from an accredited college or university
 * MS SQL Server/Azure certification preferred
 * Ability to develop project plans and meet deadlines
 * Self-starter with attention to detail and stakeholder needs
 * Able to critically analyze and solve problems of a complex nature
 * Excellent Communication skills
 * Able to work on multiple projects of moderate complexity simultaneously and independently
 * Proficient in organization and time management skills
 * Familiarity with engineering, environmental science, and/or chemistry subject matter preferred.
 * Able to work effectively in GEI’s partnership model, including a team environment, building rapport and relationships.
   
   

We are GEI.

Some of the world’s most pressing problems - from climate change to sustainable development, to critical infrastructure and the future of our energy supply - need our brightest and diverse minds working together to create safer, more resilient communities for tomorrow.

We are technical experts, collaborators, and entrepreneurs who draw from diverse backgrounds to solve our clients’ most complex challenges.

With nearly 60 offices across North America, we offer a range of engineering, science, and technical consulting services. Our range of expertise, project types, and culture make us the choice for top talent in the AEC industry.

Employee-owned. Employee-focused.

As a 100% employee-owned company, our employees support our flat leadership structure, have a say in how our business operates and benefit from our financial success. We are committed to employee growth with career development opportunities, competitive total rewards, a well-being program, flexible work arrangements and more. Our company culture is driven by our 4 Cs - we are Client-Centered, Curious, Collaborative, and Community Minded - which support our focus on sustainability, safety, diversity, equity and inclusion. Get to know us better by visiting GEI’s career site here.

GEI’s Total Rewards Package


 * Market-Competitive Compensation, including Eligibility for an Annual Performance Bonus
 * Pay Range For This Position: $33.65-72.11/hour
 * Comprehensive Benefits Program, including Medical, Dental, Vision, Life, Disability and More
 * Well-Being Program and Paid Parental Leave
 * Commuter Benefits
 * Hybrid Work Schedules and Cell Phone Stipends
 * GEI University (GEIU) with Continuing Education Assistance and Tuition Reimbursement
 * Connecting Conversation Program with a Focus on Professional Development and Opportunities for Advancement
 * Support and Financial Rewards for Publication Awards, Professional Dues, and Professional Licenses
 * Paid Holidays and Generous Paid Time Off Program
 * Rewards and Recognition
 * GEI-Funded Profit Sharing and 401(k)
 * Opportunity to be an Owner and Shareholder (Learn more here)
 * A Vibrant Culture that is Focused on Partnership, Sustainability, Giving Back to Our Communities and Diversity, Equity and Inclusion
 * And More…
   
   

Physical Job Requirements

Sedentary

X

Light

Medium

Other

Activity Level Throughout Workday

Physical Activity Requirements

Occasional

(0-35% of day)

Frequent

(33-66% of day)

Continuous

(67-100% of day)

Not Applicable

Sitting

X

Standing

X

Walking

X

Climbing

X

Lifting (floor to waist level) (in pounds)

X

Lifting (waist level and above) (in pounds)

X

Carrying objects

X

Push/pull

X

Twisting

X

Bending

X

Reaching forward

X

Reaching overhead

X

Squat/kneel/crawl

X

Wrist position deviation

X

Pinching/fine motor skills

X

Keyboard use/repetitive motion

X

Taste or smell (taste=never)

X

Talk or hear

X

Accurate 20/40

Very Accurate 20/20

Not Applicable

Near Vision

X

Far Vision

X

Yes

No

Not Applicable

Color Vision (ability to identify and distinguish colors)

X

Sensory Requirements

Minimal

Moderate

Accurate

Not Applicable

Depth perception

X

Hearing

X

Environmental Requirements

Occupational Exposure Risk Potential

Reasonably Anticipated

Not Anticipated

Blood borne pathogens

X

Chemical

X

Airborne communicable diseases

X

Extreme temperatures

X

Radiation

X

Uneven surfaces or elevations

X

Extreme noise levels

X

Dust/particular matter

X

Other (exposure Risks)

Usual workday hours:

X

8

10

12

Other work hours

GEI is an AA/equal opportunity employer, including disabled and veterans.",Full-time
4133956837,2646.0,Data Engineer III (Scala/Spark),"Position Summary...

What you'll do...

Immigration sponsorship is not available in this role.

At Walmart, we help people save money, so they can live better. This mission serves as the foundation for every decision we make and drives us to create the future of retail. We can’t do that without the best talent – talent that is innovative, curious, and driven to create exceptional experiences for our customers.  

Do you have boundless energy and passion for engineering data used to solve dynamic problems that will shape the future of retail? With the sheer scale of Walmart’s environment comes the biggest of big data sets. As a Walmart Data Engineer, you will dig into our mammoth scale of data to help unleash the power of retail data science by imagining, developing, and maintaining data pipelines that our Data Scientists and Analysts can rely on. You will be responsible for contributing to an orchestration layer of complex data transformations, refining raw data from source into targeted, valuable data assets for consumption in a governed way. You will partner with Data Scientists, Analysts, other engineers and business stakeholders to solve complex and exciting challenges so that we can build out capabilities that evolve the retail business model while making a positive impact on our customers’ and sellers’ lives.

About The Data And Customer Analytics (DCA) Organization

Our organization focuses on managing and delivering world-class data assets, including creating and maintaining data standards, driving policy compliance, creating partnerships, and developing pipelines and self-service tools. We empower our business to leverage data to fuel growth, driving revenue in our core and building new business model opportunities.

What You’ll Do


 * Data Transformation and Integration: Extract and transform data from databases, create data pipelines, and stay updated on analytics trends
 * Data Source and Modeling: Identify suitable data sources, perform quality checks, develop and evaluate data models, and design efficient data flows
 * Code Development and Testing: Write and test code for solutions, develop proofs of concept, deploy software, and document progress
 * Applied Business Acumen: Translate business requirements into projects, recommend solutions, develop business cases, and align projects with business strategy
 * Data Governance: Implement and document data governance practices, educate stakeholders, and provide recommendations for improvements
   
   

What You’ll Bring


 * 3+ years of data engineer experience
 * 3+ years of extensive experience with Spark, Scala, and SQL
 * High-level proficiency in Java and Spring Boot
 * Understanding of software development lifecycle from planning to deployment
 * You have a proven track record coding with at least one programming language (e.g., Scala, Python)
 * You’re experienced in one of cloud computing platforms (e.g., GCP, Azure)
 * You’re skilled in data modeling & data migration protocols
 * Experience with containerization technologies WCNP, Docker, and Kubernetes
 * Experience with GCP, Data warehousing, BI preferred
 * Experience with the integration tools like Automic, Airflow
 * Experience in building highly scalable Big Data solutions and ETL ecosystems
 * Working knowledge of CI/CD pipelines
 * Strong communication skills with the ability to not only understand but also articulate the how and why of a process and solution
 * A positive, collaborative, and team player mentality
   
   

Preferred Qualifications And Experience


 * Bachelor's/master’s degree in computer science or a related field
 * 4 - 6 years experience in development of big data technologies/data pipelines
 * Hands on working experience in any messaging platform like Kafka is preferred
 * Increase the efficiency of the team by setting right Processes of Software Development, Requirement Intake, Effort Estimation
 * Demonstrating creative, critical thinking & troubleshooting skills
 * Front end experience with JavaScript and React
   
   

The above information has been designed to indicate the general nature and level of work performed in the role.  It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

About Walmart Global Tech

Imagine working in an environment where one line of code can make life easier for hundreds of millions of people.  That’s what we do at Walmart Global Tech. We’re a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world’s leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.

Flexible, Hybrid Work

We use a hybrid way of working with primary in office presence coupled with an optimal mix of virtual presence. We use our campuses to collaborate and be together in person, as business needs require and for development and networking opportunities. This approach helps us make quicker decisions, remove location barriers across our global team, be more flexible in our personal lives.

Benefits

Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include a host of best-in-class benefits maternity and parental leave, PTO, health benefits, and much more.

Equal Opportunity Employer

Walmart, Inc. is an Equal Opportunity Employer – By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions – while being inclusive of all people.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎

You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎

Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For Information About Benefits And Eligibility, See One.Walmart.

‎

Sunnyvale, California US-08479:The annual salary range for this position is $117,000.00-$234,000.00

‎

Bentonville, Arkansas US-09416:The annual salary range for this position is $90,000.00-$180,000.00

‎

‎

‎

‎

‎

‎

‎

‎

‎

‎

Additional Compensation Includes Annual Or Quarterly Performance Bonuses.

‎

Additional Compensation For Certain Positions May Also Include

‎

‎


 * Stock
   
   

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelor’s degree in Computer Science and 2 years' experience in software engineering or related field. Option 2: 4 years’ experience in

software engineering or related field. Option 3: Master's degree in Computer Science.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, Master’s degree in Computer Science or related field and 2 years' experience in software engineering or related field, We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

640 W California Avenue, Sunnyvale, CA 94086-4828, United States of America

",Full-time
4120915183,1586.0,"Data Engineer , Amazon Pharmacy","Description

Innovation is at the core of what we do. We believe that by removing and reducing the barriers that prevent people from taking their medications, we can help customers conveniently get the medications they need, when they need them and take them as prescribed.

We have provided customers with the ability to find transparent and simple pricing, receive 24/7 customer service support, and have their meds delivered to their doorsteps while creating programs and products that embody our mission and position ourselves in becoming the world’s safest and fastest online pharmacy.

We are looking for a Data Engineer to join us on our journey to make it drastically easier for customers to find, choose, afford, and engage with the services, products, and professionals they need to get and stay healthy!

As a Data Engineer in Pharmacy team, you will partner with Software Engineers, Business Intelligence Engineers and product managers. You will design, implement, and maintain next generation BI solutions for large scale, highly secure and complex data structures to ensure the data is auditable, available and accessible. You will gain a deep understanding of our services and the data they produce, and become our resident expert in how to transform that data into a format that is useful for analytics and business intelligence. You will proactively help to identify new data for integration with our platform, and propose and implement new technologies to help us better understand our data.

#everydaybetter

Key job responsibilities


 * Design, implement, maintain and support a secure and robust data lake in native AWS with 300+ datasets which contain both PII and PHI data.
 * Implement ingestion routines both real time and batch using best practices in modeling, ETL/ELT processes by leveraging AWS technologies and big data tools.
 * Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL, Python and AWS big data technologies.
 * Gather business and functional requirements and translate into secure, robust, scalable,
   
   

operable solutions with a flexible and adaptable architecture.


 * Collaborate with engineers to help adopt best practices in system creation, integrity, test design, analysis, validation, and documentation.
 * Help continually improve ongoing reporting and analysis processes, automating or simplifying
   
   

self-service tools for customers.


 * Explore and learn the latest AWS technologies to provide new capabilities and increase
   
   

efficiency

Basic Qualifications


 * 3+ years of data engineering experience
 * Experience with data modeling, warehousing and building ETL pipelines
 * 3+ years of analyzing and interpreting data with Redshift, Oracle, NoSQL etc. experience
 * Experience with big data technologies such as: Hadoop, Hive, Spark, EMR
 * Bachelor's degree
 * 3+ years of experience in at least one of the programming languages like Python, Java etc.
 * Experience in working and delivering end-to-end projects independently.
 * Excellent written and verbal communication skills Amazon is committed to a diverse and
 * inclusive workplace.
   
   

Preferred Qualifications


 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
 * Experience providing technical leadership and mentoring other engineers for best practices on data engineering
 * Experience working with secure medical data, pipeline, services and HIPAA compliant environment,.
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com Services LLC

Job ID: A2832739",Full-time
4059227646,3106804.0,"Associate, Data Engineer","Avant is looking for an Associate Data Engineer, to play a crucial role in building and evolving our data model to meet a range of business initiatives. This position is suited for someone who is driven to understand complex problems and use technology to build robust solutions. You will work with teams throughout the company, understand their operational, regulatory, and reporting needs, and develop a mature model to enable their data-driven decisions.

What you'll do at Avant:


 * Model new data sets that can be incorporated into a Databricks and DBT-based platform
 * Engage with internal stakeholders and users to define clear and well-structured business requirements for our data assets
 * Support the delivery of data for key customer and operational processes
 * Build and leverage frameworks for ensuring data assets within Avant’s data platform are high-quality, well-governed, meticulously curated, and operationally well-instrumented
 * Mentor teammates and be a part of a culture of learning
   
   

Why you're a fit for Avant:


 * Expert-level proficiency with SQL (4+ years experience)
 * Advanced-level proficiency with data modeling and data structures (3+ years experience)
 * Advanced-level proficiency data engineering and pipeline automation, preferably working with dbt and Python (3+ years experience)
 * Advanced-level proficiency with database and query optimization, preferably with Databricks and Postgres (3+ years experience)
 * Disciplined Agile practitioner
 * Excellent written and oral communication skills
 * Must be a self-starter and able to work independently as well as in a team environment
 * Detail oriented with strong organizational skills
 * Ability to participate in a support rotation to provide escalation support which may occur outside of business hours
   
   

This role is based on our downtown Chicago Office, located in the Merchandise Mart. We highly value collaboration and our hybrid schedule (M, T, Th in-office) enables flexibility to balance work and individual priorities.

Compensation Range:

The base salary range for this job is USD $95,000 - USD $140,000 / Year

Employees new to Avant typically come in below the midpoint of the pay range. The compensation range is based on the level outlined in the job posting, and compensation decisions are dependent on each applicant's experience, skills and abilities.

[If an outstanding applicant's experience and skill level is above or below the qualifications outlined in the job posting, we reserve the right to make an offer at a different level than the one listed in this job posting, which may have a different compensation range.]

This role is eligible for additional incentives, including an annual bonus. These rewards are allocated based on level, impact and performance in the role.

Our benefits include:


 * Choice of great Medical, Dental, and Vision Insurance Plan options
 * 401(k) match
 * Flexible Time Off
 * Flexible Work Environment - (i.e. Mon/Tues/Thurs in-person)
 * Generous Paid Parental Leave, Adoption Assistance and Post-parental leave ramp-up program
 * Lunch Allowance (Fooda) and In-office Snacks
 * Summer Fridays
 * Fun In-Office and Virtual Social Events
 * And who doesn’t love the swag
   
   

Check out our Avant Blog!

We believe that a diverse set of backgrounds and experiences helps us create the most innovative solutions for our customers. We invite you to apply to our positions even if you do not meet 100% of the qualifications listed in the description. If you’re passionate about our mission and aligned to our values, we hope you’ll come contribute to our awesome culture.

Why Avant is the place for you:

At Avant, we believe our values make a difference:

Authenticity. We show up to work as our whole selves and make sure others can too.

Collaboration. We can only succeed when we do so as a team.

Problem-Solving. The harder the problem, the more satisfying the solution.

Customer. We are all owners of the customer experience.

Initiative. Plan. Adapt. Get Sh!t Done.

We believe that great ideas come from anyone and anywhere, that everyone is an owner who drives change, and that we have more fun when we work together. We're problem solvers who love collaborating with intelligent and highly-motivated people to reshape the face of digital banking. Avant offers terrific perks and benefits, fun social events with employees who actually like hanging out together, and a flexible growth environment where trying your hand at new projects and being the active owner of your career path is encouraged and supported.",Full-time
4148680129,716360.0,Data Engineer,"Job Title: Data Engineer with PySpark & Databricks

Location: Jersey City, NJ

Employment Type: Contract

Job Description

We are seeking a skilled Data Engineer with expertise in PySpark and Databricks to join our team in Jersey City. The ideal candidate will be responsible for designing, developing, and maintaining scalable data pipelines, optimizing performance, and ensuring data quality and integrity.

Key Responsibilities


 * Develop and maintain ETL data pipelines using PySpark and Databricks.
 * Optimize data workflows for performance, scalability, and reliability.
 * Work with large-scale structured and unstructured datasets.
 * Collaborate with data scientists, analysts, and business teams to understand data needs.
 * Implement best practices in data modeling, transformation, and governance.
 * Monitor and troubleshoot data pipeline performance and resolve issues proactively.
 * Work with cloud platforms (AWS, Azure, or GCP) for data storage and processing.
 * Ensure data security and compliance with industry standards.
   
   

Required Skills & Qualifications


 * 5+ years of experience in data engineering.
 * Strong hands-on experience with PySpark and Databricks.
 * Proficiency in SQL for data querying and transformation.
 * Experience working with cloud data platforms (AWS, Azure, or GCP).
 * Knowledge of data warehousing, data lakes, and data modeling concepts.
 * Experience with orchestration tools like Airflow.
 * Strong debugging and performance tuning skills.
 * Excellent problem-solving and communication skills.
   
   

Preferred Skills


 * Experience with Delta Lake and Lakehouse architecture.
 * Knowledge of CI/CD pipelines for data workflows.
 * Familiarity with ML workflows and integration with Databricks.
 * Hands-on experience with Kafka or other streaming technologies.",Full-time
4113934016,1482.0,Data Engineer,"The Company
PayPal has been revolutionizing commerce globally for more than 25 years. Creating innovative experiences that make moving money, selling, and shopping simple, personalized, and secure, PayPal empowers consumers and businesses in approximately 200 markets to join and thrive in the global economy.

We operate a global, two-sided network at scale that connects hundreds of millions of merchants and consumers. We help merchants and consumers connect, transact, and complete payments, whether they are online or in person. PayPal is more than a connection to third-party payment networks. We provide proprietary payment solutions accepted by merchants that enable the completion of payments on our platform on behalf of our customers.

We offer our customers the flexibility to use their accounts to purchase and receive payments for goods and services, as well as the ability to transfer and withdraw funds. We enable consumers to exchange funds more safely with merchants using a variety of funding sources, which may include a bank account, a PayPal or Venmo account balance, PayPal and Venmo branded credit products, a credit card, a debit card, certain cryptocurrencies, or other stored value products such as gift cards, and eligible credit card rewards. Our PayPal, Venmo, and Xoom products also make it safer and simpler for friends and family to transfer funds to each other. We offer merchants an end-to-end payments solution that provides authorization and settlement capabilities, as well as instant access to funds and payouts. We also help merchants connect with their customers, process exchanges and returns, and manage risk. We enable consumers to engage in cross-border shopping and merchants to extend their global reach while reducing the complexity and friction involved in enabling cross-border trade.

Our beliefs are the foundation for how we conduct business every day. We live each day guided by our core values of Inclusion, Innovation, Collaboration, and Wellness. Together, our values ensure that we work together as one global team with our customers at the center of everything we do – and they push us to ensure we take care of ourselves, each other, and our communities.

Job Description Summary:
As a Data Engineer on the Credit Platform Data team at PayPal, you'll play a key role in building and enhancing tools for data processing, enabling our internal business units to leverage data efficiently. You'll develop secure, high-performing data integration and ETL processes, participating in all stages of development from, analysis to production releases. Your responsibilities will include delivering new features, ensuring quality, and collaborating closely with the Product team in an agile environment.

Job Description:
As a Data Engineer on the Credit Platform Data team at PayPal, you'll play a key role in building and enhancing tools for data processing, enabling our internal business units to leverage data efficiently. You'll develop secure, high-performing data integration and ETL processes, participating in all stages of development from analysis to production releases. Your responsibilities will include delivering new features, ensuring quality, and collaborating closely with the Product team in an agile environment.

Responsibilities:


 * Design, build, and maintain robust data pipelines and ETL processes to ingest, transform, and load data from various sources into our data warehouse, ensuring scalability and efficiency.
 * Collaborate with product managers, analysts, and other stakeholders to understand data requirements and develop solutions that meet business needs while accommodating large volumes of data.
 * Ensure the reliability, availability, and scalability of our data systems, monitoring performance and optimizing as needed to handle increasing data volumes.
 * Implement automated data quality checks and validation processes to ensure data integrity and accuracy at scale.
 * Troubleshoot data-related issues, identify root causes, and implement solutions in a timely manner to minimize impact on data processing.
 * Create and maintain design documents and documentation for data pipelines, systems, and processes.
 * Participate actively in design and code reviews.
 * Stay current with emerging technologies and trends in data engineering, recommending and implementing improvements as necessary to support scalability and growth.
   
   
   

Qualifications:


 * Bachelor's degree in Computer Science, Engineering, or a related field.
 * 3+ years of proven experience as a Data Engineer or similar role, with a strong background in database development, ETL processes, and software development.
 * Proficiency in SQL and scripting languages such as Python, with experience working with relational databases.
 * Proficiency in PySpark, Pandas or other data processing libraries.
 * Familiarity with data warehousing concepts and tools, such as AWS Redshift, Google BigQuery, or Snowflake, and experience optimizing performance for large-scale data processing.
 * Experience with data modeling, schema design, and optimization techniques for scalability.
 * Strong analytical and problem-solving skills, with the ability to troubleshoot complex data issues and optimize data processing pipelines for scale.
 * Experience with AWS or GCP as well as experience with Unix/Linux operating systems and shell scripting.
 * Excellent communication and collaboration skills, with the ability to work effectively in a team environment.
 * Self-motivated and proactive, with a passion for continuous learning and professional development.
   
   
   

For the majority of employees, PayPal's balanced hybrid work model offers 3 days in the office for effective in-person collaboration and 2 days at your choice of either the PayPal office or your home workspace, ensuring that you equally have the benefits and conveniences of both locations.

Our Benefits:

At PayPal, we’re committed to building an equitable and inclusive global economy. And we can’t do this without our most important asset—you. That’s why we offer benefits to help you thrive in every stage of life. We champion your financial, physical, and mental health by offering valuable benefits and resources to help you care for the whole you.

We have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https://www.paypalbenefits.com

Who We Are:

To learn more about our culture and community visit https://about.pypl.com/who-we-are/default.aspx

Commitment to Diversity and Inclusion

PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state, or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at paypalglobaltalentacquisition@paypal.com.

Belonging at PayPal:

Our employees are central to advancing our mission, and we strive to create an environment where everyone can do their best work with a sense of purpose and belonging. Belonging at PayPal means creating a workplace with a sense of acceptance and security where all employees feel included and valued. We are proud to have a diverse workforce reflective of the merchants, consumers, and communities that we serve, and we continue to take tangible actions to cultivate inclusivity and belonging at PayPal.

Any general requests for consideration of your skills, please Join our Talent Community.

We know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please don’t hesitate to apply.

REQ ID R0121691",Full-time
4148902871,5234457.0,Data Engineer,"We are hiring for a Data Engineer whose primary responsibility will be to lead and drive the organization's analytics strategy and develop its capabilities.




What You'll Do In This Role

 * Engage in collaborative efforts with business stakeholders across all business functions globally to gain a deep understanding of their challenges, identify potential opportunities, and effectively translate business requirements into data-driven analytics solutions.




 * You will collaborate closely with business units across all business functions globally, the data engineering team, business applications team and other platform owners.




 * This role will play a vital role in converting data into valuable insights that inform business decisions, optimize operational efficiency, and elevate the customer experience.




 * Facilitate the transition of the team from a Business Intelligence (BI) focus to an Advanced Analytics approach by fostering the growth of data science skills within the team




Responsibilities

 * Leading high performing teams
 * Leading & Training Junior Engineers
 * Participating in network maintenance support




Required Skills

 * Minimum of 5 years of experience in a analytics team, with a demonstrated track record of successfully collaborating with business teams to drive data-driven decision-making.
 * Strong proficiency in programming languages (Python, SQL, or similar), statistical analysis, and data visualization tools (e.g., Looker, Power BI).







Please apply with your updated resume!",Full-time
4149500701,383369.0,Data Engineer (Snowflake & Python),"Data Engineer (Remote)

We have an immediate need for a contract Data Engineer to join our growing client.




The Data Engineer will be responsible for gathering business requirements, writing Python scripts for JDBC/ODBC connectors into Snowflake, building pipelines in Snowflake, and creating visualizations in Sigma. Must be willing to learn Sigma.




The ideal candidate will have strong experience with SQL, Snowflake, Python and tools such as Alteryx, Power BI, or Sigma.




Location: Remote working Central Time Zone hours

This job expects to pay about $65-75 per hour plus benefits




What You Will Do:

 * Data Pipeline Development: Design, develop, and maintain data pipelines using Snowflake.
 * Data Visualization: Create and manage dashboards and reports using Sigma.
 * Scripting and Automation: Utilize Python for data manipulation, automation, and integration tasks.
 * Requirements Gathering: Collaborate with stakeholders to gather and document requirements for manufacturing and supply chain data products.
 * Solution Development: Develop data solutions that meet business needs and ensure timely delivery to customers.
 * Performance Optimization: Optimize data pipelines and queries for performance and scalability.
 * Collaboration: Work closely with cross-functional teams to ensure data accuracy and integrity.




What Gets You The Job:

 * Must Have: Strong experience with SQL, Snowflake, Python, and data visualization tools such as Sigma, Power BI, or Alteryx.
 * Experience: Proven experience in creating and managing Snowflake data pipelines.
 * Programming: Strong Python programming skills.
 * Communication: Excellent communication skills for effective requirements gathering and stakeholder management.
 * Problem-Solving: Strong analytical and problem-solving abilities.
 * Education: Bachelor’s degree in Computer Science, Information Systems, or a related field.




Irvine Technology Corporation (ITC) is a leading provider of technology and staffing solutions for IT, Security, Engineering, and Interactive Design disciplines servicing startups to enterprise clients, nationally. We pride ourselves in the ability to introduce you to our intimate network of business and technology leaders – bringing you opportunity coupled with personal growth, and professional development! Join us. Let us catapult your career!




Irvine Technology Corporation provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Irvine Technology Corporation complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.",Contract
4024958481,66758119.0,Data Analytics Engineer,"Actifai is seeking a Data Analytics Engineer.

The Data Analytics Engineer will be a client-facing team member that manages critical client data through the full data lifecycle from ETL to analytics and reporting. They will ingest client data into Actifai’s internal data store, build data pipelines for modeling and analytics, maintain recommendation models, and manage reporting and analytics tools. As a key technical bridge between Actifai and its clients, the Data Analytics Engineer will work closely with Actifai’s MLOps, Data Science, and Customer Success teams.

The Company

Actifai is a dynamic, 4-year-old AI software startup (AIaaS company) serving some of the largest broadband and telecommunications providers in North America. We're at the forefront of AI technology in the telecom industry, transforming how companies optimize their high-value, high-leverage decisions across customer acquisition, retention, and development engagements. Learn more on our site: www.actif.ai

Actifai is part of Foundry.ai, a technology fund/studio that creates AI software companies in partnership with large global enterprises. Foundry’s operating companies focus on practical applications of AI that drive immediate, measurable, and recurring improvements to financial performance. Foundry is backed by leading private equity and venture capital partners, including The Pritzker Organization, Breyer Capital, and Madrone Capital Partners.

The Position

The Data Analytics Engineer is based in Washington, D.C. and is a hybrid, client-facing role between the Data Science and Data Engineering teams at Actifai. Depending on the needs of the business, the work may include:


 * Maintaining and improving Actifai’s data infrastructure
 * Implementing data pipelines to create the datasets that power our models and reporting tools
 * Working with technical teams at Actifai’s clients to manage transfer of client data
 * Integrating client data into Actifai’s databases
 * Managing pilot programs with new clients
 * Conducting data analysis
 * Developing dashboards and analytics tools
 * Maintaining machine learning models
   
   

Basic Qualifications:


 * Bachelor's Degree or higher in computer science/engineering, mathematics, statistics, data science or a related technical field
 * 2+ years of relevant employment experience preferred
 * Strong skills in writing and optimizing SQL queries and Python code, especially data manipulation libraries such as pandas
 * Experience with AWS and/or Google Cloud
 * Experience with data analysis and visualization
 * Excellent communication skills, both for collaboration with clients and for working within internal teams
   
   

Exceptional candidates may differentiate themselves with some of the following:


 * Expertise in ETL/ELT optimization, designing, coding, and tuning big data processes
 * Familiar with general-purpose machine learning principles and methods, such as regression, decision trees, neural networks, reinforcement learning, online inference and so on
 * Experience with Infrastructure as Code (Terraform, Serverless)
 * Detail-oriented and takes ownership of outputs
 * Well-rounded top performer who is able to “crunch the numbers” one minute, and critically think through strategic issues and system design the next
 * A “do it the right way” mindset including commitment to proper documentation and thorough testing
 * Excited to move fast and know how to prioritize and make critical decisions
 * A self-starter: you have started something on your own before -- an open-source project, a new project within a company or university, a start-up, or something else
 * Able to communicate effectively when delivering complex data-driven findings to businesspeople and when discussing machine-learning specifications with engineers
   
   

Finally, we highlight that excellence has no single mold, particularly in a field as rapidly evolving as AI. We're looking for excellent candidates of all backgrounds with strong business intuition and coding skills, and welcome applicants regardless of ethnic/national origin, gender, race, religious beliefs, disability, sexual orientation or age.

Benefits and Culture

Actifai offers an extremely competitive compensation package, including equity, 100% employer-covered health/vision/dental insurance for individuals and families (with an optional FSA/HSA), and a 401(k) plan with employer matching. Employees receive 20 days of PTO (not including holidays) and can work both remotely and from our office in downtown Washington, D.C. Successful candidates will join a small but growing team of ambitious, supportive co-workers with ample opportunities to take on responsibilities and develop skills beyond their assigned role.

For additional information on benefits and what it's like to work at Actifai, please visit www.actif.ai/careers.

Powered by JazzHR

vxmDnDvpcU",Full-time
4148829726,18059273.0,Data Engineer: Big Data,"About Us

Energize your career with one of Information Technology’s fastest growing companies.

You dream of a great career with a great company – where you can make an impact and help people. We dream of giving you the opportunity to do just this. And with the incredible growth of our business, it’s a dream that definitely can come true. Already one of the world’s leading IT companies, MNJ SOFTWARE is restlessly pursuing new ways to operate our service centers, improve our service levels and help people lead healthier lives. We live for the opportunity to make a difference and right now, we are living it up.

MNJ SOFTWARE is an IT services, business solutions and outsourcing organization that delivers real results to global businesses, ensuring a level of certainty no other firm can match.

MNJ SOFTWARE offers a consulting-led, integrated portfolio of IT and IT-enabled services delivered through its unique Global Network Delivery Model, recognized as the benchmark of excellence in software development.

MNJ SOFTWARE service offerings span business and technology consulting, application services, systems integration, product engineering, custom software development, maintenance, re-engineering, independent testing and validation services, IT infrastructure services and business process outsourcing.

MNJ SOFTWARE takes pride in building strategic long-term client relationships.

MNJ SOFTWARE is only hiring those authorized to work in the India and unable to provide visa sponsorship at this time.

Job Details

MNJ SOFTWARE is looking for talented individuals who are interested to be part of ""Our"" journey to build a best-in-class organization, driving to deliver real results to global businesses, ensuring a level of certainty no other firm can match.

Data Engineer: Big Data at MNJ SOFTWARE, you will participate in design, development and implementation of architectural deliverables of custom projects and products of MNJ SOFTWARE. The role includes working closely with lead, testers, customers, project/product managers and designers.

JobID

J0031

Title

Data Engineer: Big Data

Experience

3-6 yrs

Job Type

Permanent / Contract [Depends on Project Needs or C2H]

Position Type

Full time [Monday – Friday]. Employees are required to have flexibility to work any of our 9-hour shift schedules during our normal business hours of (6am - 10pm IST) or (6pm to 6am IST). It may be necessary, given the business need, to work occasional overtime [unpaid].

Qualification

ME/M.TECH/BE/B.TECH/MCA/M.Sc(IT) etc

Technical/Functional Skills


 * Minimum 6+ years of experience in Big Data technologies.
 * Minimum 4 + Years of experience in Python and Scala Programming.
 * Experience in developing applications on Big Data and Cognitive technologies including API development.
 * Application Development background along with knowledge of Analytics libraries, Open-source Natural Language Processing,Statistical and Big Data Computing libraries.
 * Expertise in Spark, Scala and Kafka technologies.
 * Ability to demonstrate micro / macro designing and familiar with Unix Commands and basic work experience in Unix Shell Scripting Demonstrated ability in solutioning covering data ingestion, data cleansing, ETL, data mart creation and exposing data for consumers.
   
   

Roles & Responsibilities


 * As Data Engineer, you will develop, maintain, evaluate and test big data solutions. You will be involved in the design of data solutions using Hadoop based technologies along with Python & Spark programming.
 * Responsible to Ingest data from files, streams and Databases.
 * Process the data with Spark, Scala, Kafka, Hive and Scoop.
 * Develops Hadoop applications using Horton Works or other Hadoop distribution.
 * Experienced with pulling data from various database systems, Network Elements and unstructured text from web, Social Media Sites and other Domain Specific file.
 * Develop efficient software code for multiple use cases leveraging Python and Big Data technologies for various use cases built on the platform.
   
   

Personal Attributes


 * Must be Analytical and possess good problem-solving capabilities
 * Independent thinker
   
   

Process

Aptitude Tests, Technical Tests, Interviews, Medical Health Checkup.

Reimbursement

Best in Industry

Certification

Optional

Location

Remote (Work From Home)

Competencies

Professionalism – Knowledge of general office and administrative support including MNJ SOFTWARE administrative policies, processes and procedures. Demonstrates professional competence and mastery of subject matter; is conscientious and efficient in meeting commitments, observing deadlines and achieving results; remains calm in stressful situations. Commitment to implementing the goal of gender equality by ensuring equal participation and full involvement of women and men in all aspects of work.

Teamwork – Works collaboratively with colleagues to achieve organizational goals; solicits input by genuinely valuing others’ ideas and expertise; is willing to learn from others; places team agenda before personal agenda; shares credit for team accomplishments and accepts joint responsibility for team shortcomings; ability to work beyond normal hours.

Planning and Organizing – Develops clear goals that are consistent with agreed strategies; identifies priority activities and assignments; adjusts priorities as required; allocates appropriate amount of time and resources for completing work; foresees risks and allows for contingencies when planning; uses time efficiently.

Assessment

Evaluation of qualified candidates may include an assessment exercise which may be followed by competency-based interview.

Languages

English is the working language of this above stated post. For this post, fluency in oral and written English is required.

Note

We're an Equal Opportunity Employer: You will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability.

No Fee

THE MNJ SOFTWARE DOES NOT CHARGE A FEE AT ANY STAGE OF THE RECRUITMENT PROCESS (APPLICATION, INTERVIEW MEETING, PROCESSING, OR TRAINING).

General Considerations

According to policies and processes of MNJ SOFTWARE, the paramount consideration in the employment of the staff is the necessity of securing the highest standards of efficiency, competence, and integrity. Candidates will not be considered for employment with the MNJ SOFTWARE if they have committed violations of national / international human rights law, violations of national / international humanitarian law, sexual exploitation, sexual abuse, or sexual harassment, or if there are reasonable grounds to believe that they have been involved in the commission of any of these acts. The term “sexual exploitation” means any actual or attempted abuse of a position of vulnerability, differential power, or trust, for sexual purposes, including, but not limited to, profiting monetarily, socially or politically from the sexual exploitation of another. The term “sexual abuse” means the actual or threatened physical intrusion of a sexual nature, whether by force or under unequal or coercive conditions. The term “sexual harassment” means any unwelcome conduct of a sexual nature that might reasonably be expected or be perceived to cause offence or humiliation, when such conduct interferes with work, is made a condition of employment or creates an intimidating, hostile or offensive work environment, and when the gravity of the conduct warrants the termination of the perpetrator’s working relationship. Candidates who have committed crimes other than minor traffic offences may not be considered for employment.

Due regard will be paid to the importance of recruiting the staff on as wide a geographical basis as possible. The MNJ SOFTWARE places no restrictions on the eligibility of men and women to participate in any capacity and under conditions of equality in its principal and subsidiary organs. The MNJ SOFTWARE OFFICE is a non-smoking environment.

The paramount consideration in the appointment, transfer, or promotion of staff shall be the necessity of securing the highest standards of efficiency, competence, and integrity. By accepting an offer of appointment, MNJ SOFTWARE staff members are subject to the authority of the Managers and assignment by him or her to any activities or offices of the MNJ SOFTWARE in accordance with staff regulation In this context, all internationally recruited staff members shall be required to move periodically to discharge new functions within or across duty stations under conditions established by the MNJ SOFTWARE.

The evaluation of applicants will be conducted on the basis of the information submitted in the application according to the evaluation criteria of the job opening and the applicable internal legislations of the MNJ SOFTWARE, the Staff Regulations and Rules, administrative issuances and guidelines. Applicants must provide complete and accurate information pertaining to their personal profile and qualifications according to the instructions provided in inspira to be considered for the current job opening. No amendment, addition, deletion, revision or modification shall be made to applications that have been submitted. Candidates under serious consideration for selection will be subject to reference checks to verify the information provided in the application.

Openings

Apply

Add to Cart",Contract
4148399499,96880536.0,Data Engineer,"Title: Data Engineer

Location: Baltimore, MD *(Hybrid)

Compensation: 115 to 130k, benefits

Type: Direct




Overview:

The Data Engineer is responsible for building and optimizing our data pipelines, as well as designing and maintaining scalable systems for data storage and processing. This role will collaborate closely with product leaders, software engineers, and integration teams to ensure the effective flow and accessibility of data, enabling data-driven decision-making across the organization.




Essential Functions:

 * Data Pipeline Development: Design, build, and maintain scalable, efficient, and robust data pipelines to support the processing of large volumes of data.
 * Data Integration: Integrate data from a variety of data sources (e.g., relational databases, APIs, third-party datasets) into a unified and accessible format.
 * Database Design & Management: Develop and maintain databases, data warehouses, and other data storage solutions, ensuring they meet the company’s data needs and business goals.
 * ETL/ELT Processes: Implement and manage Extract, Transform, Load (ETL/ELT) processes to ensure the accurate and efficient movement of data between systems.
 * Data Quality & Governance: Ensure high data quality and availability by implementing appropriate monitoring, testing, and validation techniques.
 * Collaboration: Work closely with data integration engineers, business analysts, and software engineers to understand their data requirements and provide timely solutions.
 * Automation: Automate manual data processes and workflows to improve efficiency and reduce errors.
 * Data Security & Compliance: Ensure that all data solutions comply with data security, privacy, and regulatory requirements (e.g., GDPR, HIPAA).
 * Performance Optimization: Continuously monitor the performance of data systems and make improvements to increase efficiency and scalability.




Qualifications:

 * Bachelor’s degree in Computer Science, Information Technology, or a related field.
 * (3+ years) as a Data Architect, Data Engineer, or in a similar role.
 * Proficiency in database technologies (e.g., MySQL, PostgreSQL, SQL Server).
 * Strong experience with data modeling, data warehousing, and ETL/ELT processes.
 * Familiarity with cloud data platforms (AWS, Azure, Google Cloud)
 * Knowledge of data governance frameworks and data quality best practices.
 * Strong problem-solving skills and the ability to translate business needs into data architecture solutions.
 * Excellent communication and interpersonal skills.




Benefits: A competitive benefits package is provided.




Equal Opportunity Employer:

We are deeply committed to building a diverse and inclusive team. We believe that different backgrounds and life experiences make our team better. We do not discriminate against qualified employees or applicants because of race, color, religion, gender identity, sex, sexual preference, sexual identity, pregnancy, national origin, ancestry, citizenship, age, marital status, physical disability, mental disability, medical condition, military status, or any other characteristic protected by local law or ordinance.",Full-time
4137886478,10667.0,"Data Engineer, Product Analytics","As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a world-class data engineering community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Data Engineer, Product Analytics Responsibilities:


 * Manage and execute data warehouse plans for a product or a group of products to solve well-scoped problems
 * Identify the data needed for a business problem and implement logging required to ensure availability of data, while working with data infrastructure to triage issues and resolve
 * Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights in a meaningful way
 * Build data expertise and leverage data controls to ensure privacy, security, compliance, data quality, and operations for allocated areas of ownership
 * Design, build and launch new data models and visualizations in production, leveraging common development toolkits
 * Independently design, build and launch new data extraction, transformation and loading processes in production, mentoring others around efficient queries
 * Support existing processes running in production and implement optimized solutions with limited guidance
 * Define and manage Service Level Agreements for data sets in allocated areas of ownership
   
   

Minimum Qualifications:


 * Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent
 * 2+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions
 * 2+ years of experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala or others.)
   
   

Preferred Qualifications:


 * Master's or Ph.D degree in a STEM field
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$114,000/year to $171,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4141636862,1821549.0,Data Engineer - Security,"About Fanduel

FanDuel Group is the premier mobile gaming company in the United States. FanDuel Group consists of a portfolio of leading brands across mobile wagering including, America’s #1 Sportsbook FanDuel Sportsbook, its leading iGaming platform FanDuel Casino, the industry’s unquestioned leader in horse racing and advance-deposit wagering, FanDuel Racing and its daily fantasy sports product.

In addition, FanDuel Group operates FanDuel TV, its broadly distributed linear cable television network and FanDuel TV+, its leading direct-to-consumer OTT platform. FanDuel Group has a presence across all 50 states and Puerto Rico with approximately 17 million customers and 31 retail locations.

The company is based in New York with offices in Los Angeles, Atlanta and Jersey City, as well as in Canada, Scotland, Ireland, Portugal, Romania and Australia.

FanDuel Group is a subsidiary of Flutter Entertainment, the world's largest sports betting and gaming operator with a portfolio of globally recognized brands and traded on the New York Stock Exchange (NYSE: FLUT).

THE ROSTER

At FanDuel, we give fans a new and innovative way to interact with their favorite games, sports and teams. We’re dedicated to building a winning team and we pride ourselves on being able to make every moment mean more, especially when it comes to your career. So, what does “winning” look like at FanDuel? It’s recognition for your hard-earned results, a culture that brings out your best work—and a roster full of talented coworkers. Make no mistake, we are here to win, but we believe in winning right. That means we’ll never compromise when it comes to looking out for our teammates. From creatives professionals to cutting edge technology innovators, FanDuel offers a wide range of career opportunities, best in class benefits, and the tools to explore and grow into your best selves. At FanDuel, our principle of “We Are One Team” runs through all our offices across the globe, and you can expect to be a part of an exciting company with many opportunities to grow and be successful.

THE POSITION

Our roster has an opening with your name on it

As a valued member of the Data Engineering Team, the Data Security Engineer will be responsible for implementing and maintaining secure data infrastructure, ensuring compliance with FanDuel and industry standards and regulations. Your expertise in compliance frameworks, coupled with your technical skills in Python, SQL, GitHub, Redshift, Databricks, and dbt, will be instrumental in driving the success of FanDuel's data security initiatives. You will work closely with various stakeholders, including data engineers, data analysts, and security professionals, to design and implement secure data pipelines, analyze security risks, and enhance overall data protection. The ability to work across organizations, a detailed approach and a passion for documentation are musts!

THE GAME PLAN

Everyone on our team has a part to play

Working within Data Engineering and with the broader FanDuel Security/Compliance teams, this role will have the following responsibilities


 * Collaborate with FanDuel security teams to identify and mitigate potential vulnerabilities and security risks within data systems and infrastructure.
 * Implement and maintain data encryption, tokenization, and access control mechanisms to protect sensitive data.
 * Utilize Python, SQL, GitHub, Redshift, Databricks, and dbt to design and secure data models, queries, and data integration workflows.
 * Stay updated with the latest industry trends, tools, and technologies related to data security and compliance, and make recommendations for process improvements and enhancements.
 * Participate in agile development practices, including sprint planning, daily stand-ups, and retrospectives, to ensure timely and efficient project delivery.
 * Collaborate with data engineers to support data initiatives, providing insights and guidance on data security and compliance.
   
   
   

THE STATS

What we're looking for in our next teammate


 * Bachelor's degree in Computer Science, Information Systems, or a related field.
 * Proven experience as a Data Security Engineer or a similar role, with a strong focus on data security and compliance.
 * Knowledge of compliance frameworks and regulations, such as SOX, ISO, NIST, GDPR etc.
 * Proficiency in programming languages such as Python and SQL, with experience in leveraging these languages for data engineering tasks.
 * Knowledge of data security best practices, including secure coding practices, vulnerability management, and security incident response.
 * Experience with version control systems like GitHub and working collaboratively in a team environment.
 * Hands-on experience with cloud-based data platforms, such as Redshift and Databricks.
 * Proven experience with AWS services, particularly IAM (Identity and Access Management).
 * Familiarity with dbt (data build tool) and its application in data modeling and transformation.
 * Understanding of data encryption, tokenization, and access control mechanisms.
 * Experience working in an agile environment, delivering high-quality results within defined sprint cycles.
 * Strong analytical and problem-solving skills, with an ability to identify and mitigate potential security risks.
 * Excellent communication and collaboration skills, with the ability to work effectively across cross-functional teams.
   
   
   

Player Benefits

We treat our team right

From our many opportunities for professional development to our generous insurance and paid leave policies, we’re committed to making sure our employees get as much out of FanDuel as we ask them to give. Competitive compensation is just the beginning. As part of our team, you can expect:


 * An exciting and fun environment committed to driving real growth
 * Opportunities to build really cool products that fans love
 * Career and professional development resources to help you refine your game plan for owning and driving your career and development
 * Be well, save well and live well - with FanDuel Total Rewards your benefits are one highlight reel after another
   
   
   

FanDuel is an equal opportunities employer and we believe, as one of our principal states, “We Are One Team!” We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, Veteran status, or another other characteristic protected by state, local or federal law. We believe FanDuel is strongest and best able to compete if all employees feel valued, respected, and included. We want our team to include diverse individuals because diversity of thought, diversity of perspectives, and diversity of experiences leads to better performance. Having a diverse and inclusive workforce is a core value that we believe makes FanDuel stronger and more competitive as One Team!

The applicable salary range for this position is $134,000 - $168,000, which is dependent on a variety of factors including relevant experience, location, business needs and market demand. This role may offer the following benefits: medical, vision, and dental insurance; life insurance; disability insurance; a 401(k) matching program; among other employee benefits. This role may also be eligible for short-term or long-term incentive compensation, including, but not limited to, cash bonuses and stock program participation. This role includes paid personal time off and 14 paid company holidays. FanDuel offers paid sick time in accordance with all applicable state and federal laws.

",Full-time
3998841067,1431.0,Data Engineer,"Overview

PepsiCo operates in an environment undergoing immense and rapid change. Big-data and digital technologies are driving business transformation that is unlocking new capabilities and business innovations in areas like eCommerce, mobile experiences and IoT. The key to winning in these areas is being able to leverage enterprise data foundations built on PepsiCo’s global business scale to enable business insights, advanced analytics and new product development. PepsiCo’s Enterprise Data Operations (EDO) team is tasked with the responsibility of developing quality data collection processes, maintaining the integrity of our data foundations and enabling business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.

What PepsiCo Enterprise Data Operations (EDO) does:


 * Maintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company
 * Responsible for day-to-day data collection, transportation, maintenance/curation and access to the PepsiCo corporate data asset
 * Work cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders
 * Increase awareness about available data and democratize access to it across the company
   
   

As a member of the data engineering team, you will be the key technical expert developing and overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be an empowered member of a team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems.

Responsibilities


 * Active contributor to code development in projects and services.
 * Manage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products.
 * Build and own the automation and monitoring frameworks that captures metrics and operational KPIs for data pipeline quality and performance.
 * Responsible for implementing best practices around systems integration, security, performance and data management.
 * Empower the business by creating value through the increased adoption of data, data science and business intelligence landscape.
 * Collaborate with internal clients (data science and product teams) to drive solutioning and POC discussions.
 * Develop and optimize procedures to “productionalize” data science models.
 * Define and manage SLA’s for data products and processes running in production.
 * Support large-scale experimentation done by data scientists.
 * Prototype new approaches and build solutions at scale.
 * Research in state-of-the-art methodologies.
 * Create documentation for learnings and knowledge transfer.
 * Create and audit reusable packages or libraries.
   
   

Compensation & Benefits:


 * The expected compensation range for this position is between $100,000 - $167,500 based on a full-time schedule.
 * Location, confirmed job-related skills and experience will be considered in setting actual starting salary.
 * Bonus based on performance and eligibility; target payout is 8% of annual salary paid out annually.
 * Paid time off subject to eligibility, including paid parental leave, vacation, sick, and bereavement.
 * In addition to salary, PepsiCo offers a comprehensive benefits package to support our employees and their families, subject to elections and eligibility: Medical, Dental, Vision, Disability, Health and Dependent Care Reimbursement Accounts, Employee Assistance Program (EAP), Insurance (Accident, Group Legal, Life), Defined Contribution Retirement Plan.
   
   

Qualifications


 * 4+ years of overall technology experience that includes at least 3+ years of hands-on software development, data engineering, and systems architecture.
 * 3+ years of experience with Data Lake Infrastructure, Data Warehousing, and Data Analytics tools.
 * 3+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.).
 * 2+ years in cloud data engineering experience in Azure
 * Experience with Azure Data Factory, Azure Databricks and Azure Machine learning tools is a plus.
 * Fluent with Azure cloud services. Azure Certification is a plus.
 * Experience with integration of multi cloud services with on-premises technologies.
 * Experience with data modeling, data warehousing, and building high-volume ETL/ELT pipelines.
 * Experience with data profiling and data quality tools like Apache Griffin, Deequ, and Great Expectations.
 * Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.
 * Experience with at least one MPP database technology such as Redshift, Synapse or SnowFlake.
 * Experience with running and scaling applications on the cloud infrastructure and containerized services like Kubernetes.
 * Experience with version control systems like Github and deployment & CI tools.
 * Experience with Statistical/ML techniques is a plus.
 * Experience with building solutions in the retail or in the supply chain space is a plus
 * Understanding of metadata management, data lineage, and data glossaries is a plus.
 * Working knowledge of agile development, including DevOps and DataOps concepts.
 * Familiarity with business intelligence tools (such as PowerBI).
   
   

Education


 * BA/BS in Computer Science, Math, Physics, or other technical fields.
   
   

Skills, Abilities, Knowledge


 * Excellent communication skills, both verbal and written, along with the ability to influence and demonstrate confidence in communications with senior level management.
 * Proven track record of leading, mentoring data teams.
 * Strong change manager. Comfortable with change, especially that which arises through company growth. Able to lead a team effectively through times of change.
 * Ability to understand and translate business requirements into data and technical requirements.
 * High degree of organization and ability to manage multiple, competing projects and priorities simultaneously.
 * Positive and flexible attitude to enable adjusting to different needs in an ever-changing environment.
 * Strong leadership, organizational and interpersonal skills; comfortable managing trade-offs.
 * Foster a team culture of accountability, communication, and self-management.
 * Proactively drives impact and engagement while bringing others along.
 * Consistently attain/exceed individual and team goals
 * Ability to lead others without direct authority in a matrixed environment.
   
   

Competencies


 * Highly influential and having the ability to educate challenging stakeholders on the role of data and its purpose in the business.
 * Understands both the engineering and business side of the Data Products released.
 * Places the user in the center of decision making.
 * Teams up and collaborates for speed, agility, and innovation.
 * Experience with and embraces agile methodologies.
 * Strong negotiation and decision-making skill.
 * Experience managing and working with globally distributed teams.
   
   

EEO Statement

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.

PepsiCo is an Equal Opportunity Employer: Female / Minority / Disability / Protected Veteran / Sexual Orientation / Gender Identity

If you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy.

Please view our Pay Transparency Statement",Full-time
4148967522,3042775.0,Data Engineer,"Job Title: Data Engineer

Location-Type: Remote (CST)

Start Date Is: ASAP

Duration: 6-month contract with potential to convert to FTE

Compensation Range: $35-45/hr W2







Role Overview: We are seeking a skilled Sr. Data Engineer to join our client’s Commercial Team. In this role, you will collaborate with stakeholders to design, build, and maintain data infrastructure that supports the commercial team's efforts. This role focuses on enabling seamless data flow, analysis, and reporting, ensuring that data drives business decisions and growth.

Day-to-Day Responsibilities:

 * Integrate various data sources to create a unified view of key business data (revenue, orders, pipeline, marketing, customer).
 * Develop efficient data models for business reporting and decision-making using SQL, Python, or R.
 * Work closely with data scientists and analysts to ensure data quality and integrity.
 * Design and maintain a commercial data dictionary for clear data element definitions.
 * Build and optimize Power BI data models and dashboards for reporting and analytics.
 * Collaborate with business analysts to translate business needs into technical data models and visualizations.
 * Automate data processing tasks to improve operational efficiency.
 * Develop scalable data pipelines to support real-time analytics and reporting.

Must-Haves:

 * 3+ years of experience in data engineering, with a focus on building data models and managing data dictionaries.
 * Proficiency with Power BI, including building complex models and dashboards with DAX/PowerQuery.
 * Experience with Snowflake data models and architecture.
 * Strong SQL skills for data querying, manipulation, and ETL processes.
 * Experience with CRM systems (e.g., Salesforce) and sales performance data.
 * Bachelor's or Master’s degree in Computer Science, Data Engineering, Information Systems, or related field.
 * Expertise in statistical and mathematical methodologies for data analysis.
 * Exceptional project management and organizational skills.
 * Strong communication skills to convey technical data insights to non-technical audiences.

Nice-to-Haves:

 * Familiarity with automated data processing tools and techniques.
 * Knowledge of advanced data modeling and visualization techniques.

",Contract
4144968701,28665250.0,Data Engineer,"APiJET is a Seattle-based pioneer in real-time aircraft data analytics and software products. Our team works with advanced algorithms and data streams to uncover hidden efficiencies that enable our customers to operate more efficiently and reduce their environmental footprints. We work across diverse data sets spanning public source and private aerospace data, searching for meaningful patterns to drive our platform. If you want something new and challenging the status quo, check us out!




As a Data Engineer, you will build and maintain ETL systems within AWS, utilizing in-house and cloud-specific tooling. You will develop and improve the data lake, data collection systems, data integrity, and other strategic systems that support the data science team, the customer, and the business. Your contribution will be key to the success of the company!




Duties and Responsibilities:




Build and support data systems and pipelines by:




 * Cleaning and transforming raw data (internally and externally sourced) to be ingested by reports and applications.
 * Implementing data mart tools to facilitate data mining and curation needs.
 * Optimizing and automating ETL processes.

Enhance data quality and reliability by:

 * Analyzing and organizing data, including ad-hoc request fulfillment and deep data exploration.
 * Implementing, monitoring, and alarming on ETL pipelines and bad data.
 * Generating reports on data quality and anomalies.

Collaborate with data scientists and software architects on data exploration projects by:

 * Developing analytical tools and programs to support the data team.
 * Extracting and preparing data based on requirements and specifications.

Required Skills and Abilities

 * 3+ years previous experience as a data engineer or a similar role.
 * 3+ years implementing data models, data mining, data pipelines, and similar activities.
 * 2+ years in Python programming (PySpark, Pandas, and AWS-related data-wrangling tools).
 * 3+ years working with AWS services to deliver quality, reliable, and timely data pipeline solutions.
 * 2+ years supporting containerized and serverless pipelines.
 * 2+ years working with large datasets.




Soft Skills:

 * Comfortable in an Agile task management environment (Atlassian Suite, Agile methodologies).
 * Ability to work with ambiguous requirements.
 * Clear written and verbal communication. Being hybrid, asynchronous communication is a necessity.
 * A people person, collaboration is a must!

Educational and Physical Requirements

 * Must have a bachelor's degree in computer science, a related field, or equivalent experience.
 * Must be a U.S. Person (U.S. Citizen or Green Card holder).
 * The company is headquartered in Seattle, Washington, and this position must reside within a 30-mile radius of Seattle due to the hybrid nature of the role.

",Full-time
4129308634,66321745.0,Junior Data Engineer,"Since 2010 Synergisticit has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this Job market also, our candidates are able to achieve multiple job offers and $100k + salaries.

Please Check The Below Links

Synergisticit Pics /Salaries of Successful Candidates

Synergisticit at Oracle Cloudworld 2023

Synergisticit at Gartner Data & Analytics summit

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

Required Skills

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, Gen AI, LLM, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full Stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java , javascript , C++ or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Contract
3890650480,3052223.0,Data Engineer (United States),"Our Solution

Demyst unlocks innovation with the power of data. Our platform helps enterprises solve strategic use cases, including lending, risk, digital origination, and automation, by harnessing the power and agility of the external data universe. We are known for harnessing rich, relevant, integrated, linked data to deliver real value in production. We operate as a distributed team across the globe and serve over 50 clients as a strategic external data partner. Frictionless external data adoption within digitally advancing enterprises is unlocking market growth and allowing solutions to finally get out of the lab. If you like actually to get things done and deployed, Demyst is your new home.

The Opportunity

As a Data Engineer at Demyst, you will be powering the latest technology at leading financial institutions around the world. You may be solving a fintech's fraud problems or crafting a Fortune 500 insurer's marketing campaigns. Using innovative data sets and Demyst's software architecture, you will use your expertise and creativity to build best-in-class solutions. You will see projects through from start to finish, assisting in every stage from testing to integration.

To meet these challenges, you will access data using Demyst's proprietary Python library via our JupyterHub servers, and utilize our cloud infrastructure built on AWS, including Athena, Lambda, EMR, EC2, S3, and other products. For analysis, you will leverage AutoML tools, and for enterprise data delivery, you'll work with our clients' data warehouse solutions like Snowflake, DataBricks, and more.

Demyst is a remote-first company. The candidate must be based in the United States.

Responsibilities


 * Collaborate with internal project managers, sales directors, account managers, and clients' stakeholders to identify requirements and build external data-driven solutions
 * Perform data appends, extracts, and analyses to deliver curated datasets and insights to clients to help achieve their business objectives
 * Understand and keep current with external data landscapes such as consumer, business, and property data.
 * Engage in projects involving entity detection, record linking, and data modelling projects
 * Design scalable code blocks using Demyst's APIs/SDKs that can be leveraged across production projects
 * Govern releases, change management and maintenance of production solutions in close coordination with clients' IT teams
   
   
   

Requirements


 * Bachelor's in Computer Science, Data Science, Engineering or similar technical discipline (or commensurate work experience); Master's degree preferred
 * 1-3 years of Python programming (with Pandas experience)
 * Experience with CSV, JSON, parquet, and other common formats
 * Data cleaning and structuring (ETL experience)
 * Knowledge of API (REST and SOAP), HTTP protocols, API Security and best practices
 * Experience with SQL, Git, and Airflow
 * Strong written and oral communication skills
 * Excellent attention to detail
 * Ability to learn and adapt quickly
   
   
   

Benefits


 * Distributed working team and culture
 * Generous benefits and competitive compensation
 * Collaborative, inclusive work culture: all-company offsites and local get togethers in Bangalore
 * Annual learning allowance
 * Office setup allowance
 * Generous paid parental leave
 * Be a part of the exploding external data ecosystem
 * Join an established fast growth data technology business
 * Work with the largest consumer and business external data market in an emerging industry that is fueling AI globally
 * Outsized impact in a small but rapidly growing team offering real autonomy and responsibility for client outcomes
 * Stretch yourself to help define and support something entirely new that will impact billions
 * Work within a strong, tight-knit team of subject matter experts
 * Small enough where you matter, big enough to have the support to deliver what you promise
   
   
   

Demyst is committed to creating a diverse, rewarding career environment and is proud to be an equal opportunity employer. We strongly encourage individuals from all walks of life to apply.",Full-time
4125061634,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4151644417,35478479.0,Software Engineer,"About Middesk

Our goal is to make it easier for businesses to work together. Since 2018, we have been a leading disruptor in the business identity market. While consumer identity technology has seen significant modernization and digitization over the past decade, business identity and verification largely continues to be a manual process, specifically in the context of onboarding businesses to receive access to financial products and services. Our best-in-class business identity platform provides access to complete, up-to-date information that financial services institutions and fintechs need to make educated decisions about their customers and facilitate rapid onboarding and transacting. Our vision is that every company can instantly gain access to all the data, products, and services they need to establish and grow their business with ease. Middesk came out of Y Combinator, is backed by Sequoia Capital and Accel Partners, and was recently named to Forbes Fintech 50 List and cited as an industry leader in business verification by digital identity strategy firm, Liminal.

About Middesk Engineering

We believe ""velocity"" is the rate at which we effect realized value for our customers, not the rate at which we ship code. And this pushes us to center our work around customers; how will this change I'm about to make help our customers get jobs done?

When we’re coding, we're making hundreds of micro-decisions about user experience that add up. How can I communicate this exception to our customers in a manner that helps them understand what's happened and unblock themselves?

Middesk Engineering is customer-first engineering. (check out our blog post on the topic).

The role

Engineers have the freedom to create a lot of impact for our customers. The role requires high agency and comfort with change. It requires people who believe the interesting problems in Engineering are stack-agnostic. It requires Engineers who believe that solving customer problems quickly is what matters first; building scalable systems matters when customer problems are scaling problems.

What You'll Do


 * Work in React, Redux, Ruby, Rails, Postgres, and potentially Scala, Python, and Go to solve problems for our customers.
 * Dive into all layers of the stack; frontend, backend, API, data processors, etc.
 * Jam with Product Managers, Designers, Ops, and other Engineers every day to shape the direction of our products.
 * Share your knowledge with others in Engineering; people should get better at their craft because they work with you. Even if you’re early in your career, you have something to teach.
 * Contribute to the psychological safety of your team. Software is built by groups of people, and good relationships matter.
 * Help us interview and hire other Engineers.
   
   

What We’re Looking For


 * While we agree the interesting problems in Engineering are stack-agnostic, we’d love it if you had experience with a couple of the languages in our stack (see the first point above). We’ve found that Engineers with prior stack experience usually ramp faster.
 * You’ve worked for a high-growth, venture-backed startup before and are looking for a similar role. Or, you've founded a company and are looking to get back into it.
 * You’ve been working as a professional Software Engineer for at least three or more years.
 * You understand SaaS business fundamentals (e.g. annual contract value, customer acquisition cost, and annual-recurring revenue) and can demonstrate how the work you’ve done influences these metrics.",Full-time
4125071965,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4033428093,90667110.0,Data Engineer,"Unleash your talents and venture into a new career that innovates and transforms products & services globally!

Data Engineer (Java & Spark)

Job Type: W2/Full Time

Location: Alpharetta, GA (Hybrid - 3 Days a Week)

Salary: $110k - $130k (additional $20k bonus.)

[Key Responsibilities]

We are seeking an experienced Data Engineer with a strong background in Java and Spark to join our team in Alpharetta, GA. This is a hybrid role, requiring you to be onsite three days a week. The ideal candidate will have over 8 years of experience in data engineering and be proficient in a variety of data technologies. Here are the key responsibilities:


 * Design, develop, and maintain scalable data pipelines and systems
 * Work with large datasets using Spark, Hadoop, and Hive QL
 * Develop and optimize SQL queries for data extraction and analysis
 * Implement data solutions using Snowflake
 * Write clean, efficient, and maintainable code in Java and Springboot
 * Collaborate with cross-functional teams to understand data requirements and deliver solutions
 * Utilize Git and Teamcity for version control and continuous integration
 * Create and maintain documentation for data processes and systems
 * (Nice to have) Develop data visualizations using Tableau
   
   

[Key Requirements]


 * Bachelor’s degree in Computer Science, Information Technology, or a related field
 * Extensive experience with Spark, Hadoop, and Hive QL
 * Proficiency in SQL and Snowflake
 * Strong programming skills in Java and Springboot
 * Experience with Git and Teamcity
 * Excellent problem-solving and analytical skills
 * Strong communication and teamwork abilities
 * Experience with Tableau for data visualization. (preferred skill)
   
   

[About Ccube]

Ccube delivers measurable impact across industries with singular focus on Data + AI in the Cloud.

Our Expertise:


 * Data Strategy & Architecture
 * Data Engineering & Integration
 * Analytics & AI
 * Cloud, DataOps & MLOps
   
   

[Life @Ccube]

At Ccube we,


 * Do more with less
 * Deliver WOW through service
 * Embrace and drive change and
 * Stay humble
   
   

Benefits


 * Startup culture with opportunity to grow
 * Performance bonuses
 * Company stock options
 * Health, dental and vision insurance plans
 * Pursue growth and learning with career development expenses
   
   

Powered by JazzHR

jBQn5ofw12",Full-time
4126528742,5250800.0,"Data Engineer, L/S Equity","A Career in Long/Short Equities at Point72

Long/Short Equity is Point72’s core strategy and its success is dependent upon our sector-based investing teams. Using fundamental research, our research analysts inform the investment strategies of our portfolio managers. Through our Point72 University, you have access to an unparalleled training and coaching curriculum to help foster your success. We offer you a clear path based on your abilities, willingness to work hard, and performance. Join us if you're looking for a career at the forefront of investing.

What you’ll do

As a data engineer embedded in an equity investing team, you will leverage a variety of innovative technologies to drive data-driven solutions and analyses. In this role, you will focus on bridging the gap between fundamental research and technological innovation. You will partner closely with an investment team to help connect fundamental research with data analysis and software solutions. Specifically, you will:


 * Work alongside senior data scientists to develop ""quantamental"" strategies.
 * Develop cross-sector quantitative insights to aid in generating investment ideas.
 * Create tools and infrastructure to support and enhance the team’s quantitative efforts.
 * Maintain and enhance the current codebase and productionize processes.
 * Integrate and process Compliance-approved datasets.
 * Leverage technologies such as Spark, Terraform, and Airflow in your projects.
 * Employ programming languages like Python and SQL to build robust data solutions.
   
   

What’s Required

We’re looking for a deeply curious individual with demonstrated technical excellence who thrives in a fast-paced entrepreneurial environment. The ideal candidate is a proactive self-starter, ready to take the lead on projects with minimal oversight. No prior experience in fundamental equities or finance is necessary, however, you should have:


 * A bachelor's degree in computer science, engineering, or a related technical field, or equivalent practical experience.
 * Minimum 2 years experience in an engineering role or similar position.
 * Strong proficiency in SQL and Python (with an emphasis on Pandas, PySpark, etc.)
 * Experience with cloud platforms, Terraform, CI/CD pipelines & Git, Linux, Airflow, Databricks, Spark.
 * Experience with data visualization tools and libraries such as Tableau and matplotlib/seaborn.
 * Understanding of data warehousing concepts and experience with databases (e.g. PostgreSQL).
 * Strong analytical skills and the ability to adapt to a rapidly changing environment.
 * A commitment to upholding the highest ethical standards.
   
   

We take care of our people

We invest in our people, their careers, their health, and their well-being. When you work here, we provide:


 * Fully-paid health care benefits
 * Generous parental and family leave policies
 * Mental and physical wellness programs
 * Volunteer opportunities
 * Non-profit matching gift program
 * Support for employee-led affinity groups representing women, minorities and the LGBTQ+ community
 * Tuition assistance
 * A 401(k) savings program with an employer match and more
   
   

About Point72

Point72 is a leading global alternative investment firm led by Steven A. Cohen. Building on more than 30 years of investing experience, Point72 seeks to deliver superior returns for its investors through fundamental and systematic investing strategies across asset classes and geographies. We aim to attract and retain the industry’s brightest talent by cultivating an investor-led culture and committing to our people’s long-term growth. For more information, visit www.Point72.com/about.

The annual base salary range for this role is $150,000-$200,000 (USD) , which does not include discretionary bonus compensation or our comprehensive benefits package. Actual compensation offered to the successful candidate may vary from posted hiring range based upon geographic location, work experience, education, and/or skill level, among other things.",Full-time
4132131854,18722039.0,Data Engineer,"About Us

Canary Technologies is changing the game for hotels with modern software powered by Canary's hospitality-specific AI platform.

Canary is utilized by 20,000+ hoteliers in 90+ countries to equip hoteliers with the technology they need to work smarter and wow their guests. Major hotel brands such as Wyndham, Marriott, IHG, Four Seasons, Rosewood, and Best Western trust Canary to deliver results.

Canary was named a 2024 Deloitte Technology Fast 500™ company, a Most Innovative Company by Fast Company and a HotelTechReport Best Place to Work — and is backed by top Silicon Valley investors like Y Combinator, FPrime, and Insight Ventures.

Join us in shaping the future of hospitality!

About The Role

Our team is growing and we’re hiring a Data Engineer to join our engineering team and enable our next phase of growth. Canary's engineering team is fully remote!

You will work with the Platform Engineering team on designing, building and maintaining scalable data pipelines and infrastructure to support our data-driven initiatives.

Responsibilities


 * Design, develop, and maintain data models using Snowflake and DBT
 * Implement and manage ETL processes to ensure data integrity and consistency
 * Collaborate with cross-functional teams to understand data requirements and deliver solutions
 * Optimize SQL queries and data pipelines for performance and scalability
 * Participate in code reviews and contribute to best practices in data engineering
   
   

Qualifications


 * Proficiency in Snowflake, DBT, SQL, ETL, Data Modeling, and Data Warehousing
 * A minimum of 3 years of relevant experience, with at least 2-3 projects involving DBT
 * Good working knowledge of GitHub and GitHub Actions
 * Understanding of cloud platforms such as AWSStrong analytical and problem-solving skills
 * Excellent communication and teamwork abilities
 * A proactive attitude with a passion for continuous learning and improvement
 * Ability to manage multiple tasks and projects simultaneously.
   
   

We also work hard to ensure Canary is a fun and exciting place to work. Here are some of the additional benefits

Canary Days: As a company we want to ensure that the team has time to recharge. Each month we provide company wide days off to ensure there is at least one extended weekend or day off.

Self Improvement Club: We meet each month and share our personal goals for the month. Each individual is provided a budget towards any purchases that help us achieve these goals.

Professional Development Chats: We provide budget to help drive cross functional professional development conversations across the organization.

Travel Reimbursement: Team members are able to visit our offices across New York, San Francisco or Dallas when they choose, and are provided a travel stipend for doing so. Spend time working with the team in their office, and use the rest of your time exploring a new city!

Personal Travel Reimbursement: If you stay at a hotel that Canary works with, we provide a credit towards your stay.

Canary Technologies is an equal opportunity employer. We recruit, employ, train, compensate and promote talent regardless of race, religion, ethnicity, national origin, citizenship, gender, gender identity, sexual orientation, age, veteran status, disability, genetic information or any other protected characteristic.",Full-time
4125548060,101021.0,Data Engineer,"Location: Remote, with a preference of being in the DMV area

Clearance: Must be able to obtain a public trust and ability to get a secret clearance

Summary Of Position

As a Data Engineer, you will design and build data pipeline systems for collecting, storing and analyzing data to ensure it is usable for data scientists and analysts, while utilizing software best practices, data optimizations (including storage, indexing, and normalization), anomaly detection, and machine learning principles. This role does not focus on working on a single product necessarily, is fast paced, and allows the opportunity for someone to learn and grow as an engineer. If you are excited about working in a dynamic environment, this role would be great for you!

Job Duties


 * Develop, deploy and maintain multiple data pipelines to support various data science models as required by client projects.
 * Take client requests and help turn into a dashboard to help solve client problems.
 * Provide support to existing data pipelines that ingest raw data from disparate sources and move the data to a destination for storage and analysis.
 * Provide internal IT support for the company’s cloud infrastructures.
 * Collaborate with Data Scientists to facilitate project completion according to client needs.
 * Attend and present at client project update meetings.
 * Attend regular Data Engineering mentorship meetings and Data Engineering Team-building and knowledge-share meetings.
 * Attend monthly meetings with supervisors
 * Complete professional development curriculum created for the Data Engineering Team.
   
   

Minimum Job Requirements


 * Bachelor of Science degree in Computer Science or closely related IT field.
 * 2+ years of experience
 * Experience working with Python
 * AWS Experience
 * JavaScript familiarity
 * Willingness to learn
   
   

About Elder Research, Inc

Elder Research is a fast growing consulting firm specializing in predictive analytics. Being in the data mining business almost 30 years, we pride ourselves in our ability to find creative, cutting-edge solutions to real-world problems. We work hard to provide the best value to our clients and allow each person to contribute their ideas and put their skills to use immediately.

Our team members are passionate, curious, life-long learners. We value humility, servant-leadership, teamwork, and integrity. We seek to serve our clients and our teammates to the best of our abilities. In keeping with our entrepreneurial spirit, we want candidates who are self-motivated with an innate curiosity and strong teamwork.

Elder Research believes in continuous learning and community - each week the entire company attends a “Tech Talk” and each office location provides lunch. Elder Research provides a supportive work environment with established parental, bereavement, and PTO policies. By prioritizing a healthy work-life balance - with reasonable hours, solid pay, low travel, and extremely flexible time off - Elder Research enables and encourages its employees to serve others and enjoy their lives.

Elder Research, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. Elder Research is a Government contractor and many of our positions require US Citizenship.",Full-time
4128220538,1742506.0,Data Engineer,"Title: Data Engineer
Location: Hybrid (Vienna, CVA or Pensacola, FL)
Duration: Initial 6 months plus extensions

Job Description
Develop strategies for data acquisition, data pipelines, and database implementation. Responsible for
designing, building, integrating data from various resources, and managing big data. Develop and write
complex queries, while ensuring they are easily accessible, work smoothly, with the goal of optimizing the performance of Navy Federal’s big data ecosystem within CI/CD pipelines. Recognized as an expert with a specialized depth and/or breadth of expertise in discipline. Solves highly complex problems; takes a broad perspective to identify solutions. Leads functional projects. Works independently.

Responsibilities:
 * Provide Data Intelligence and Data Warehousing (DW) solutions and support by leveraging project standards and leading data platforms
 * Build and maintain Azure data pipelines using DevSecOps process
 * Define and build data integration processes to be used across the organization
 * Build conceptual and logical data models for stakeholders and management
 * Work directly with business leadership to understand data requirements; propose and develop solutions that enable effective decision-making and drives business objectives
 * Prepare advanced project implementation plans which highlight major milestones and deliverables, leveraging standard methods and work planning tools
 * Document existing and new processes to develop and maintain technical and non-technical reference materials.
 * Recognize potential issues and risks during the analytics project implementation and suggest mitigation strategies
 * Coach and mentor project team members in carrying out analytics project implementation activities
 * Communicate and own the process of manipulating and merging large datasets
 * Perform other duties as assigned
   

Qualifications and Education Requirements:
 * Master’s degree in Information Systems, Computer Science, Engineering, or related field, or the equivalent combination of education, training and experience
 * Expert skill in Azure Data Factory, Databricks
 * Advanced skill in Azure SQL, Azure Data Lake, and Azure App Service, Python, T-SQL
 * Experienced in sourcing, maintaining, and updating data in On-Prem and Cloud environments
 * Knowledge of and the ability to perform basic statistical analysis
 * Thorough understanding of SQL
 * Experienced in the use of ETL tools and techniques
 * Experience Designing and building of data pipelines using API ingestion and Streaming ingestion methods.
 * Ability to understand the business problem and determine what aspects of it require optimization; articulate those aspects in a clear and concise manner
 * Ability to understand other projects or functional areas in order to consolidate analytical needs and processes
 * Demonstrates change management and/or excellent communication skills
 * Understands data warehousing, data cleaning, data pipelines and other analytical techniques required for data usage
 * Demonstrates deep understanding of multiple data related concepts
 * Understands the concepts and application of data mapping and building requirements
 * Understands data models, large datasets, business/technical requirements, BI tools, data warehousing, statistical programming languages and libraries
 * Experience using GIT & Source Control
 * Skilled in managing the process between updating and maintaining data source systems and implementing data related requirements

 Our benefits package includes: 
 * Comprehensive medical benefits
 * Competitive pay
 * 401(k) retirement plan
 * ...and much more!
   

About INSPYR Solutions
Technology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients' business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com.

INSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities
 ",Contract
4136795880,77837310.0,Data Engineer,"Company Description:

Camlin is a global technology leader that operates with the vision of bringing revolutionary products to life for a wide range of industries, including power and rail, and also has interests in a number of R&D projects in a variety of scientific sectors.




At Camlin we believe in high quality engineering and design, allowing us to develop market leading products and services. In short, we love creating value for our customers by solving difficult problems. As of today, the Camlin operation spans over 20 countries across the globe.







About The Role

We are seeking a highly experienced Data Engineer to join our team. The ideal candidate will have a strong background in the utility or related industry, coupled with expertise in COTS and SaaS software administration or management. This role requires hands-on experience with APIs and system integrations, along with excellent analytical and problem-solving abilities.




What You'll Do

 * Perform analysis of customer provided data and create reports and recommendations.
 * Configure SaaS applications based on data evaluation
 * Prepare and load data sets.
 * Administer user access and roles for customers.
 * Test configuration, data and software with customers
 * Train customers to use software.
 * Provide functional analysis of reported customer problems in the form of support cases to produce findings, conclusions, and solutions.
 * Liaise with other Camlin departments to obtain any other functional information required to help resolve more complicated problems for customers.
 * Communicate regularly with customers by phone and email to update them on support cases.
 * Provide live support to customers and internal teams.
 * Create work instructions and training documentation to support customers.
 * Capture quality issues and raising internal support tickets.
 * Preparing trip reports, presentations and reports outlining progress, deliverables, and areas for improvement.




WHAT YOU WILL NEED TO SUCCEED

 * Minimum of 5 years experience in utility or related industry
 * Minimum of 5 years experience with commercial off the shelf (COTS) or SaaS software administration or management
 * Experience with APIs and integration
 * Previous experience in customer facing role
 * Good analytical and problem-solving abilities.
 * Proficient in Microsoft Office
 * A positive, can-do attitude, keen to learn and develop industry and product knowledge
 * Attention to detail
 * Effective time and workload management
 * Excellent verbal and written communication skills




PREFERRED SKILLS

 * Previous experience with Asset Performance Management or similar Asset Health based systems
 * Previous experience with advanced analytics or business intelligence systems
 * Previous experience with electrical generation, transmission or distribution asset or facility management
 * Previous experience with electrical substation equipment




Our Values:

 * We work together - We know that working collaboratively will help us reach our shared goals faster, so we always look for ways to help each other.
 * We believe in people - Here at Camlin, our people are central to what we do and what we can achieve. And as we move towards becoming industry and customer ‘partners’ that’s even more important. We trust our team members to do their best and be supportive.
 * We won’t accept the ‘way it’s always been done’ - Since Camlin’s inception, we’ve been curious, inquisitive and always want to improve. Thinking differently is in our DNA and we love solving tough challenges.
 * We listen to learn - Whether it’s our customers, our markets, or each other, we ask questions and listen to the answers so we can learn and improve.
 * We’re trying to do the right thing - We take responsibility for our actions and take decisions based on what’s right for people, profit, and planet.




Equal Employment Opportunity Statement

Individuals seeking employment at Camlin are considered without regards to race, colour, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, gender identity, or sexual orientation.",Full-time
4127595520,27007409.0,Data Engineer,"Aureon Consulting is currently seeking a skilled Data Engineer for one of our most favorite clients. The ideal candidate will have strong experience integrating data from multiple sources, including legacy systems, cloud applications, structured databases, proprietary file formats, APIs, and event streams.




Responsibilities




 * Implement and manage data mesh and event streaming architectures, such as Azure Event Hub and Kafka.
 * Work with structured, semi-structured, and unstructured data forms, including SQL, JSON, and YAML.
 * Integrate data from various sources, including legacy systems, cloud applications, structured databases, proprietary file formats, APIs, and event streams.
 * Develop and maintain ETL/ELT pipelines using tools like SSIS, Azure Data Factory, Function Apps, Logic Apps, Databricks, SPARK, and Azure Synapse Analytics.
 * Utilize Microsoft Visual Studio and Azure DevOps for development and deployment (preferred).
 * Follow the software development life cycle within an Agile framework.
 * Administer and manage the organization's data infrastructure.
 * Monitor and optimize database performance to ensure efficiency.
 * Ensure database performance and security are maintained.






Qualifications




 * Proven experience integrating data from multiple sources.
 * Proficiency in both relational and dimensional data models, particularly within Azure SQL Server. Extensive experience with ETL/ELT pipelines.
 * Experience with data mesh and event streaming architectures, such as Azure Event Hub and Kafka. Proficiency with structured, semi-structured, and unstructured data forms, including SQL, JSON, and YAML.
 * Familiarity with Microsoft Visual Studio and Azure DevOps (preferred).
 * Understanding of the software development life cycle in an Agile framework.
 * Experience in administering and managing data infrastructure.
 * Ability to monitor and optimize database performance and ensure security.




Does this sound like you? Would you like more information? Please apply here!",Full-time
4147411881,18104003.0,AWS Data Engineer,"AWS Data Engineer

Location - Irving, TX

Fulltime




Work Location Type: Hybrid

Amazing Work Culture & Team

Excellent Growth Opportunities




PLEASE READ BEFORE APPLYING:

THIS ROLE WILL NOT CONSIDER CANDIDATES WHO ARE CURRENTLY ON VISA STATUS OR OPT STATUS.




Role Purpose Statement

The AWS Data Engineer will own the planning, design, and implementation of data structures for LSG Sky Chefs North America in our AWS environment. This role will be responsible for incorporating all internal and external data sources into a robust, scalable, and comprehensive data model within AWS to support business intelligence and analytics needs throughout the company.




Main Accountabilities

 * Collaborate with cross-functional teams to understand and define business intelligence needs and translate them into data modeling solutions
 * Develops, builds and maintains scalable data pipelines, data schema design, and dimensional data modelling in Databricks and AWS for all system data sources, API integrations, and bespoke data ingestion files from external sources
 * Responsible for data cleansing, standardization, and quality control
 * Create data models that will support comprehensive data insights, business intelligence tools, and other data science initiatives
 * Create data models and ETL procedures with traceability, data lineage and source control
 * Design and implement data integration and data quality framework
 * Implement data monitoring best practices with trigger based alerts for data processing KPIs and anomalies
 * Investigate and remediate data problems, performing and documenting thorough and complete root cause analyses. Make recommendation for mitigation and prevention of future issues.
 * Work with Business and IT to assess efficacy of all legacy data sources, making recommendations for migration, anonymization, archival and/or destruction.
 * Continually seek to optimize performance through database indexing, query optimization, stored procedures, etc.
 * Ensure compliance with data governance and data security requirements, including data life cycle management, purge and traceability.
 * Create and manage documentation and change control mechanisms for all technical design, implementations and systems maintenance.



Knowledge, Skills and Experience

 * Bachelor's or graduate degree in computer science, information systems or related field preferred, or similar combination of education and experience
 * At least 4 years’ experience designing and managing data pipelines, schema modeling, and data processing systems.
 * Hands-on expertise with Databricks (or similar tools like Microsoft Fabric, Snowflake, etc.) to drive scalable data solutions.
 * Proficient in Python, with a track record of solving real-world data challenges.
 * Advanced SQL skills, including experience with database design, query optimization, and stored procedures.
 * Familiarity with AWS, Azure, or GCP data ecosystems and their key services.
 * Experience with Terraform or other infrastructure-as-code tools is a plus.
 * Must be willing and able to work in a hybrid office environment, with 4 days per week in office in the North America headquarters in the Dallas, Texas area
 * Must be willing and able to work in a hybrid office environment, with 4 days per week in office in the North America headquarters in the Dallas, Texas area






#LSGNS

LSG Sky Chefs is an EEO and Affirmative Action Employer of Women/Minorities/Veterans/Individuals with Disabilities.

",Full-time
4105081018,15901706.0,Data Engineer,"Weekly outpatient therapy isn't always enough, and a trip to the ER isn't the only answer. Patients and their families rely on Compass Health Center when in crisis – every day, we help people overcome depression, anxiety, suicidality, obsessions/compulsions, trauma, chronic pain, and other obstacles in order for our patients to live freely.

About This Role

We're seeking a talented Azure Data Architect to take the lead in designing, implementing, and managing our data architecture on the Azure platform. In this role, you'll leverage your expertise in data management, cloud computing, and data analytics to ensure seamless, secure data operations. If you're passionate about driving innovation and empowering data-driven decision-making, you would be a great addition to our team!

Our dedicated operations teams work behind the scenes to bring our shared mission to life. Each department delivers their own set of strengths which empower our clinicians to focus on their expertise, and ultimately perform the meaningful work that we do.


 * This is a Hybrid position with the expectation of 2 days on-site per week at our Northbrook, IL location*
   
   

What You'll Do:


 * Design and implement scalable data architectures on Azure.
 * Develop and maintain data models, data integration, and data warehousing solutions.
 * Collaborate with stakeholders to understand business requirements and translate them into technical solutions.
 * Lead the design and implementation of Microsoft Fabric-centric data platforms and data warehouses.
 * Ensure data security, privacy, and compliance with relevant regulations.
 * Optimize data storage and retrieval processes for performance and cost-efficiency.
 * Participate in the development of Database Architecture and Roadmaps in support of business strategies
 * Provide technical leadership and mentorship to the data engineering team.
 * Stay updated with the latest Azure technologies and best practices.
 * Strong proficiency in Excel, Power BI, SSIS, PowerShell scripting
 * Strong understanding of Azure and Microsoft M365
 * Experience with cloud and hybrid-cloud implementations including IaaS, PaaS, and SaaS. This includes leveraging the scalability and flexibility of cloud platforms to enhance the efficiency and effectiveness of data solutions.
   
   

Who You Are:


 * Bachelor’s or Master’s degree in Computer Science, Information Technology, or a related field.
 * Proven experience as a Data Architect, preferably with Azure.
 * 7+ years of experience working on solutions that collect, process, store, and analyze large volumes of business-critical data.
 * Strong knowledge of Azure data services (e.g., Azure SQL Database, Azure Data Lake, Azure Synapse Analytics).
 * Experience with data modeling, ETL processes, and data warehousing.
 * Proficiency in SQL, Python, or other relevant programming languages.
 * Excellent problem-solving skills and attention to detail.
 * Strong communication and collaboration skills.
 * Azure certifications preferred (e.g., Azure Data Engineer, Azure Solutions Architect)
 * Experience with big data technologies preferred (e.g., Hadoop, Spark).
   
   

We are committed to a fair and equitable work environment. The expected compensation range for this role is below. This range includes multiple career path levels across the organization; where you fall in the range is dependent upon a number of factors including, but not limited to, your years of experience, type of experience, location, and education/certifications. Compass reserves the right to update these ranges.

Compensation

$90,000—$120,000 USD

We know job descriptions can be intimidating, so if this sounds like an opportunity for you, please don't hesitate to apply!

Who We Are

Compass Health Center is a recognized leader in crisis-level mental health, bringing passion, connection, and patient-centered care to the Partial Hospitalization and Intensive Outpatient space (PHP/IOP). Based in Chicagoland, we serve hundreds of patients every day, ranging from ages 5 through adulthood, in our onsite facilities or through our flourishing virtual programming. Compass fills a critical gap between outpatient and inpatient care through an intermediate level of Behavioral Healthcare.

A few more things we want you to know: our values are super important to us, and hopefully will be to you, too. Cultural humility, teamwork, continuous improvement, connection, patient centered care, passion, innovation, and agility should be your power sources. Joining Compass is an opportunity to feel fulfilled through a joint mission towards healing our communities.

Benefits & Perks

We know that you will be dedicated to your purpose here. We look at that investment as a two-way street. We are proud to offer plenty of space for growth, and opportunities to pursue continuous development within our organization.

For eligible positions, our other benefits include: comprehensive medical/dental/vision plans, 401k program with company matching, generous PTO (including competitive parental leave after 1 year of employment), and continuous training through CEU seminars and volunteering opportunities.

What’s Next?

Compass is committed to cultivating diverse and dynamic teams who exude passion for their craft, so whether or not you check all the boxes, we encourage you to apply – we’d be grateful to hear from you!",Full-time
4119047235,102017555.0,Data Engineer,"Data Engineer (3 Openings)

Onsite :: Charlotte or Atlanta—Charlotte is the first choice

Client :: IBM/ Truist Bank

Job Description ::

Kafka Cluster Management

Deploying, configuring, and maintaining Kafka clusters on OpenShift, including topic creation, partition management, and scaling operations.

Data Pipeline Design

Architecting and implementing data pipelines using Kafka streams, connectors, and other related technologies to process and route data in real-time.

IDDR Implementation

Applying data ingestion, transformation, and distribution techniques to ensure data quality and reliability within the Kafka pipelines.

OpenShift Integration

Leveraging OpenShift features like deployments, services, and monitoring to manage Kafka applications within the containerized environment.",Full-time
4125060554,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4046336836,11070.0,Data Engineer,"Why Ryan?


 * Hybrid Work Options
 * Award-Winning Culture
 * Generous Personal Time Off (PTO) Benefits
 * 14-Weeks of 100% Paid Leave for New Parents (Adoption Included)
 * Monthly Gym Membership Reimbursement OR Gym Equipment Reimbursement
 * Benefits Eligibility Effective Day One
 * 401K with Employer Match
 * Tuition Reimbursement After One Year of Service
 * Fertility Assistance Program
 * Four-Week Company-Paid Sabbatical Eligibility After Five Years of Service
   
   
   

The Data Engineer, Data Engineering is responsible for the identifying, developing, and maintaining the technologies that enable the efficient flow of data throughout the organization. This role requires an enterprise mindset to build out robust, high-performance technology.

Duties And Responsibilities, Aligned With Key Results

People


 * Use a variety of programming languages and tools to develop, test, and maintain data pipelines within the Platform Reference Architecture.
 * Working directly with management, product teams and practice personnel to understand their platform data requirements
 * Maintaining a positive work atmosphere by behaving and communicating in a manner that encourages productive interactions with customers, co-workers and supervisors
 * Developing and engaging with team members by creating a motivating work environment that recognizes, holds team members accountable, and rewards strong performance
 * Fostering an innovative, inclusive and diverse team environment, promoting positive team culture, encouraging collaboration and self-organization while delivering high quality solutions
   
   
   

Client


 * Collaborating on an Agile team to design, develop, test, implement and support highly scalable data solutions
 * Collaborating with product teams and clients to deliver robust cloud-based data solutions that drive tax decisions and provide powerful experiences
 * Analyzing user feedback and activity and iterate to improve the services and user experience
   
   
   

Value


 * Securing data in alignment with internal information and data security policies, best practices and client requirements
 * Creating and implementing robust cloud-based data solutions that scale effectively, and provide powerful experiences for both internal teams and clients
 * Performing unit tests and conducting reviews with other team members to make sure solutions and code are rigorously designed, elegantly coded and effectively tuned for performance
 * Staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities and mentoring other members of the engineering community
 * Perform other duties as assigned
   
   
   

Education And Experience


 * Bachelor’s and/or master’s degree in a related field
 * 3+ years of experience developing data technologies.
 * 3+ years of experience deploying ETL solutions in production environments.
 * 3+ years of experience with cloud-based data services, preferably in AWS or Azure.
 * 3+ years of experience developing Python, Scala, Java, .Net or similar solutions in a backend or data wrangling capacity.
 * 3+ years of experience in mixed Windows/Linux environments.
   
   
   

Additional Required Skills And Experience


 * Results-proven track record of exceeding goals and evidence of the ability to consistently make good decisions through a combination of analysis, experience and judgment
 * Fluency in one or more databases, preferably relational and NoSQL is a plus.
 * Experience with distributed data platforms is a plus.
 * Exposure to AI/ML pipelines is preferred.
 * Experience deploying, monitoring, and maintaining data pipelines in production environments
 * Commitment to diversity, accountability, transparency, and ethics.
   
   
   

Computer Skills

To perform this job successfully, an individual must have intermediate knowledge of Microsoft Project, Word, Excel, Access, PowerPoint, Outlook, and Internet navigation and research.

Supervisory Responsibilities


 * None
   
   
   

Work Environment


 * Standard indoor working environment.
 * Occasional long periods of sitting while working at computer.
 * Must be able to lift, carry, push or pull up to 30 lbs.
 * Position requires regular interaction with employees at all levels of the Firm and interface with external vendors as necessary.
 * Independent travel requirement: As Needed
   
   
   

Equal Opportunity Employer: disability/veteran",Full-time
4130843721,7556.0,Data Engineer III,"Position Summary...

What you'll do...

You have a deep interest and passion for technology. You have a passion to drive critical business initiatives with Data. You love writing and owning codes and enjoy working with people who will keep challenging you at every stage. You have strong problem solving, analytic, decision- making and excellent communication with interpersonal skills. You are self-driven and motivated with the desire to work in a fast- paced, results-driven agile environment with varied responsibilities.

About Team

Sam's Club is our membership warehouse club, a business model that provides our members with high-quality products at prices that are unrivaled by traditional retail. Sam's Club provides a carefully curated assortment of items, as well as developing and leading technologies and services such as Scan & Go, Club Pickup, and home delivery service in select markets. Sam's Club also provides travel, auto purchasing, pharmacy, optical, hearing aid centers, tire and battery centers, and a portfolio of business operations support services.

“Immigration sponsorship is not available in this role.”

What You'll Do


 * Design, build, test and deploy cutting edge solutions at scale, impacting millions of customers worldwide drive value from data
 * Interact with Sams Club engineering teams across geographies to leverage expertise and contribute to the tech community.
 * Engage with Product Management and Business to drive the agenda, set your priorities and deliver awesome product features
   
   

to keep platform ahead of market scenarios.


 * Identify right open source tools to deliver product features by performing research, POC/Pilot and/or interacting with various
   
   

open source forums


 * Develop and/or Contribute to add features that enable adoption of data across Sams Club
 * Deploy and monitor products on Cloud platforms
 * Develop and implement best-in-class monitoring processes to enable data applications meet SLAs
 * Guide the team technically for end to end solution Lifecycle.
   
   

What you'll bring:


 * 2 - 3 years of Big data development experience
 * 1 - 2 Years of Experience in GCP/Azure cloud platforms
 * Demonstrates up-to-date expertise in Data Engineering, complex data pipeline development
 * Architect, Design, develop, implement and tune distributed data processing pipelines that process large volume of data;
   
   

focusing on scalability, low -latency, and fault-tolerance in every system built.


 * Exposure to Data Governance ( Data Quality, Metadata Management, Security, etc.)
 * Experience with Java, Scala and/or Python to write data pipelines and data processing layers
 * Demonstrates expertise in writing complex, highly-optimized queries across large data sets
 * Proven working expertise with Big Data Technologies Spark Scala/PySpark, and SQL
 * Knowledge and experience in Kafka, Spark Streaming, Druid and Presto.
   
   

About Sam's Club

Sam Walton opened the first Sam's Club in 1983 to meet a growing need among customers who wanted to buy merchandise in bulk. Since then, Sam's Club has grown rapidly, opening more than 600 clubs in the U.S. and 100 clubs internationally. By offering affordable, wholesale merchandise to members, Sam's Club helps make saving simple for families and small business owners. Sam's Club employs about 110,000 associates in the U.S. The average club is 134,000 square feet and offers bulk groceries and general merchandise. Most clubs also have specialty services, such as a pharmacy, an optical department, a photo center, or a tire and battery center.

Flexible, Hybrid Work

We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.

Benefits

Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.

Equal Opportunity Employer

Walmart, Inc. is an Equal Opportunity Employer – By Choice. We believe we are best equipped to help our associates, customers and the

communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions – while being inclusive of all people.

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

At Sam's Club, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet!

‎


 * Health benefits include medical, vision and dental coverage
   
   

‎


 * Financial benefits include 401(k), stock purchase and company-paid life insurance
   
   

‎


 * Paid time off benefits include PTO, parental leave, family care leave, bereavement, jury duty, and voting. You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.
   
   

‎

For information about PTO, see https://one.walmart.com/notices.

‎


 * Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.
   
   

‎

Live Better U is a company paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For Information About Benefits And Eligibility, See One.Walmart.

‎

The annual salary range for this position is $117,000.00-$234,000.00

‎

Additional Compensation Includes Annual Or Quarterly Performance Bonuses.

‎

‎

‎

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelor’s degree in Computer Science and 2 years' experience in software engineering or related field. Option 2: 4 years’ experience in

software engineering or related field. Option 3: Master's degree in Computer Science.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, Master’s degree in Computer Science or related field and 2 years' experience in software engineering or related field, We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

640 W California Avenue, Sunnyvale, CA 94086-4828, United States of America",Full-time
4127592723,164711.0,Data Engineer II,"Job Description

We are Lennar

Lennar is one of the nation's leading homebuilders, dedicated to making an impact and creating an extraordinary experience for their Homeowners, Communities, and Associates by building quality homes and providing exceptional customer service, giving back to the communities in which we work and live in, and fostering a culture of opportunity and growth for our Associates throughout their career. Lennar has been recognized as a Fortune 500® company and consistently ranked among the top homebuilders in the United States.

Join a Company that Empowers you to Build your Future

The primary mission of the Data Engineer II role is to help our business evolve into a data and insights-driven organization. This position sits in our Enterprise Data and Analytics team, which aims to drive improved business outcomes using insights gleaned from data and analytics, infusing them into Lennar’s corporate fabric.

The Data Engineer II will be involved in technical planning & solutions implementation as part of our data platform engineering team. This is done by helping implement our next generation data and analytics platforms and products using Data engineering best practices. This position will also help mentor more junior associates, such as recent college graduates and early career teammates. The Data Engineer II is a key role in operationalizing Lennar’s enterprise data fabric.



 * A career with purpose.
 * A career built on making dreams come true.
 * A career built on building zero defect homes, cost management, and adherence to schedules.
   
   
   

Your Responsibilities On The Team



 * Build and operationalize data engineering solutions for Lennar’s data and analytics platforms and products.
 * Be part of the operational support excellence rotation team, available to provide insight and troubleshoot during support calls.
 * Implement ETL, ELT and streaming data ingestion data delivery processes across multiple sources.
 * Experience in data modeling, cloud data lake, cloud data warehouse
 * Instrument data analytics platforms with robust metrics and monitoring.
 * Improve data ingestion architecture, emphasizing data quality, maintainability, and extensibility.
 * Support process improvement on the team to enable rapid development of data products.
 * Implement standards and best practices for data analytics team, including code modularization, versioning, testing, automation of CI/CD workflows, code reviews etc.
 * Gain an understanding of core business processes and align data development with business strategy.
 * Wrangle and integrate data from disparate systems to allow data analysts and data scientists to leverage end-to-end data and information.
   
   
   

Requirements

Technical Requirements



 * At least 4+, prefers 5+ years in:
    * Data Architecture design
    * Data modeling & Data warehousing concepts
    * Data transformations and standardizations
    * ETL processes & strategies
    * Monitoring and error handling
    * SDLC & workflow best practices
       * Code Reviews
       * QA/Testing methodologies
         
         

 * At least 2+, prefers 3+ years with the following technologies and platforms:
    * AWS platform: S3, EC2, EMR, EKS, Glue, Lambda, AppFlow, Cloudwatch etc.
    * AWS certification is big plus
    * Snowflake Data Cloud
       * Account Administration
       * Virtual warehouse strategies
       * Snowflake feature implementation: Data Sharing, Time Travel, and Zero-copy cloning
       * Role-based Access Control strategies
   
    * Dbt
       * Managing dbt cloud environment
       * Managing multi-repository dbt projects
       * Creating and managing dbt models
       * Creating and leveraging dbt macros
   
    * Version control & branching strategies (Github a plus)
    * Proficient in languages: SQL, Python
    * Data governance, security, and compliance concepts
    * Data Ingestion
       * Incremental and CDC ingestion methods
       * REST APIs
         
         

 * Familiarity (At least 1+ years of experience) with:
    * Orchestration & scheduling tools (Prefect, Airflow is a plus)
    * Qlik Replicate
      
      
      

Other Requirements



 * Willingness and availability to be:
    * On-site at a Lennar designated office location up to 5 days a week.
    * Part of on-call support calls, which could happen during off hours and weekends.

 * Ability to work collaboratively and productively with other team members to achieve Lennar’s objectives.
 * Thirst to help transform Lennar into an insights-driven organization.
 * Demonstrated some experience in all aspects of development including, but not limited to, gathering requirements, development of technical components related to process scope and supporting testing and post implementation support.
 * Ability to work and partner with users and stakeholders to gather solution requirements.
 * Experience working with business users to understand how to optimally deliver insights within their operational workflows & decision-making processes.
 * Ability and willingness to quickly learn new technologies.
 * Ability and willingness to learn about the business, its strategy, objectives, and core business processes.
   
   

Additional Requirements:



 * Travel up to 10% of the time to Divisions within the Lennar family.
 * Interact well with co-workers.
 * Cross train for position(s) within the team organizational structure from time to time, as required by the Leadership Team.
 * Comply with and implement company policies and procedures.
 * Accept constructive criticism.
 * Strong work ethic.
 * Team player.
   
   
   

This description outlines the basic responsibilities and requirements for the position noted. This is not a comprehensive listing of all job duties of the Associates. Duties, responsibilities and activities may change at any time with or without notice.

Physical & Office/Site Presence Requirements:

This is primarily a sedentary office position which requires he position to have the ability to operate computer equipment. Finger dexterity is necessary.

Life at Lennar

At Lennar, we are committed to fostering a supportive and enriching environment for our Associates, offering a comprehensive array of benefits designed to enhance their well-being and professional growth. Our Associates have access to robust health insurance plans, including Medical, Dental, and Vision coverage, ensuring their health needs are well taken care of. Our 401(k) Retirement Plan, complete with a $1 for $1 Company Match up to 5%, helps secure their financial future, while Paid Parental Leave and an Associate Assistance Plan provide essential support during life's critical moments. To further support our Associates, we provide an Education Assistance Program and up to $30,000 in Adoption Assistance, underscoring our commitment to their diverse needs and aspirations. From the moment of hire, they can enjoy up to three weeks of vacation annually, alongside generous Holiday, Sick Leave, and Personal Day policies. Additionally, we offer a New Hire Referral Bonus Program, significant Home Purchase Discounts, and unique opportunities such as the Everyone’s Included Day. At Lennar, we believe in investing in our Associates, empowering them to thrive both personally and professionally. Lennar Associates will have access to these benefits as outlined by Lennar’s policies and applicable plan terms. Visit Lennartotalrewards.com to view our suite of benefits.

Join the fun and follow us on social media to see what's happening at our company, and don't forget to connect with us on Lennar: Overview | LinkedInhttps://www.linkedin.com/company/lennar/> for the latest job opportunities.

Lennar is an equal opportunity employer and complies with all applicable federal, state, and local fair employment practices laws.

",Full-time
4118836224,165158.0,"Software Engineer L4/L5 - Data and Feature Infrastructure, Machine Learning Platform","Netflix is one of the world's leading entertainment services, with 283 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.

Machine Learning/Artificial Intelligence powers innovation in all areas of the business, from helping members choose the right title for them through personalization, to better understanding our audience and our content slate, to optimizing our payment processing and other revenue-focused initiatives. Building highly scalable and differentiated ML infrastructure is key to accelerating this innovation.

ML models can only be as good as the data we provide them. That's why we continue to innovate on making data and feature engineering as simple, scalable, and efficient as possible. Are you interested in joining us on this mission? You will have the opportunity to build cutting-edge data and feature infrastructure that will power ML models across various domains, including personalized recommendations, payments, games, ads, and more.

The Opportunity

In this role, you will have the opportunity to build a next-generation ML data and feature platform to significantly improve the productivity of ML practitioners. Our goal is to enable our ML practitioners to easily define and test ML features and labels, while our platform takes care of the computation, storage, and serving of feature values for both high-throughput training and low-latency member-scale inference use cases.

You will also have the opportunity to build a centralized feature and embedding store to enable sharing across various ML domains. Unlocking access to these shared datasets will foster innovation through ML in new business areas that otherwise wouldn’t have been feasible. You will collaborate closely with ML practitioners and domain experts to ensure that our models are built with high-quality features and labels. You will also get to work with the broader Machine Learning Platform organization to deliver a cohesive end-user experience that significantly improves the productivity of ML practitioners.

Here are some examples of the types of things you would work on:


 * Design and build a near-real-time feature computation engine to generate ML features for both high-throughput training and low-latency inference applications.
 * Operate and manage the feature computation pipelines and feature serving infrastructure for various ML models across multiple ML domains.
 * Build and scale systems that accelerate training through performant data loading, transformation, and writing.
 * Create frameworks to streamline and expedite the availability of new data for training and serving.
 * Develop feature stores that enable feature discovery and sharing.
 * Increase the productivity of ML practitioners by making it easy to define and access features and labels for experimentation and productization.
   
   

Minimum Qualifications


 * Experience in building ML or data infrastructure
 * Strong empathy and passion for providing a fantastic user experience to ML practitioners
 * Experience in building and operating 24/7 high-traffic and low-latency online applications
 * Experience with large-scale data processing frameworks such as Spark, Flink, and Kafka
 * Experience in working with and optimizing Scala and/or Python codebases
 * Experience with public clouds, especially AWS
 * Self-driven and highly motivated team player
   
   

Preferred Qualifications


 * Experience in building and operating ML feature stores
 * Experience with Functional Programming
 * Experience working with Notebooks such as Jupyter or Polynote
   
   

Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $100,000 - $720,000.

Netflix provides comprehensive benefits, including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, a Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and serious injury benefits. We also offer paid leave of absence programs. Full-time salaried employees are immediately entitled to flexible time off. See more details about our Benefits here.

Netflix has a unique culture and environment. Learn more here.

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.",Full-time
4111225263,1469436.0,Data Engineer,"Omitron is seeking a highly experienced and motivated Senior Data Engineering Specialist in Melbourne, FL, to join our growing team. The ideal candidate will have extensive experience in designing, building, and optimizing scalable data pipelines, as well as managing and deploying data infrastructure in cloud environments. You will work closely with our data science, analytics, and DevOps teams to ensure seamless data flow and integration across our systems, and you will mentor junior team members to elevate the overall technical capability of the team.

Responsibilities:


 * Lead the design, development, and maintenance of complex, scalable data pipelines.
 * Optimize and troubleshoot data pipelines for performance, reliability, and scalability.
 * Collaborate with engineers and analysts to understand data requirements and deliver high-quality data solutions.
 * Implement and manage ETL processes using advanced tools like Apache Airflow, Spark, or similar.
 * Ensure data quality and consistency through rigorous testing, validation, and governance practices.
 * Deploy, monitor, and maintain data infrastructure in cloud environments (AWS, GCP, Azure).
 * Implement DevOps practices to streamline data workflows, including CI/CD pipelines, Docker, and Kubernetes.
 * Mentor and provide guidance to junior data engineers, fostering a culture of continuous improvement and collaboration.
 * Stay up-to-date with industry trends and emerging technologies to drive innovation within the data engineering team.
   
   

Minimum Requirements:


 * US Citizenship required
 * Security Clearance: must have a current/active TS/SCI and be willing and able to pass a CI polygraph
 * Education: Bachelor's degree in Computer Science, Engineering, or a related field or 4+ years relevant experience in lieu of a degree
 * Experience: minimum 7+ years in data engineering or related roles
    * Advanced proficiency in SQL and experience with relational databases (e.g., PostgreSQL, MySQL).
    * Extensive experience with big data technologies (e.g., Hadoop, Spark).
    * Deep understanding of cloud platforms (AWS, GCP, Azure) and their data services.
    * Strong understanding and practical experience with DevOps practices and tools (CI/CD, Docker, Kubernetes).
    * Proven ability to optimize and troubleshoot complex data systems and pipelines.
    * Excellent problem-solving skills and attention to detail.
    * Strong communication and leadership abilities, with experience mentoring junior engineers.
      

Desired Qualifications:


 * Experience with NoSQL databases (e.g., MongoDB).
 * Proficiency in programming languages such as Python, Java, or Kotlin.
 * Experience with data visualization tools (e.g., Tableau, Power BI).
 * Strong understanding of data governance and security practices.
 * Experience working in Agile/Scrum environments.
   
   

Company Overview:

Omitron is an Aerospace Engineering and Information Technology small business firm headquartered in Beltsville, Maryland with a field office located in Colorado Springs, Colorado. Since 1984, Omitron has provided excellence in engineering services and product development to government and industry customers for both civilian and military aerospace programs.

Omitron recognizes that outstanding people are the key to our success. Our goal is to select highly qualified and motivated individuals and provide them with an environment necessary to stimulate and nurture engineering and business objectives. Omitron offers its employees competitive salaries, a full benefits package, and excellent career growth opportunities. We welcome talented professionals who wish to take advantage of the opportunities we offer.

Benefits:


 * Health, Dental and Vision Insurance
 * HSA or FSA accounts
 * Company paid ST/LT Disability and AD&D insurance
 * Paid Federal Holidays
 * Paid Vacation Leave and Sick Leave
 * Parental Leave
 * 401k with company match
 * Supplemental Insurance options like AFLAC
 * Professional Development Reimbursement
 * Voluntary Life Insurance
   
   

Omitron is an equal-opportunity employer committed to creating an inclusive environment for all our employees. We strongly encourage women, persons of color, persons with disabilities, and veterans to apply. E-Verify Participation.",Full-time
4125067664,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4125058810,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4129678250,164518.0,Data Engineer I,"If you are an internal associate, please login to Workday and apply through Jobs Hub.

Job Purpose

The Data Engineer I will be responsible for building and supporting the data platform. The Data Engineer will provide the development and automation of computing processes to detect, and respond to opportunities in business operations. The Data Engineer will work with a variety of disparate datasets that encompass many disciplines and business units. They will strive to transform and implement true business integration, leveraging top-notch data integration best practices. Merging and securing data in a way that reduces the cost to maintain and increases the utilization of enterprise-wide data as an asset and developing business intelligence.

Essential Responsibilities


 * Engineers and implements solutions that align to architecture patterns and security guidelines for data, compute and technology platforms, meeting business needs.
 * Works in partnership with business product owners, and DevSecOps to engineer and build mature scalable and robust business capabilities.
 * Follows IT architecture and IT operations guidelines and requirements while implementing optimal engineering solutions for the company.
 * Participates in engineering and planning initiatives related to capabilities, future roadmaps, operations, and strategic planning.
 * Engineers and implements business and technology innovation that drives the organization's top and bottom lines.
 * Stays current with industry trends, making recommendations of new technologies that deliver strategic business value and reduce costs.
 * Engineers and implements architecture solutions that maximize reuse and are efficient, maintainable, scalable, stable, highly available, portable, secure, and implemented correctly.
 * Strong communication competency across all levels of stakeholders, providing engineering guidance and insight into best practices.
 * Follows organizational policies and goals for IT security, change management, and operational risk.
 * Synthesizes information into clear and concise materials with thoughtful attention to detail and quality.
 * Provides engineering consulting services within domain to help achieve desired business and operational outcomes across Jackson.
 * Engineers and implements the service management processes for maintaining the technology platforms in production.
 * Acquires and maintains a working knowledge of Jackson processes and procedures across various departments.
 * Assists in researching, planning, and executing the migration of on-prem data infrastructure to Azure, including evaluating tradeoffs between cost, performance, and maintainability.
 * Develops and maintains data pipelines for complex business use cases.
 * Develops, designs, and builds solutions on a platform dedicated to large-scale processing of various data sets.
 * Collaborates with IT architecture and IT operations to identify and implement the most optimal data engineering solutions for the company.
 * Collaborates with team to execute and iterate on application development, including interfacing with
 * legacy databases, parsing raw structured and unstructured data, documenting the data warehouse, debugging, and deploying to production environments.
 * Collaborates with other teams to clarify and answer complex business questions using statistical and graphical approaches.
 * Employs exceptional problem-solving skills, with the ability to see and solve issues before applications are moved to production systems.
 * Sets, communicates, and reinforces technical standards.
 * Leads and develops best practices for larger Data Engineer Community of Practice (Data CoP).
 * Stays current with industry trends, makes recommendations of new technologies that deliver strategic business value and reduce costs.
 * Performs other duties and/or projects as assigned.
   
   

Knowledge, Skills And Abilities


 * Knowledge of industry standards, emerging technologies; and security and system best practices.
 * Excellent verbal and written communication skills including presentation creation and delivery.
 * Experience with the Microsoft Cloud ecosystem.
 * Strong organizational skills; ability to independently prioritize tasks and projects to meet deadlines.
 * Strong collaboration skills with the ability to build consensus, influencing across all levels in the organization.
 * Ability to learn and maintain a comprehensive understanding of finance/insurance business and technology.
 * Knowledge of Lean and Agile principles, systems, and tools.
 * Ability to explain and communicate technical concepts clearly.
 * Ability to conduct gap analysis and identify possible solutions for continuous improvements.
 * Basic programming skills in Python, R, Powershell and or Java with experience parsing, manipulating, and converting data to and from a wide range of formats (CSV, json, XML, html, SQL tables, etc.).
 * Good understanding of modern database concepts and SQL syntax, including experience with DB2, MongoDB, SQL Server, CosmosDB, Data Lake, Hadoop, etc.
 * Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
 * Strong analytic skills related to working with unstructured datasets.
 * Build processes supporting data transformation, data structures, metadata, dependency and workload management.
   
   

Qualifications


 * Bachelor's Degree in Computer Science/Computer Engineering and/or equivalent experience required.
 * 2+ years related IT experience required.
 * 1+ years in Data Engineering required.
 * Software development or related position experience preferred.
 * 1+ years SQL, relational database experience and unstructured datasets required.
 * 1+ years experience Azure Databricks, Azure Data Factory, Python, C# (preferred) Java, SDLC, Terraform, Spark, Config Management and Monitoring required.
 * 1+ years experience using Agile methodologies, data streaming, data as a service (REST APIs), CI/CD pipelines, Parquet, JSON preferred.
 * 1+ years experience working with Jupyter notebooks, microservices and data modeling preferred.
 * 1+ years IT infrastructure/operations role preferred.
 * Certification in Azure Fundamentals & Data Engineer upon hire preferred.
   
   

We don't just accept difference - we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Jackson is proud to be an equal opportunity workplace. The Company subscribes to and endorses federal and state laws and regulations relating to equal employment opportunity for all persons without regard to race, color, religion, gender, age, national origin, legally-recognized disability, marital status, legally-protected medical condition, citizenship, ancestry, height, weight, sexual orientation, veteran status, or any other factor not related to the needs of the job. The Company is committed to a policy of equal opportunity. Company facilities and campuses are tobacco-free environments.",Full-time
4122914153,66321745.0,Junior Data Engineer,"Are you passionate about coding or technology and ready to make your mark in tech? For more than 14 years, SynergisticIT has been helping aspiring developers like you excel in the tech industry. We focus on equipping you with the skills and experience needed to not only secure a job but to thrive in your career!

Why Partner with SynergisticIT?


 * Customized inputs to achieve the desired output : designed with industry needs in mind, ensuring you're equipped with the most sought-after skills.
 * Exclusive Opportunities: Our extensive network allows you to connect with leading tech firms.
 * Outstanding Outcomes: Many of our candidates land multiple job offers, often with starting salaries of $100k or more!
   
   

Synergisticit Pics /Salaries of Successful Candidates

Synergisticit at Oracle Cloudworld 2023

Synergisticit at Gartner Data & Analytics summit

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

Who Should Apply? We're looking for recent grads in Mathematics, Statistics , Computer Science or Engineering or candidates with gaps in their career or people wanting to switch careers into tech. SynergisticIT is committed to supporting your journey!

Preferred SKILLS For Java /Full Stack/Devops Positions

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Knowledge of Core Java , javascript , C++ or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

For data Science/Data Analyst/AI/Machine learning Positions

Preferred SKILLS

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude

Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools

Candidates lacking technical skills or relevant experience can research our Job Placement Programs which can assist in landing a Job

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates

Embrace Your Future! We also assist with F1 OPT to transition into H1B and Green Card byproviding comprehensive support. All positions are open to candidates of all visa types and US citizens.

Are you ready to make an impact?",Contract
4145711967,2829078.0,Data Engineer (Remote),"Description

Data Engineer, Data Services

Company Overview

Over the next ten years, there will be at least 4.6 million hospitalizations from the misuse of prescription drugs in people 65 or older, resulting in $528 billion in annual avoidable costs. RxAnte is on a mission to improve people’s health by helping them get more from medicines. A rapidly growing, tech-enabled healthcare services company with over 30 million lives under management, RxAnte has become a leading provider of value-based pharmacy care management solutions for health plans.

RxAnte launched Mosaic Pharmacy Service in 2019, a wholly owned subsidiary designed to offer pharmacy and chronic care management services for our clients’ most medically complex and vulnerable members. Using data, advanced analytics, specialized software and pharmacy automation, Mosaic is transforming the pharmacy experience for medically complex seniors while also helping payers achieve their quality improvement and cost savings objectives.

Job Profile

The Data Engineer of Data Services reports directly to the VP, Data Services and is responsible for taking part in the managing, designing, and building of systems required to deliver Mosaic and RxAnte's analytic products in a scalable manner using cloud data warehouse/lake technology. Strong analytic, communication, and AWS cloud experience is required. The Data Engineer will have data architectural and system engineering skills. In addition to taking part in the design and development of the systems, the Data Engineer will contribute to overall future cloud data warehouse/lake vision. The Data Engineer will be responsible for helping to assess and gather project requirements and assess work effort. Additionally, the role will interact with both technical and non-technical internal stakeholders. We are seeking someone who loves to set the vision in a new environment as a trailblazer, educate internal team members, and then work within the environment to apply best practices. This is a remote work position.

Specific Responsibilities Include


 * Work with Data Services leadership to architect, develop, and maintain processes and programs
 * Establish and maintain project-deliverable processes with an eye toward full scalability and automation
 * Support and establish cloud data environment design and development
 * Engineer within the AWS cloud data environment using Glue, EMR Serverless, Databricks, Snowflake, or similar technologies
 * Collaborate with internal IT team to establish best practices
 * Collaborate with product, analytical, business intelligence, and data teams to establish best practices utilizing the cloud data environment
 * Gather business requirements and work on system design frameworks documentation using Atlassian tools
 * A strong desire to be able to lead projects, set vision of data governance, establish CI/CD pipelines, and contribute to ongoing development
 * Ability to successful manage individual projects through the entire project lifecycle
 * Other activities as needed
   
   

Requirements


 * 5+ years of relevant/related experience in similar role
 * Experience with SQL and/or NoSQL databases including coding and system design
 * Experience with clouds (ideally AWS)
 * Experience with Java, Spark, and/or Python
 * Experience with ETL/ELT tool set
 * Experience with CI/CD pipeline
 * Experience designing, constructing, and using data databases/lakes for product delivery
 * Experience working with administrative health care data (e.g., commercial medical, hospital, and pharmacy claims, and Medicare or Medicaid data), healthcare informatics, or health care claims processing a plus
 * Experience with SAS programming a plus
 * Strong communication, analytical, and data quality skills
 * Ability to document and work through requirements gathering
 * Experience working in an environment which utilizes project management tools such as Atlassian
 * Willingness to travel as needed
   
   

We strongly encourage candidates from all backgrounds and every walk of life to apply. We are committed to creating an inclusive and diverse workforce. Every person on our team brings their own unique perspective, and it’s what makes our products better and our work more rewarding.",Full-time
4092101330,66321745.0,Junior Level Data Engineer,"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you need

Position open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, IT enthusiasts, Python/Java developers, Data analysts/ Data Scientists.

We welcome candidates with all visas and citizens to apply.

Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates looking to make their careers in IT Industry

Candidates who are serious about their future in the IT Industry and have set big goals for themselves.

Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience which our clients need with great outcomes

Candidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancement

Candidates Who Lack Experience

Have had a break in careers

Lack Technical Competency

Different visa candidates who want to get employed and settle down in the USA

Please Also Check The Below Links

https://www.synergisticit.com/candidate-outcomes/

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://www.youtube.com/playlist?list=PLJgkOBQ51j5AHT5I6n29glr0q6trzkxYD

https://synergisticit.wistia.com/medias/k6t6a1n4kb

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

If not a match candidates can opt for Skill enhancement.

REQUIRED SKILLS For Java/Software Programmers


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Core Java , javascript , C&plus;&plus; or software programming
 * Spring boot, Microservices and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, Python, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, Time series analysis

Please understand skills are required by clients for selection even if its Junior or entry level position the additional skills are the only way a candidate can be picked by clients.

No third party candidates or c2c candidates

Please understand skills are required by clients for selection even if its Junior or entry level position the additional skills are the only way a candidate can be picked by clients.

Please apply to the posting

No phone calls please. Shortlisted candidates would be reached out",Full-time
4149218666,856702.0,Data Engineer,"Our client helps businesses streamline and automate document-heavy processes by transforming unstructured information into usable data. Their platform simplifies operations, improves efficiency, and supports smarter decision-making, providing companies with a competitive advantage. They are looking for a Data Engineer who will collaborate with a dynamic group of data scientists and developers to design, build, and optimize AI and machine learning models tailored to customer requirements. This is a hybrid position based in Fairfield County, CT.




Data Engineer’s Responsibilities and Duties

 * Build AI models based on customer requirements.
 * Maintain and optimize machine learning (ML) and natural language processing (NLP) modules.
 * Develop and enhance ML Ops pipelines for efficient model deployment.
 * Design data extraction prompts for large language models (LLMs).




Data Engineer’s Qualifications and Skills

 * Bachelor’s or Master’s degree in Computer Science, Mathematics, or a related field.
 * At least 5 years of experience in data science, ML, or AI.
 * Proficient in Python, Jupyter Notebook, and VS Code.
 * Experience with cloud computing platforms like GCP Vertex AI is a plus.
 * Familiarity with LLMs such as Google Gemini 1.5 or OpenAI GPT-4 is a bonus.




RightClick is an equal opportunity employer who agrees not to discriminate against any employee or job applicant irrespective of race, color, creed, alienage, religion, sex, national origin, age, disability, gender (including gender identity), marital status, sexual orientation, citizenship or any other characteristic protected by law.",Full-time
4124947687,2815.0,Jr. Data Engineer,"Job Description

The Data Science team within Aramark Sports + Entertainment is the epicenter of business intelligence, uncovering impactful insights that put Aramark clients in the sports and entertainment industry ahead of the curve. Using leading-edge technology and analytics, Data Science synthesizes operational and consumer data to optimize strategies that enhance the guest hospitality experience and blaze a trail for innovation. Through continuous expansion of analytical capabilities and a comprehensive method of understanding the industry at large, Data Science harnesses the power of data as the most strategic asset in maximizing value for consumers, operators, and businesses alike.

Job Responsibilities


 * Design, maintain, monitor, analyze, and enhance ETL processes independently
 * Configure and maintain databases and processes, including monitoring of system health and performance
 * Utilize their experience in database administration to identify performance issues and carry out performance tuning
 * Support data acquisition efforts through development of data pipelines
 * Review, refine, and automate existing and/or new processes with supporting documentation
 * Ensure data quality through development of monitoring and/or automated test scripts. Track and solve data quality issues with appropriate parties
 * Provide recommendations for architecture changes, standard maintenance routines, and provide details for creating redundancies in the database environment.
 * Work with various industry leading data warehouse components (databases in Snowflake, Oracle, SQL), ETL tools like Snaplogic, BI/reporting tools like Qliksense, PowerBI)
 * Work on project teams to develop new data products
 * Share technical expertise, provide technical mentorship and cross-training to other peers and team members
   
   

Qualifications


 * 1-3 years of related data engineering experience
 * Bachelor?s Degree in Computer Science, Engineering, Information Systems, Mathematics, or a related field or equivalent experience required
 * Working SQL knowledge including query development required
 * Experience working in a cloud environment (Snowflake, AWS) required
 * Experience with JSON based data sources required
 * Experience in monitoring, troubleshooting, and maintaining relational databases
 * Proficiency in warehousing architecture techniques, including ODS and EDW
 * Experience with automating workflows using advanced analytical languages (e.g. R, python)
 * Familiarity with database migration tools like AWS DMS is a plus
 * Experience reading and transforming unstructured data sources a plus
 * Experience with writing transform scripts to move data into a new data model
 * Excellent communication skills, both written and verbal
 * Excellent critical thinking skills to problem-solve and troubleshoot issues
 * Demonstrated ability to work well independently and as a member of a team
 * Eager to learn and develop oneself within Aramark Data Community
   
   

Education

About Aramark

Our Mission

Rooted in service and united by our purpose, we strive to do great things for each other, our partners, our communities, and our planet.

At Aramark, we believe that every employee should enjoy equal employment opportunity and be free to participate in all aspects of the company. We do not discriminate on the basis of race, color, religion, national origin, age, sex, gender, pregnancy, disability, sexual orientation, gender identity, genetic information, military status, protected veteran status or other characteristics protected by applicable law.

About Aramark

The people of Aramark proudly serve millions of guests every day through food and facilities in 15 countries around the world. Rooted in service and united by our purpose, we strive to do great things for each other, our partners, our communities, and our planet. We believe a career should develop your talents, fuel your passions, and empower your professional growth. So, no matter what you're pursuing - a new challenge, a sense of belonging, or just a great place to work - our focus is helping you reach your full potential. Learn more about working here at http://www.aramarkcareers.com or connect with us on Facebook, Instagram and Twitter.",Full-time
4139736588,101021.0,Data Engineer,"Location: Remote, with a preference for those in the District of Columbia, Maryland, and Virginia

Clearance Required: Secret

People Centered. Data Driven

Elder Research Inc. is a Data Science consulting firm specialized in providing analytic solutions to clients in Commercial and Government industries. Providing analytic solutions to hundreds of companies across numerous industries, our team enjoys a great variety in the type of work they do and exposure to a wide range of techniques and tools

We are trusted advisors to our clients, building lasting relationships and partnering as preferred analytics providers. We use a variety of programming languages and tools to create analytic solutions, often fitting within our clients’ environment and needs.

Join our team and find great opportunities to hone your analytic skills, work on complex problems with amazing teammates, and gain valuable analytics consulting experience.

Summary Of Position

As a Data Engineer, you will design and build data pipeline systems for collecting, storing and analyzing data to ensure it is usable for data scientists and analysts, while utilizing software best practices, data optimizations (including storage, indexing, and normalization), anomaly detection, and machine learning principles.

Essential Functions


 * Define and execute data management techniques and products that promote effective creation of data science, enterprise analytics, and AI products.
 * Implement auditable controls that prohibit users from updating, deleting, accessing, viewing, or otherwise manipulating data that is outside their explicit control.
 * Demonstrate the ability to work with and handle information assets characterized by a high volume, velocity, variety, and/or veracity that require technology that employs massively parallel processing to deliver insights into the data.
 * Provide data model support for user-defined data structures, schemas, and data ingest capabilities.
 * Research and define master data management techniques to centrally manage lookup tables, business glossaries, and data profile information.
 * Develop and automate data transfer of authoritative data sources and trusted aggregators to data platforms like Advana, Power BI or other platforms.
 * Develop Secure API mechanisms for users to develop machine to machine interfaces to retrieve data for external application use.
   
   

Job Specifications/Requirements


 * Bachelor of Science degree in Computer Science or closely related IT field.
 * 3+ years of experience
 * Experience working with Python
 * AWS Experience
 * JavaScript familiarity
 * Willingness to learn
   
   

Desired Skills


 * Experience with Advana is a plus
 * Experience with CDAO is a plus
 * Familiarity with the mission space and Office of the Undersecretary of Defense for Personnel and Readiness (O is a plus)
   
   

About Elder Research, Inc

Elder Research is a fast growing consulting firm specializing in predictive analytics. Being in the data mining business almost 30 years, we pride ourselves in our ability to find creative, cutting edge solutions to real-world problems. We work hard to provide the best value to our clients and allow each person to contribute their ideas and put their skills to use immediately.

Our team members are passionate, curious, life-long learners. We value humility, servant-leadership, teamwork, and integrity. We seek to serve our clients and our teammates to the best of our abilities. In keeping with our entrepreneurial spirit, we want candidates who are self-motivated with an innate curiosity and strong team work.

Elder Research believes in continuous learning and community - each week the entire company attends a “Tech Talk” and each office location provides lunch. Elder Research provides a supportive work environment with established parental, bereavement, and PTO policies. By prioritizing a healthy work-life balance - with reasonable hours, solid pay, low travel, and extremely flexible time off - Elder Research enables and encourages its employees to serve others and enjoy their lives.

Elder Research, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

Elder Research is a Government contractor and many of our positions require US Citizenship.",Full-time
4048812851,93246786.0,Data Engineer,"Hybrid

Data Engineer

12+ Months


 * Strong expertise in data modeling, ETL/ELT processes, and data warehousing concepts.
 * Hands-on experience with programming languages (Python, Java, or Scala) and SQL.
 * Strong understanding of data governance, metadata management, data quality controls, data lineage and data security.
 * Proficiency in cloud data platforms such as AWS, Azure, or Google Cloud Platform.",Contract
4099386336,100690228.0,Data Engineer,"Sr Data Engineer

Experience: 7 - 25 Years

Location: USA - Glendale

Must-Have


 * Airflow
 * Apache Spark
 * Snowflake OR Databricks
 * Data Modeling
   
   

Location: Glendale, CA – Onsite 3-4 days a week

The Company

Headquartered in Los Angeles, this leader in the Entertainment & Media space is focused on delivering world-class stories and experiences to it's global audience. To offer the best entertainment experiences, their technology teams focus on continued innovation and utilization of cutting edge technology.

Platform / Stack

You will work with technologies that include Python, AWS, Snowflake, Databricks, and Airflow.

Qualifications

You could be a great fit if you have:


 * 7+ years of data engineering experience developing large data pipelines
 * Proficiency in at least one major programming language (e.g. Python, Java, Scala)
 * Hands-on production environment experience with distributed processing systems such as Spark
 * Hands-on production experience with data pipeline orchestration systems such as Airflow for creating and maintaining data pipelines
 * Experience with at least one major Massively Parallel Processing (MPP) or cloud database technology (Snowflake, Databricks, Big Query).
 * Experience in developing APIs with GraphQL
 * Advance understanding of OLTP vs OLAP environments
 * Graph Database experience a plus
 * Realtime Event Streaming experience a plus
   
   

What You'll Do As a Sr Data Engineer


 * Contribute to maintaining, updating, and expanding existing Core Data platform data pipelines
 * Build and maintain APIs to expose data to downstream applications
 * Develop real-time streaming data pipelines
 * Tech stack includes Airflow, Spark, Databricks, Delta Lake, and Snowflake
 * Collaborate with product managers, architects, and other engineers to drive the success of the Core Data platform
 * Contribute to developing and documenting both internal and external standards and best practices for pipeline configurations, naming conventions, and more
 * Ensure high operational efficiency and quality of the Core Data platform datasets to ensure our solutions meet SLAs and project reliability and accuracy to all our stakeholders (Engineering, Data Science, Operations, and Analytics teams)
   
   

Skills: delta lake,core data,database,graphql,aws,snowflake,technology,apache spark,pipelines,spark,databricks,python,airflow,data engineering,data modeling,data",Contract
4085437538,22688.0,"Data Engineer Intern, 2025 Summer U.S.","Overview

Working at Atlassian

Atlassians can choose where they work – whether in an office, from home, or a combination of the two. That way, Atlassians have more control over supporting their family, personal goals, and other priorities. We can hire people in any country where we have a legal entity. Interviews and onboarding are conducted virtually, a part of being a distributed-first company.

Join Atlassian as an intern and spend your summer with us having an impact on how millions of users collaborate and use software. We're in the business of developing software to help teams everywhere get amazing ideas on the ground and into the world. Sound like an exciting place to start your career? Here you'll be encouraged to use your imagination and try new things. You'll be guided (as we are) by our core values, and you'll be supported by some of the best minds in tech. Apply for our Summer 2025 Intern Program and start an awesome career!

Our paid internship program runs for 12 weeks between May/June - August/September 2025. Not eligible for Visa sponsorship. Unfortunately, we do not offer U.S. work visa sponsorship to F-1/OPT/CPT, J-1/TN, or H-1B student graduates at this time. Please note: At this time, this role is only open to entry level candidates with less than a year of professional experience (this does not include internships/co-ops).

Responsibilities

Your future team

As an intern in our world-class Data Engineering team, you'll influence product teams, inform Dat Science and Analytics Platform teams, and partner with data consumers and products to ensure qualify and usefulness of data assets. You will help strategize measurement, collecting data, and generating insights.

This work will help understand and improve product experience and engagement, improve efficiency and costs, and guide strategy. You'll report to a Data Engineering Manager, and learn from your team mentor who are some of the best Data Engineers in the business.

What You'll Do

Data Engineering is a multi-faceted role, where you can have focused or broad set of responsibilities, including:


 * Define metrics
 * Instrument logging
 * Acquire/ingest data
 * Architect & modeling data
 * Transform data
 * Ensure data quality, governance, and enablement
 * Alerting, visualization, and reporting
 * Develop at scale and improving efficiency
   
   
   

Qualifications

Your background


 * Experience programming with Python, or other related object-oriented programming languages
 * Have an interest in software engineering demonstrated by previous internships, work experience, projects, or publications
 * Knowledge of data structures, in particular how they are implemented and how to apply them to meet data challenges
 * Huge Plus: An understanding of the SaaS business model and data structures or experience in Enterprise Software product development
 * Proficiency in SQL and relational databases experience
 * Demonstrated interest in the Data Engineering field through academic coursework, previous work or internship experience, or personal projects
 * Able to commit to a 12 week full-time (40hrs/week) program during Summer 2025
 * Currently enrolled full-time in a 4-year bachelor's degree program and returning to the program after the completion of the internship, graduating by June 2026
   
   
   

Compensation

At Atlassian, we strive to design equitable and explainable compensation programs. To support this goal, the baseline of our range is higher than that of the typical market range, but in turn we expect to hire most candidates near this baseline. Base pay within the range is ultimately determined by a candidate's skills, expertise, or experience.

Role

In the United States, we have three geographic pay zones. For this role, our current base pay ranges for new hires in each zone are:

Zone A: $56/hr - $64/hr

Zone B: $51/hr - $58/hr

Zone C: $47/hr - $54/hr

Please visit go.atlassian.com/payzones for more information on which locations are included in each of our geographic pay zones. However, please confirm the zone for your specific location with your recruiter.

Our Perks & Benefits

Atlassian offers a variety of perks and benefits to support you, your family and to help you engage with your local community. Our offerings include health coverage, paid volunteer days, wellness resources, and so much more. Visit go.atlassian.com/perksandbenefits to learn more.

About Atlassian

At Atlassian, we're motivated by a common goal: to unleash the potential of every team. Our software products help teams all over the planet and our solutions are designed for all types of work. Team collaboration through our tools makes what may be impossible alone, possible together.

We believe that the unique contributions of all Atlassians create our success. To ensure that our products and culture continue to incorporate everyone's perspectives and experience, we never discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. All your information will be kept confidential according to EEO guidelines.

To provide you the best experience, we can support with accommodations or adjustments at any stage of the recruitment process. Simply inform our Recruitment team during your conversation with them.

To learn more about our culture and hiring process, visit go.atlassian.com/crh .

",Full-time
4109240840,66321745.0,Junior Data Engineer,"2024 is almost over and we hope the Job market improves . Almost 600,000 tech employees have been laid off since 2022 and it's still ongoing. The effect of this has led hundreds of thousands of laid off Tech employees competing with existing Jobseekers.

Entry level Job seekers struggle to get responses to their applications, are getting ghosted after interviews. In such a scenario the Job seekers need to differentiate themselves by ensuring to obtain exceptional skills and technologies so that they can wear multiple roles at a client as clients now would want to expand roles and responsibilities assigned to a particular job to save costs.

Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.

All Positions are open for all visas and US citizens

We are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this challenging economy every client wants to save $$$ 's and they want the best value for their money. Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs as Clients now post covid can also hire remote workers which increases even more competition for jobseekers

.We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few

.We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients

.Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry

.We assist in filing for STEM extension and also for H1b and Green card filing to Candidate

sPlease Check The Below Link

shttps://www.synergisticit.com/candidate-outcomes

/https://synergisticit.wistia.com/medias/o5gmv7i9e

uhttps://www.youtube.com/playlist?list=PLJgkOBQ51j5AHT5I6n29glr0q6trzkxY

Dhttps://synergisticit.wistia.com/medias/k6t6a1n4k

bWhy do Tech Companies not Hire recent Computer Science Graduates | SynergisticI

TTechnical Skills or Experience? | Which one is important to get a Job? | SynergisticI

TFor preparing for interviews please visit https://www.synergisticit.com/interview-questions

/We are looking for the right matching candidates for our client

sPlease apply via the job postin

gREQUIRED SKILLS For Java /Full Stack/Software Programme


 * r Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, I
 * T Highly motivated, self-learner, and technically inquisitiv
 * e Experience in programming language Java and understanding of the software development life cycl
 * e Project work on the skill
 * s Knowledge of Core Java , javascript , C++ or software programmin
 * g Spring boot, Microservices, Docker, Jenkins and REST API's experienc
 * e Excellent written and verbal communication skill
   
   

sFor data Science/Machine learning Position

sRequired Skill


 * s Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, I
 * T Project work on the technologies neede
 * d Highly motivated, self-learner, and technically inquisitiv
 * e Experience in programming language Java and understanding of the software development life cycl
 * e Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tool
 * s Excellent written and verbal communication skill
   
   

sPreferred skills: NLP, Text mining, Tableau, PowerBI, SAS, Tensorflo

wIf you get emails from our skill enhancement team please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements

.No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Contract
4150342086,1337.0,Senior Software Engineer,"

LinkedIn is the world’s largest professional network, built to create economic opportunity for every member of the global workforce. Our products help people make powerful connections, discover exciting opportunities, build necessary skills, and gain valuable insights every day. We’re also committed to providing transformational opportunities for our own employees by investing in their growth. We aspire to create a culture that’s built on trust, care, inclusion, and fun – where everyone can succeed.

Join us to transform the way the world works.

Job Description

This role will be based in Mountain View, CA.

At LinkedIn, our approach to flexible work is centered on trust and optimized for culture, connection, clarity, and the evolving needs of our business. The work location of this role is hybrid, meaning it will be performed both from home and from a LinkedIn office on select days, as determined by the business needs of the team.

LinkedIn's engineers wear multiple hats as software engineers, data/research scientists and ML engineers. Unlike other companies that separate these roles, our engineers work on projects from ideation to implementation. Join us in building and enhancing LinkedIn’s economic graph powering core value for LinkedIn.

Responsibilities:
-You will scale distributed applications, make architectural trade-offs applying synchronous and asynchronous design patterns, write code, and deliver with speediness and quality.
-You will develop multi-tier scalable, high-volume performing, and reliable user-centric
applications that operate 24x7.
-Work with BIG data, crunching millions of samples for statistical modeling, data mining,
recommendation solutions
-Write production quality code and influence the next generation of LinkedIn’s system
-Build scalable AI innovations with foundation and infra partners and enhance LinkedIn’s
Economic Graph
-You will produce high quality software that is unit tested, code reviewed, and checked in
regularly for continuous integration.
-You will provide technical leadership, driving and performing best engineering practices to
initiate, plan, and execute large-scale, cross functional, and company-wide critical programs. ----Identify, leverage, and successfully evangelize opportunities to improve engineering productivity.

Basic Qualifications:
-BA/BS in Computer Science or related technical field or equivalent practical experience
2+ years of industry experience in software design, development, and algorithm related
solutions.
-2+ years programming experience in languages such as Java, Python, Javascript, C/C++, C#,
Objective-C, Ruby, etc.
-2+ years experience with machine learning, data mining, and information retrieval or natural l
language processing

Preferred Qualifications:
-BS and 5+ years of relevant work experience, MS and 4+ years of relevant work experience, or
PhD and 2+ years of relevant work experience.
-Working knowledge in one or more of the following: machine learning, data mining, information
retrieval, security data science, advanced statistics or natural language processing.
-Experience in designing and building infrastructure and web services at large scale.
-Experience with large data processing, Hadoop, Pig, or other MapReduce paradigms.
-Expert knowledge of computer science, with strong competencies in data structures, graphs,
algorithms, and software design.
-Proven coding skills in Python or JavaScript/AJAX, database design and SQL, and/or
knowledge of TCP/IP and network programming.
-Experience building web applications and services with IDEs, ant, junit, etc.

Suggested Skills:
-Advanced Programming Skills
-Experience in Machine Learning and Deep Learning
-Experience in Big Data
-Strong technical background & Strategic thinking
-API Development
-Performance Optimization and Scalability
-Collaboration

You will Benefit from our Culture
We strongly believe in the well-being of our employees and their families. That is why we offer generous health and wellness programs and time away for employees of all levels.

LinkedIn is committed to fair and equitable compensation practices. The pay range for this role is $121,000 - $198,000. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to skill set, depth of experience, certifications, and specific work location. This may be different in other locations due to differences in the cost of labor.

The total compensation package for this position may also include annual performance bonus, stock, benefits and/or other applicable incentive compensation plans. For more information, visit https://careers.linkedin.com/benefits.


Equal Opportunity Statement
LinkedIn is committed to diversity in its workforce and is proud to be an equal opportunity employer. LinkedIn considers qualified applicants without regard to race, color, religion, creed, gender, national origin, age, disability, veteran status, marital status, pregnancy, sex, gender expression or identity, sexual orientation, citizenship, or any other legally protected class. LinkedIn is an Affirmative Action and Equal Opportunity Employer as described in our equal opportunity statement here: https://microsoft.sharepoint.com/:b:/t/LinkedInGCI/EeE8sk7CTIdFmEp9ONzFOTEBM62TPrWLMHs4J1C_QxVTbg?e=5hfhpE. Please reference https://www.eeoc.gov/sites/default/files/2023-06/22-088_EEOC_KnowYourRights6.12ScreenRdr.pdf and https://www.dol.gov/ofccp/regs/compliance/posters/pdf/OFCCP_EEO_Supplement_Final_JRF_QA_508c.pdf for more information.

LinkedIn is committed to offering an inclusive and accessible experience for all job seekers, including individuals with disabilities. Our goal is to foster an inclusive and accessible workplace where everyone has the opportunity to be successful.

If you need a reasonable accommodation to search for a job opening, apply for a position, or participate in the interview process, connect with us at accommodations@linkedin.com and describe the specific accommodation requested for a disability-related limitation.

Reasonable accommodations are modifications or adjustments to the application or hiring process that would enable you to fully participate in that process. Examples of reasonable accommodations include but are not limited to:

-Documents in alternate formats or read aloud to you
-Having interviews in an accessible location
-Being accompanied by a service dog
-Having a sign language interpreter present for the interview

A request for an accommodation will be responded to within three business days. However, non-disability related requests, such as following up on an application, will not receive a response.

LinkedIn will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by LinkedIn, or (c) consistent with LinkedIn's legal duty to furnish information.

Pay Transparency Policy Statement
As a federal contractor, LinkedIn follows the Pay Transparency and non-discrimination provisions described at this link: https://lnkd.in/paytransparency.

Global Data Privacy Notice for Job Candidates
This document provides transparency around the way in which LinkedIn handles personal data of employees and job applicants: https://lnkd.in/GlobalDataPrivacyNotice",Full-time
4135299641,89936203.0,Data Engineer (Summer 2025 Intern),"About Meetsta: Meetsta is a dynamic and innovative social networking platform. Our mission is to provide a tailored and engaging space where individuals can connect, collaborate, and build meaningful relationships.

Position Overview: We are looking for a Data Engineer Intern who possesses a passion for pushing mobile technologies to the limits and will work with our team of talented engineers to design and build the next generation of our mobile applications.

Responsibilities


 * Design and build advanced applications for the iOS platform
 * Collaborate with cross-functional teams to define, design, and ship new features.
 * Unit-test code for robustness, including edge cases, usability, and general reliability.
 * Work on bug fixing and improving application performance.
 * Continuously discover, evaluate, and implement new technologies to maximize development efficiency.
   
   

Requirements


 * Must be enrolled in a BS/MS/PhD program in Computer Science, Engineering, or a related subject at an accredited college.
 * Experience in Data Engineering and expertise in the development of mobile technologies. Familiarity with relevant frameworks and languages.
 * Startup Interest: Strong work ethic and conviction to work in a demanding startup environment.
 * Experience with third-party libraries and APIs
 * Working knowledge of the general mobile landscape, architectures, trends, and emerging technologies
 * Solid understanding of the full mobile development life cycle
   
   

Compensation

$15-$20 / hr depending on location, previous work experience and qualifications.

Minimum Hours

30-40 hours/week.

Important Notes


 * We are only considering US citizens and Permanent Residents for the role.
 * This is a temporary position between June and August.",Full-time
4120829089,10667.0,"Data Engineer, Product Analytics","As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a world-class data engineering community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Data Engineer, Product Analytics Responsibilities:


 * Manage and execute data warehouse plans for a product or a group of products to solve well-scoped problems
 * Identify the data needed for a business problem and implement logging required to ensure availability of data, while working with data infrastructure to triage issues and resolve
 * Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights in a meaningful way
 * Build data expertise and leverage data controls to ensure privacy, security, compliance, data quality, and operations for allocated areas of ownership
 * Design, build and launch new data models and visualizations in production, leveraging common development toolkits
 * Independently design, build and launch new data extraction, transformation and loading processes in production, mentoring others around efficient queries
 * Support existing processes running in production and implement optimized solutions with limited guidance
 * Define and manage Service Level Agreements for data sets in allocated areas of ownership
   
   

Minimum Qualifications:


 * Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent
 * 2+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions
 * 2+ years of experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala or others.)
   
   

Preferred Qualifications:


 * Master's or Ph.D degree in a STEM field
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$114,000/year to $171,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4137001696,40655225.0,Data Engineer,"Omega Holdings is a private equity-owned leading distributor of air conditioning and other high demand aftermarket components to a broad range of light-duty and heavy-duty vehicle end markets. Omega has created a unique, market leading platform in the automotive aftermarket with numerous opportunities to apply its repeatable playbook to grow both organically and through acquisition.




We are hiring a Data Engineer to support our corporate Information Technology department which works in partnership with our portfolio companies.




With our product portfolio, dedication to quality, entrepreneurial setting, and competitive strength, we are a great place to build a lasting career.




Position Summary:

Reporting to the VP of IT, the Data Engineer will play a major role in running daily IT operations and working on new projects. This position is onsite and located within the corporate office in Irving, TX. This individual will work with various teams and divisions across the US & Canada to support aggressive growth and IT targets.




Desired Professional Skills and Experience:

 * Bachelor’s degree in computer science or software engineering.
 * At least one year of experience.
 * Relational database experience is required.
 * Reporting experience is required (Jet, Power BI or Tableau).
 * ETL experience and programming skills in at least one of the following languages: Java or Python.
 * This individual should be from a development background in data engineering.
 * Experience working with onsite and offshore teams.
 * Ability to work under minimal supervision, relying on experience, research, and judgment to plan and accomplish assigned goals.
 * Understanding of data archival strategy.
 * Strong complex problem solving and troubleshooting skills.
 * Ability to learn quickly and manage time effectively.
 * Proven written and oral communication skills.




Responsibilities:

 * Able to work on complex data intensive projects.
 * Good understating of Python, Spark best practices and commonly used modules based on work experience and creating self-contained, reusable, and testable modules and components.
 * Responsible for prototyping, developing, and troubleshooting software in the user interface or service layers.
 * Participate in collaborative technical discussions that focus on software user experience, design, architecture, and development.
 * Keep up to date with technology and apply new knowledge.
 * Manage Github PRs and act as release manager for some of the Data Engineering projects.
 * Experience with technical project documentation.
 * Work with onsite/offshore teams and help the team in clearing blockers.
 * Ability to follow established coding standards.




Education and Experience Requirements:

 * Bachelor’s degree in Computer Science or related field.
 * At least one year of hands-on experience.

",Full-time
4146189911,99080702.0,Data Engineer,"Data Engineer, TIFIN AG

Charlotte, NC or Boulder, CO




WHO WE ARE:




TIFIN is a fintech platform backed by industry leaders including JP Morgan, Morningstar, Broadridge, Hamilton Lane, Franklin Templeton, SEI, Motive Partners and a who’s who of the financial service industry. We are creating engaging wealth experiences to better financial lives through AI and investment intelligence powered personalization. We are working to change the world of wealth in ways that personalization has changed the world of movies, music and more but with the added responsibility of delivering better wealth outcomes.




We use design and behavioral thinking to enable engaging experiences through software and application programming interfaces (APIs). We use investment science and intelligence to build algorithmic engines inside the software and APIs to enable better investor outcomes.




In a world where every individual is unique, we match them to financial advice and investments with a recognition of their distinct needs and goals across our investment marketplace and our advice and planning divisions.




OUR VALUES: Go with your GUT




 * Grow at the Edge. We are driven by personal growth. We get out of our comfort zone and keep egos aside to find our genius zones. With self-awareness and integrity we strive to be the best we can possibly be. No excuses.
 * Understanding through Listening and Speaking the Truth. We value transparency. We communicate with radical candor, authenticity and precision to create a shared understanding. We challenge, but once a decision is made, commit fully.
 * I Win for Teamwin. We believe in staying within our genius zones to succeed and we take full ownership of our work. We inspire each other with our energy and attitude. We fly in formation to win together.




ABOUT TIFIN AG:




TIFIN AG is a predictive AI platform that helps wealth management enterprises answer specific data questions to drive net new assets. TIFIN AG is powered by a proprietary algo ensemble, unifying wealth data sources, and delivering growth through actionable feedback loops. It helps firms combine data through integrations with leading CRM and WealthTech providers, organize and enrich firm data against 3rd party data providers, and then engage clients and prospects using modern marketing distribution capabilities. As a result, TIFIN AG delivers better intelligence to help advisors with more precise client acquisition, retention, and expansion.




WHAT YOU'LL BE DOING:




We are looking for an experienced Data Engineer to join our team as we scale our data infrastructure and automation capabilities to serve our clients in the wealth management industry. Your focus will be helping design and implement scalable ETL pipelines, improving our data quality monitoring systems, and creating tools that help streamline our client data integration process. As a Data Engineer, you will report to TIFIN AG's Director of Backend Engineering.




The ideal candidate will take ownership of critical data infrastructure projects. This is an opportunity to work with cutting-edge technologies while having an incredible amount of impact pushing our business forward.




THE ROLE:




 * Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources
 * Design and build ETL pipelines to dynamically process data.
 * Integrate our products with other APIs and data sources.
 * Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
 * Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader
 * Keep our data separated and secure across national boundaries through multiple data centers and AWS regions
 * Help drive best practices around data quality, monitoring, and alerting.
 * Able to optimize our ETL processes balancing different concerns - human effort, technical complexity and cost.




WHO YOU ARE:




 * 3-5 years of software engineering / data engineering experience
 * Experience designing and building ETL pipelines using tools like AWS Glue, Lambda, Redshift, Airflow/Dagster, Snowflake, DBT/SQLMesh, etc.
 * Strong coding skills in Python
 * Expertise in various data engineering technologies, both open source and cloud native, AWS preferred (Kinesis, Athena, Spark/Glue, Airflow/Dagster)
 * Ability to work comprehensively with a variety of databases (Postgres, DynamoDB, DuckDB, etc.)




COMPENSATION AND BENEFITS PACKAGE:




The expected starting salary range for this position is between $120,000 - $140,000. Applicable salary ranges may differ across markets. Actual pay will be determined based on experience and other job-related factors permitted by law. The position is also eligible for incentive compensation.




TIFIN offers a competitive benefits package that includes:




 * Medical, dental, vision, life and disability insurance
 * Flexible Spending Account (FSA) and Health Savings Account (HSA)
 * 401(k) Retirement Plan
 * Flexible PTO policy and Company-paid holidays
 * Parental Leave: 12 week paid maternity, 6 week paid paternity leave
 * Corporate Social Responsibility and volunteering opportunities
 * Access to our Chief Mindfulness Officer for Mindfulness events and 1:1 personal coaching
 * Company sponsored events like mindfulness events, development workshops, team dinners, pickleball games, happy hours, holiday parties and more!
 * The ability to make a real impact in an incredibly fast-growing organization




A note on location. While we have team centers in New York City, San Francisco, Charlotte, Mumbai, Bangalore and Madrid, TIFIN is headquartered in Boulder, CO and our preference is to build the team here whenever possible, so relocation packages are available for any candidate willing to relocate to the Boulder area.




TIFIN is proud to be an equal opportunity workplace and values the multitude of talents and perspectives that a diverse workforce brings. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status.",Full-time
4013205397,93246786.0,Data Engineer,"Skill

Experience

Last used

3+ years of experience programming in SQL, Python and relevant packages like Pandas, and with Apache Spark

Proven experience in designing and maintaining robust data pipelines that are performant on big data sets

Experience writing clean code that utilizes object-oriented paradigms when appropriate

A strong foundation in data modeling, architecture and data warehousing

Experience working in a CI/CD environment and deploying pipelines

Hands-on experience with a cloud platform, preferably Azure (Azure SQL, Synapse, Databricks, etc.)

Experience building visualizations in Power BI

Communication skills to translate data asks into technical specs for a pipeline and visualization

An understanding of data security best practices and how to implement them

Passion for staying updated on emerging technologies in data engineering

Contributing to a culture of continuous improvement and innovation within the team

A bachelor’s degree in Computer Science, Engineering, Statistics, or equivalent professional experience

Experience in agile development methodologies and version control systems (e.g., Git) is a plus

Experience working with NoSQL databases

An ability to work with cross-functional, inter-agency teams

Experience working on small teams in fast-paced environments",Contract
4125062348,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4120825489,10667.0,"Data Engineer, Product Analytics","As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a world-class data engineering community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Data Engineer, Product Analytics Responsibilities:


 * Manage and execute data warehouse plans for a product or a group of products to solve well-scoped problems
 * Identify the data needed for a business problem and implement logging required to ensure availability of data, while working with data infrastructure to triage issues and resolve
 * Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights in a meaningful way
 * Build data expertise and leverage data controls to ensure privacy, security, compliance, data quality, and operations for allocated areas of ownership
 * Design, build and launch new data models and visualizations in production, leveraging common development toolkits
 * Independently design, build and launch new data extraction, transformation and loading processes in production, mentoring others around efficient queries
 * Support existing processes running in production and implement optimized solutions with limited guidance
 * Define and manage Service Level Agreements for data sets in allocated areas of ownership
   
   

Minimum Qualifications:


 * Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent
 * 2+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions
 * 2+ years of experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala or others.)
   
   

Preferred Qualifications:


 * Master's or Ph.D degree in a STEM field
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$114,000/year to $171,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4079998263,2833966.0,Data Engineer,"Location: Charlotte, NC

Main Skills: Data Engineer, Data Transformation, Data Workflows, Data Pipelines

Job Description

This role will lead designing, developing, and maintaining data pipelines ensuring efficient and secure data transmission and optimizing data workflows in a cloud environment. The key responsibilities include designing, implementing, documenting, and maintaining data architectures, data transmission processes along with associated data quality measures. In addition, they will develop ETL processes to extract data from various sources and transform data to meet business needs working with tech-to-tech data providers, internal governance partners, and a vendor cloud solution.

Requirements Include


 * Strong background in cloud data solutions, data transmission protocols and ETL processes
 * Strong understanding of data transmission protocols (HTTP, FTP, SFTP) and security best practices
 * Proficient in Java
 * Experience with SQL and NoSQL databases
 * Familiarity with data warehousing concepts
 * Familiarity with machine learning concepts and data science workflows",Contract
4144495420,36232.0,Data Engineer,"Job Summary:

Our client is seeking a Data Engineer to join their team! This position is located in Orlando, Florida!




Duties:

 * Lead hands-on data engineering development across multiple projects, ensuring scalable and efficient data solutions
 * Design, develop, and optimize database schema, tables, and views to support business needs
 * Build and maintain data pipelines using technologies like Airflow, Python, and Snowflake
 * Develop automation solutions to streamline data ingestion, transformation, and processing workflows
 * Implement data validation and proactive monitoring to ensure data integrity and accuracy
 * Optimize performance tuning for databases, queries, and data processing workflows
 * Design and implement data visualizations to provide insights and support analytics initiatives
 * Manage containerized deployments using Docker and CI/CD pipelines with GitLab
 * Leverage AWS cloud services for scalable and cost-effective data infrastructure
 * Collaborate with data science and analytics teams to enhance existing data pipelines and support evolving business needs
 * Maintain and improve the data engineering codebase, ensuring best practices in software development and data management
 * Provide operational support for existing data pipelines, troubleshooting issues, and enhancing functionality




Desired Skills/Experience:

 * 3+ years of overall technical experience
 * Experience with ELT/ETL data pipeline development and maintenance
 * High Proficiency in SQL coding
 * Proven experience and expertise using Python, Docker, Snowflake and/or Postgres
 * Ability to showcase an understanding of one or more business domains
 * Prior experience gathering and refining data requirements and producing data design solutions
 * Experience leveraging job scheduling software like Apache Airflow
 * Experience with developing in a multi environment (Dev, QA, Prod, etc.) and DevOps procedures for code deployment/promotion
 * Experience using containerization technologies such as Docker or Kub
 * Knowledgeable on cloud architecture and product offerings, preferably AWS




Benefits:

 * Medical, Dental, & Vision Insurance Plans
 * 401K offered




$43.47 - $62.10 (est. hourly)",Contract
4045411332,66321745.0,Junior Data engineer,"SYNERGISTIC wants every candidate to know we are always here to support your efforts. Indeed engagement is a priority for all SYNERGISTICIT Employees. No matter what issue you are facing, either it's a job search or upskilling your It portfolio, assistance in cracking interviews or anything, you can always count on a member of SynergisticIT to be there for you.

We at Synergistic it understand the problem and that's why for the past 10 years we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, bankofamerica, visa, etc to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, IT enthusiasts, Python/Java developers, Data analysts/ Data Scientists.

Who Should Apply Recent IT Graduates looking to make their careers in IT Industry Candidates having basic knowledge or with one or two years of experience in JAVA, C&plus;&plus;, Core JAVA.

Candidates looking to upskill/enhance their IT skills.

Candidates who are serious about their future in the IT Industry and have set big goals for themselves.

Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio.

Required Skill

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT


 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Core Java
 * Excellent written and verbal communication skills
   
   

No third party candidates or c2c candidates

To apply for this position, please apply to the posting

No phone calls please . Shortlisted candidates would be reached out.

Regards,

Prakash G

Talent Acuisition Manager

Phone:(151)0989-4911

Email:Prakash@synergisticit.com

Website : https://[www.synergisticit.com]www.synergisticit.com

39141 Civic Centre Dr, Fremont, CA

94539, United States",Full-time
4123387824,15691.0,Data Engineer,"Our mission is to be a trusted workplace for team members to be their whole selves at work. A company that people love and positively impacts the lives of all whom we touch.




be your best self




At Interstate Batteries, you have the chance to be excellent at work and excellent at life. We know that professional success depends on personal wellbeing. That's why we want to enrich your life with the tools and services you need to succeed in every area of your life. Join us!




Purpose of Job:

As a Data Engineer, you will be responsible for the design, implementation, and management of our data and architecture. You will play a pivotal role in enabling data-driven decision-making by providing accessible, reliable, and scalable data solutions working within the Enterprise Data and Analytics team.




Job Components:

 * Design and implement robust, scalable data models and data storage solutions to support enterprise data needs
 * Develop and maintain ETL (Extract, Transform, Load) processes and data pipelines, ensuring high data quality and efficient data processing
 * Collaborate with data analysts, data engineers, business teams, and IT staff to identify and meet data requirements
 * Implement data governance and compliance standards, ensuring data security and privacy
 * Optimize data retrieval and develop dashboards and reports to facilitate data analysis and business intelligence
 * Monitor and troubleshoot data systems performance, proposing and implementing improvements and optimizations
 * Stay updated with emerging trends and technologies in data engineering and propose their adoption where beneficial




Qualifications & Requirements:

 * Bachelor’s Degree in Business Administration, Computer Science, Accounting or Finance, or equivalent work experience
 * 2-3 years of experience in a similar role
 * Strong Computer Science fundamentals in Algorithms and Data Structures
 * Strong experience in data modeling, data architecture, and Data Warehouses, such as Snowflake
 * Excellent verbal and written communication skills
 * Excellent organizational skills




Scope Data:

 * Work with other Technical resources including but not limited to Project Managers, Development Managers, QA, Tech Services, Business Analysts, the User Community, and others in requirements-gathering endeavors and problem-solving.
 * Judgment/Decision Making - Ability to think logically and practically before making decisions. Use of independent thought, originality, and reasoning. Ability to handle confidential information.




Work Environment:

 * Ability to sustain posture in a seated position for prolonged periods of time
 * Regularly required to use hands to grasp or handle, talk and hear, stand and walk
 * Specific vision abilities include close vision, depth perception, and ability to adjust focus
 * Ability to occasionally lift and/or move 20+ lbs.
 * May be exposed to battery warehouse conditions such as exposure to moving equipment, mechanical parts, fumes or airborne particles, and toxic or caustic chemicals
 * Prolonged use of personal computer & telephone




Note: We do not accept resumes from headhunters, placement agencies, or other suppliers that have not signed a formal agreement with us.




Interstate Batteries provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sex, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. Interstate Batteries complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including, but not limited to, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.




Interstate Batteries expressly prohibits unlawful discrimination on the basis of age, race, color, religion, creed, sex, gender (including pregnancy, childbirth, breastfeeding or related medical conditions), sexual orientation, medical condition, genetic information, national origin, ancestry, disability (mental and physical), marital status, military status, veteran status, citizenship or any other characteristic protected under applicable local, state or federal law.",Full-time
4119563821,15249661.0,Data Engineer,"Job Summary

The Data Engineer is responsible for SJSU’s Campus Data Warehousing/Business Intelligence. This position will play a key role in the research, design, architecture, creation, development, implementation and maintenance of Campus Data Warehouse. This includes identifying and pulling data from 500+ individual databases across SJSU and curating them into a single data source in order to facilitate data-driven decisions.

The Data Engineer should possess a breadth of knowledge, technical skills, and strategic thinking to build a Data Warehouse to answer important questions across a variety of functional areas and collaborate with business stakeholders and IT management to understand solution requirements and system design for delivering the data model, developing and implementing the solution to deliver the desired business outcomes. Assist in conducting technical reviews, creating definitions of business problems, including the preparation of business/technical requirements to support the mission of the university and administrative departments, provide systems and technical support of vendor and locally developed software, and work with the Data Warehouse Project Manager, SJSU IT Enterprise Solutions resources, external vendors, and IT team members. Duties and system assignments can be temporarily or permanently changed to meet the needs and goals of the department and university.

Key Responsibilities


 * Capture, maintain, and apply data and information in order to support key business processes.
 * Optimize how the organization uses data both internally and externally.
 * Evaluate data that recognizes trends, calling insights, and making recommendations to the executive leadership team to make recommendations to define business strategy.
 * Assist with the development of strategies and coordinates the implementation that support the Organization's development plans and that capture new opportunities.
 * Partner cohesively with the broader Insights leaders across campus concerning the alignment capabilities.
 * Oversee the implementation of analytic methodologies including segmentation, predictive modeling, advanced statistical methods, regression, experimental design, etc.
 * Oversee the sourcing and creation of partnerships with key analytical vendors who can provide specialized expertise to assist with solution development while leading the in-house effort and managing CO interface.
 * Oversee project plans, timelines, and vendor relationships to ensure releases are delivered with the highest quality, on-time and within budget.
 * Partner with University stakeholders and be responsible for data analytics, custodianship, and infrastructure to ensure alignment with departmental data and analytics requirements to avoid conflicting activities, and develop the most efficient data analytics insights across the departments.
 * Identify, interpret, analyze and address critical business issues, questions and to develop use cases.
 * Organize and create an environment that makes data and information accessible with appropriate channels of access controls.
 * Work with internal and external stakeholders to build a relationship of trust and play an advisory role in the use of data to improve performance and University-wide strategy formulation.
 * Develop and document clear understandable plans, roadmaps and communication for business users, technical staff and IT groups.
 * Follow IT policies and standards for maintaining consistency and standards across SJSU campus.
 * Be proactive in making recommendations and ensure users/departments have the most up-to-date technological solutions to perform their jobs and serve the university community effectively.
   
   

Knowledge, Skills & Abilities


 * Advanced skills in analytical and holistic problem-solving, project management, effective communication and coordination of internal and external resources
 * Ability to work effectively with faculty, staff, and senior administrators in areas other than technology to develop and implement appropriate uses of technology
 * Advanced technical knowledge in IT systems and emerging technology trends and issues
 * Ability to synthesize data from multiple sources to address complex business questions
 * Advanced knowledge with analytics tools, “big data” technologies, cloud computing environments, relational database
 * Advanced working knowledge in large ERP scale analytics, optimization, business intelligence, and statistics for IT organizations
 * Ability to identify key insights and built large-scale data products that enhance the customer experience and improve operations processes
 * Strong ability to provide guidance on emerging technologies to innovate and ensure the SJSU is well-positioned in delivering analytic solutions
 * Strong ability to deliver on high-impact analytics projects
 * Advanced working SQL knowledge and skills working with relational databases like Oracle, query authoring (SQL), as well as, working familiarity with a variety of databases
 * Expert knowledge in high level programming languages like: Python, SQL, Java, and JavaScript
 * Advanced knowledge in application architectures on public cloud platform such as Amazon Web Services (AWS), Google Cloud Platform (GCP) or IBM Cloud Pak
 * Advanced knowledge of enterprise data architecture, ETL integration, data warehousing techniques, analytics/end-user reporting tool sets
 * Advanced knowledge in Visualization tools like Google Data Studio, Tableau, Looker etc
 * Knowledge building and optimizing ‘big data’ data pipelines, architectures and data sets
 * Ability to build processes supporting data transformation, data structures, metadata, dependency and workload management
 * Advanced knowledge of Systems development life cycle methodologies (Agile and Waterfall) in order to develop effective systems
 * Advanced knowledge of application development, testing and deployment processes and tools
 * Knowledge performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
 * Strong analytic skills related to working with unstructured datasets
 * Knowledge with big data languages such as R, Python/PySpark and familiarity with cloud architecture
 * Advanced knowledge in data mining, forecasting, simulation, and/or predictive modeling
 * Advanced knowledge building BI environments with significant scale and scope
   
   

Required Qualifications


 * A bachelor’s degree, preferably in computer science or business, or equivalent training and applied experience
 * Five years of experience in business applications analysis, design, and programming for medium or large scale, multi-programmed computers
   
   

Preferred Qualifications


 * Master’s in Business Administration, Computer Science or equivalent degree
 * 3+ years’ experience developing, maintaining and collecting structured and unstructured data sets for analysis and reporting
 * 3+ years advanced analytics experience in support of business strategy
 * 3+ years working experience in implementing public cloud solutions
   
   

Compensation

Classification: Analyst/Programmer - Expert

CSU Salary Range: $7,371/month - $14,274/month

San José State University offers employees a comprehensive benefits package typically worth 30-35% of your base salary. For more information on programs available, please see the Employee Benefits Summary .

Application Procedure

Click Apply Now to complete the SJSU Online Employment Application and attach the following documents:


 * Resume
 * Letter of Interest
   
   

All applicants must apply within the specified application period: January 9, 2025 through January 22, 2025. This position is open until filled; however, applications received after screening has begun will be considered at the discretion of the university.

Contact Information

University Personnel

jobs@sjsu.edu

408-924-2252

CSU Vaccination Policy

The CSU strongly recommends that all individuals who access any in-person program or activity (on- or off-campus) operated or controlled by the University follow COVID-19 vaccine recommendations adopted by the U.S. Centers for Disease Control and Prevention (CDC) and the California Department of Public Health (CDPH) applicable to their age, medical condition, and other relevant indications and comply with other safety measures established by each campus. The system wide policy can be found at https://calstate.policystat.com/policy/9779821/latest/ and questions may be sent to jobs@sjsu.edu .

Additional Information

Satisfactory completion of a background check (including a criminal records check) is required for employment. SJSU will issue a contingent offer of employment to the selected candidate, which may be rescinded if the background check reveals disqualifying information, and/or it is discovered that the candidate knowingly withheld or falsified information. Failure to satisfactorily complete the background check may affect the continued employment of a current CSU employee who was offered the position on a contingent basis.

The standard background check includes: criminal check, employment and education verification. Depending on the position, a motor vehicle and/or credit check may be required. All background checks are conducted through the university's third party vendor, Accurate Background. Some positions may also require fingerprinting. SJSU will pay all costs associated with this procedure. Evidence of required degree(s) or certification(s) will be required at time of hire.

SJSU IS NOT A SPONSORING AGENCY FOR STAFF OR MANAGEMENT POSITIONS. (e.g. H1-B VISAS)

All San José State University employees are considered mandated reporters under the California Child Abuse and Neglect Reporting Act and are required to comply with the requirements set forth in CSU Executive Order 1083 as a condition of employment. Incumbent is also required to promptly report any knowledge of a possible Title IX related incident to the Title IX Office or report any discrimination, harassment, and/or retaliation to the Office of Equal Opportunity.

Jeanne Clery Disclosure of Campus Security Policy and Crime Statistics Act and Campus Housing Fire Safety Notification:

Pursuant to the Jeanne Clery Disclosure of Campus Security Policy and Campus Crime Statistics Act, the Annual Security Report (ASR) is also now available for viewing at https://www.sjsu.edu/clery/docs/SJSU-Annual-Security-Report.pdf. The ASR contains the current security and safety-related policy statements, emergency preparedness and evacuation information, crime prevention and Sexual Assault prevention information, and information about drug and alcohol prevention programming. The ASR also contains statistics of Clery crimes for San José State University locations for the three most recent calendar years. A paper copy of the ASR is available upon request by contacting the Office of the Clery Director by phone at 408-924-1501 or by email at clerycompliance@sjsu.edu .

Pursuant to the Higher Education Opportunity Act, the Annual Fire Safety Report (AFSR) is also available for viewing at https://www.sjsu.edu/clery/docs/SJSU-Annual-Fire-Safety-Report.pdf . The purpose of this report is to disclose statistics for fires that occurred within SJSU on-campus housing facilities for the three most recent calendar years, and to distribute fire safety policies and procedures intended to promote safety on Campus. A paper copy of the AFSR is available upon request by contacting the Housing Office by phone at 408-795-5600 or by email at uhs-frontdesk@sjsu.edu .

Campus Security Authority - In accordance with the Jeanne Clery Disclosure of Campus Security Policy and Campus Crime Statistics Act (Clery Act) and CSU systemwide policy, this position is subject to ongoing review for designation as a Campus Security Authority. Individuals that are designated as Campus Security Authorities are required to immediately report Clery incidents to the institution and complete Clery Act training as determined by the university Clery Director.

Equal Employment Statement

San José State University (SJSU) is an Equal Opportunity/Affirmative Action employer committed to nondiscrimination on the basis of age, ancestry, citizenship status, color, creed, disability, ethnicity, gender, genetic information, marital status, medical condition, national origin, race, religion or lack thereof, sex, sexual orientation, transgender, or protected veteran status consistent with applicable federal and state laws. This policy applies to all SJSU students, faculty and staff programs and activities. Title IX of the Education Amendments of 1972, and certain other federal and state laws, prohibit discrimination on the basis of sex in all education programs and activities operated by the university (both on and off campus).

",Full-time
3980082352,78445528.0,Data engineer,"Job Title: Senior Data Analyst

Location: Chicago, IL or Dallas, TX

Overview: Are you a seasoned Data Analyst with a robust background in Data Warehousing and Enterprise Data Management? Do you excel in both technical and functional aspects of data analysis? Our client, a leader in financial services, is seeking a highly skilled Senior Data Analyst to join their team. This role is crucial for their ongoing Data Warehouse integration project and offers the opportunity to work with cutting-edge technologies and top-tier professionals in the industry.

Key Responsibilities


 * Data Architecture Design: Utilize your deep understanding of data architecture to design and validate technical components, ensuring they support business solutions.
 * Business Solution Focus: Translate data into functional business solutions with an emphasis on investor and potential investor reporting.
 * Financial Services Expertise: Apply your knowledge of commercial lending, asset management, or financial services to provide insightful and relevant data analysis.
 * Technical Proficiency: Work extensively with SQL Server 2019 (on-prem) and, if possible, leverage your experience with Azure for the Dallas office.
 * Seamless Integration: Contribute to the Data Warehouse integration into the shared services unit, focusing on providing customizable data sets with minimal manual validation effort.
   
   

Qualifications


 * Experience: Proven track record in Data Warehousing, Enterprise Data Management, and as a Business Analyst.
 * Technical Skills: Expertise in SQL Server 2019 (on-prem) is essential; experience with Azure is a plus.
 * Financial Background: Strong understanding of commercial lending and/or asset management. Familiarity with industry terminology and regulatory environment is highly desirable.
 * Location: Must be local to Chicago or Dallas, with a preference for Chicago-based candidates. Occasional meetings at the client’s office may be required.
 * Professional Attributes: Ability to hit the ground running, with a focus on delivering business solutions over technical/processing solutions.
   
   

Skills: integration,data warehousing,business solution focus,technical proficiency,data architecture,enterprise data management,data architecture design,azure,business analyst,seamless integration,data engineering,financial services expertise,data",Contract
4145108435,74012521.0,Data Engineer,"Evio Overview

Evio is a highly unique pharmacy solutions company that was founded by and works closely with health plans to implement transformative (to cost, quality, access and experience) initiatives primarily focused on specialty and other high-cost medication solutions.

In 2020, a group of five amazing Blue Cross Blue Shield health plans that in total serve more than 25 million members recognized that the way medications get to patients needs to be transformed—rapidly rising costs and massive system complexities are detrimental to patients and the entire industry. Each company made, and continues to make, a significant investment to establish Evio as the independent entity to lead this transformation. 

With five prominent founding investor health plans and access to more than 25 million members, Evio has advanced analytics and contracting capabilities at scale, and a suite of digital tools, to power our high-cost medication solutions. Our solutions act as a self-reinforcing “flywheel” where each element strengthens and feeds into the next, and support an “Only Evio can do that,” mindset and prioritization.

Evio is also a company that has invested heavily in and been highly intentional about people, team and culture. We believe we have created a very special place to work and encourage candidates to observe and ask us about our culture and decide for themselves.

Evio's Values


 * Empathy – The people our business serves always come first. We care for our teammates and put ourselves in the shoes of our health plan customers and the patients and clinicians our solutions benefit.
 * Diversity – We are committed to fostering a culture where everyone belongs and is valued for their background, experience and insights – one that encourages diversity of ideas, and is a nurturing, trusting, and accepting place for all.
 * Adventure – We are flexible, thrive in ambiguity, fail fast, and pivot quickly to get to a better answer. We celebrate wins and pivots with equal intensity.
 * Relentless – Guided by evidence and data, we are creative, curious, and unwavering in our pursuit of challenging the status quo and each other.
 * Transparency – Just as we seek to bring transparency to the pharmacy supply chain, authenticity and integrity are core to the way we communicate.
 * Excellence – We strive to raise the bar in all we do by hiring and developing exceptional talent and holding ourselves and our thinking to the highest standard.
   
   

We are seeking an experienced Data Engineer with expertise in an AWS cloud native environment to design, develop, and maintain our data infrastructure and systems necessary for efficient data processing, storage, and analysis. This role will work closely with our product management and data analytics teams to create and manage effective data ETL processes on our application and analytics platforms.

Key Responsibilities

Data Architecture and Design:


 * Design and implement scalable data architectures using AWS cloud services, including data lakes, data warehouses, bulk data ingestion, transaction processing and streaming solutions.
 * Collaborate with stakeholders and other cross-functional teams, to comprehend data requirements and align data models with business needs for optimal data utilization.
 * Assemble large, complex data sets that meet functional business requirements.
   
   

ETL And Data Processing


 * Lead the development and implementation of ETL processes to ingest, clean, and transform data from various sources into the data platform.
 * Identify, design, and implement internal process improvements to automate manual processes and optimize data delivery.
   
   

AWS Cloud Services And Database Administration


 * Leverage AWS services, such as AWS Glue, AWS Data Pipeline, AWS Lambda, AWS Step Functions, Amazon Redshift, Amazon S3 and Amazon Kinesis, to build and optimize data workflows and processing pipelines.
 * Administer AWS databases effectively, within Amazon RDS, RedShift, PostgreSQL or MySQL.
 * Stay current with AWS services and recommend suitable tools for specific data engineering tasks.
   
   

Performance Optimization


 * Monitor and optimize data pipelines and data storage for performance, cost, and reliability.
 * Implement caching mechanisms and data partitioning strategies to enhance query efficiency and reduce data processing times.
   
   

Software Development


 * Develop and support the development of internal applications software using Python, SQL, and Stored Procedures.
   
   

Technical Leadership And Collaboration


 * Technical lead for Data Engineering team, providing technical guidance, mentoring, and fostering a collaborative and innovative environment.
 * Assist in establishing and managing the data security process.
 * Experience in supporting and working with cross-functional teams in a dynamic environment.
   
   

Data Security And Compliance


 * Implement and enforce data security measures, ensuring compliance with relevant data regulations and industry best practices.
 * Maintain data governance standards and access controls to protect sensitive data.
   
   

Continuous Improvement


 * Drive the adoption of best practices, automation, and modern data engineering techniques to improve the efficiency and reliability of data processes.
 * Identify opportunities for process optimization and drive initiatives to enhance the data engineering ecosystem.
 * Conduct root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
   
   

The skills and experience you bring to this role include:


 * Bachelor’s degree in Computer Science, Informatics, Information Systems, or another quantitative field.
 * 5+ years of experience in data engineering or a similar role with demonstrated technical leadership experience.
 * Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), writing views, stored procedures and triggers in an AWS Cloud Environment with RedShift, MySQL, PostgreSQL or similar RDBMS.
 * Strong database administration skills in AWS cloud databases, RedShift, RDBMS, PostgreSQL, or MySQL.
 * Software development skills and prior experience using Python, SQL, and Stored Procedures.
 * Experience with healthcare data (HL7, Medical Claims, Rx Claims) or similar healthcare data is preferred.
 * Excellent communication and organizational skills.
   
   

Salary Considerations

Anticipated annual base pay range: $100,000 – $120,000 plus additional variable compensation.

At Evio, we’re committed to building a competitive compensation package to honor the value our teammates bring as well as attract and retain top talent that is aligned with our culture, mission and values. Compensation includes base pay (range shown) and could include other variable compensation opportunities depending on job seniority, location, and date of hire. Evio also offers a number of attractive benefits to eligible teammates including health insurance, retirement savings, life and disability insurance, paid and unpaid time off, and other benefits to make sure Evio teammates and families are well supported.

Please note that the base pay information shown is a general guideline for the job responsibilities and qualifications listed. Salary decisions are based on candidate experience, and market and business considerations.

How We Take Care Of You


 * Great Health Insurance - The company pays 100% of medical, dental, and vision premiums for teammates, and 50% for dependents.
 * 401K Match - Evio matches 100% of teammate contribution up to 5% of salary, subject to IRS limits. 401K is administered through Guideline.
 * Time Off - We have a flexible vacation policy for teammates to unplug and recharge when you need it. There is no minimum or maximum amount of vacation allowed per year, and there is no payment in consideration for unused vacation. Vacation is to be used at your discretion, with approval of leadership.
 * Parental Leave - Generous paid leave for new parents (includes birth and non-birth parents).
   
   

Evio values a diverse workplace and is committed to supporting and celebrating the diversity that each teammate brings to the table. We are proud to provide equal employment opportunities to all teammates and applicants for employment and prohibit discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, medical condition, genetic information, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.",Full-time
4147274440,136203.0,Data Engineer,"About the job

Droisys is an innovation technology company focused on helping companies accelerate their digital initiatives from strategy and planning through execution. We leverage deep technical expertise, Agile methodologies, and data-driven intelligence to modernize systems of engagement and simplify human/tech interaction.




Amazing things happen when we work in environments where everyone feels a true sense of belonging and when candidates have the requisite skills and opportunities to succeed. At Droisys, we invest in our talent and support career growth, and we are always on the lookout for amazing talent who can contribute to our growth by delivering top results for our clients. Join us to challenge yourself and accomplish work that matters.




Position : Data Engineer

Mid - Sr level







Experience must include:

 * Programming languages such as Python, Java, and Scala
 * Big Data Frameworks such as Hadoop, Hive, Spark, and Databricks
 * ETL Tools such as Informatica and PLSQL
 * Scripting such as Unix, and PowerShell
 * Databases, such as Oracle, MYSQL, SQL Server, Teradata, and Snowflake
 * Cloud Technologies such as AWS, Azure Cloud, EC2, S3, Azure Blob, API Gateway, Aurora, EC2, RDS, Elastic Cache, and Spark Streaming
 * Analytics Tools, such as Tableau and Azure Analysis Services
 * Agile Teams
 * Source Control tools such as Github and related dev process







Droisys is an equal opportunity employer. We do not discriminate based on race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law. Droisys believes in diversity, inclusion, and belonging, and we are committed to fostering a diverse work environment.

",Contract
4152199087,22456.0,Senior Data Engineer,"Job Title: Sr. Data Engineer (HYBRID SCHEDULE-NJ)

Location: North New Jersey



Overview:

Client is seeking an energetic and collaborative Sr. Data Engineer to work on data and analytics projects. This group is responsible for technology support of all Data Engineering, Analytics and Reporting for their systems. This includes Data Engineering services, Enterprise reporting support and ML Ops Engineering operations for these groups. The candidate must be hands on with excellent technical skills and a proven track record of project delivery.



Responsibilities:

Hands on development and support of new or existing data applications.
Work closely with business and analysts to understand data and business process and make recommendations to clients as requested on best practices or long-term solutions to resolve current issues and also for future system design
Works closely with Application and Enterprise Architects to create/review low level implementation designs, understand high level data flow designs developed by data architects.
Provide technical guidance to the team for implementing complex data solutions.
Provide support in the design, development, code reviews, test deploy and documentation of data engineering and data integration Applications.
Maintain detailed documentation to support downstream integrations
Provide support for production issues
Performs activities of a scrum master
Identify technology trends and explore opportunities for use within the organization

Qualifications:

Knowledge and Requirements

Five to seven years of experience in Data Warehousing, Data integration or Data Engineering projects
Experience in Azure Databricks ,Cognos, Netezza Performance servers
Experience working within Azure ecosystem
Experienced in any of these analytical platforms - PowerBI, AzureML, Databricks or Synapse
Proficient in SQL
Experience using Python or Scala.
Experience in Azure DevOps and Github is preferred
Ability to effectively work well with people in other departments and/or outside of the enterprise.
P&C Insurance experience is preferred
Possesses excellent communication skills.
Bachelor's degree in computer science or related engineering field preferred.


Highly desired Skills:

Informatica Powercenter, IICS


Desired Skills and Experience

Job Title: Sr. Data Engineer (HYBRID SCHEDULE-NJ)

Location: North New Jersey



Overview:

Client is seeking an energetic and collaborative Sr. Data Engineer to work on data and analytics projects. This group is responsible for technology support of all Data Engineering, Analytics and Reporting for their systems. This includes Data Engineering services, Enterprise reporting support and ML Ops Engineering operations for these groups. The candidate must be hands on with excellent technical skills and a proven track record of project delivery.



Responsibilities:

Hands on development and support of new or existing data applications.
Work closely with business and analysts to understand data and business process and make recommendations to clients as requested on best practices or long-term solutions to resolve current issues and also for future system design
Works closely with Application and Enterprise Architects to create/review low level implementation designs, understand high level data flow designs developed by data architects.
Provide technical guidance to the team for implementing complex data solutions.
Provide support in the design, development, code reviews, test deploy and documentation of data engineering and data integration Applications.
Maintain detailed documentation to support downstream integrations
Provide support for production issues
Performs activities of a scrum master
Identify technology trends and explore opportunities for use within the organization


Qualifications:

Knowledge and Requirements

Five to seven years of experience in Data Warehousing, Data integration or Data Engineering projects
Experience in Azure Databricks ,Cognos, Netezza Performance servers
Experience working within Azure ecosystem
Experienced in any of these analytical platforms - PowerBI, AzureML, Databricks or Synapse
Proficient in SQL
Experience using Python or Scala.
Experience in Azure DevOps and Github is preferred
Ability to effectively work well with people in other departments and/or outside of the enterprise.
P&C Insurance experience is preferred
Possesses excellent communication skills.
Bachelor's degree in computer science or related engineering field preferred.

Highly desired Skills:
Informatica Powercenter, IICS



Beacon Hill is an Equal Opportunity Employer that values the strength diversity brings to the workplace. Individuals with Disabilities and Protected Veterans are encouraged to apply.


California residents: Qualified applications with arrest or conviction records will be considered for employment in accordance with the Los Angeles County Fair Chance Ordinance for Employers and the California Fair Chance Act.


If you would like to complete our voluntary self-identification form, please click here or copy and paste the following link into an open window in your browser: https://jobs.beaconhillstaffing.com/eeoc/


Completion of this form is voluntary and will not affect your opportunity for employment, or the terms or conditions of your employment. This form will be used for reporting purposes only and will be kept separate from all other records.


Company Profile:

Beacon Hill Technologies, a premier National Information Technology Staffing Group, provides world class technology talent across all industries utilizing a complete suite of staffing services. Beacon Hill Technologies' dedicated team of recruiting and staffing experts consistently delivers quality IT professionals to solve our customers' technical and business needs.

Beacon Hill Technologies covers a broad spectrum of IT positions, including Project Management and Business Analysis, Programming/Development, Database, Infrastructure, Quality Assurance, Production/Support and ERP roles.


Learn more about Beacon Hill and our specialty divisions, Beacon Hill Associates, Beacon Hill Financial, Beacon Hill HR, Beacon Hill Legal, Beacon Hill Life Sciences and Beacon Hill Technologies by visiting www.bhsg.com.


Benefits Information:


Beacon Hill offers a robust benefit package including, but not limited to, medical, dental, vision, and federal and state leave programs as required by applicable agency regulations to those that meet eligibility. Upon successfully being hired, details will be provided related to our benefit offerings.




We look forward to working with you.

Beacon Hill. Employing the Future™",Full-time
4139142257,2289109.0,"Data Engineer, Analytics (Technical Leadership)","Every month, billions of people leverage Meta products to connect with friends and loved ones from across the world. On the Data Engineering Team, our mission is to support these products both internally and externally by delivering the best data foundation that drives impact through informed decision making. As a highly collaborative organization, our data engineers work cross-functionally with software engineering, data science, and product management to optimize growth, strategy, and experience for our 3 billion plus users, as well as our internal employee community.We are looking for a technical leader in our Data Engineering team to work closely with Product Managers, Data Scientists and Software Engineers to support building out a great platform for the future of computing. In this role, you will see a direct correlation between your work, company growth, and user satisfaction. You’ll work with some of the brightest minds in the industry, work with one of the richest data sets in the world, use cutting edge technology, and see your efforts affect products and people on a regular basis.The ideal candidate will have strong data infrastructure and data architecture skills as well as experience in areas such as governing company wide data marts, enabling security and privacy data solutions, and full stack experience with analytical technologies. Candidates should also have a proven track record of leading and scaling efforts related to end-to-end analytics systems, strong operational skills to drive efficiency and speed, strong project management leadership, and a strong vision for how data can proactively improve companies.As we continue to expand and create, we have a lot of exciting work ahead of us!

Data Engineer, Analytics (Technical Leadership) Responsibilities:


 * Proactively drive the vision for data foundation and analytics to accelerate building and improvement of cross platform components across Instagram, and define and execute on plan to achieve that vision.
 * Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems.
 * Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve.
 * Build cross-functional relationships with Data Scientists, Product Managers and Software Engineers to understand data needs and deliver on those needs.
 * Define and manage SLA for all data sets in allocated areas of ownership.
 * Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership.
 * Design, build, and launch collections of sophisticated data models and visualizations that support use cases across different products or domains.
 * Solve our most challenging data integrations problems, utilizing optimal ETL patterns, frameworks, query techniques, sourcing from structured and unstructured data sources.
 * Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts.
 * Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts.
 * Influence product and cross-functional teams to identify data opportunities to drive impact.
 * Mentor team members by giving/receiving actionable feedback.
   
   

Minimum Qualifications:


 * Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.
 * 10+ years experience in the data warehouse space.
 * 10+ years experience in custom ETL design, implementation and maintenance.
 * 10+ years experience with object-oriented programming languages.
 * 10+ years experience with schema design and dimensional data modeling.
 * 10+ years experience in writing SQL statements.
 * Experience analyzing data to identify deliverables, gaps and inconsistencies.
 * Experience managing and communicating data warehouse plans to internal clients.
   
   

Preferred Qualifications:


 * BS/BA in Technical Field, Computer Science or Mathematics.
 * Experience working with either a MapReduce or an MPP system.
 * Knowledge and practical application of Python.
 * Experience working autonomously in global teams.
 * Experience influencing product decisions with data.
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$206,000/year to $281,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.

",Full-time
4125057967,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4137559516,7577299.0,Data Engineer,"Overview:

Data Engineers serve a unique and important role in daily operations at Wider Circle. Customer data is the bedrock of our business, and Data Engineering is responsible for laying the foundation for our success. Data Engineers work with internal and external stakeholders to gather, validate, clean and move data inside and outside the organization using technology and automation. Our data engineering team is also responsible for quality curation of data to ensure our products are released on time and with minimal errors and/or bugs.

You will be joining a talented, fully remote Data Science, Engineering and Analytics team that handles a wide range of requests including customer data processing, weekly report automation, new product development and complex data integration.

Company Overview

At Wider Circle, we connect neighbors for better health. Wider Circle's groundbreaking Connect for Life® program brings neighbors together in-person and online for health, wellness, and social activities that improve mental and physical health. We create webs of community circles by employing local and culturally competent engagement specialists, whose hand-on-hand approach to forming trusted circles is informed by a sophisticated analytics platform. We are on a mission to make the world a better place for older adults and disadvantaged communities.

Immerse yourself in our LOVE, LEARN, GROW culture, where the ethos of making a profound impact, fostering respect, and nurturing career development reign supreme. We offer competitive compensation, benefits, and policies meticulously crafted to uphold our unwavering commitment to our internal team and the communities we proudly serve. Join us in shaping healthier futures and embracing boundless personal and collective growth opportunities.

Responsibilities


 * Develop and maintain data quality and accuracy dashboards, and scorecards to track data quality and model performance
 * Develop, maintain, and enhance a comprehensive data quality framework that defines data standards, quality and accuracy expectations, and validation processes
 * Enhance our data quality through rapid testing, feedback and insights
 * Partnering with Engineering & Product to predict data quality issues and production flaws
 * Conceptualize data architecture (visually) and implement practically into logical structures
 * Performing testing of data after ingesting and database loading
 * Manage internal SLAs for data quality and frequency
 * Provide expert support for solving complex problems of data integration across multiple data sets
 * Updating and evolving our data ecosystem to streamline processes for maximum efficiency
   
   
   

Requirements


 * Degree in Computer Science, Information Systems, or equivalent education or work experience
 * Experience with AWS or similar (S3, Redshift, RDS, EMR) 3+ Years
 * Strong abilities with SQL & Python 3+ Years
 * Building test automation suites for test and production environments
 * Experience using API's for data extraction and updating
 * Experience with Git and version control
   
   
   

Really Nice to Have:


 * Experience with Healthcare Data (Claims, CDAs/HRAs, Eligibility)
 * Experience using Salesforce (Salesforce API)
 * Matillion, Mulesoft, or related tooling
 * Airflow, cron, or other automation tools
 * Experience working with Data Packages written in R or Python
 * Experience partnering with Data Scientists to optimize or productionalize models
   
   
   

Location


 * This fully remote position offers the flexibility to work from anywhere while contributing to meaningful projects in a supportive and dynamic environment
   
   
   

Submission Requirements


 * Candidates must submit a GitHub or Bitbucket repository or provide coding samples of completed projects along with their resumes. We look forward to seeing your work!
   
   
   

Benefits

Compensation

As a venture-backed company, Wider Circle offers competitive compensation including:


 * Performance-based incentive bonuses
 * Opportunity to grow with the company
 * Comprehensive health coverage including medical, dental, and vision
 * 401(k) Plan
 * Paid Time Off
 * Employee Assistance Program
 * Health Care FSA
 * Dependent Care FSA
 * Health Savings Account
 * Voluntary Disability Benefits
 * Basic Life and AD&D Insurance
 * Adoption Assistance Program
 * Training and Development
 * $95,000-$110,000
   
   

And most importantly, an opportunity to Love, Learn, and Grow while making the world a better place!

Wider Circle is proud to be an equal opportunity employer that does not tolerate discrimination or harassment of any kind. Our commitment to Diversity & Inclusion supports our ability to build diverse teams and develop inclusive work environments. We believe in empowering people and valuing their differences. We are committed to equal employment opportunities without consideration of race, color, religion, ethnicity, citizenship, political activity or affiliation, marital status, age, national origin, ancestry, disability, veteran status, sexual orientation, gender identity, gender expression, sex or gender, or any other basis protected by law.",Full-time
3970352584,3650502.0,Data Engineer,"Figma is growing our team of passionate people on a mission to make design accessible to all. Born on the Web, Figma helps entire product teams brainstorm, design and build better products — from start to finish. Whether it’s consolidating tools, simplifying workflows, or collaborating across teams and time zones, Figma makes the design process faster, more efficient, and fun while keeping everyone on the same page. From great products to long-lasting companies, we believe that nothing great is made alone—come make with us!

We are looking for an experienced Data Engineer to partner with our Data Science and Data Infrastructure teams to own and scale our data pipelines. You’ll also work closely with stakeholders across business teams including sales, marketing, and finance to ensure that the data they need arrives promptly and reliably. You’ll play an integral role in building the metrics and self-serve reporting capabilities to unlock Figma’s next phase of growth.

This is a great role for an individual who is passionate about working with data and data systems, and who loves solving problems. You’ll have a good sense for when it makes sense to build fast, scrappy solutions to unblock a key stakeholder vs. when to push back or bring in an outside service. The ideal candidate will be a great communicator who can help coordinate across multiple internal and external teams and takes pride in building end-to-end projects.

What you'll do at Figma:


 * Own, build, and maintain scalable data pipelines that connect various cloud data sources.
 * Develop a deep understanding of Figma’s core data models and optimize data pipelines for scale.
 * Partner with the Data Science and Data Infrastructure teams to build new foundational data sets that are trusted, well understood, and enable self-service.
 * Work with a wide range of cross-functional stakeholders to derive requirements and architect shared datasets; ability to document, simplify and explain complex problems to different types of audiences.
 * Establish best practices for the development of specialized data sets for analytics and modeling.
   
   

We'd love to hear from you if you have:


 * 4+ years in a relevant field
 * Fluency with both SQL and Python
 * Familiarity with Snowflake, dbt, Dagster, and ETL/reverse ETL tools.
 * Excellent judgment and creative problem solving skills
 * A self-starting mindset along with strong communication and collaboration skills
   
   

While not required, it’s an added plus if you also have:


 * Knowledge in data modeling methodologies to design and build robust data architectures for insightful analytics
 * Experience with business systems such as Salesforce, Customer IO, Stripe, NetSuite is a big plus.
   
   

At Figma, one of our values is Grow as you go. We believe in hiring smart, curious people who are excited to learn and develop their skills. If you’re excited about this role but your past experience doesn’t align perfectly with the points outlined in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles.

Pay Transparency Disclosure

If based in Figma’s San Francisco or New York hub offices, this role has the annual base salary range stated below.

Job level and actual compensation will be decided based on factors including, but not limited to, individual qualifications objectively assessed during the interview process (including skills and prior relevant experience, potential impact, and scope of role), market demands, and specific work location. The listed range is a guideline, and the range for this role may be modified. For roles that are available to be filled remotely, the pay range is localized according to employee work location by a factor of between 80% and 100% of range. Please discuss your specific work location with your recruiter for more information.

Figma offers equity to employees, as well a competitive package of additional benefits, including health, dental & vision, retirement with company contribution, parental leave & reproductive or family planning support, mental health & wellness benefits, generous PTO, company recharge days, a learning & development stipend, a work from home stipend, and cell phone reimbursement. Figma also offers sales incentive pay for most sales roles. Figma’s compensation and benefits are subject to change and may be modified in the future. You may view our Pay Transparency Policy by clicking on the corresponding link.

Annual Base Salary Range (SF/NY Hub):

$164,000—$338,000 USD

At Figma we celebrate and support our differences. We know employing a team rich in diverse thoughts, experiences, and opinions allows our employees, our product and our community to flourish. Figma is an equal opportunity workplace - we are dedicated to equal employment opportunities regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity/expression, veteran status, or any other characteristic protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.

We will work to ensure individuals with disabilities are provided reasonable accommodation to apply for a role, participate in the interview process, perform essential job functions, and receive other benefits and privileges of employment. If you require accommodation, please reach out to accommodations-ext@figma.com. These modifications enable an individual with a disability to have an equal opportunity not only to get a job, but successfully perform their job tasks to the same extent as people without disabilities.

Examples of accommodations include but are not limited to:


 * Holding interviews in an accessible location
 * Enabling closed captioning on video conferencing
 * Ensuring all written communication be compatible with screen readers
 * Changing the mode or format of interviews
   
   

By applying for this job, the candidate acknowledges and agrees that any personal data contained in their application or supporting materials will be processed in accordance with the applicable candidate section of Figma's Privacy Policy.",Full-time
4125067236,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4052363228,66321745.0,Junior Data Engineer,"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you need

Position open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, IT enthusiasts, Python/Java developers, Data analysts/ Data Scientists.

We welcome candidates with all visas and citizens to apply.

Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates looking to make their careers in IT Industry

We assist in filing for STEM extension and also for H1b and Green card filing.

Candidates who are serious about their future in the IT Industry and have set big goals for themselves.

Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience which our clients need with great outcomes

Candidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancement

Candidates Who Lack Experience

Have had a break in careers

Lack Technical Competency

Different visa candidates who want to get employed and settle down in the USA

Please Also Check The Below Links

https://www.synergisticit.com/candidate-outcomes/

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

How Can Recently Laid Off Tech People Get Employed Again? | SynergisticIT

If not a match candidates can opt for Skill enhancement.

REQUIRED SKILLS For Java/Software Programmers


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Core Java , javascript , C++ or software programming
 * Spring boot, Microservices and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, Python, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, Time series analysis

Please understand skills are required by clients for selection even if its Junior or entry level position the additional skills are the only way a candidate can be picked by clients.

No third party candidates or c2c candidates

Please understand skills are required by clients for selection even if its Junior or entry level position the additional skills are the only way a candidate can be picked by clients.

Please apply to the posting

No phone calls please. Shortlisted candidates would be reached out",Contract
4117851033,523382.0,Data Engineer,"Your Job

As a Data Engineer at INVISTA, you will be a vital contributor to our Enterprise Data Platform, responsible for designing and implementing data pipelines, optimizing data workflows, and ensuring data reliability and accessibility. Your work will be instrumental in empowering our organization to make data-driven decisions and fueling innovation across the company.

Our Team

Joining our Data and Analytics team means becoming a key player in a dynamic and innovative group of professionals dedicated to unlocking the power of data. Here, you'll find a diverse and collaborative environment where your ideas and expertise will shape the future of our data-driven organization. We pride ourselves on fostering a culture of continuous learning, creativity, and teamwork, and we're looking for individuals who are eager to contribute their skills and passion to our shared mission.

This role may work a hybrid schedule out of our Wichita (KS) or Katy (TX) office location.

What You Will Do


 * Collaborate closely with business partners and data scientists to align data engineering efforts with their specific needs and objectives, ensuring that data solutions contribute effectively to the organization's overall goals. This includes proposing alternative solutions, with their pros and cons, to help guide the workstream forward.
 * Understand, develop, maintain/troubleshoot, automate, and optimize orchestration and data pipelines using tools such as Snowflake, dbt, GitHub, AWS, Power BI, and Neo4J.
 * Implement data integration strategies for streaming, event driven, and batch data sources.
 * Design and implement data modeling and ETL/ELT processes to ensure data quality, consistency, availability and data centricity.
 * Manage and maintain data warehouses and ensure data security and compliance with company policies and relevant regulations.
 * Perform data transformations, aggregations, and data cleansing to support analytics and reporting needs.
 * Document data engineering processes, pipelines, and architecture for knowledge sharing and compliance.
 * Stay up to date with industry best practices, emerging technologies, and trends in data engineering.
   
   
   

Who You Are (Basic Qualifications)


 * Experience in data modeling with SQL
 * Experience collaborating with a Finance team or in the Financial Services industry
 * Experience programming in Python
 * Ability to travel up to 20% of the time
 * This role is not eligible for visa sponsorship
   
   
   

What Will Put You Ahead


 * Experience with Snowflake data warehouse technology
 * Proficiency in designing software and data solutions that scale
 * Proficiency in Power BI, strong in DAX and analytics report building
 * Hands-on experience with AWS cloud computing platform
 * SAP Financial domain knowledge – Financial accounting and controlling modules
 * Experience with DevOps practices and tools, such as continuous integration (CI) and continuous deployment (CD) pipelines, version control systems (e.g., Git)
 * Knowledge of data governance and compliance best practices
   
   
   

At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.

Hiring Philosophy

All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here.

Who We Are

As a Koch company, INVISTA has a long history of working to make the world around you a better place. From parts for the automotive industry to medical equipment, air bags, food packaging and clothing, our ingredients in the nylon 6,6 and polypropylene value chains help bring many of life’s essential products to market.

At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.

Our Benefits

Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength - focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes - medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.

Additionally, everyone has individual work and personal needs. We seek to enable the best work environment that helps you and the business work together to produce superior results.

Equal Opportunities

Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, some offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please click here for additional information. (For Illinois E-Verify information click here, aquí, or tu).

",Full-time
4118311237,66321745.0,Data Engineer - Junior,"Since 2010 SynergisticIT has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients.

The Tech Job market has been affected by massive layoffs and since 2021 there have been more than 600,000.00 tech layoffs.

Good news is that the Fed Reserve has cut interest rates which should boost tech hiring however tech companies will still only hire the best candidates and would not over hire. Also there are a large number of laid off techies who would want to get hired first. To ensure candidates get hired they need to be better than the other Jobseekers.

The Job market is Hyper Competitive. For 1 position 500-1000 candidates or more are applying and laid off job seekers are also competing for entry level Job positions.

Please see the below links to know more about Synergisticit and some useful tips

https://www.synergisticit.com/candidate-outcomes/

How Can Recently Laid Off Tech People Get Employed Again? | SynergisticIT

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

We regularly interact with the Top Tech companies to give our candidates a competitive advantage.

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

We are continuously looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Data Engineers, Machine Learning engineers for full time positions with clients.

Who Should Apply? Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We need Data Science/Machine learning/Data Analyst and Java Full stack candidates

Preferred SKILLS For Java /Full Stack/Devops Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Knowledge of Core Java , javascript , C++ or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

For data Science/Data Analyst/AI/Machine learning Positions

Preferred SKILLS

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude

Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools

Candidates lacking technical skills can research our other programs which can assist in landing a Job

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Contract
4143623537,11028146.0,Data Engineer,"Position: Data Engineer

Location: Alpharetta, GA – On site




About the role:

We are seeking a hands-on, highly technical Data Engineer with a background in implementing data models distributed to end business users. In this role you will focus on ensuring data availability, data accuracy, and maintaining one source of truth. This role will have technical responsibilities involving SQL programming, utilizing the full Azure suite, and developing and implementing data governance practices. The right candidate will have experience working in a cross-functional global environment with excellent communication skills.




Key Responsibilities:




Data Engineering:

 * Design and build end-to-end SQL database solutions to maintain one source of truth focusing on efficient data models for querying and analytics.
 * Translate business requirements, recommend technologies, develop code, and troubleshoot data issues before end users identify them.
 * Develop unit testing to ensure data availability and completeness, focusing on the semantic/ golden layer.
 * Design, build, and maintain scalable data pipelines and storage solutions using modern tools and platforms (Azure, SQL Server, or equivalent).
 * Optimize data flows for performance and scalability.




Data Governance:

 * Design data classification and meta-data management strategies.
 * Establish, enforce, and improve data governance policies to maintain data quality, consistency, and security.
 * Ensure compliance with international data standards and regulations, adapting governance policies to align with global best practices.
 * Drive the adoption of data governance tools and technologies to streamline data management processes.
 * Support efforts to monitor and address data anomalies and inconsistencies.
 * Define and monitor data quality metrics (e.g., completeness, timeliness, and validity).




Required Qualifications:

 * Bachelor’s degree in computer science or related degree/experience.
 * Expert in SQL Server, Python, or equivalent programming languages and SSIS experience
 * Experience with Azure suite; Data Factory, Databricks, OpenAI, Data Lake, Azure SQL, Azure AI
 * Experience with data governance principles and best practices.
 * Strong understanding of data modeling, database design, and optimization.
 * Demonstrated ability to reduce uncertainty and to manage ambiguity. Deals constructively with problems that do not have clear solutions.
 * Excellent critical thinking skills and attention to detail.
 * Experience working cross-functionally with business teams to deliver data solutions.
 * Knowledge of data visualization tools (e.g., Power BI and Fabric) is a plus.

",Full-time
4132895751,95313.0,Data Engineer,"Data Analyst / Engineer

10 Months of Contract

San Jose, CA - 95110 ( HYBRID )




ONLY SOMEONE WHO CAN WORK ON W2




Responsibilities

 * Partner with product and business teams to understand requirements and KPIs.
 * Support regular ad-hoc data querying and in-depth analyses to better understand customer behavior.
 * Support teams in running growth programs and A/b tests through analyzing results and communicating insights.
 * Conduct exploratory data analysis to answer business questions that help inform decision-making.
 * Slice and dice data sets through various dimensions to generate meaningful insights and diagnostics.




Skills Required:

 * Hands-on experience working with large data sets.
 * Prior experience with a big data platform like Databricks, Apache Spark or Apache Hadoop.
 * Expert in at least one programming or data manipulation language, preferably Python and SQL.
 * Basic understanding of statistics, and prior experience with A/b testing.
 * Data storytelling skills.
 * Good communication skills - ability to communicate business insights from data to stakeholders effectively.

",Contract
4137192129,1586.0,"Data Engineer, F3 DASH","Description

Are you interested in being a part of Amazon’s fastest growing business? Are you excited to work on cutting edge Big Data technologies to help shape the future of Grocery data? If the answer to both these questions is Yes, then come be a part of Amazon Fresh’s Central Data Infrastructure team (DASH). Our vision is to build a world class, centralized and secure data infrastructure for Amazon’s Worldwide Omnichannel Grocery Business. Our mission is to make it extremely convenient for Internal stakeholders, 3P partners and the Grocery engineering community to access timely and accurate data for all their reporting and analytics needs. The scale and the complexity of the data we manage requires constant innovation and pushing the boundaries on what’s possible. This role offers you an opportunity to work on VP level visibility initiatives and make a lasting impression on how grocery data is managed and distributed across the globe.

Key job responsibilities

In This Role You Will


 * Help build the infrastructure to answer questions with data, using software engineering best practices, data management fundamentals, data storage principles, and recent advances in distributed systems
 * Manage AWS resources.
 * Collaborate with Business Intelligence Engineers to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation
 * Collaborate with Data Scientists to implement advanced analytics algorithms that exploit our rich data sets for statistical analysis, prediction, clustering and machine learning
 * Drive the architecture and technology choices that enable a world-class user experience
 * Develop expertise in a broad range of Amazon’s data resources and know when, how, and which to use and which not to use
 * Encourage the organization to adopt next-generation data architecture strategies, proposing both data flows and storage solutions
 * be comfortable with a degree of ambiguity and willing to develop quick proof of concepts, iterate and improve
 * Create extensible designs and easy to maintain solutions with the long term vision in mind
 * Have an understanding and empathy for business objectives, and continually align your work with those objectives and seek to deliver business value. You listen effectively.
   
   

A day in the life

Successful candidate would have extensive experience working with big data, building data warehouses and data processing services. They are effective at seeing data patterns and building generic data solutions to improve user experience. Proficiency in SQL and data modelling allows to create data warehouses and tables conforming to wide range of business needs. Previous ETL and MPP experience enables candidate to build extensible and scalable pipelines capable of processing large amounts of data in a short time, ex. >1T rows within few hours. Wide industry experience helps detect inefficiencies in existing designs and address them with minimal effort.

About The Team

F3 DASH is Amazon Fresh central data team responsible for the creation and maintenance of Amazon Grocery’s global data infrastructure. Our mission is to make all of grocery data easily accessible across multiple businesses by all users from a single location without any restrictions for all their reporting and analytics needs. Our long-term vision is to build a best-in-class data infrastructure to support worldwide grocery data to enable timely reporting and automated decision-making with standardized metrics to deliver top-line and bottom-line impact to Amazon’s grocery business.

Basic Qualifications


 * 1+ years of data engineering experience
 * Experience with data modeling, warehousing and building ETL pipelines
 * Experience with one or more query language (e.g., SQL, PL/SQL, DDL, MDX, HiveQL, SparkSQL, Scala)
 * Experience with one or more scripting language (e.g., Python, KornShell)
   
   

Preferred Qualifications


 * Experience with big data technologies such as: Hadoop, Hive, Spark, EMR
 * Experience with any ETL tool like, Informatica, ODI, SSIS, BODI, Datastage, etc.
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $91,200/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com Services LLC

Job ID: A2872706",Full-time
3875370889,46623.0,Data Engineer,"Description

Your role at GEI.

GEI Consultants has an opening in our Operational Development Team for a qualified Data Engineer to support a variety of systems and data engineering tasks focused on data flow activities. The majority of our systems are based in MS SQL Server, Tableau Server, Azure, and FastField Forms. This person will primarily work closely with members of the Operational Development Team and with members of our IT staff. The ideal candidate will be focused, detail-oriented, and driven to attain and maintain very high standards for efficiency and accuracy in data acquisition and integration into our systems. The ideal candidate will have more than 3 years of data engineering experience in the AEC industry or in similar science and/or engineering environments. GEI seeks a committed, self-motivated, organized and detail-oriented individual who anticipates issues and thrives on creative, independent problem solving within a rapid, deadline-driven environment.

Essential Responsibilities & Duties


 * ETL of data from a wide variety of sources
 * Database and Data Warehouse design/expansion/backup & recovery
 * Index management and optimization
 * Support data sources for Tableau Server, Power BI, and ArcGIS
 * Stored procedure development and maintenance
 * Identify new opportunities within GEI where existing business approaches to data can be replaced with a more efficient/automated data flow and presentation of data for analysis
 * Develop and optimize ETL/SSIS packages to facilitate data transfer between FTP, remote data loggers, Azure, and on-premises databases
 * Troubleshoot SSIS package permission issues related to execute-as/data source read/write access
 * SQL Agent Job development and monitoring
 * Develop data reporting and visualizations as specified by clients using Tableau, SSRS, etc
 * Perform DML and DDL via tsql/stored procedures executed directly within SSMS and remotely via SSIS
 * Develop test plans, implementation plans, and project timelines for various data engineering projects
 * Define, prioritize, communicate, and foster shared understanding of project objectives and scope
 * Coordinate the development of standard operating procedures (SOPs), technical training programs, and QA/QC procedures for staff and work product
 * Team with all staff necessary to complete assignments
 * Collaborate with technical team members to ensure the solution design satisfies project objectives and business requirements
 * Other duties as assigned
   
   

Minimum Qualifications


 * 3+ years of experience in a position performing similar data engineering tasks
 * Proven record of ability to design, manage, and support MS SQL Server and Azure databases
 * Ability to work with the following programming/mark-up/scripting languages preferred: VB.net, python, XML, javascript, and R
 * Bachelor's Degree, from an accredited college or university
 * MS SQL Server/Azure certification preferred
 * Ability to develop project plans and meet deadlines
 * Self-starter with attention to detail and stakeholder needs
 * Able to critically analyze and solve problems of a complex nature
 * Excellent Communication skills
 * Able to work on multiple projects of moderate complexity simultaneously and independently
 * Proficient in organization and time management skills
 * Familiarity with engineering, environmental science, and/or chemistry subject matter preferred.
 * Able to work effectively in GEI’s partnership model, including a team environment, building rapport and relationships.
   
   

We are GEI.

Some of the world’s most pressing problems - from climate change to sustainable development, to critical infrastructure and the future of our energy supply - need our brightest and diverse minds working together to create safer, more resilient communities for tomorrow.

We are technical experts, collaborators, and entrepreneurs who draw from diverse backgrounds to solve our clients’ most complex challenges.

With nearly 60 offices across North America, we offer a range of engineering, science, and technical consulting services. Our range of expertise, project types, and culture make us the choice for top talent in the AEC industry.

Employee-owned. Employee-focused.

As a 100% employee-owned company, our employees support our flat leadership structure, have a say in how our business operates and benefit from our financial success. We are committed to employee growth with career development opportunities, competitive total rewards, a well-being program, flexible work arrangements and more. Our company culture is driven by our 4 Cs - we are Client-Centered, Curious, Collaborative, and Community Minded - which support our focus on sustainability, safety, diversity, equity and inclusion. Get to know us better by visiting GEI’s career site here.

GEI’s Total Rewards Package


 * Market-Competitive Compensation, including Eligibility for an Annual Performance Bonus
 * Pay Range For This Position: $33.65-72.11/hour
 * Comprehensive Benefits Program, including Medical, Dental, Vision, Life, Disability and More
 * Well-Being Program and Paid Parental Leave
 * Commuter Benefits
 * Hybrid Work Schedules and Cell Phone Stipends
 * GEI University (GEIU) with Continuing Education Assistance and Tuition Reimbursement
 * Connecting Conversation Program with a Focus on Professional Development and Opportunities for Advancement
 * Support and Financial Rewards for Publication Awards, Professional Dues, and Professional Licenses
 * Paid Holidays and Generous Paid Time Off Program
 * Rewards and Recognition
 * GEI-Funded Profit Sharing and 401(k)
 * Opportunity to be an Owner and Shareholder (Learn more here)
 * A Vibrant Culture that is Focused on Partnership, Sustainability, Giving Back to Our Communities and Diversity, Equity and Inclusion
 * And More…
   
   

Physical Job Requirements

Sedentary

X

Light

Medium

Other

Activity Level Throughout Workday

Physical Activity Requirements

Occasional

(0-35% of day)

Frequent

(33-66% of day)

Continuous

(67-100% of day)

Not Applicable

Sitting

X

Standing

X

Walking

X

Climbing

X

Lifting (floor to waist level) (in pounds)

X

Lifting (waist level and above) (in pounds)

X

Carrying objects

X

Push/pull

X

Twisting

X

Bending

X

Reaching forward

X

Reaching overhead

X

Squat/kneel/crawl

X

Wrist position deviation

X

Pinching/fine motor skills

X

Keyboard use/repetitive motion

X

Taste or smell (taste=never)

X

Talk or hear

X

Accurate 20/40

Very Accurate 20/20

Not Applicable

Near Vision

X

Far Vision

X

Yes

No

Not Applicable

Color Vision (ability to identify and distinguish colors)

X

Sensory Requirements

Minimal

Moderate

Accurate

Not Applicable

Depth perception

X

Hearing

X

Environmental Requirements

Occupational Exposure Risk Potential

Reasonably Anticipated

Not Anticipated

Blood borne pathogens

X

Chemical

X

Airborne communicable diseases

X

Extreme temperatures

X

Radiation

X

Uneven surfaces or elevations

X

Extreme noise levels

X

Dust/particular matter

X

Other (exposure Risks)

Usual workday hours:

X

8

10

12

Other work hours

GEI is an AA/equal opportunity employer, including disabled and veterans.",Full-time
4149784405,1482.0,Software Engineer - Recent Graduate,"The Company
PayPal has been revolutionizing commerce globally for more than 25 years. Creating innovative experiences that make moving money, selling, and shopping simple, personalized, and secure, PayPal empowers consumers and businesses in approximately 200 markets to join and thrive in the global economy.

We operate a global, two-sided network at scale that connects hundreds of millions of merchants and consumers. We help merchants and consumers connect, transact, and complete payments, whether they are online or in person. PayPal is more than a connection to third-party payment networks. We provide proprietary payment solutions accepted by merchants that enable the completion of payments on our platform on behalf of our customers.

We offer our customers the flexibility to use their accounts to purchase and receive payments for goods and services, as well as the ability to transfer and withdraw funds. We enable consumers to exchange funds more safely with merchants using a variety of funding sources, which may include a bank account, a PayPal or Venmo account balance, PayPal and Venmo branded credit products, a credit card, a debit card, certain cryptocurrencies, or other stored value products such as gift cards, and eligible credit card rewards. Our PayPal, Venmo, and Xoom products also make it safer and simpler for friends and family to transfer funds to each other. We offer merchants an end-to-end payments solution that provides authorization and settlement capabilities, as well as instant access to funds and payouts. We also help merchants connect with their customers, process exchanges and returns, and manage risk. We enable consumers to engage in cross-border shopping and merchants to extend their global reach while reducing the complexity and friction involved in enabling cross-border trade.

Our beliefs are the foundation for how we conduct business every day. We live each day guided by our core values of Inclusion, Innovation, Collaboration, and Wellness. Together, our values ensure that we work together as one global team with our customers at the center of everything we do – and they push us to ensure we take care of ourselves, each other, and our communities.

Job Description Summary:
At PayPal, we’re literally reinventing how the world pays and gets paid. We understand that it’s about people. We connect individuals to let them shop, get paid, donate and send money using today’s technology with the confidence that comes from the security and control PayPal enables. Are you ready to help us change the world? The world’s leading payments company, PayPal, brings together a family of brands that are revolutionizing the way people move money. At PayPal you will be immersed in an amazing community with a vibrant culture that thrives on innovation, collaboration, inclusion and wellness. Software Engineers at PayPal develop innovative solutions and high-quality products that touch millions of people every day around the globe. Our engineers solve some of the most complex technical problems in the world of connected payments across all business units, including PayPal, Braintree, Venmo, Paydiant and others. We are looking for the highest levels of technical talent and programming skills, as well as a keen desire to deeply understand our products and services to push our technology forward with respect to functionality, performance, reliability, and scalability. You’ll work alongside the best and the brightest engineering talent in the industry. We have opportunities in a wide range of areas including development, design, search, platform, test, quality, big data, front end and back end. As a core participant of your team, you’ll estimate engineering efforts, design your changes, implement and test your changes, push to live, and triage production issues. You need to be dynamic, collaborative, and curious as we build new experiences, improve existing products, and develop distributed systems powering the world’s largest e-commerce and payments websites at a scale only a few companies can match.

Job Description:
Key Responsibilities:


 * Code high-volume and scalable software (front-end and/or back-end focused). This may include creating web applications using React/Node, creating back-end services using Java, SQL, ReST and/or building and developing new user-facing experiences
 * Partner closely with cross functional teams in design, product and other business units
   
   
   

 Basic Requirements:


 * Strong applied experience. You’ve built, broken, and rebuilt software applications. We’re looking for creative thinkers who also know how to create real-world products.
 * Working knowledge of web technologies (such as HTTP, HTML/DOM, JavaScript, CSS, AJAX)
 * Familiarity with any or multiple of the following: Node.js applications, Java, C++. Python
 * Understanding of concepts like Web Services, SOA, REST APIs
 * A constant desire to grow, learn, and explore new things
   
   
   

Recent Graduate Position Information and Requirements:


 * This is a Recent Graduate Full-Time position.
 * Must have graduated within the past 12 months, or will be graduating by Spring 2025, with a Bachelor’s or Master’s degree in Computer Science or related field from an accredited college or university.
 * Must reside in the U.S.
 * Must be able to obtain authorization to work in the U.S.
   
   
   

globaluniversitygraduatesoftwareengineering

For the majority of employees, PayPal's balanced hybrid work model offers 3 days in the office for effective in-person collaboration and 2 days at your choice of either the PayPal office or your home workspace, ensuring that you equally have the benefits and conveniences of both locations.

Our Benefits:

At PayPal, we’re committed to building an equitable and inclusive global economy. And we can’t do this without our most important asset—you. That’s why we offer benefits to help you thrive in every stage of life. We champion your financial, physical, and mental health by offering valuable benefits and resources to help you care for the whole you.

We have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https://www.paypalbenefits.com

Who We Are:

To learn more about our culture and community visit https://about.pypl.com/who-we-are/default.aspx

Commitment to Diversity and Inclusion

PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state, or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at paypalglobaltalentacquisition@paypal.com.

Belonging at PayPal:

Our employees are central to advancing our mission, and we strive to create an environment where everyone can do their best work with a sense of purpose and belonging. Belonging at PayPal means creating a workplace with a sense of acceptance and security where all employees feel included and valued. We are proud to have a diverse workforce reflective of the merchants, consumers, and communities that we serve, and we continue to take tangible actions to cultivate inclusivity and belonging at PayPal.

Any general requests for consideration of your skills, please Join our Talent Community.

We know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please don’t hesitate to apply.

As part of PayPal’s commitment to employees’ health and safety, we have established in-office Covid-19 protocols and requirements, based on expert guidance. Depending on location, this might include a Covid-19 vaccination requirement for any employee whose role requires them to work onsite. Employees may request reasonable accommodation based on a medical condition or religious belief that prevents them from being vaccinated.

Notice to Applicants and Employees who reside within New York city. Click https://careers.pypl.com/Contact-Us/default.aspx

to view the notice.

REQ ID R0119020",Full-time
4120826371,10667.0,"Data Engineer, Product Analytics","As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a world-class data engineering community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Data Engineer, Product Analytics Responsibilities:


 * Manage and execute data warehouse plans for a product or a group of products to solve well-scoped problems
 * Identify the data needed for a business problem and implement logging required to ensure availability of data, while working with data infrastructure to triage issues and resolve
 * Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights in a meaningful way
 * Build data expertise and leverage data controls to ensure privacy, security, compliance, data quality, and operations for allocated areas of ownership
 * Design, build and launch new data models and visualizations in production, leveraging common development toolkits
 * Independently design, build and launch new data extraction, transformation and loading processes in production, mentoring others around efficient queries
 * Support existing processes running in production and implement optimized solutions with limited guidance
 * Define and manage Service Level Agreements for data sets in allocated areas of ownership
   
   

Minimum Qualifications:


 * Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent
 * 2+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions
 * 2+ years of experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala or others.)
   
   

Preferred Qualifications:


 * Master's or Ph.D degree in a STEM field
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$114,000/year to $171,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4125076115,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
3875376305,46623.0,Data Engineer,"Description

Your role at GEI.

GEI Consultants has an opening in our Operational Development Team for a qualified Data Engineer to support a variety of systems and data engineering tasks focused on data flow activities. The majority of our systems are based in MS SQL Server, Tableau Server, Azure, and FastField Forms. This person will primarily work closely with members of the Operational Development Team and with members of our IT staff. The ideal candidate will be focused, detail-oriented, and driven to attain and maintain very high standards for efficiency and accuracy in data acquisition and integration into our systems. The ideal candidate will have more than 3 years of data engineering experience in the AEC industry or in similar science and/or engineering environments. GEI seeks a committed, self-motivated, organized and detail-oriented individual who anticipates issues and thrives on creative, independent problem solving within a rapid, deadline-driven environment.

Essential Responsibilities & Duties


 * ETL of data from a wide variety of sources
 * Database and Data Warehouse design/expansion/backup & recovery
 * Index management and optimization
 * Support data sources for Tableau Server, Power BI, and ArcGIS
 * Stored procedure development and maintenance
 * Identify new opportunities within GEI where existing business approaches to data can be replaced with a more efficient/automated data flow and presentation of data for analysis
 * Develop and optimize ETL/SSIS packages to facilitate data transfer between FTP, remote data loggers, Azure, and on-premises databases
 * Troubleshoot SSIS package permission issues related to execute-as/data source read/write access
 * SQL Agent Job development and monitoring
 * Develop data reporting and visualizations as specified by clients using Tableau, SSRS, etc
 * Perform DML and DDL via tsql/stored procedures executed directly within SSMS and remotely via SSIS
 * Develop test plans, implementation plans, and project timelines for various data engineering projects
 * Define, prioritize, communicate, and foster shared understanding of project objectives and scope
 * Coordinate the development of standard operating procedures (SOPs), technical training programs, and QA/QC procedures for staff and work product
 * Team with all staff necessary to complete assignments
 * Collaborate with technical team members to ensure the solution design satisfies project objectives and business requirements
 * Other duties as assigned
   
   

Minimum Qualifications


 * 3+ years of experience in a position performing similar data engineering tasks
 * Proven record of ability to design, manage, and support MS SQL Server and Azure databases
 * Ability to work with the following programming/mark-up/scripting languages preferred: VB.net, python, XML, javascript, and R
 * Bachelor's Degree, from an accredited college or university
 * MS SQL Server/Azure certification preferred
 * Ability to develop project plans and meet deadlines
 * Self-starter with attention to detail and stakeholder needs
 * Able to critically analyze and solve problems of a complex nature
 * Excellent Communication skills
 * Able to work on multiple projects of moderate complexity simultaneously and independently
 * Proficient in organization and time management skills
 * Familiarity with engineering, environmental science, and/or chemistry subject matter preferred.
 * Able to work effectively in GEI’s partnership model, including a team environment, building rapport and relationships.
   
   

We are GEI.

Some of the world’s most pressing problems - from climate change to sustainable development, to critical infrastructure and the future of our energy supply - need our brightest and diverse minds working together to create safer, more resilient communities for tomorrow.

We are technical experts, collaborators, and entrepreneurs who draw from diverse backgrounds to solve our clients’ most complex challenges.

With nearly 60 offices across North America, we offer a range of engineering, science, and technical consulting services. Our range of expertise, project types, and culture make us the choice for top talent in the AEC industry.

Employee-owned. Employee-focused.

As a 100% employee-owned company, our employees support our flat leadership structure, have a say in how our business operates and benefit from our financial success. We are committed to employee growth with career development opportunities, competitive total rewards, a well-being program, flexible work arrangements and more. Our company culture is driven by our 4 Cs - we are Client-Centered, Curious, Collaborative, and Community Minded - which support our focus on sustainability, safety, diversity, equity and inclusion. Get to know us better by visiting GEI’s career site here.

GEI’s Total Rewards Package


 * Market-Competitive Compensation, including Eligibility for an Annual Performance Bonus
 * Pay Range For This Position: $33.65-72.11/hour
 * Comprehensive Benefits Program, including Medical, Dental, Vision, Life, Disability and More
 * Well-Being Program and Paid Parental Leave
 * Commuter Benefits
 * Hybrid Work Schedules and Cell Phone Stipends
 * GEI University (GEIU) with Continuing Education Assistance and Tuition Reimbursement
 * Connecting Conversation Program with a Focus on Professional Development and Opportunities for Advancement
 * Support and Financial Rewards for Publication Awards, Professional Dues, and Professional Licenses
 * Paid Holidays and Generous Paid Time Off Program
 * Rewards and Recognition
 * GEI-Funded Profit Sharing and 401(k)
 * Opportunity to be an Owner and Shareholder (Learn more here)
 * A Vibrant Culture that is Focused on Partnership, Sustainability, Giving Back to Our Communities and Diversity, Equity and Inclusion
 * And More…
   
   

Physical Job Requirements

Sedentary

X

Light

Medium

Other

Activity Level Throughout Workday

Physical Activity Requirements

Occasional

(0-35% of day)

Frequent

(33-66% of day)

Continuous

(67-100% of day)

Not Applicable

Sitting

X

Standing

X

Walking

X

Climbing

X

Lifting (floor to waist level) (in pounds)

X

Lifting (waist level and above) (in pounds)

X

Carrying objects

X

Push/pull

X

Twisting

X

Bending

X

Reaching forward

X

Reaching overhead

X

Squat/kneel/crawl

X

Wrist position deviation

X

Pinching/fine motor skills

X

Keyboard use/repetitive motion

X

Taste or smell (taste=never)

X

Talk or hear

X

Accurate 20/40

Very Accurate 20/20

Not Applicable

Near Vision

X

Far Vision

X

Yes

No

Not Applicable

Color Vision (ability to identify and distinguish colors)

X

Sensory Requirements

Minimal

Moderate

Accurate

Not Applicable

Depth perception

X

Hearing

X

Environmental Requirements

Occupational Exposure Risk Potential

Reasonably Anticipated

Not Anticipated

Blood borne pathogens

X

Chemical

X

Airborne communicable diseases

X

Extreme temperatures

X

Radiation

X

Uneven surfaces or elevations

X

Extreme noise levels

X

Dust/particular matter

X

Other (exposure Risks)

Usual workday hours:

X

8

10

12

Other work hours

GEI is an AA/equal opportunity employer, including disabled and veterans.",Full-time
4087430535,36095797.0,Data Engineer,"EvenUp is one of the fastest-growing generative AI startups in history, on a mission to level the playing field for personal injury victims, which range from motor vehicle accidents to child abuse cases. Our products empower law firms to secure faster settlements, higher payouts, and better outcomes for those who need it most.

We have experienced unprecedented growth and need to scale out our data warehousing, data tooling and internal analytics. As a Data Engineer on this team, we will architect the future of our data infrastructure at EvenUp and we’re seeking engineering leaders to help drive that vision. We will need to 10x our pipeline processing throughput over the next 12 months and to do that, we’ll need to rethink and rebuild how we extract, process and model our ingestion to enable our organization with precise and actionable data.

This is a hybrid role with 2-3 days per week spent collaborating with the team in the office. We are open to applicants located in either the San Francisco Bay Area or the Greater Toronto Area.

What You’ll Do


 * Democratize data at EvenUp. Ensure our organization can scale with consistent, standardized access to our data stores and accelerate our ability to build and experiment with data products
 * Architect and build out the future of data warehousing at EvenUp
 * Enable and empower our Data Science team to rapidly iterate on model experimentation
 * Design, organize and refine data storage strategies that reduce development friction for our tech organization
 * Collaborate with cross functional teams to solve critical data problems
 * Help grow our nascent Analytics team and define a “data first” mentality across our organization
   
   

What We Look For


 * Extensive professional data engineering experience
 * Previous experience building out data warehousing, data pipelines, and internal analytics
 * Strong understanding and practical experience with data tooling, BI tools, and systems such as DBT, BigQuery, Elasticsearch
 * The ability to communicate cross-functionally with various stakeholders to derive requirements and architect scalable solutions
 * Have several years of industry experience building high-quality software, shipping production-ready code and infrastructure
 * You enjoy owning a project from start to finish and love to drive a project across the finish line
 * Interest in making the world a fairer place (we don’t get paid unless we’re helping injured victims and/or their attorneys)
   
   

Benefits & Perks

Our goal is to empower every team member to contribute to our mission of fostering a more just world, regardless of their role, location, or level of experience. To that end, here is a preview of what we offer:


 * Choice of medical, dental, and vision insurance plans for you and your family
 * Flexible paid time off
 * 10 US observed holidays, and Canadian statutory holidays by province
 * A home office stipend
 * 401(k) for US-based employees
 * Paid parental leave
 * Sabbatical program
 * A meet-up program to get together in person with colleagues in your area
 * Offices in San Francisco and Toronto
   
   

Please note the above benefits & perks are for full-time employees

About EvenUp

EvenUp is on a mission to level the playing field in personal injury cases. EvenUp applies machine learning and its AI model known as Piai™ to reduce manual effort and maximize case outcomes across the personal injury value chain. Combining in-house human legal expertise with proprietary AI and software to analyze records. The Claims Intelligence Platform™ provides rich business insights, AI workflow automation, and best-in-class document creation for injury law firms. EvenUp is the trusted partner of personal injury law firms. Backed by top VCs, including Bessemer Venture Partners, Bain Capital Ventures (BCV), SignalFire, NFX, DCM, and more, EvenUp’s customers range from top trial attorneys to America’s largest personal injury firms. EvenUp was founded in late 2019 and is headquartered in San Francisco. Learn more at www.evenuplaw.com.

EvenUp is an equal opportunity employer. We are committed to diversity and inclusion in our company. We do not discriminate based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

",Full-time
4138391474,1586.0,"Data Engineer, Amazon Shipping","Description

Amazon’s global fulfillment network enables any merchant to ship items that are ordered on Amazon to any place on earth. There is a complex network of ways in which items move between vendor locations, Amazon warehouses, and customer locations as well as several intermediate locations through which packages travel before reaching the customer. With a scale of millions of packages, each with different attributes and delivery requirements, what results is a highly dense graph of nodes.

We have built a highly respected BI and Data Engineering team which is focused on solving complex problems in worldwide transportation using workflows, optimization algorithms, and machine learning systems. These are large-scale distributed systems handling millions of packages being shipped through the Amazon logistics network.

As a Data Engineer, you will develop data pipelines, datasets, manage data infrastructures, build automated BI services to support strategic planning within Amazon Shipping.

Basic Qualifications


 * 1+ years of data engineering experience
 * 2+ years of analyzing and interpreting data with Redshift, Oracle, NoSQL etc. experience
 * Bachelor's degree in a quantitative/technical field such as computer science, engineering, statistics
 * Knowledge of distributed systems as it pertains to data storage and computing
 * Experience with data modeling, warehousing and building ETL pipelines
 * Experience with one or more query language (e.g., SQL, PL/SQL, DDL, MDX, HiveQL, SparkSQL, Scala)
 * Experience with one or more scripting language (e.g., Python, KornShell)
   
   

Preferred Qualifications


 * Experience with big data technologies such as: Hadoop, Hive, Spark, EMR
 * Experience with any ETL tool like, Informatica, ODI, SSIS, BODI, Datastage, etc.
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $91,200/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com LLC

Job ID: A2859440",Full-time
4090674532,96668235.0,Data Engineer,"Job Title: Data Engineer

Location: Nashville, TN (3 days onsite)

Duration: 12 Months +

Job Type: Contract

I am looking for Data Engineer who has extensive Oracle Database Development & deep coding experience in Oracle PL/SQL as they will be designing and developing modules in Sony Music Publishing’s proprietary application housed in Oracle.

External Communities Job Description

Data Engineer supporting proprietary Oracle Application

Who You Are: (required experience and skills)


 * 5+ years of Oracle Database Development Experience through all development life cycle phases
 * Has deep coding experience in Oracle PL/SQL
   
   

Enterprise Req Skills

Etl, Big data, Cloud, Python, SQL, Data, Aws

Top Skills Details


 * 5+ years of Oracle Database Development Experience through all development life cycle phases
 * Oracle PL/SQL experience including analysis, design, and creation of custom packages, stored procedures, functions, and triggers
 * Ability to analyze and create high-performance SQL queries over very large datasets
   
   

Skills


 * Oracle PL/SQL including analysis, design, and creation of custom packages, stored procedures, functions, and triggers
 * Oracle Scheduler integration for on-demand requirements
 * Ability to analyze and create high-performance SQL queries over very large datasets
 * Dynamic SQL and BULK Collection methodologies
 * ETL functions using External tables, Oracle’s UTL_FILE package, and SQL Loader
 * DDL and DML scripting
 * LINUX shell scripting
 * Database development IDE; Quest Toad for Oracle or other
 * AWS Workspace development environment
 * GitLab code repositories; SourceTree or other git tools
 * Effective communication and interpersonal skills for the purpose of understanding complex technical issues and solutions",Contract
4090109946,49151727.0,Data Engineer,"Company Description

CoLab is a fully integrated, cross-discipline team that provides best-in-class services in a fluid and modular way. With our clients at the center, we create brand movement at the speed of people’s lives by connecting real-time data with world-class creative, content, and media in service of growth and Return on investment.

CoLab is a “power of one” solution, encompassing data, media, and production. By drawing from across the vast Publicis Groupe network, we are uniquely positioned to deliver innovation and specialized skills to our clients, as well as enriching opportunities and inclusive benefits to our employees. We pride ourselves on combining the atmosphere of a startup company with the stability and experience of a global leader.

Overview

Our team is looking for a high-performing Data Engineer who will be responsible for the design, development, implementation and on-going support of a data driven software platform. You enjoy and thrive in a fast-paced environment on multiple projects simultaneously, including both enhancements as well as new project development. The candidate must be a self-starter with a sense of urgency and a commitment to quality and professionalism.

Responsibilities


 * Analyze ambiguous business requirements and partner with product team to provide a strategic solution
 * Collaborate with frontend engineers to design or modify schema for optimal software performance
 * Advanced database administration and development including stored procedures, user defined functions, triggers and ETL packages as well as security and roles
 * Uphold quality standards and create monitoring tools to ensure high fidelity data
 * Optimization and tuning of existing stored procedures to improve performance
 * Troubleshoot database issues, identify root causes, and implement optimal solutions
 * Extract, transform, and load data from multiple data sources using languages and tools such as Python and AWS Glue
 * Design, Build, Test, Debug, Monitor, and Troubleshoot ETL and software processes in Python
 * Recommend solutions to existing or anticipated issues
 * Serve as an escalation point for any issues that may arise
 * Design testing requirements and prepare test plans and test modules
 * Ability to follow implementation standards, develop documentation and transfer of knowledge
 * The following experience is a plus:
 * Experience with Snowflake
 * Experience with Business Intelligence software (Tableau, PowerBI)
 * Experience and thorough understanding of a variety of APIs
 * Experience supporting analytics and data science teams/tools (Pandas, R, Alteryx)
 * Experience with front-end development
   
   

Qualifications


 * 4+ years’ experience with ETL and databases, (Redshift preferred)
 * 4+ years’ experience with Python
 * Familiarity with cloud technologies such as Amazon Web Services (Redshift, S3, Glue, Lambda)
 * Advanced PostgreSQL programming skills (stored procedures, functions, etc.)
 * Experience with marketing data and digital media
 * Experience with complex processing logic against large data sets
 * Excellent data modelling skills and experience working with multiple datasets
 * Possession of strong communication and presentation skills as well as an analytical mindset
 * Good problem solving and testing skills
 * Familiarity with code versioning tools such as Git
 * Strong organizational skills & attention to detail
 * Possess a desire to work for a fast-paced, results-based company
 * Experience managing multiple projects simultaneously
 * Self-driven/entrepreneurial spirit with the ability to think outside of the box
 * Bachelor’s Degree in Computer Sciences, Information Technology, or equivalent
   
   

Additional Information

Our Publicis Groupe motto “Viva La Différence” means we’re better together, and we believe that our differences make us stronger. It means we honor and celebrate all identities, across all facets of intersectionality, and it underpins all that we do as an organization. We are focused on fostering belonging and creating equitable & inclusive experiences for all talent.

Publicis Groupe provides robust and inclusive benefit programs and policies to support the evolving and diverse needs of our talent and enable every person to grow and thrive. Our benefits package includes medical coverage, dental, vision, disability, 401K, as well as parental and family care leave, family forming assistance, tuition reimbursement, and flexible time off.

If you require accommodation or assistance with the application or onboarding process specifically, please contact USMSTACompliance@publicis.com.

All your information will be kept confidential according to EEO guidelines.

Compensation Range: $87,210 - $137,195 annually. This is the pay range the Company believes it will pay for this position at the time of this posting. Consistent with applicable law, compensation will be determined based on the skills, qualifications, and experience of the applicant along with the requirements of the position, and the Company reserves the right to modify this pay range at any time. Temporary roles may be eligible to participate in our freelancer/temporary employee medical plan through a third-party benefits administration system once certain criteria have been met. Temporary roles may also qualify for participation in our 401(k) plan after eligibility criteria have been met. For regular roles, the Company will offer medical coverage, dental, vision, disability, 401k, and paid time off. The Company anticipates the application deadline for this job posting will be 02/17/2025.",Full-time
4064417083,66321745.0,Junior Data Engineer,"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you need

Position open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, IT enthusiasts, Python/Java developers, Data analysts/ Data Scientists.

We welcome candidates with all visas and citizens to apply.

Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates looking to make their careers in IT Industry

We assist in filing for STEM extension and also for H1b and Green card filing.

Candidates who are serious about their future in the IT Industry and have set big goals for themselves.

Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience which our clients need with great outcomes

Candidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancement

Candidates Who Lack Experience

Have had a break in careers

Lack Technical Competency

Different visa candidates who want to get employed and settle down in the USA

Please Also Check The Below Links

https://www.synergisticit.com/candidate-outcomes/

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

How Can Recently Laid Off Tech People Get Employed Again? | SynergisticIT

If not a match candidates can opt for Skill enhancement.

REQUIRED SKILLS For Java/Software Programmers


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Core Java , javascript , C++ or software programming
 * Spring boot, Microservices and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, Python, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, Time series analysis

Please understand skills are required by clients for selection even if its Junior or entry level position the additional skills are the only way a candidate can be picked by clients.

No third party candidates or c2c candidates

Please understand skills are required by clients for selection even if its Junior or entry level position the additional skills are the only way a candidate can be picked by clients.

Please apply to the posting

No phone calls please. Shortlisted candidates would be reached out.",Contract
4151639597,445873.0,Data Engineer," * Working on groundbreaking projects here is a game-changer. I leverage advanced analytics and machine learning while collaborating with a brilliant team. The innovative environment has given me the tools and support to push the boundaries of data science and drive meaningful impact.
 * - J. Gem, Data Scientist
   
   

As an AWS Data Engineer, you�ll play a crucial role in shaping our data infrastructure and analytics capabilities. You'll design, build, and optimize scalable data pipelines and platforms, empowering our teams to harness data for strategic decision-making. This is an exciting opportunity to work with the latest AWS technologies and contribute to high-impact projects that drive our business forward.

Core Functions


 * Data Pipeline Development: Design, deploy, and refine cutting-edge, scalable data pipelines on AWS to ingest, process, and store massive datasets for next-gen machine learning applications.
 * Machine Learning Integration: Collaborate with data scientists to deploy, manage, and enhance machine learning models on AWS, creating innovative models to improve performance and ensuring seamless integration with data pipelines.
 * User Interface Integration: Use your hands-on UX/UI development experience to work with front-end developers and UX/UI designers, integrating machine learning outputs into intuitive user interfaces for efficient data delivery.
 * AWS Infrastructure Management: Utilize AWS services such as S3, Redshift, Lambda, Glue, EMR, and QuickSight to build and maintain a robust data infrastructure, ensuring systems are secure, scalable, and high performing.
 * Automation and Optimization: Develop and implement automation scripts and tools, including Python, to streamline data workflows and model deployments. Continuously monitor and optimize performance, costs, and resource utilization, setting up alerts for any disruptions.
 * Collaboration and Communication: Work closely with data scientists, front-end developers, UX/UI designers, and product managers to deliver high-quality solutions that align with business goals.
 * Documentation: Maintain comprehensive and up-to-date documentation for data pipelines, infrastructure configurations, integration processes, and technology procedures.
   
   

Collaborative Responsibilities


 * Data Source Identification: Identify and evaluate cutting-edge data sources to leverage the best information for transformative insights.
 * Data Analysis: Analyze data to uncover trends and patterns, validate results, and identify anomalies to ensure accuracy.
 * System Enhancement: Enhance and optimize databases and data systems, ensuring they run smoothly and adapt to evolving needs.
 * Performance Review: Review reports and performance indicators to identify issues, refine logic, and drive continuous improvement.
   
   

What We�re Looking For


 * Bachelor�s degree in computer science, Engineering, Information Management, Data Science, or a related field.
 * 3+ years of experience in data engineering with a focus on AWS Cloud Services.
 * Strong proficiency in AWS services (S3, Lambda, Glue, EMR, QuickSight, etc.).
 * Experience with data pipeline tools and technologies (Apache Airflow, Spark, etc.).
 * Familiarity with Python, GitHub, SQL, and containerization (such as Docker), CI/CD pipelines, etc.
 * Strong analytical skills with attention to detail and accuracy in collecting, organizing, analyzing, and presenting data.
 * Exceptional communicator with the ability to thrive in a collaborative, team-oriented environment.
 * Outstanding critical thinking and problem-solving abilities, with a keen aptitude for analyzing and interpreting data.
 * Understanding of data models and process flows, with the capability to navigate and optimize them effectively.
 * Ability to work autonomously and contribute effectively within a team, with a strong capacity to adapt swiftly to evolving situations and ideas.
   
   

Work Schedule

Work Monday to Friday from 8:00 a.m. to 5:00 p.m.

Competitive wage range: $25 - $30 per hour, commensurate with experience and qualifications.

This hybrid position requires onsite presence in our San Diego, California location 2-3 days per week after a 90-day training period and upon management approval.

Benefits

Enjoy a balanced work/life environment with a robust wellness program, PTO, remote work, and flexible schedules (where available). Full-time employees become eligible for benefits following a 30-day waiting period, with benefits offering that includes medical, dental, vision, life, AD&D, EAP, STD, and LTD. Additionally the firm provides parental leave for both primary and non-primary caregivers as well. Also available are voluntary income protection benefits such as supplemental life, accident, critical illness, and short and long-term care insurances, as well as a 401(k)-retirement plan with a company match. Part-time employees may have access to some of these benefits, which may be on a pro-rated basis.

Physical Demands

While performing the duties of this job, the employee is consistently required to: walk; use hands to finger, grasp, feel objects tools or controls; reach with hands and arms; balance; stoop and consistently sit, talk or hear. Employees may be required to perform all functions on a repetitive basis.

Exert up to 10 pounds of force occasionally; lift, carry, push, pull or otherwise move objects, to include the human body.

Specific vision abilities required by the job include close vision, distance vision, color vision, peripheral vision, depth perception and the ability to adjust focus. The physical demands and work environment characteristics described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Security Requirement

While performing the duties of this job, the employee is required to ensure the security and confidentiality of all sensitive information, including but not limited to threats or hazards to the security or integrity of sensitive information that could result in any harm or inconvenience to any customer, employee or the company.

Work Environment

Typical office environment with a quiet to moderate noise level.

Ready to take the next step? Apply now and be part of our thriving team!

https://mccarthyholthus.hrmdirect.com/employment/job-openings.php?search=true&&cust_sort1=200442

Notice

The above information on this job description has been described to indicate the general nature and level of work performed by incumbents. Other duties and responsibilities not specifically described may be assigned from time to time, consistent with knowledge, skills and abilities of the incumbent.

McCarthy Holthus and our affiliate companies are Equal Opportunity Employers. We are committed to providing a work environment free from discrimination and harassment. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law. We celebrate diversity and are dedicated to creating an inclusive environment for all employees.

McCarthy Holthus and our affiliate companies will consider qualified applicants with a criminal history pursuant to the San Diego County Fair Chance Ordinance and the California Fair Chance Act. You do not need to disclose your criminal history or participate in a background check until a conditional job offer is made to you. After making a conditional offer and running a background check, if McCarthy Holthus and our affiliate companies is concerned about conviction that is directly related to the job, you will be given the chance to explain the circumstances surrounding the conviction, provide mitigating evidence, or challenge the accuracy of the background report. Find out more about the Fair Chance Ordinance by visiting the San Diego County Office of Labor Stands and Enforcement webpage.

As part of our commitment to maintaining a lawful and compliant workforce, McCarthy Holthus and our affiliate companies participate in the E-Verify program. All candidates who accept a job offer will be required to complete the E-Verify process to verify their employment eligibility in the United States.

Applications will be accepted until the closing date of 2-20-2025.",Part-time
4146947895,23662.0,Data Engineer Intern,"Are you a highly motivated college student eager to gain hands-on experience and develop your technical and analytical skills? Kimball Midwest, a national leader in maintenance, repair, and operation products, is looking for a Data Engineer Intern to join our team in Columbus, OH. This is your chance to work on real-world data engineering projects, gain valuable industry experience, and contribute to our data modernization efforts in a collaborative and fast-paced environment.

As a Kimball Midwest associate, you will experience why we have been recognized as one of the Top Workplaces in Columbus TWELVE years in a row! Our sales revenue growth is dynamic, increasing from $1 million in 1983 to over $500 million today. Throughout all our growth we have kept the family owned and operated culture alive. At Kimball Midwest, you are a name and not a number and we pride ourselves on our unique culture.

Responsibilities


 * Assist in data modernization projects to ensure scalable, secure, and stable data solutions.
 * Support the integration of data from multiple sources into the company’s data warehouse.
 * Read, review, and analyze complex SQL code to ensure data accuracy, consistency, and integrity.
 * Document findings, technical processes, and system designs to support internal documentation efforts.
 * Participate in Agile Scrum processes, including daily stand-ups, sprint planning, and retrospectives.
 * Work closely with IT teams to ensure data integrity, security, and compliance with company policies.
 * Assist in developing and maintaining data models, pipelines, and architecture for efficient data processing.
 * Collaborate with business and IT stakeholders to ensure alignment between source systems and data platforms.
   
   

Qualifications


 * Currently enrolled in a bachelor’s degree program in Computer Science, Software Engineering, Data Analytics, or related field.
 * Preferred experience or coursework in SQL (T-SQL), Azure Data Services, and ADO (Azure DevOps).
 * Strong communication and collaboration skills.
 * Ability to work independently and within a team.
 * Detail-oriented with strong analytical skills.
   
   

Additional Information

We offer a benefits package that includes health, dental and vision insurance, company sponsored life, optional life and disability insurance, Health Savings Accounts and Flexible Spending Accounts, a 401(k) plus match, Tuition Assistance, Paid Parental Leave, Paid Time Off (PTO), a Dress for your Day dress code and paid holidays.

Kimball Midwest is an equal opportunity employer that is committed to a program of recruitment of females, minority group members, individuals with disabilities, qualifying veterans and any other classification that is protected by federal, state, or local law.

We Participate in E-Verify. Participamos en E-Verify.

",Internship
4114569752,1742506.0,Data Engineer,"Title: Data Engineer
Location: Remote - US
Duration:  11months, can extend
Compensation: $65-68hr
Work Requirements: US Citizen, GC Holders or Authorized to Work in the U.S.
Skillset / Experience:


The Data Engineer will join a critical engineering team responsible for maintaining data infrastructure utilized by global customers. You will have ownership of a critical data lake. You will be responsible for collaborating with customers and internal teams to build and maintain data pipelines, onboard data sets into the data lake, and respond to customer requests regarding critical data. You will also support migration activities. 
Successful candidates will have:
 * 6+ years of experience creating and maintaining enterprise data pipelines (terabyte, exabyte) - strong experience onboarding data sets into a data lake
 * Experience contributing to system design or architecture
 * Experience developing data pipeline parsers (Scala), experience with compression technology (Apache Parquet)
 * AWS experience required, experience with CDK - ECS
 * Strong experience with SQL - ability to write and amend complex queries
 * Strong scripting experience with Python

W2, direct hires only. No C2C or vendor opportunities available.

JOB BENEFITS 
 * Medical, vision, and dental insurance 

 
About INSPYR Solutions
Technology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients’ business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com.
INSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities.
 ",Contract
4152142438,86694680.0,Senior Data Engineer,"About Ascendion

Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next.




Ascendion | Engineering to elevate life

We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:

 * Build the coolest tech for the world’s leading brands
 * Solve complex problems – and learn new skills
 * Experience the power of transforming digital engineering for Fortune 500 clients
 * Master your craft with leading training programs and hands-on experience




Experience a community of change-makers!

Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.




About the Role:




Job Title: Data Engineer




Role Overview:

About the Role:

We are seeking a skilled Data Engineer to design, build, and optimize scalable data pipelines in a cloud environment. The ideal candidate will have strong experience in Python, AWS (Glue, Lambdas), and PySpark, with a focus on automated testing to ensure data integrity and reliability.




Responsibilities:

Develop and maintain ETL pipelines using AWS Glue and PySpark.

Implement serverless data processing with AWS Lambda.

Ensure data quality and reliability through automated testing.

Optimize data workflows for performance and scalability.

 * Collaborate with cross-functional teams to support data-driven solutions.




Qualifications:

 * Strong Python programming skills for data processing and automation.
 * Experience with AWS Glue and AWS Lambda for serverless data workflows.
 * Proficiency in PySpark for big data processing.
 * Hands-on experience with automated testing in a data pipeline context.




Preferred Qualifications:

 * Familiarity with Behave framework for automated testing in Python.
 * Experience with CI/CD for data pipelines.
 * Knowledge of data governance and security best practices.




Locations: McLean, VA




Salary Range: The salary for this position is between $130K– $150K annually. Factors that may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.




Benefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal days accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertain to the City/ State] [10-15 days of paid vacation time] [6 paid holidays and 1 floating holiday per calendar year] [Ascendion Learning Management System]




Want to change the world? Let us know.

 * Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let’s talk!",Full-time
4143007707,162515.0,Data Engineer,"Aristotle, a leading player in the computer software industry, is currently seeking a talented and driven Data Engineer to join our dynamic team. At Aristotle, we have a deep-rooted belief in the importance of the democratic process, which serves as the foundation of everything we do. We are committed to advancing democracy around the world through innovative software solutions that empower organizations and individuals alike.

As a Data Engineer, you'll be an integral part of our mission to revolutionize the way data is utilized. You'll have the opportunity to work and learn in a collaborative environment where your opinions truly matter. We welcome passionate individuals who are dedicated to advancing the democratic process, regardless of their political affiliation. Join us at Aristotle and love what you do while contributing to a greater cause.

Aristotle’s Integrity division is a leading provider of identity and age verification services across numerous vertical markets. Our age/identity verification solutions are used by companies to comply with various regulatory requirements such as AML, KYC and Age Verification.

Please visit https://integrity.aristotle.com for more information about this division.

Responsibilities


 * Data Load and Transformation: Develop data load processes for efficient storage and retrieval of data from databases and other file systems. Create data conversion and transformation processes and utilities for handling large datasets.
 * Solution Development: Utilize .NET/SSIS/SQL Server technologies to design and implement solutions that align with data consumer requirements and adhere to business rules.
 * Web-Based Reporting: Build web-based reporting systems to monitor system performance, transaction metrics, and error rates.
 * Data Transformation Rules: Collaborate in defining and documenting data transformation rules to ensure data integrity and accuracy.
 * ETL Design and Performance: Focus on the design, development, and performance tuning of ETL (Extract, Transform, Load) processes to optimize data processing efficiency.
 * Collaborative Development: Work closely with other developers to provide data services to both existing and new applications. This includes modifying production data, creating and optimizing stored procedures, functions, views, and more.
 * System Performance Enhancement: Develop and analyze strategies to enhance system performance, ensuring efficient data processing and retrieval.
 * Documentation and Testing: Prepare comprehensive documentation and test procedures to ensure the reliability and quality of developed solutions.
 * Industry Standard Practices: Develop software using industry-standard programming techniques to maintain code quality and consistency.
 * Unit Testing and Debugging: Perform unit testing and debugging of application components to identify and resolve issues promptly.
   
   

Requirements


 * Bachelor's or Associate's degree in Computer Science or a related field.
 * Minimum of 2 years of hands-on experience with ETL (Extract, Transform, Load) processes.
 * Proficiency in T-SQL programming and working with Microsoft SQL Server 2005 and 2008. A deep understanding of the SQL Server Query Processing Engine is required.
 * Knowledge and experience in designing, developing, debugging, and deploying SQL Server stored procedures, T-SQL scripts, DTS (Data Transformation Services), and SSIS (SQL Server Integration Services) packages.
 * Ability to manage multiple priorities, adhere to project plans, and consistently meet project deliverables.
 * Proficiency in Microsoft SQL as well as Microsoft SQL Server Reporting Services. Familiarity with MS Office applications, including Word and Excel.
 * Demonstrated ability to quickly learn and adapt to new technologies as needed.
   
   

Desired Requirements


 * Proficiency in using Microsoft Visio for creating sequence diagrams, component diagrams, and other UML (Unified Modeling Language) diagrams.
 * Proficiency in data modeling using tools such as MS Visio or Erwin data modeler.
 * Familiarity with identity verification for fraud, marketing, and risk mitigation solutions within the industry.
 * Knowledge of internet technologies, including XML, DHTML, CSS, and JavaScript.
 * Familiarity with ASP.NET 2.0, C#, and Traditional ASP (Active Server Pages).
   
   

Benefits

All positions are Full-Time, with competitive compensation, medical benefits, paid vacation, 401k plan and stock options. Casual dress code and a non-corporate atmosphere make this a fun place to work and learn in a team environment. Please visit our website at www.aristotle.com.",Full-time
4149180996,18476.0,Data Engineer,"Data Engineer

Contract

Cincinnati, OH




The data engineer designs and builds platforms, tools, and solutions that help manage, secure, and generate value from its data. The person in this role creates scalable and reusable solutions for gathering, collecting, storing, processing, and serving data on both small and very large (i.e. Big Data) scales. These solutions can include on-premise and cloud-based data platforms, and solutions in any of the following domains ETL, business intelligence, analytics, persistence (relational, NoSQL, data lakes), search, messaging, data warehousing, stream processing, and machine learning.




ESSENTIAL DUTIES AND RESPONSIBILITIES:-

 * Responsible for design, Development, and Support of data solutions, APIs, tools, and processes to enable rapid delivery of business capabilities.
 * Work closely with IT application teams, Enterprise architecture, infrastructure, information security, and LOB stakeholders to translate business and technical strategies into data-driven solutions.
 * Act as a technical Expert addressing problems related to system and application design, performance, integration, security, etc.
 * Conduct research and Development based on current trends and technologies related to the banking industry, data engineering and architecture, data security, and related topics.
 * Work with developers to Build CI/CD pipelines, Self-service Build tools, and automated deployment processes.
 * Evaluate software products and Provide documented recommendations as needed.
 * Provide Support and troubleshooting for data platforms. Must be willing to Provide escalated on-call Support for complicated and/or critical incidents.
 * Participate in the planning process for hardware and software.
 * Plan and work on internal projects as needed, including legacy system replacement, Monitoring and analytics improvements, tool Development, and technical documentation.
 * Provide technical guidance and mentoring for other team members.
 * Manage and prioritize multiple assignments.




MINIMUM KNOWLEDGE, SKILLS, AND ABILITIES REQUIRED:

 * Bachelor's degree in Computer Science/Information Systems or equivalent combination of education and experience.
 * Must be able to communicate ideas both verbally and in writing to management, business and IT sponsors, and technical resources in language that is appropriate for each group.
 * Fundamental understanding of distributed computing principles
 * Knowledge of application and data security concepts, best practices, and common vulnerabilities.
 * Conceptual understanding of one or more of the following disciplines preferred big data technologies and distributions, metadata management products, commercial ETL tools, Bi and reporting tools, messaging systems, data warehousing, Java (language and run time environment), major version control systems, continuous integration/delivery tools, infrastructure automation and virtualization tools, major cloud, or rest API design and development.




MUST HAVE SKILLS

 * DBT/Snowflake 4-5 years
 * Strong Communications Skills
 * Able to run meetings
 * Problem Solving and Critical Thinking
 * Onsite in Cincinnati



NICE TO HAVE SKILLS/Experience

 * Analytical
 * DataStage
 * Dataiku
 * AFS system application (AFS Level III or Vision)

",Contract
4151623319,1097.0,Data Engineer,"When you join Verizon

You want more out of a career. A place to share your ideas freely — even if they’re daring or different. Where the true you can learn, grow, and thrive. At Verizon, we power and empower how people live, work and play by connecting them to what brings them joy. We do what we love — driving innovation, creativity, and impact in the world. Our V Team is a community of people who anticipate, lead, and believe that listening is where learning begins. In crisis and in celebration, we come together — lifting our communities and building trust in how we show up, everywhere & always. Want in? Join the V Team Life.

What You’ll Be Doing...

As a Data Engineer, you’ll work with world-class team members to help drive telecom business to its full potential. We are building data products/assets for telecom wireless and wireline business, which includes consumer analytics, telecom network performance and service assurance analytics. We are working on cutting-edge technologies like digital twin to build these analytical platforms and provide data support for varied AI ML implementations.

You’ll collaborate with business product owners, coaches, data scientists, and system architects to develop strategic data solutions. You will enable the required data sets from different sources both structured and unstructured data into our data warehouse and data lake with real-time streaming and/or batch processing to generate insights and perform analytics for business teams within Verizon.


 * Understanding the business requirements and converting them to technical design.
 * Working on Data Ingestion, Preparation, and Transformation.
 * Developing data streaming applications.
 * Debugging the production failures and identifying the solution.
 * Working on ETL/ELT development.
 * Understanding DevOps process and contributing for DevOps pipelines
   
   

What we’re looking for...

You’re curious about new technologies and the game-changing possibilities it creates. You like to stay up-to-date with the latest trends and apply your technical expertise to solving business problems.

You’ll Need To Have


 * Bachelor’s degree or four or more years of work experience.
 * Four or more years of relevant work experience.
 * Experience with Data Warehouse concepts and Data Management life cycle.
 * Experience in GCP cloud platform - (BigQuery, Cloud Composer, Data Proc (or Hadoop & Spark), Cloud Function).
 * Experience in any programming language, preferably Python.
 * Experience in troubleshooting the data issues.
 * Experience in writing complex SQL and performance tuning.
 * Experience in DevOps
   
   

Even Better If You Have


 * Proficiency in graph data modeling, including experience with graph data models and graph query language
 * Any relevant Certification on ETL/ELT developer.
 * Certification in GCP-Data Engineer.
 * Exposure to working on GenAI use cases.
 * Good problem-solving, analytical, and research capabilities.
 * Good verbal and written communication.
 * Experience presenting to and influencing stakeholders.
   
   

If Verizon and this role sound like a fit for you, we encourage you to apply even if you don’t meet every “even better” qualification listed above.

Where you’ll be working

In this hybrid role, you'll have a defined work location that includes work from home and a minimum eight assigned office days per month that will be set by your manager.

Scheduled Weekly Hours

40

Equal Employment Opportunity

We’re proud to be an equal opportunity employer - and celebrate our employees’ differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. At Verizon, we know that diversity makes us stronger. We are committed to a collaborative, inclusive environment that encourages authenticity and fosters a sense of belonging. We strive for everyone to feel valued, connected, and empowered to reach their potential and contribute their best. Check out our diversity and inclusion page to learn more.",Full-time
4130373024,66321745.0,Data Engineer (Junior),"For more than 14 years Synergisticit has helped Jobseekers stand out from other Jobseekers by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this market also our candidates get multiple job offers and $100k + salaries.

Please Check The Below Links

Synergisticit Pics /Salaries of Successful Candidates

Synergisticit at Oracle Cloudworld 2023

Synergisticit at Gartner Data & Analytics summit

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

Required Skills

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full Stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java , javascript , C++ or software programming

Spring boot, Microservices, Docker, Jenkins and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Contract
4148160102,9319439.0,Data Engineer,"The true B2B data pioneer, Bombora connects the B2B ecosystem in a one-of-a kind Data Cooperative—enabling a holistic view of an account's research and consumption behavior. From this data, Bombora derives actionable insights that make it possible for brands, agencies, and publishers to identify, understand, and reach their prospects and customers, throughout the buyer and user experience, across the activation platforms of choice.

Bombora is continually recognized by analyst firms as a leader in Intent data powering GTM data solutions.

As a Data Engineer, you will be responsible for developing and expanding our systems that handle billions of content interactions every day to detect intent signals from companies across the world. You will collaborate closely with product management, design, and other engineers, applying your strong critical thinking and analytical skills to transform visions into reality. Additionally, you will have the chance to lead cross-team initiatives, provide guidance to your team members, and establish engineering best practices. Bombora's engineering teams are very collaborative, supportive, curious and enjoy experimentation.

You will….


 * Develop and maintain scalable, high-performance ETL and data processing pipelines using Python, Airflow (Composer), and Dataflow.
 * Design cloud-native distributed data processing systems that are optimized for dynamic scaling, high availability, and parallel execution, leveraging Kubernetes and operational tools to ensure reliability and observability in production.
 * Design databases, optimize SQL queries, and implement efficient data processing patterns.
 * Work heavily within GCP (Google Cloud Platform) utilizing services including Composer, BigQuery, Pub/Sub, Dataflow, Kubernetes, and GCS.
 * Drive engineering excellence by maintaining coding standards and implementing best practices.
 * Have fun in an environment of collaboration, curiosity, and experimentation.
   
   

You have…


 * 5+ years of commercial software development experience in Python.
 * 5+ years of SQL experience (BigQuery preferred).
 * 3+ years of experience working with cloud and/or big data systems (GCP preferred)
 * Excellent communication and collaboration skills
 * Bachelor's degree or equivalent experience
   
   

Bonus points for….


 * GCP experience
 * Dataflow and Java
   
   

Perks and Benefits


 * Competitive Salary
 * Health / Dental / Vision
 * Flexible Spending Account
 * Commuter Benefits
 * Flexible Vacation / Paid Holidays
 * Education / Tuition Assistance
 * 401K / Match
 * Generous Parental Leave
 * On Demand Learning (Udemy)
 * Team Lunches / Outings /Events (Yes! We found a way to do virtually!)
 * Offices (for when you want one)
   
   

Compensation Package


 * The salary range for this position is $140,000 to $155,000 Actual compensation may vary and will be based on a candidate's qualifications, skills, experience, and location.
 * Equity
   
   

At Bombora, we embrace diversity because it breeds innovation. Bombora is an equal opportunity employer and participates in E-Verify. Employment offers are contingent upon completion of successful background checks.",Full-time
4136369909,101021.0,Data Engineer,"Location: Arlington, VA (Hybrid, candidates must live in the greater Washington, DC metro area)

Clearance Required: MUST HAVE AN ACTIVE SECRET CLEARANCE; an ACTIVE TOP SECRET is PREFERRED

Position Overview

AI / Analytics Platform Data Engineers are responsible for building and maintaining analytics systems using AWS cloud services. Their job responsibilities include:


 * Design and implement data modeling, ETL processes, and data structures to support machine learning and analytics.
 * Provide technical leadership and guidance to the development teams.
 * Participate in all phases of the software development lifecycle, from design to deployment.
   
   

Requirements


 * Knowledge of CI/CD
 * EMR Studio
 * Analytics Repo
 * GitHub experience
 * Clearance Required: Current Secret required
 * Must reside in the DC Metro area and be able to attend regularly scheduled in-person meetings
   
   

About Elder Research, Inc

People Centered. Data Driven

Elder Research is a fast growing consulting firm specializing in predictive analytics. Being in the data mining business almost 30 years, we pride ourselves in our ability to find creative, cutting edge solutions to real-world problems. We work hard to provide the best value to our clients and allow each person to contribute their ideas and put their skills to use immediately.

Our team members are passionate, curious, life-long learners. We value humility, servant-leadership, teamwork, and integrity. We seek to serve our clients and our teammates to the best of our abilities. In keeping with our entrepreneurial spirit, we want candidates who are self-motivated with an innate curiosity and strong team work.

Elder Research believes in continuous learning and community - each week the entire company attends a “Tech Talk” and each office location provides lunch. Elder Research provides a supportive work environment with established parental, bereavement, and PTO policies. By prioritizing a healthy work-life balance - with reasonable hours, solid pay, low travel, and extremely flexible time off - Elder Research enables and encourages its employees to serve others and enjoy their lives.

Elder Research, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

Elder Research is a Government contractor and many of our positions require US Citizenship.

This position specifically requires an active Secret Clearance.",Full-time
4125068143,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4148243134,2433416.0,Data Engineer II,"Our Opportunity

Chewy is seeking a Data Engineer II to join the growing Transportation Systems team. You will be a part of a team responsible for strategic system design, research initiatives, and financial data cataloging centered around our transportation planning and execution. This includes building enterprise data pipelines that drive analytic solutions and creating data products for analytics and data scientist team members to improve their productivity. The Transportation team operates in a fast-paced environment where every day brings new challenges and opportunities. You will be responsible for building and implementing data products and technologies which will handle the growing business needs and play a key role in redefining what it means to be a world-class ecommerce organization.

What You’ll Do


 * Own the design, development, and maintenance of our end to end data pipelines!
 * Tackle complex data issues to provide insights needed to accomplish our business goals
 * Develop data products for analytics and data scientist Team Members to boost their efficiency
 * Assist in crafting Proof of Concepts and advise, consult, mentor and coach other data and analytic professionals on data standards and practices
 * Lead the evaluation, implementation and deployment of emerging tools and process for analytic data engineering to improve our efficiency as a team
 * Develop and deliver communication and education plans on analytic data engineering capabilities, standards, and processes
 * Code, test, and detail new or modified data systems to build robust and scalable applications for data analytics
 * Actively contribute to team discussions and initiatives, valuing diverse perspectives and encouraging a cooperative work atmosphere.
 * Data cataloging & documentation of data sources
 * Regularly meet with business partners and analytics teams to understand and solve data needs, short-term and medium-term
 * Build trust with internal collaborators to encourage data-driven decision-making
 * Partner with data engineering to grow the value of our data products by onboarding new data from our backend and 3rd party systems
   
   

What You’ll Need


 * Bachelor of Science or Master's degree in Computer Science, Engineering, Information Systems or related field.
 * 5+ years of experience in Data Engineering or Business Intelligence roles working with ETL, Data Modeling, and Data Architecture, developing modem data pipelines and applications for analytics (e.g., BI, reporting, dashboards) and advanced analytics (e.g., machine learning, deep learning) use cases.
 * Current permanent U.S. work authorization is required
 * Expertise crafting and implementing enterprise data pipelines using modern data engineering approach and tools: Spark, PySpark, Scala, Docker, Databricks, Glue, cloud-native EDW (Snowflake, Redshift), Kafka/Confluence, Presto/Dremio/Athena
 * Proficiency in AWS ecosystem, Java, Python, SQL
 * Proficiency in data warehouse methodologies and techniques from transactional databases to dimensional data modeling, to wide denormalized data marts.
 * Experience with writing and reviewing version-controlled code (GitHub).
 * Experience with building statistical and predictive models from scratch.
 * Experience effectively presenting insights and summarizing complex data to diverse audiences through visualizations.
 * To be a self-starter with the ability to take initiative and drive projects forward independently.
 * Familiarity with supply chain and logistics a plus
 * Demonstrated experience working with and delivering to various key Team Members from different parts of the company (Finance, Engineering, Human Resources, Supply Chain etc.)
 * Excellent written and oral communication skills
 * This role requires 5% domestic travel
   
   

Chewy values diversity and inclusion. Contact CAAR@chewy.com for accommodations related to disabilities or religion.

If you have a question regarding your application, please contact HR@chewy.com.

To access Chewy's Customer Privacy Policy, please click here. To access Chewy's California CPRA Job Applicant Privacy Policy, please click here.

The specific salary offered to a candidate may be influenced by a variety of factors including but not limited to the candidate’s relevant experience, education, and work location. In addition, this position is eligible for 401k and a new hire and annual equity grant.

We offer different types of insurance, such as medical/Rx, vision, dental, life, disability, hospital indemnity, critical illness, and accident. We offer parental leave, family services benefits, backup dependent care, flexible spending accounts, telemedicine, pet adoption reimbursement, employee assistance program, and many discounts including 10% off pet insurance and 20% off at Chewy.com.

Salaried-exempt team members have unlimited PTO, subject to manager approval. Team members will receive six paid holidays per year. Team members may be eligible for paid sick and family leave in compliance with applicable state and local regulations.

Pay Range

$115,500—$183,500 USD

Chewy is committed to equal opportunity. We value and embrace diversity and inclusion of all Team Members. If you have a disability under the Americans with Disabilities Act or similar law, and you need an accommodation during the application process or to perform these job requirements, or if you need a religious accommodation, please contact CAAR@chewy.com.

If you have a question regarding your application, please contact HR@chewy.com.

To access Chewy's Customer Privacy Policy, please click here. To access Chewy's California CPRA Job Applicant Privacy Policy, please click here.",Full-time
4059574274,66321745.0,Junior Data Engineer,"SYNERGISTICIT is aware that the Job Market is Challenging because of Tech Layoffs due to which The Job market is flooded with hundreds and thousands of laid off Jobseekers who are competing with existing Jobseekers. For entry level Job seekers to get client interviews and jobs they need to differentiate themselves by ensuring they have exceptional skills and technologies to be noticed by clients.

Since 2010 we have helped Jobseekers differentiate themselves by providing the clients with candidates who have the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers. All Positions are open for all visas and US citizens We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few. We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers. Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates looking to make their careers in IT Industry We welcome candidates with all visas and citizens to apply. We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

Candidates can benefit from skill enhancement if they fall into the below categories.

Candidates who Lack Experience or are freshers with No actual on Job experience with projects with clients Have had a break in careers Lack Technical Competency or skills being demanded by clients Different visa candidates (Like OPT/H4EAD/L2EAD ) who want to get employed and settle down in the USA please check the below links to see success outcomes of our candidates https://www.synergisticit.com/candidate-outcomes/

If you have relevant skills and industry experience, please apply if not then candidates can opt for Skill enhancement.

https://www.synergisticit.com/candidate-outcomes/

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

REQUIRED SKILLS For Java /Software Programmers


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Project work on the skills
 * Knowledge of Core Java , javascript , C&plus;&plus; or software programming
 * Spring boot, Microservices, Docker, Jenkins and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Project work on the technologies needed
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, PowerBI, Time series analysis

Please understand skills and relevant experience on real world projects are required by clients for selection even if its Junior or entry level position the additional skills and Project work with hands on experience building projects at client site are the only way a candidate can be picked by clients. If not having the skills or hands on project work at client site then candidates can opt for skill enhancement to gain the required skills and project work. No third party candidates or c2c candidates

please only apply to the posting

No phone calls please. Shortlisted candidates would be reached out.",Full-time
4128621563,3653845.0,Software Engineer - Database Engineering,"Build the future of the AI Data Cloud. Join the Snowflake team.

We’re hiring talented Software Engineers to join the Snowflake Database Engineering team! In this role you will work directly with our team to evolve our elastic, large scale, high-performance data processing system. We need smart engineers who can pick up and understand complex technical areas quickly – and who are enthusiastic about building new technologies!

AS A SOFTWARE ENGINEER AT SNOWFLAKE, YOU WILL:


 * Design, develop, and support a petabyte-scale cloud database that is highly parallel and fault-tolerant.
 * Build high-quality and highly reliable software to meet the needs of some of the largest companies on the planet.
 * Analyze and understand performance and scalability bottlenecks in the system and solve them.
 * Pinpoint problems, instrument relevant components as needed, and ultimately implement solutions.
 * Design and implement novel query optimization or distributed data processing algorithms which allow Snowflake to provide industry leading data warehousing capabilities.
 * Design and implement the new service architecture required to enable the Snowflake Data Cloud
 * Develop tools for improving our customers' insights into their workloads.
   
   
   

OUR IDEAL SOFTWARE ENGINEER WILL HAVE:


 * 2+ years industry experience working on commercial or open-source software.
 * Fluency in Java or C++.
 * Familiarity with development in a Linux environment.
 * Excellent problem solving skills, and strong CS fundamentals including data structures, algorithms, and distributed systems.
 * Systems programming skills including multi-threading, concurrency, etc.
 * Experience with implementation testing, debugging and documentation.
 * Bachelor’s degree or foreign equivalent in Computer Science, Software Engineering or related field; Masters or PhD preferred.
 * Ability to work on-site in our San Mateo / Bellevue / Berlin office.
   
   
   

BONUS POINTS FOR EXPERIENCE WITH THE FOLLOWING:


 * SQL or other database technologies including internal design and implementation.
 * Query optimization, query execution, compiler design and implementation.
 * Experience with internals of distributed key value stores like FoundationDB and storage engines like RocksDB, InnoDB, BerkeleyDB etc.
 * Experience with MySQL, PostgreSQL internals
 * Data warehouse design, database systems, and large-scale data processing solutions like Hadoop and Spark.
 * Large scale distributed systems, transactions and consistency models.
 * Experience in database replication technology
 * Big data storage technologies and their applications, e.g., HDFS, Cassandra, Columnar Databases, etc.
   
   
   

Every Snowflake employee is expected to follow the company’s confidentiality and security standards for handling sensitive data. Snowflake employees must abide by the company’s data security plan as an essential part of their duties. It is every employee's duty to keep customer information secure and confidential.

Snowflake is growing fast, and we’re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.

How do you want to make your impact?

The following represents the expected range of compensation for this role:


 * The estimated base salary range for this role is $157,000 - $230,000.
 * Additionally, this role is eligible to participate in Snowflake’s bonus and equity plan.
   
   
   

The successful candidate’s starting salary will be determined based on permissible, non-discriminatory factors such as skills, experience, and geographic location. This role is also eligible for a competitive benefits package that includes: medical, dental, vision, life, and disability insurance; 401(k) retirement plan; flexible spending & health savings account; at least 12 paid holidays; paid time off; parental leave; employee assistance program; and other company benefits.

Snowflake is growing fast, and we’re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.

How do you want to make your impact?",Full-time
4145148222,1834233.0,Data Engineer II,"Our Purpose

Mastercard powers economies and empowers people in 200+ countries and territories worldwide. Together with our customers, we’re helping build a sustainable economy where everyone can prosper. We support a wide range of digital payments choices, making transactions secure, simple, smart and accessible. Our technology and innovation, partnerships and networks combine to deliver a unique set of products and services that help people, businesses and governments realize their greatest potential.

Title And Summary

Data Engineer II

Overview

Mastercard’s Technical Implementation team is seeking a Data Engineer II to contribute to the data management aspects of client engagements, delivering and other innovative solutions within the Services group. In this role, you will develop robust data pipelines, implement scalable data solutions, and collaborate with cross-functional teams. Additionally, you will help foster a high-performance, collaborative workplace culture. This hybrid position is based in Arlington, VA, requiring three days per week onsite.

Technical Implementation is part of the Services within Mastercard group and one of its fastest-growing organizations. The Services group is responsible for acquiring, engaging, and retaining customers by managing fraud and risk, enhancing cybersecurity, and improving the digital payments experience. We provide value-added services and leverage expertise, data-driven insights, and execution.

100 of the largest corporations in the world use these products and services like Test & Learn™ for Sites, Test & Learn™ for Customers, Mastercard Intelligence Center, and other similar products which employ patented algorithms and workflows to design business experiences and interpret real-world data that evaluate, target, and refine business programs.

Technical Implementation is a core component to these services, managing the data acquisition, integration, and transformation of client provided data within Test & Learn and other platforms for global engagements.

Role


 * Support the design, implementation, and maintenance of enterprise ETL processes for data platforms, for a global client base.
 * Develop scalable and efficient code to process data, ensuring availability and accessibility in a timely manner.
 * Collaborate with senior engineers to address data challenges, contributing to solutions that maintain high data quality.
 * Assist in the data delivery process, working alongside Data Engineers and Analysts to support accurate, high-value data solutions across various clients and industries.
 * Build strong working relationships with team members and clients, contributing to both local and global projects.
 * Learn and apply industry best practices, including version control, code reviews, and data validation, to ensure quality in data processes.
 * Use SQL and other database technologies to help optimize data processing and reduce the time required to handle large data sets.
 * Participate in efforts to automate routine data tasks and streamline processes.
 * Comply with all Mastercard internal policies and adhere to external regulations.
   
   

All Abut You


 * Experience as a Data Engineer or in a similar role, with a strong understanding of data engineering concepts and methodologies.
 * Strong knowledge of writing and optimizing SQL queries to retrieve, manipulate, and analyze data efficiently.
 * Experience with Relational Databases (RDBMS), with strong hands-on expertise in Microsoft SQL Server and related technologies.
 * Familiarity with ETL frameworks and the ability to design, implement, and maintain data pipelines.
 * Understanding of data modeling concepts and database design to support scalable data solutions.
 * Familiarity with at least one scripting language (e.g., PowerShell, Python).
 * Ability to analyze and troubleshoot data issues and provide solutions with minimal supervision.
 * Basic knowledge of testing and validating data to ensure accuracy and consistency in data pipelines.
 * Excellent verbal and written communication skills, with the ability to articulate complex ideas clearly and concisely to both technical and non-technical stakeholders.
 * Bachelor's degree in a quantitative discipline such as Engineering, Mathematics, Finance, Business, or a related field. Equivalent practical experience may also be considered.
   
   

Mastercard is an inclusive equal opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. In the US or Canada, if you require accommodations or assistance to complete the online application process or during the recruitment process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.

Corporate Security Responsibility

Responsibilities

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:


 * Abide by Mastercard’s security policies and practices;
 * Ensure the confidentiality and integrity of the information being accessed;
 * Report any suspected information security violation or breach, and
 * Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.
   
   

In line with Mastercard’s total compensation philosophy and assuming that the job will be performed in the US, the successful candidate will be offered a competitive base salary based on location, experience and other qualifications for the role and may be eligible for an annual bonus or commissions depending on the role. Mastercard benefits for full time (and certain part time) employees generally include: insurance (including medical, prescription drug, dental, vision, disability, life insurance), flexible spending account and health savings account, paid leaves (including 16 weeks new parent leave, up to 20 paid days bereavement leave), 10 annual paid sick days, 10 or more annual paid vacation days based on level, 5 personal days, 10 annual paid U.S. observed holidays, 401k with a best-in-class company match, deferred compensation for eligible roles, fitness reimbursement or on-site fitness facilities, eligibility for tuition reimbursement, gender-inclusive benefits and many more.

Pay Ranges

Arlington, Virginia: $106,000 - $169,000 USD

",Full-time
4109282447,2646.0,Data Engineer III,"Position Summary...

What you'll do...

We are looking for a Data Engineer III to join our Customer Data Engineering team to advance the way we empower internal teams with best-in-class customer data products and privacy compliant data platforms. This hands-on role requires proficient data engineering and coding skills, a passion for data engineering and engineering excellence. You will play a critical role in our team, focusing on the development of petabyte scale Customer data products. You will work closely with teams such as Marketing, Walmart Connect, Data Ventures, and Walmart+ to enable business growth and provide best in class omni customer experiences for Walmart’s customers.

About Team

Everyone has data, but the sheer volume of data at Walmart can be limitless. In the Data Engineering team, we help Walmart manage this data by building pipelines and data lakes to prepare big data for analysis and unlocking actionable insights in real-time. We also use cross-departmental data and machine learning to build a holistic view of true profitability, saving millions of dollars across item categories and geographies while assisting our leadership in making better decisions faster.

What You'll Do


 * Collaborate with cross-functional teams to understand data requirements and design data solutions that meet business needs
 * Develop and maintain data pipelines and ETL processes using Spark and Scala
 * Design, build, and optimize data models and data architecture for efficient data processing and storage
 * Implement data integration and data transformation workflows to ensure data quality and consistency
 * Monitor and troubleshoot data pipelines to ensure data availability and reliability
 * Conduct performance tuning and optimization of data processing systems for improved efficiency and scalability
 * Work closely with data scientists and analysts to provide them with the necessary data sets and tools for analysis and reporting
 * Stay up-to-date with the latest industry trends and technologies in data engineering and apply them to enhance the data infrastructure
   
   

What You'll Bring


 * Proven working experience as a Data Engineer with a minimum of 2 years in the field
 * Experience in multiple stack technologies such as Java, Python, Scala
 * Exposure with Hadoop, Hive, Spark using Scala, Spark Serverless, Spark Streaming, Presto/Trino, Kubernetes, Cloud, Airflow and Data Lake concepts
 * Strong programming skills in Scala and experience with Spark for data processing and analytics
 * Familiarity with Google Cloud Platform (GCP) services such as BigQuery, GCS, Dataproc, Pub/Sub, etc.
 * Experience working with public cloud technologies such as Google Cloud Platform
 * Experience with data modeling, data integration, and ETL processes
 * Strong knowledge of SQL and database systems
 * Understanding of data warehousing concepts and best practices
 * Proficiency in working with large-scale data sets and distributed computing frameworks
 * Strong problem-solving and analytical skills
 * Excellent communication and teamwork abilities
   
   

About Walmart Global Tech

Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. That’s what we do at Walmart Global Tech. We’re a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world’s leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.

Flexible, Hybrid Work

We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.

Benefits

Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.

Equal Opportunity Employer

Walmart, Inc. is an Equal Opportunity Employer – By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions – while being inclusive of all people.

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎

You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎

Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For Information About Benefits And Eligibility, See One.Walmart.

‎

The annual salary range for this position is $90,000.00-$180,000.00

‎

Additional Compensation Includes Annual Or Quarterly Performance Bonuses.

‎

Additional Compensation For Certain Positions May Also Include

‎

‎


 * Stock
   
   

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelor’s degree in Computer Science and 2 years' experience in software engineering or related field. Option 2: 4 years’ experience in

software engineering or related field. Option 3: Master's degree in Computer Science.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, Master’s degree in Computer Science or related field and 2 years' experience in software engineering or related field, We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

2501 Se J St, Ste A, Bentonville, AR 72716-3724, United States of America",Full-time
4091035973,1586.0,"Data Engineer, GSF","Description

Over the past 20 years, Amazon has reinvented on behalf of customers and has become the largest internet retailer in the world. Amazon is now reinventing the global supply chain and international e-commerce and is recruiting a senior data engineer to help make this vision a reality. In this role, you will be responsible for the development and improvement of Workforce Planning Analytics platform used for planning, reporting, and forecasting purposes as well as dataset management. You will get the unique opportunity to work closely with a variety of stakeholders, including Business Analysts, Site Leads, and other Program Management teams. The candidate will also be in charge of driving strategic initiatives to improve reporting efficiency, develop new bridging workflow tools and establish new key performance metrics where appropriate.

The ideal candidate will not only raise the bar on Data engineering skills but demonstrates a strong curiosity to understand the business end-to-end and be comfortable working with ambiguity. The candidate will also have an eye for detail, be proficient/advanced in SQL/DWH/Python and invent for solving data and reporting challenges. The role requires good communication skills with other functional teams.

Key job responsibilities


 * Design, implement and support an analytical data infrastructure using AWS technologies
 * Build robust and scalable data integration (ETL) pipelines using SQL, and AWS data storage technologies like Aurora, Red Shift etc.
 * Design and develop Analytics applications using modern scripting languages (Python, R, PHP, etc) supporting critical business functions.
 * Gather business and functional requirements and translate these requirements into robust, scalable, operable solutions with a flexible and adaptable data architecture.
 * Lead architecture design and implementation of next generation BI solution
 * Continually improve ongoing reporting and analysis processes, automating or simplifying self-service modeling and production support for customers.
   
   

Basic Qualifications


 * 3+ years of data engineering experience
 * Experience with data modeling, warehousing and building ETL pipelines
   
   

Preferred Qualifications


 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com Services LLC

Job ID: A2838541",Full-time
4149110150,90439523.0,Software Engineer - LLM infrastructure,"Build the future of the AI Data Cloud. Join the Snowflake team.

Snowflake delivers a unified platform for secure development and deployment of LLMs and ML models. Snowflake AI and ML capabilities allow you to create generative AI applications with fully managed and enterprise-grade LLMs while providing full governance.

We are seeking a skilled and experienced Infrastructure Engineer to join our AI/ML organization. In this role, you will be responsible for designing, developing, and maintaining the infrastructure that supports serving large language models with world class performance and availability.

Responsibilities


 * Contribute to the open source vLLM inference engine
 * Design and implement scalable infrastructure solutions to support the deployment of large language models.
 * Optimize compute, storage, and networking resources to enhance the performance and cost-efficiency of LLM operations.
 * Develop and maintain tools for monitoring and managing LLM performance, including resource utilization, latency, and throughput.
 * Implement security measures and best practices to protect sensitive data processed by LLMs.
 * Troubleshoot and resolve infrastructure issues in a timely manner, ensuring minimal disruption to model deployment and availability.
 * Stay updated with advancements in AI infrastructure technologies and contribute to the adoption of new tools and frameworks.
 * Document infrastructure designs, processes, and configurations for knowledge sharing and training purposes.
 * Provide technical guidance and mentorship to junior members of the infrastructure team.
   
   

Requirements


 * Have 2+ years of industry experience designing, building, and supporting Internet serving infrastructure, machine learning platforms, machine learning services and frameworks.
 * Experience working with vLLM or similar technologies
 * Proficiency in cloud computing platforms such as AWS, Azure, or GCP.
 * Strong programming skills in at least one of Python, Go, Java, C++.
 * Experience with containerization and orchestration tools such as Docker and Kubernetes.
 * Solid understanding of distributed computing, parallel processing, and data storage systems (e.g., Hadoop, Spark, Elasticsearch).
 * Knowledge of security best practices and data protection measures in AI environments.
 * Excellent problem-solving skills and ability to troubleshoot complex issues in a production environment.
 * Strong communication skills and ability to collaborate effectively in a cross-functional team environment.
 * BS/MS/PhD in Computer Science, Engineering, or a related field.
   
   

Every Snowflake employee is expected to follow the company’s confidentiality and security standards for handling sensitive data. Snowflake employees must abide by the company’s data security plan as an essential part of their duties. It is every employee's duty to keep customer information secure and confidential.

Snowflake is growing fast, and we’re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.

How do you want to make your impact?

The following represents the expected range of compensation for this role:


 * The estimated base salary range for this role is $195,000 - $287,500.
 * Additionally, this role is eligible to participate in Snowflake’s bonus and equity plan.
   
   

The successful candidate’s starting salary will be determined based on permissible, non-discriminatory factors such as skills, experience, and geographic location. This role is also eligible for a competitive benefits package that includes: medical, dental, vision, life, and disability insurance; 401(k) retirement plan; flexible spending & health savings account; at least 12 paid holidays; paid time off; parental leave; employee assistance program; and other company benefits.

Snowflake is growing fast, and we’re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.

How do you want to make your impact?",Full-time
4078225045,66321745.0,Junior Data Engineer,"Are you passionate about coding or technology and ready to make your mark in tech? For more than 14 years, SynergisticIT has been helping aspiring developers like you excel in the tech industry. We focus on equipping you with the skills and experience needed to not only secure a job but to thrive in your career!

Why Partner with SynergisticIT?


 * Customized inputs to achieve the desired output : designed with industry needs in mind, ensuring you're equipped with the most sought-after skills.
 * Exclusive Opportunities: Our extensive network allows you to connect with leading tech firms.
 * Outstanding Outcomes: Many of our candidates land multiple job offers, often with starting salaries of $100k or more!
   
   

Synergisticit Pics /Salaries of Successful Candidates

Synergisticit at Oracle Cloudworld 2023

Synergisticit at Gartner Data & Analytics summit

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

Who Should Apply? We're looking for recent grads in Mathematics, Statistics , Computer Science or Engineering or candidates with gaps in their career or people wanting to switch careers into tech. SynergisticIT is committed to supporting your journey!

Preferred SKILLS For Java /Full Stack/Devops Positions

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Knowledge of Core Java , javascript , C++ or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

For data Science/Data Analyst/AI/Machine learning Positions

Preferred SKILLS

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude

Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools

Candidates lacking technical skills or relevant experience can research our Job Placement Programs which can assist in landing a Job

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates

Embrace Your Future! We also assist with F1 OPT to transition into H1B and Green Card byproviding comprehensive support. All positions are open to candidates of all visa types and US citizens.

Are you ready to make an impact?",Contract
4125059659,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4127871476,11104.0,Data Engineer,"Position Summary

Bridges the gap between raw data and data science processes by ensuring that the data landscape is well-prepared for deeper analysis.

LOCATION

Remote - (US)

Functions Of The Job

Essential Functions: which may be representative but not all inclusive of those commonly associated with this position.


 * Evaluates new data sources to ensure alignment with ongoing projects.
 * Maintains knowledge of existing datasets, sources, structure and quality.
 * Translates business cases into technical requirements.
 * Collaborates with data engineering and data science teams to ensure alignment.
 * Cleans, transforms and preprocesses data for advanced analytics.
 * Develops and implements data quality checks and collaborates with engineering to resolve issues.
 * Conducts exploratory analysis to identify trends, patterns and anomalies.
 * Creates summaries and visualization for the data science team.
 * Develops and maintains ETL (Extract, Transform, Load) pipelines to ensure data availability for downstream processes.
 * Demonstrates and promotes a workplace culture of innovation, high performance, accountability, commitment, respect and teamwork.
 * Regular attendance.
 * Other duties as assigned.
 * Supports our BMI Core Values and cultivates a culture of diversity and inclusion.
   
   

Position Qualification Requirements

Education: Bachelor’s degree preferred.

Experience: Minimum five years of experience building and maintaining data pipelines. Minimum five years of experience working in a large data environment. Minimum five years of experience with data modeling tools (e.g. Erwin).

Skills And Abilities

Which may be representative but not all inclusive of those commonly associated with this position.


 * ETL processes with Databricks experience a plus.
 * Experience in normalized, dimensional, star schema and snow-flake models.
 * Proficient in Python (especially Pandas, NumPy, Matplotlib, Seaborn, etc.), PySpark experience preferred, and SQL.
 * Familiarity with the Databricks workspace, notebooks, and jobs, including automation and orchestration using Azure Data Factory.
 * Experience working with Parquet files, Delta Lake, Unity Catalog, and optimizing data storage within Azure.
 * Understanding of data modeling concepts, normalization techniques.
 * Ability to develop and implement data quality checks.
 * Experience with version control systems like Git to manage code in a collaborative environment.
 * Ability to create data visualizations using tools like Power BI or Plotly to support preliminary analysis.
 * Strong communication skills to collaborate effectively with data scientists, data engineers, and stakeholders across the business.
 * Well versed with software engineering processes (especially Agile).
 * Strong analytical and problem-solving skills.
 * Organized, goal-oriented, self-starter, can manage multiple tasks from start to completion with limited supervision.
 * Ability to effectively present information and respond to questions.
 * Knowledge of entertainment industry a plus.
   
   

SALARY RANGE

The specific base salary offered to a successful applicant will be based on individual qualifications, skills, experience, and education. The pay range is subject to change at any time based on various internal and external factors. The position may also be eligible for one or more performance-based bonuses. In addition to cash compensation, BMI offers a competitive portfolio of benefits to its employees, as described below.

What We Give To You


 * Health, dental, and vision insurance
 * 401K with employer match
 * Flexible spending accounts
 * Paid vacation and paid sick/personal time
 * 12 paid calendar holidays
 * Paid volunteer time off
 * Summer hours that offer more time for fun in the sun
 * Company paid life insurance
 * Up to 12 weeks paid parental leave
 * Tuition assistance for qualified team members
 * Commuter benefits (New York)
 * Amazing and engaging culture
 * Employee Resource Groups
   
   

BROADCAST MUSIC, INC. IS AN EQUAL OPPORTUNITY EMPLOYER: All applicants will receive equal opportunity for employment without regard of race, color, sex, religion, nationality, age, sexual orientation, gender identity and/or expression, veteran’s or marital status, disability, or any other cultural factor.

",Full-time
4081422480,33258172.0,Data Engineer,"Seneca Technologies is part of the Seneca Nation Group (SNG) portfolio of companies. SNG is the federal government contracting business wholly owned by the Seneca Nation of Indians. SNG meets mission-critical needs of federal civilian, defense, and intelligence community customers across a variety of domains. The SNG portfolio receives shared services support from its parent company Seneca Holdings and is comprised of multiple companies that participate in the Small Business Administration 8(a) program. To learn more visit www.senecanationgroup.com and follow us on LinkedIn.

The Seneca Nation Group companies offer competitive compensation and a strong benefits package including comprehensive medical and dental care, matching 401K, paid time off, flexible spending accounts, disability coverage, and other benefits that help provide financial protection for you and your family. We pride ourselves on our collaborative work environment and culture which embraces our mission of providing financial and non-financial benefits back to the members of the Seneca Nation.

Seneca Technologies is seeking a Data Engineer in the Washington, DC metro region. The objective of this work is to support a large GenAI program for our IRS customer.

Responsibilities include, but are not limited to:


 * Data System Design and Architecture:
    * Design and implement effective database solutions and models to store and retrieve company data.
    * Examine and identify database structural necessities by evaluating client operations, applications, and programming.

 * Pipeline Development and Maintenance:
    * Build robust data pipelines that serve as the backbone for data collection, integration, and transformation necessary for AI model training and inference. Work with vector databases.
    * Automate data pipelines and optimize data flow between databases and backend systems.

 * Performance Monitoring and Optimization:
    * Monitor analytics and metrics results to ensure system performance and reliability.
    * Adjust architectures as needed to improve data reliability and quality.
      

Basic Qualifications:


 * 3+ years of experience as a Data Engineer with extensive expertise in SQL and NoSQL databases, data warehouse solutions, vector databases, and ETL tools.
 * Experience with cloud services (AWS, Azure, Google Cloud) especially in relation to data storage and compute resources.
 * Strong programming skills in Python, Java, Scala, or similar languages.
 * Familiarity with machine learning frameworks and their data requirements
 * Possess the ability to obtain and maintain an IRS security clearance
   
   
   
   

Equal Opportunity Statement:

Seneca Holdings provides equal employment opportunities to all employees and applicants without regard to race, color, religion, sex/gender, sexual orientation, national origin, age, disability, marital status, genetic information and/or predisposing genetic characteristics, victim of domestic violence status, veteran status, or other protected class status. This policy applies to all terms and conditions of employment, including, but not limited to, hiring, placement, promotion, termination, layoff, recall, transfer, leave of absence, compensation and training. The Company also prohibits retaliation against any employee who exercises his or her rights under applicable anti-discrimination laws. Notwithstanding the foregoing, the Company does give hiring preference to Seneca or Native individuals. Veterans with expertise in these areas are highly encouraged to apply.",Full-time
4151561751,40787483.0,Senior Data Engineer,"About the Position

At Thryv, we’re a team that lives by teamwork. However, it’s not the work that drives us, it’s the respect, trust, and care for each other that defines us as a team. We’re a diverse community of trendsetters who do our best work in a fun, relaxed environment. Technology never stops evolving and neither do we. We’re always looking for the best and brightest team players to join us.

This role is responsible for designing, building, and overseeing the deployment of data solutions to capture, manage, store, and utilize structured and unstructured data from various sources. Additionally, this role may be responsible for creating and maintaining documentation of test plans, test cases, and testing results for our data pipelines.

Responsibilities

 * Designs, evaluates, and tests data infrastructures.
 * Establishes and builds processes and structures based on business and technical requirements to channel data from multiple inputs, route appropriately and store using any combination of distributed (cloud) structures, local databases, and other applicable storage forms as required.
 * Develops technical tools and programming that leverage artificial intelligence, machine learning and big-data techniques to cleanse, organize and transform data and to maintain, defend and update data structures and integrity on an automated basis.Designs, develops and implements statistical models to carry out various novel aspects of classification and information extraction from data.
 * Creates and establishes design standards and assurance processes for software, systems, and applications development to ensure compatibility and operability of data connections, flows and storage requirements.
 * Works closely with developers, data scientists, and product managers to understand the questions that are being asked and how to answer them.
 * Builds data pipeline(s) and platform(s) for our customer facing products and improves on existing tools/platforms to help developers take advantage of the data.

Who We’re Looking For

 * Bachelor's degree (or international equivalent), required.
 * 5+ years of related experience, required.
 * 9+ years of related experience, preferred.
 * Strong understanding of working with different file types (CSV, JSON, Parquet, XML, etc.), compression algorithms, and character sets (UTF-8, ISO-8859-1, windows-1252, etc.).
 * Strong communication and presentation skills with the ability to collaborate with broader teams and leaders.
 * Highly skilled in SQL (required) as well as Python, JavaScript, Scala, etc. (preferred), data processing tools (e.g. Hadoop, Spark, Dataflow, etc.), Google Cloud, BigQuery, Snowflake.
 * Strong ability to use relational database management systems with a working knowledge of common methods of data validation. ·
 * Exceptional ability to manage multiple tasks and projects with competing deadlines and to collaborate with different teams and leaders.
 * Strong ability to data-lake in a cloud environment, real time streaming data ingestion and processing pipeline using Kafka or Pub/Sub.
 * Experience with ETL/ELT pipelines and Airflow.
 * Ability to travel less than 5% of the time.
 * Must be 18 years of age or older.
 * Must successfully complete pre-employment screening process, as required.
 * Must successfully complete any required training or orientation courses, as needed.



What We Offer

 * Life requires balance, so we provide benefits around health and wellness, continued education, and work/life balance to help you live your best life when you’re working…and when you’re not.
 * Work from anywhere – Thryv is a Remote First company!
 * Competitive medical, dental, and vision plans, plus a wellness program with added incentives
 * 401(k) savings plan with company match and employee stock purchase plan
 * Continuing education benefits with tuition assistance programs
 * One week of paid time off at the end of the year, in addition to our standard paid time off policy.

Who We Are

At Thryv, we’re a team fiercely devoted to the success of local businesses. We’ve been around for over 100 years, always with one goal in mind — helping small businesses compete, win, and succeed. We provide the technology, software and local business automation tools small business owners need to better manage their time, communicate with clients, and get paid, so they can take control of their business and be more successful.

We support businesses across the U.S. and our team members are located across the country, and internationally. We operate as a work from anywhere company and believe this allows us to be more productive.

Culture is vital at Thryv because it shapes our identity and, therefore, our measurements for growth. We have an identified set of values that hold all of us accountable paving the way for our company success and our legacy. All of this helps us deliver results for our clients and creates success for our employees. At Thryv, making a positive impact within our team and in our local community is the reason we get out of bed every morning.



Thryv Core Values:

Client Devoted – Be humble with a servant mentality. Understand the uniqueness of each interaction while being flexible, knowledgeable, and genuine.

Under Promise, Over Deliver – Deliver expectations and exceed them, have accountability, listen, and understand the ask.

Act Like You Own the Place – Taking ownership and accountability in your day-to-day decisions empowers you to act like you own the place.

Invest in our People – Hire people that are aligned with Thryv’s core values. Provide learning opportunities to enable all of us to adapt, belong, and create a lifelong career.

DONE3 – Define what you say (Done), Do what you say (Done), Follow up and ensure completion (Done).

Making $$ is a Byproduct of Helping People – Always be devoted to people, act with integrity.

Think Long Term, Act with Passion & Integrity – Focus on making every interaction exceptional. Bring enthusiasm and devotion to every act. This includes doing the right thing, even when no one is looking. Think five years out or think for the long play.




Find out more at corporate.thryv.com/careers/




Belonging at Thryv

We believe in a work environment where all individuals are treated fairly and respectfully, have equal access to opportunities and resources, and can contribute fully to the organization’s success. We want our employees to feel a part of something big and we encourage the sharing of ideas and collaboration across the organization.

We strive to ensure our work environment reflects diversity, fairness, and meritocracy. We believe all employees should have the opportunity to perform effectively in their position. We value every employee and the authenticity they bring to their role and to the organization. As a result, our employee policies and internal practices focus on ability and merit as the standards for success.




Requisition Detail and Process

This information indicates the general nature and level of work performed by employees in this job. It is not designed to contain a comprehensive inventory of all duties, responsibilities, and qualifications required of employees assigned to this job. The duties and responsibilities in this job description may be subject to change at any time due to reasonable accommodation or other reasons.

The final job level offered may vary based on the applicant’s competencies and qualifications such as experience and education, and other job-related reasons.




Our Commitment to Equal Opportunity

Thryv is proud to provide equal employment opportunities to all employees and applicants, without regard to gender, color, race, religion, sexual orientation, national origin, citizenship, age, disability, veteran status, pregnancy, genetic information, or any characteristic protected by law. Thryv is committed to provide equal employment opportunities throughout the employment relationship including recruitment, hiring, discharge, compensation, benefits, discipline, development, and advancement or other aspects of employment.

",Full-time
4125076116,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4148686745,3879704.0,Data Engineer Intern,"Overview & Responsibilities

About Republic Finance:

In business for more than 70 years, Republic Finance is proud to be a trusted lender in over 250 communities across the United States! We specialize in providing flexible lending solutions and incomparable customer service. Driven by our shared mission to pursue excellence for our team, our customers, and our performance, we are continuously improving our customer offerings in tandem with opening more branches in new states each year. We also regularly promote from within and enjoy giving back to the communities we serve. In a nutshell, our company culture is about helping customers, investing in our employee's future, and ensuring that our performance makes an impact on our community!

We are looking for an up and coming Data Engineer to join our dynamic team. In this role, you will be instrumental in designing, developing, and maintaining data pipelines and architectures that support data-driven decision-making across the organization. You will collaborate with analysts, and business stakeholders to ensure high-quality data availability.

Key Responsibilities:


 * Create and implement scalable ETL (Extract, Transform, Load) processes to move data from various sources into data warehouses or lakes.
 * Design and maintain robust data architectures that optimize performance and cost efficiency.
 * Work with cross-functional teams to integrate diverse data sources, ensuring consistency and accuracy.
 * Monitor data workflows, troubleshoot issues, and enhance processes for improved efficiency.
 * Set and uphold data quality standards, conduct regular audits, and implement validation checks to maintain data integrity.
 * Partner with data analysts and scientists to understand their data needs and provide the necessary datasets for analysis.
 * Create and maintain clear documentation for data processes, pipelines, and architecture to ensure knowledge sharing and compliance.
   
   

Requirements


 * Bachelor’s degree in Computer Science, Information Technology, Data Science, or a related field.
 * Minimum of 1 year of experience in a Data Engineer role or a similar capacity.
 * Strong experience in SQL stored procedures and programs.
 * Ability to use data engineering tools and technologies (e.g. Microsoft SQL Server, Databricks, NoSQL-MongoDB or Dynamo DB).
 * Exposure to cloud platforms (AWS or Azure) and data pipeline orchestration tools (e.g., Apache Airflow).
 * Understanding of data warehousing solutions (e.g., Snowflake, Redshift, BigQuery) and data modelling.
 * Excellent analytical and problem-solving capabilities, strong communication skills, and the ability to work effectively in a team.
   
   

Benefits

Additional benefits with Republic Finance include:


 * Employee of the Month Program
 * Philanthropic support for charities such as Juvenile Diabetes Research Foundation and the American Cancer Society
 * Regular drawings for Sports tickets
 * Professional offices with a friendly team environment
   
   

Republic Finance, LLC is an Equal Opportunity Employer and does not discriminate on the basis of race, sex, color, religion, national origin, age disability or veteran status in employment opportunities and benefits. Republic Finance, LLC maintains a Drug-Free Workplace.",Full-time
4137563290,73072.0,Data Engineer Intern,"Cadent powers the evolution of TV brand advertising. We provide marketers, agencies, operators, and media owners with data-driven solutions for buying and selling TV advertising. By connecting brands with opportunities across national inventory sources—cable, broadcast, and digital media—our technology improves efficiencies and boosts the results of linear, addressable, and cross-screen campaigns.



As we continue to grow, we’re looking for a Data Engineer - Intern to join our Data Engineering team for Spring 2025. The Intern will have an opportunity to gain hands-on experience by working directly with our teams, not for them.



The Intern will also spend the spring on an individual project customized to their specific skill set which they’ll present to our Tech Leadership team at the end of the program. Details of the projects and timeline will be laid out by supervisors at the beginning of the program.




The Intern will be responsible for fulfilling tasks set out by supervisors from the specific department they’re working in, including but not limited to:

 * Using a variety of open-source technologies (Python, Spark, Airflow), build data pipelines to extract, cleanse, and integrate data, from a variety of sources and formats **Python experience is required**
 * Develop scalable solutions that support real-time, batch, and event-based data processing
 * Collaborate effectively with other members of the engineering team and broader data services group, including but not limited to Data Scientists, Analytics Engineers, Performance Engineers, Software Engineers and Business Intelligence Analysts
 * Conduct research and present findings to the data science team and business stakeholders
 * Collaborate with the team in Agile Sprint Planning, demos, seminars, and other team meetings.

Perks:

 * Competitive pay
 * College credit (if applicable)
 * A senior pursuing a Bachelor’s degree at a college or university majoring in a field closely related to the department they are interning preferably
 * Able to commit to a part-time (20 hours per week) work schedule between Feb 24, 2025 – May 2, 2025
 * Proficient in Python, SQL, and Shell scripting, with some knowledge Docker containerization and Cloud data processing technologies
 * Strong problem-solving skills; collaborator
 * Excellent verbal and written communicators

Self-motivated with a desire to learn from a rapidly growing company



So, if the leading edge of media technology is the place you want to be, please contact us today and let’s start the conversation!

",Internship
4117967811,2689946.0,Data Engineer,"Role: Data Engineer

Duration: 6+ Months Contract

Location: Sunnyvale, CA




Job Description

What you'll do:

 * Demonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans by providing expert advice and guidance to others.
 * Supporting and aligning efforts to meet customer, business needs and building commitment for perspectives and rationales.
 * Create software design and architecture for next software solution.
 * This will be your channel to communicate your ideas with rest of the team.
 * Not just one but evaluate multiple solutions
 * Analyze competing requirements and articulate tradeoffs and lead discussions
 * with business and development team, leading white board sessions with team.
 * Drives the execution of multiple business plans and projects by identifying customer and operational needs.
 * Developing and communicating business plans and priorities, removing barriers and obstacles that impact performance.
 * Demonstrating adaptability and supporting continuous learning.
 * Creates training documentation.
 * Oversees the tasks of less experienced programmers and stipulates system troubleshooting supports.




What you'll bring:

Experience with

 * Hadoop, Spark, Cloud, Scala, Streaming, Kafka
 * SQL / Data warehousing
 * BI and Looker Views, Models, Explores, Looks/Charts
 * DS and Algorithm
 * CI/CD
 * Data Modeling
 * Airflow
 * ·Knowledge of
 * Cloud (GCP/Azure)
 * Backend, Spring
 * Python







KARAN MODI | TECHNICAL RECRUITER

Mobile: +1925-218-2354

Email: kmodi@bayonesolutions.com

Address: 4637 Chabot Dr #250, Pleasanton, CA 94588

BAYONE.COM| CONNECT ON LINKEDIN",Contract
4144534680,72742192.0,Data Engineer,"EDGE (www.edgescore.com) is a B2B fintech on a mission to expand credit access for consumers historically unserved and underserved by the reports and scores of traditional credit bureaus. We’re doing this with risk analytics based on complementary alternative data that reveals a more complete financial picture.




Founded in 2021, Edge is part of a larger family of fintech brands that sits underneath our parent company, NinjaHoldings (www.ninjaholding.com). NinjaHoldings’ brands also include CreditNinja, a nationwide online consumer lending business established in 2017, and NinjaCard, a neobanking platform focused on consumers in the emerging credit space.




The EDGE business is at an inflection point where we’ve proven our platform’s value with early adopters and we’re ready to go full-throttle into our target markets. Elevating every aspect of our marketing efforts is a critical element in this planned ramp-up.

Join Edge’s dynamic Data Science & Analytics team and drive the backbone of our high-performance data services.




As a Data Engineer, you’ll collaborate closely with data scientists and platform engineers, leveraging your expertise in Python, data intensive workflows, and distributed computing to power cutting-edge fintech solutions. In this role, you’ll shape data pipelines, optimize workflows, and streamline analytics services, all while navigating a fast-paced startup environment. Your contributions will directly influence the evolution of our analytics capabilities, enabling real-time insights and innovation for our customers.




Key Responsibilities

 * Work collaboratively with data scientists and engineers on the team to scope, design, and develop high-performance data analysis services
 * Coordinate with the platform and product teams, contributing to the deployment and iterative improvement of our analytics services
 * Participate in multiple projects simultaneously, adapting to priorities and thriving in a dynamic, fast-paced environment
 * Provide technical expertise and recommendations in assessing new software projects and initiatives




Requirements:

 * 2+ Years of hands-on experience in a Data Engineering or Software Engineering role
 * Proficiency in Python and its data ecosystem (Pandas, NumPy, etc.).
 * Hands-on experience with Kubernetes & Docker for containerization and orchestration
 * Strong understanding of distributed and parallel computing principles in data engineering.
 * Experience with cloud services, especially AWS (e.g., S3, RDS, EKS).
 * Experience designing and consuming gRPC and REST
 * Experience with relational databases (Postgres or similar) and proficiency in SQL
 * Understanding of machine learning workflows and familiarity with ML Ops tools and practices
 * Experience with version control (GitHub) and CI/CD pipelines for data applications
 * Strong problem-solving skills and ability to debug and optimize complex workflows




Additional Pluses, but Not Requirements:

 * Experience with Kubeflow
 * Experience with Clickhouse and other column-oriented databases
 * Proficiency in Go or Rust, with application to data processing




Benefits:




 * Competitive salary and benefits package
 * Fun, fast-paced work environment
 * Dynamic start-up culture
 * Ability to make an immediate impact in a growth stage company
 * Convenient downtown Chicago office located in the heart of the city
 * Equal opportunity employer







IMPORTANT NOTICE:

Please carefully review communications to ensure that they are from the official Breezy applicant tracking platform (@breezy-mail.com) or an official NinjaHoldings brand email: @ninjaholdings.com, @creditninja.com, @ninjacard.com, or @edgescore.com. If you have been contacted regarding a job opening at NinjaHoldings from any other email address, including similar email variations, this is NOT a trusted source. We recommend that you refrain from responding to suspicious emails and file a complaint with the FBI's Internet Crime Complaint Center (IC3) at https://www.ic3.gov. For questions or to confirm the authenticity of a communication, please email hr @ninjaholdings.com.",Full-time
4125070004,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4131992393,2284.0,Data Engineer,"About Our Organization

Dow Jones is a global provider of news and business information, delivering content to consumers and organizations around the world across multiple formats, including print, digital, mobile and live events. Dow Jones has produced unrivaled quality content for more than 130 years and today has one of the world’s largest news-gathering operations globally. It is home to leading publications and products including the flagship Wall Street Journal, America’s largest newspaper by paid circulation; Barron’s, MarketWatch, Mansion Global, Financial News, Investor’s Business Daily, Factiva, Dow Jones Risk & Compliance, Dow Jones Newswires, OPIS and Chemical Market Analytics. Dow Jones is a division of News Corp (Nasdaq: NWS, NWSA; ASX: NWS, NWSLV).

About The Team

OPIS, a Dow Jones company, provides price transparency across the global fuel supply chain, including the Spot, Wholesale Rack and Retail markets. OPIS enables customers to buy and sell energy commodities with confidence with multi-platform access to accurate data, real-time news, powerful software and educational events. Our commitment to reliability is reinforced by personalized customer service and constant innovation. OPIS listens to what the energy community needs and responds with flexible and easy-to-use products. Navigating world fuel markets is complex – OPIS makes it simpler.

About The Role

We are looking for a Data Engineer with SQL experience that will develop and maintain database architecture and code initiatives, delivering excellent products in scope and on time, and meeting current and long-term business needs for the business area. Participate in an agile team of motivated, driven, high-energy developers, building trust and confidence with team members and business stakeholders. Play a key role in analyzing data, identifying data patterns/anomalies and implementing algorithms with a focus on accuracy and completeness.

You Will


 * Work in a collaborative agile development environment
 * Develop database code, objects and scripts to support project initiatives
 * Manage code and releases through Azure DevOps CI/CD build/release pipelines
 * Optimize database systems for performance and optimal resource utilization
 * Identify and troubleshoot issues related to data quality
 * Continue to enhance your skills in data analysis, database development and data validation
   
   

You Have


 * Bachelor’s Degree in computer science, related technical field, or equivalent experience
 * 6 months database experience or related coursework (SQL Server, PostgreSQL preferred)
 * Ability to create and maintain stored procedures, views and functions
 * Ability to write SQL queries and statements to explore source data and data issues
 * Familiarity with agile development, code repositories such as Git, and CI/CD principles
 * Familiarity with Python and Snowflake
 * Must speak and write in English fluently
   
   

Our Benefits


 * Comprehensive Healthcare Plans
 * Paid Time Off
 * Retirement Plans
 * Comprehensive Insurance Plans
 * Lifestyle programs & Wellness Resources
 * Education Benefits
 * Family Care Benefits & Caregiving Support
 * Commuter Transit Program
 * Subscription Discounts
 * Employee Referral Program
   
   

Learn More About All Our US Benefits

Reasonable accommodation: Dow Jones, Making Careers Newsworthy - We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by law.EEO/AA/M/F/Disabled/Vets. Dow Jones is committed to providing reasonable accommodation for qualified individuals with disabilities, in our job application and/or interview process. If you need assistance or accommodation in completing your application, due to a disability, email us at talentresourceteam@dowjones.com. Please put ""Reasonable Accommodation"" in the subject line and provide a brief description of the type of assistance you need. This inbox will not be monitored for application status updates.

Business Area: Dow Jones - OPIS

Job Category: Data Analytics/Warehousing & Business Intelligence

Union Status

Non-Union role

Pay Range: $75,000 - $95,000

We recognize that attracting the best talent is key to our strategy and success as a company.As a result, we aim for flexibility in structuring competitive compensation offers to ensure we are able to attract the best candidates.The quoted salary range represents our good faith estimate as to what our ideal candidates are likely to expect, and we tailor our offers within the range based on the selected candidate's experience, industry knowledge, location, technical and communication skills, and other factors that may prove relevant during the interview process.

Pay-for-performance is a key element in our strategy to attract, engage, and motivate talented people to do their best work. Similarly to salary, for bonus eligible roles, targets are set based on a variety of factors including competitive market practice.

For benefits eligible roles, in addition to cash compensation, the company provides a comprehensive and highly competitive benefits package, with a variety of physical health, retirement and savings, caregiving, emotional wellbeing, transportation, and other benefits, including ""elective"" benefits employees may select to best fit the needs and personal situations of our diverse workforce..

Since 1882, Dow Jones has been finding new ways to bring information to the world’s top business entities. Beginning as a niche news agency in an obscure Wall Street basement, Dow Jones has grown to be a worldwide news and information powerhouse, with prestigious brands including The Wall Street Journal, Dow Jones Newswires, Factiva, Barron’s, MarketWatch and Financial News.

This longevity and success is due to a relentless pursuit of accuracy, depth and innovation, enhanced by the wisdom of past experience and a solid grasp on the future ahead. More than its individual brands, Dow Jones is a modern gateway to intelligence, with innovative technology, advanced data feeds, integrated solutions, expert research, award-winning journalism and customizable apps and delivery systems to bring the information that matters most to customers, when and where they need it, every day.

Req ID: 44604",Full-time
3917185512,11787695.0,Data Engineer,"Full-time, Remote - Location Requirement: Must be located in the Eastern Time Zone

Available for W-2 or 1099 Individual.

Our client, one of the largest Amazon Web Services (AWS) partners for data services, is looking for a true Mid level Big Data Engineer to contribute to join their team of technologists to build and contribute to large-scale, innovative projects. Technological and career growth opportunities are a natural and every day part of the working environment.

Responsibilities:


 * Analyze system requirements and design responsive algorithms and solutions
 * Use big data and cloud technologies to produce production quality code
 * Engage in performance tuning and scalability engineering
 * Work with team, peers and management to identify objectives and set priorities
 * Perform related SDLC engineering activities like sprint planning and estimation
 * Work effectively in small agile teams
 * Provide creative solutions to problems
 * Identify opportunities for improvement and execute
   
   

Requirements:


 * Minimum 4 years of proven professional experience working in the IT industry within U.S
 * Bachelor's in Computer Science or related domain
 * Experience with cloud based Big Data technologies
 * Experience with big data technologies like Hadoop, Spark and Hive
 * AWS experience (S3 and EMR)
 * Proficiency in Hive / Spark SQL / SQL. Experience with Spark
 * Experience with one or more programming languages like Python, Java, Scala
 * Ability to push the frontier of technology and independently pursue better alternatives
   
   

Thanks for applying!

Powered by JazzHR

WwXkuCvB6I",Full-time
4150550646,4593.0,"Senior Leader, Data Analytics Engineering, Distinguished Engineer","Salary Range: 203,150.00-287,800.00

Company Description

At Western Digital, our vision is to power global innovation and push the boundaries of technology to make what you thought was once impossible, possible.

At our core, Western Digital is a company of problem solvers. People achieve extraordinary things given the right technology. For decades, we’ve been doing just that—our technology helped people put a man on the moon and capture the first-ever picture of a black hole.

We offer an expansive portfolio of technologies, HDDs, and platforms for business, creative professionals, and consumers alike under our Western Digital®, WD®, WD_BLACK™, and SanDisk® Professional brands.

We are a key partner to some of the largest and highest-growth organizations in the world. From enabling systems to make cities safer and more connected, to powering the data centers behind many of the world’s biggest companies and hyperscale cloud providers, to meeting the massive and ever-growing data storage needs of the AI era, Western Digital is fueling a brighter, smarter future.

Today’s exceptional challenges require your unique skills. Together, we can build the future of data storage.

Job Description

The Advanced Analytics Office (AAO) within the Information Technology organization, is missioned with accelerating advanced Data and Analytics solutions across the Enterprise to unlock business value and create competitive advantage. These solutions target key operational metrics, such as, reducing cost, improving capital & asset efficiency, and improving operational efficiency. The Analytics solutions also target improving our market position by enabling business agility, reducing time-to-market to develop new products, and improving customer 360 experience.

The solutions use cutting edge technologies and are delivered through a platform approach to enable rapid scaling across the Enterprise. These solutions span both Operational data and Big data platforms using both Cloud and On-premise environments. The solutions leverage the latest in analytics technologies, such as, Artificial Intelligence & Machine Learning (AI/ML), Digital Twin Simulations, and Operations Research based Optimization methods to deliver to business outcomes.

We partner with over dozen factories across US and Asia that manufacture our Hard Disk Drive and Flash drives; these factories generate vast amounts of manufacturing and test data with tremendous amount of information. Apart from manufacturing data, our enterprise functions generate operational data which spans Business units, Sales & Marketing, Finance, Supply chain, Logistics, Procurement, and many other supporting functions. We continually seek to connect this data across the enterprise to enable rapid decision making. This journey is already in full swing, and we expect to continue to accelerate. The goal is to connect End-to-end enterprise information that enables rapid evaluation of next best decisions and optimize Enterprise resources and our position in the market.

We are looking for a dynamic Senior leader (Distinguished Engineer role equivalent) who will play a pivotal role in helping accelerate the overall IT Connected Enterprise vision. We are looking for a leader who will take an enterprise view to understand complex cross-functional business processes and then take a hands-on approach to define, prioritize and lead implementation of foundation components required to connect the Enterprise. These components can span infrastructure review, Data fabric design, platform choices, Software stack and applications, and integration decisions.

Essential Duties And Responsibilities


 * Lead technology direction with business focus
 * Evaluate emerging technologies and trends and assess their relevance to the WDC organization and recommend adoption strategies.
 * Collaborate with business leaders, IT teams, and other stakeholders to develop a point of view on architectural underpinnings for enabling an incremental and prioritized process towards achieving an end-to-end connected enterprise.
 * Develop and champion the organization's enterprise architecture that continuously strengthens technology, application, data & analytics, and security posture.
 * Ensure enterprise architecture modernization effort remains aligned with the organization's strategic goals and objectives and make recommendations for adjustments as necessary.
 * Champion and execute for business agility
 * Embrace and champion Agile methodologies within IT organization to promote collaboration, flexibility, and continuous improvement through short development cycles (sprints) and iterative development.
 * Integrate development (Dev) and operations (Ops) to automate processes, improve deployment speed, and enhance collaboration between development and IT operations teams.
 * Integrate security practices throughout the development lifecycle (DevSecOps) to identify and address vulnerabilities and protect against security threats
   
   

Enable the API economy mindset


 * Develop and implement an API strategy aligned with the organization's business objectives, identifying opportunities to leverage APIs for growth and innovation.
 * Establish and champion API governance standards, including design, security, and documentation, to ensure consistency, quality, and compliance.
 * Collaborate with software development teams to design, develop API strategy that enable seamless integration and data exchange between systems, both internally and externally.
   
   

Drive to Cloud and modern Software practices


 * Build Cloud-native applications taking advantage of cloud services like AWS, Azure, or Google Cloud for scalability, reliability, and cost-efficiency.
 * 
 * Champion best practice of decomposing complex applications into smaller, loosely coupled microservices, and leverage containerization (e.g., Docker) for scalability, portability, and isolation.
 * Utilize open-source software and libraries to accelerate development and promote code reusability. Contribute back to open-source communities when possible.
   
   

Improve customer experience and create new opportunities


 * Prioritize user experience (UX) by involving users in solution design process, define usability testing, and continuously gathering feedback for iterative improvements.
 * Partner with Sales and Business unit functions to explore new opportunities, such as, implement strategies to monetize APIs, API marketplaces, subscription models, or partnerships, to create new revenue streams.
   
   

Qualifications

REQUIRED


 * Desirable to have Master’s or higher degree in a relevant field such as Computer Science, Engineering, or applied Sciences
 * Proven experience in technology leadership roles, with a track record of successfully implementing technology strategies aligned with organization goals and objective. A strategic mindset to identify opportunities for technological innovation to create competitive advantage.
 * 15+ years of proven experience in building scalable platforms that supports complex cross-functional business processes, leverages modern Software principles, and incrementally builds and expands the API economy.
 * Familiarity and understanding of challenges around cross-functional business processes, such as, Design to Build, Plan to Fulfill, Order to Cash, Procure to Pay, Record to Report, etc. Experience in enabling solutions and their integration to meet business needs.
 * Have partnered with leaders of Enterprise business functions, such as, Finance, Sales and Marketing, Business Units, Supply Chain, Procurement etc. and have helped enabled cross-functional applications to support their business processes.
 * Extensive technical knowledge and proficiency in IT systems, software development, cybersecurity, cloud computing, and emerging data and analytics technologies Understanding of various programming language paradigms and software development methodologies to provide mentorship and guidance to development teams
 * Experience with cloud platforms (e.g., AWS, Azure, Google Cloud) and containerization technologies (e.g., Docker, Kubernetes).
   
   

Skills


 * Strong understanding of software development methodologies (e.g., Agile, Scrum) and DevOps practices.
 * Familiarity with industry-specific technologies and trends, such as, artificial intelligence, Internet of Things (IoT), AI/ML, and Gen AI.
 * Proficiency in designing, developing, and leading the API delivery approach. This includes knowledge of API protocols (e.g. REST, SOAP, GraphQL), API security, and version control. Familiarity with programming languages commonly used in API development (e.g. JavaScript, Python, Java, and Ruby). Familiarity with API management platforms and tools (e.g., Apigee, AWS API Gateway, Azure API Management) used to create, publish, and manage APIs.
 * 
 * Knowledge of Technology Stack covering wide range of technologies, including infrastructure, software development, databases, and cloud computing. Understanding of data modeling, data governance, and data integration principles. Expertise in integrating disparate systems and applications within the enterprise. Knowledge of security best practices and the ability to design secure architectures.
   
   

Additional Information

Western Digital is committed to providing equal opportunities to all applicants and employees and will not discriminate against any applicant or employee based on their race, color, ancestry, religion (including religious dress and grooming standards), sex (including pregnancy, childbirth or related medical conditions, breastfeeding or related medical conditions), gender (including a person’s gender identity, gender expression, and gender-related appearance and behavior, whether or not stereotypically associated with the person’s assigned sex at birth), age, national origin, sexual orientation, medical condition, marital status (including domestic partnership status), physical disability, mental disability, medical condition, genetic information, protected medical and family care leave, Civil Air Patrol status, military and veteran status, or other legally protected characteristics. We also prohibit harassment of any individual on any of the characteristics listed above. Our non-discrimination policy applies to all aspects of employment. We comply with the laws and regulations set forth in the ""Know Your Rights: Workplace Discrimination is Illegal” poster. Our pay transparency policy is available here.

Western Digital thrives on the power and potential of diversity. As a global company, we believe the most effective way to embrace the diversity of our customers and communities is to mirror it from within. We believe the fusion of various perspectives results in the best outcomes for our employees, our company, our customers, and the world around us. We are committed to an inclusive environment where every individual can thrive through a sense of belonging, respect and contribution.

Western Digital is committed to offering opportunities to applicants with disabilities and ensuring all candidates can successfully navigate our careers website and our hiring process. Please contact us at jobs.accommodations@wdc.com to advise us of your accommodation request. In your email, please include a description of the specific accommodation you are requesting as well as the job title and requisition number of the position for which you are applying.

Based on our experience, we anticipate that the application deadline will be 04/22/2025(3 months from posting), although we reserve the right to close the application process sooner if we hire an applicant for this position before the application deadline. If we are not able to hire someone from this role before the application deadline, we will update this posting with a new anticipated application deadline.

Compensation & Benefits Details


 * An employee’s pay position within the salary range may be based on several factors including but not limited to (1) relevant education; qualifications; certifications; and experience; (2) skills, ability, knowledge of the job; (3) performance, contribution and results; (4) geographic location; (5) shift; (6) internal and external equity; and (7) business and organizational needs.
 * The salary range is what we believe to be the range of possible compensation for this role at the time of this posting. We may ultimately pay more or less than the posted range and this range is only applicable for jobs to be performed in California, Colorado, New York or remote jobs that can be performed in California, Colorado and New York. This range may be modified in the future.
 * You will be eligible to participate in Western Digital’s Short-Term Incentive (STI) Plan, which provides incentive awards based on Company and individual performance. Depending on your role and your performance, you may be eligible to participate in our annual Long-Term Incentive (LTI) program, which consists of restricted stock units (RSUs) or cash equivalents, pursuant to the terms of the LTI plan. Please note that not all roles are eligible to participate in the LTI program, and not all roles are eligible for equity under the LTI plan. RSU awards are also available to eligible new hires, subject to Western Digital’s Standard Terms and Conditions for Restricted Stock Unit Awards.
 * We offer a comprehensive package of benefits including paid vacation time; paid sick leave; medical/dental/vision insurance; life, accident and disability insurance; tax-advantaged flexible spending and health savings accounts; employee assistance program; other voluntary benefit programs such as supplemental life and AD&D, legal plan, pet insurance, critical illness, accident and hospital indemnity; tuition reimbursement; transit; the Applause Program, employee stock purchase plan, and the Western Digital Savings 401(k) Plan.
 * Note: No amount of pay is considered to be wages or compensation until such amount is earned, vested, and determinable. The amount and availability of any bonus, commission, benefits, or any other form of compensation and benefits that are allocable to a particular employee remains in the Company's sole discretion unless and until paid and may be modified at the Company’s sole discretion, consistent with the law.
   
   ",Full-time
4125065300,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4112699926,40783.0,Data Engineer,"Compensation: $89,000 - $112,000/year

Location: Oklahoma City, OK

Position: Data Engineer

Inceed has partnered with a great company to help find a skilled Data Engineer to join their team!

Responsibilities:


 * Design, develop, document, test, and support the implementation of secure, medium-to-complex database solutions and ETL processes, working across relational, non-relational, and multi-dimensional environments.
 * Conduct data development tasks, address research requests, resolve defects, and manage time and project activities for both new and existing data management projects.
 * Develop and test solutions, including creating automated test scripts, while collaborating with IT colleagues and business users to define development requirements.
   
   

Required Qualifications & Experience:


 * Most important skillsets include: SQL, Data Warehouse, and ETL
 * Expertise in SQL development, with proficiency in designing, writing, and maintaining complex SQL-based ETL processes, including building large-scale batch and real-time data pipelines.
 * Skilled in designing data models and management strategies to support analytical applications, modeling tasks, and the needs of Analytical and Data Science teams.
 * Strong knowledge of data warehouse concepts and designs, including ETL processes, Star Schema, Multi-Dimensional databases, and cloud computing platforms such as Azure, AWS, Redshift, Lambda, and Cassandra.
 * Proficiency in at least one scripting language, such as PowerShell, JavaScript, Python, Ruby, Perl, or Bash.
 * Advanced data management and processing skills, with experience in relational and non-relational data stores, including NoSQL, S3, and Hadoop.
 * Ability to adapt database designs to meet project objectives and timelines while adhering to solid database design principles.
 * Expertise in defining data element descriptions and definitions, with proficiency in physical data modeling tools, such as Erwin.
 * Experience with SOA, Service Bus technologies, and other data abstraction tools and access layers.
 * Strong written and verbal communication skills, including technical documentation, Jupyter notebooks, presentations, and meetings.
 * Ability to deliver results effectively within project management methodologies, such as Agile, Scrum, and Waterfall.
 * Commitment to achieving organizational, departmental, and team goals and objectives.
 * Familiarity with DevOps practices, data pipeline management, and code repository tools like GIT.
   
   

Perks & Benefits:


 * Competitive and Comprehensive Benefits Package - Health, Vision, & Dental
 * Company Bonus Structure
 * 2023 Top Place to work
   
   

If you are interested in learning more about the Data Engineer opportunity, please submit your resume for consideration. Our client is unable to provide sponsorship at this time.

We are Inceed, a staffing and direct placement firm who believes in the possibility of something better. Our mission is simple: We’re here to help every person, whether client, candidate, or employee, find and secure what’s better for them.

Inceed is an equal opportunity employer. Inceed prohibits discrimination and harassment of any type and affords equal employment opportunities to employees and applicants without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by law.

",Full-time
4125058750,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4140342503,70099836.0,Data Engineer/Senior Data Engineer,"COMPANY

Volastra Therapeutics, Inc. is a clinical-stage oncology biotech company based in New York City, pioneering novel approaches to treating cancer by targeting chromosomal instability (CIN), a unique vulnerability in cancer. Since its founding in 2019, Volastra has grown to support ongoing discovery efforts and a growing clinical organization.

Our lead pipeline programs focus on two distinct inhibitors of KIF18A, a novel therapeutic target. VLS-1488, internally discovered, entered clinical trials in Q4 2023 for the treatment of advanced cancers. Sovilnesib, in-licensed from Amgen in 2023, re-entered the clinic in Q2 2024. Both assets have been granted Fast-Track Designation by the FDA.

Volastra is backed by top US and European venture firms such as Arch, Polaris, Vida, Droia, Catalio, and B Capital, alongside strategic investment from Eli Lilly. In addition to venture funding, Volastra has established partnerships with oncology leaders. Our senior leadership team is highly experienced, supported by a world-class advisory board.

We are headquartered in West Harlem, New York City, within easy reach of Columbia, Cornell, Memorial Sloan Kettering, and surrounding areas. Please visit www.volastratx.com for more information.

JOB DESCRIPTION

The Data Engineer/Senior Data Engineer will report to the Head of Data Science and work closely with team members across the organization to improve and maintain Volastra's data infrastructure, empowering researchers with data-driven insights. This position requires hands-on experience designing and implementing data pipelines, warehousing solutions, analytics frameworks and data dashboards. The Data Engineer will be instrumental in accelerating our scientific discoveries by enabling researchers to effectively analyze complex multimodal datasets, identify promising therapeutic targets, optimize patient selection strategies, and prioritize research initiatives.

The ideal candidate combines technical expertise with strong problem-solving abilities, can work independently while supporting cross-functional initiatives, and has experience scaling data systems in a high-growth environment. They will establish and maintain best practices for our data architecture and infrastructure, making sure that all systems of ingesting data are efficient, scalable and maintainable.

Volastra is a fast-paced and growing biotech company with a culture of continuous learning and innovation. There are numerous opportunities for professional growth as we expand our data capabilities and tackle new challenges. The job is based in NYC with a flexible option for partial hybrid work.

RESPONSIBILITIES


 * Design, build, and maintain scalable data pipelines and ETL processes to handle complex biological data, including high-throughput imaging and next-gen 'omics datasets.
 * Design, build, and maintain analysis dashboards to empower researchers to gain more insights from their data.
 * Develop and implement data warehouse architecture, ensuring optimal performance, reliability, and data quality for both structured and unstructured data
 * Collaborate with computational biologists, data scientists, wet lab researchers and leadership to understand data requirements and deliver solutions that accelerate rigorous, data-driven decision making.
 * Create and maintain documentation for data systems, processes, and models while establishing best practices for data engineering.
 * Optimize data infrastructure for performance, cost, and reliability while maintaining data security and compliance standards.
 * Clearly communicate key findings to members of the scientific and leadership teams.
 * Educate researchers on data management best practices and standards.
 * Contribute to building a culture that embraces technical excellence, integrity, and collaboration internally and externally.
   
   

QUALIFICATIONS


 * B.S. in Computer Science or a related discipline.
 * 5+ years of experience in data engineering or similar technical roles.
 * Strong programming skills in Python, R, SQL, and bash scripting and experience with modern data engineering tools.
 * 3+ years of experience with cloud computing, preferably Databricks and AWS (e.g., Data Warehouse, Lakehouse, Unity Catalog, EC2, S3), with expertise in designing, developing, and maintaining data warehouses and lakes.
 * Experience identifying data bottlenecks and implementing scalable ETL/ELT pipelines, with a proven track record of architecting effective solutions.
 * Experience in designing and implementing software solutions, including coding and development, from initial concept to deployment, tailored for seamless use by non-technical end users (i.e. DevOps).
 * Experience working with images and 'omics data types (e.g. whole genome sequencing, RNA-seq, proteomics).
 * Demonstrated expertise in designing and developing user-friendly cloud-based data analysis tools and dashboards (e.g., Shiny apps, Dash/Streamlit).
 * Strong problem-solving skills with ability to work independently while collaborating effectively.
 * Excellent communication skills with ability to effectively explain technical concepts to non-technical stakeholders.
   
   

PREFERRED SKILLS


 * Experience with the Benchling electronic lab notebook system, including API and lab automation functionality.
 * Experience and familiarity with machine learning models lifecycle, their maintenance and deployments (MLOps).
 * Expertise in cloud resource management, with a focus on implementing best practices for data accessibility and robust security measures, including IAM role management and cloud policy enforcement.
 * Experience working with bioinformatics tools and pipelines, particularly for processing NGS (e.g. Nextflow pipelines)
   
   

SALARY RANGE

Base salary of approximately $150,000- $175,000 which may vary depending on qualifications, experience, and ultimate leveling.",Full-time
4147808808,1447520.0,Staff Data Engineer - Samsung Ads,"Position Summary

Samsung Ads is a leading innovator in advertising technology, dedicated to providing cutting-edge solutions that optimize ad performance and deliver exceptional results for our clients. We are seeking a highly skilled and experienced front-end staff engineer to join our dynamic team and help shape the future of the ad tech industry. We seek a talented Staff Data Engineer to play a pivotal role in enhancing our platform’s performance advertising capabilities. As an integral part of our engineering team, you will collaborate with cross-functional teams to design, implement, and optimize attribution models, ensuring accurate measurement of marketing campaign effectiveness.




Role and Responsibilities

 * Develop and implement advanced attribution models to analyze and attribute the impact of various marketing channels on user conversion.
 * Collaborate with data scientists, product managers, and other engineers to refine and improve attribution methodologies.
 * Design and maintain scalable and optimized data pipelines for efficient collection, processing, and storage of attribution-related data.
 * Work closely with stakeholders to understand and translate business requirements into technical solutions.
 * Conduct A/B testing and performance analysis to validate and iterate on attribution models.
 * Stay updated on industry trends and emerging technologies related to attribution modeling and ad tech.




Qualifications

 * Bachelor’s or Master’s in Computer Science, Data Science, or a related field.
 * Requires at least 8 years of related experience and a Bachelor's degree; or 6 years and a Master's degree; or a PhD with 3 years
 * Proven experience in attribution modeling within the ad tech industry.
 * Strong programming skills in Python, Java, or Scala.
 * Experience in working with Kubernetes and stream data processing frameworks (Flink, Apache Ignite)
 * Proficient in working with big data technologies and databases (e.g., Hadoop, Spark, SQL, and MapReduce).
 * Hands-on experience with orchestration tools like Airflow or similar
 * Solid understanding of statistical concepts and experience with relevant tools.
 * Excellent problem-solving and communication skills.




Preferred Qualifications

 * Experience with machine learning techniques for attribution modeling.
 * Familiarity with real-time data processing and streaming technologies.
 * Knowledge of end-to-end digital advertising ecosystems and industry standards.
 * Knowledge of Snowflake and related technologies




California Only

Compensation for this role is expected to be between $200,000 and $220,000. Actual pay will be determined considering factors such as relevant skills and experience, and comparison to other employees in the role.

 * Please visit Samsung membership to see Privacy Policy, which defaults according to your location. You can change Country/Language at the bottom of the page. If you are European Economic Resident, please click here.

At Samsung, we believe that innovation and growth are driven by an inclusive culture and a diverse workforce. We aim to create a global team where everyone belongs and has equal opportunities, inspiring our talent to be their true selves. Together, we are building a better tomorrow for our customers, partners, and communities.

 * Samsung Electronics America, Inc. and its subsidiaries are committed to employing a diverse workforce, and provide Equal Employment Opportunity for all individuals regardless of race, color, religion, gender, age, national origin, marital status, sexual orientation, gender identity, status as a protected veteran, genetic information, status as a qualified individual with a disability, or any other characteristic protected by law.

Reasonable Accommodations for Qualified Individuals with Disabilities During the Application Process

Samsung Electronics America is committed to providing reasonable accommodations for qualified individuals with disabilities in our job application process. If you have a disability and require a reasonable accommodation in order to participate in the application process, please contact our Reasonable Accommodation Team (855-557-3247) or SEA_Accommodations_Ext@sea.samsung.com for assistance. This number is for accommodation requests only and is not intended for general employment inquiries.",Full-time
4125072864,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4076509364,33246798.0,Software Engineer Graduate (Data - Search - TikTok.US ) - 2025 Start (BS/MS),"Responsibilities

TikTok is the leading destination for short-form mobile video. At TikTok, our mission is to inspire creativity and bring joy. TikTok's global headquarters are in Los Angeles and Singapore, and its offices include New York, London, Dublin, Paris, Berlin, Dubai, Jakarta, Seoul, and Tokyo.

Why Join Us

Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible.

Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day.

To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always.

At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.

Join us.

About The Team

On the TikTok Search Team, you will have the opportunity to develop and apply cutting-edge machine learning technologies in real-time large-scale systems, which serve billions of search requests every day. Via advanced NLP and multi-modal models, our projects impact and improve the search experience for hundreds of millions of users globally. We are also exploring how to leverage LLM to further enhance TikTok users search experience, potentially sharping the search engine for the next generation. We embrace a culture of self-direction, intellectual curiosity, openness, and problem-solving.

We are looking for talented individuals to join our team in 2025. As a graduate, you will get unparalleled opportunities for you to kickstart your career, pursue bold ideas and explore limitless growth opportunities. Co-create a future driven by your inspiration with TikTok

Successful candidates must be able to commit to an onboarding date by end of year 2025.

We will prioritize candidates who are able to commit to these start dates. Please state your availability and graduation date clearly in your resume.

Applications will be reviewed on a rolling basis. We encourage you to apply early.

Candidates can apply for a maximum of TWO positions and will be considered for jobs in the order you applied for. The application limit is applicable to TikTok and its affiliates' jobs globally.

Online Assessment

Candidates who pass resume evaluation will be invited to participate in TikTok 's technical online assessment through HackerRank.

Responsibilities:


 * Search Engine Research and Development: Participate in the research and development of ByteDance's search engine. Utilize cutting-edge machine learning algorithms and vast amounts of data to create the most exciting technologies and provide users with the best search experience.
 * Core Product Search Development: Contribute to the search development of core products like Toutiao and Douyin, serving hundreds of millions of users.
 * Search Core Architecture Improvement:
 * Web Search System: Design and develop data flows for web searches at the trillion-page scale, distributed indexing systems, and online retrieval systems. Create industry-leading retrieval architectures.
 * Spider System: Design and develop services for real-time computing, scheduling, distribution, pressure control, and crawling in a trillion-page Spider system.
 * Stability Solutions: Design and develop high-availability solutions for search engine stability, automated testing, and maintenance platforms.
 * Innovative Architecture Implementation: Here, you can realize your architectural dreams without any historical burdens.
   
   

Qualifications

Minimum Requirements:


 * Academic Background: Current undergraduate or graduate student graduating in 2025, majoring in Computer Science, Software Engineering, or a related field.
 * Problem-Solving Skills: Excellent analytical and problem-solving abilities.
 * Programming Skills: Outstanding coding skills, with a strong foundation in data structures and basic algorithms.
 * Development Environment: Familiarity with Linux development environment and proficiency in at least one programming language such as C++, Java, Python, or Go.
   
   

Preferred Requirements:


 * Distributed Systems Experience: Prior experience in distributed systems development.
 * Search Engine Technologies: Familiarity with search engine technologies and architectures.
 * Machine Learning Knowledge: Understanding of machine learning algorithms and their application in search engines.
 * Team Collaboration: Experience working in a collaborative, team-oriented environment.
   
   

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at https://shorturl.at/cdpT2.

Job Information

【For Pay Transparency】Compensation Description (Annually)

The base salary range for this position in the selected city is $118657 - $250000 annually.

Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.

Benefits may vary depending on the nature of employment and the country work location. Employees have day one access to medical, dental, and vision insurance, a 401(k) savings plan with company match, paid parental leave, short-term and long-term disability coverage, life insurance, wellbeing benefits, among others. Employees also receive 10 paid holidays per year, 10 paid sick days per year and 17 days of Paid Personal Time (prorated upon hire with increasing accruals by tenure).

The Company reserves the right to modify or change these benefits programs at any time, with or without notice.

For Los Angeles County (unincorporated) Candidates:

Qualified applicants with arrest or conviction records will be considered for employment in accordance with all federal, state, and local laws including the Los Angeles County Fair Chance Ordinance for Employers and the California Fair Chance Act. Our company believes that criminal history may have a direct, adverse and negative relationship on the following job duties, potentially resulting in the withdrawal of the conditional offer of employment:


 * Interacting and occasionally having unsupervised contact with internal/external clients and/or colleagues;
 * Appropriately handling and managing confidential information including proprietary and trade secret information and access to information technology systems; and
 * Exercising sound judgment.",Full-time
4125072865,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4139522372,520950.0,Data Engineer,"As a 100% Employee-Owned company, Robert E. Mason & Associates, Inc. believes our Associates are the foundation of both our customers’ and our success. Our strong company culture, and belief in continued investment in our Associates, has helped us realize long Associate tenures, as well as long lasting relationships with our customers. Under the Robert E. Mason & Associates, Inc. umbrella there are two divisions: R.E. Mason and Apperture Solutions.

R.E. Mason is an Emerson Impact Partner covering North Carolina, South Carolina, and Virginia. Emerson is the global leader of process systems and solutions. R.E. Mason provides industry-leading process equipment and service for process control, automation, safety, and reliability. The industries served include Chemical, Pharmaceutical & Life Sciences, Power & Utilities, Food & Beverage, and Pulp & Paper.

Apperture Solutions is a technology independent, professional consulting, and implementation services firm. Apperture Solutions offers Data Enablement, Production Optimization, Operations Management, and Other Value-Added Services. Apperture Solutions partners with other providers to offer our customers the technologies and solutions that fit their needs.

What Apperture Offers Associates

Apperture is a 100% employee-owned company that offers a comprehensive, industry leading benefits package to all eligible Associates:


 * Participation in the Employee Stock Ownership Program (ESOP)
 * Retirement plan, including a Safe Harbor contribution
 * Medical / Dental / Vision Insurance
 * Employer paid Life Insurance and Long-Term Disability Insurance
 * Generous paid leave options that include vacation time, sick leave, personal leave time, R.E. Mason Way Half Day, paid Jury Duty, and paid Bereavement Leave
 * Paid Parental Leave
 * Paid company holidays
 * Career Development Program
 * Retirement and Financial Wellness program
 * Employee Assistance Program (EAP)
 * Alternative/Hybrid Work Schedules
   
   

General Description

The Data Engineer will play a crucial role in leveraging data analytics platforms to transform raw data into actionable insights. This position requires a strong background in data engineering, experience with Seeq Analytics, and a passion for solving complex data problems.

Specific Responsibilities


 * Develop, implement, and maintain data pipelines and ETL processes to ensure efficient data flow and transformation.
 * Utilize Seeq Analytics to analyze time-series data, generate insights, and support decision-making processes.
 * Experience in a data visualization tool such as PowerBI or related.
 * Collaborate with data scientists, analysts, and other stakeholders to understand data requirements and deliver solutions.
 * Optimize and tune data systems for performance and reliability.
 * Ensure data quality and integrity across various data sources.
 * Create and maintain documentation related to data engineering processes and workflows.
 * Assist in the deployment and management of machine learning models and advanced analytics solutions.
 * Troubleshoot and resolve data-related issues in a timely manner.
 * Support internal customers by developing innovative solutions to meet their data needs.
 * Enhance and support the CI/CD automation needs of the business.
 * Previous experience as an active SCRUM team member.
   
   

Required Competencies


 * Bachelor's degree in Computer Science, Information Technology, Engineering, or a related field.
 * 3-5 years of experience in data engineering or a similar role.
 * Proficiency in Seeq Analytics, including experience with its core functionalities and features.
 * Strong SQL skills and experience with relational databases (e.g., MySQL, PostgreSQL).
 * Experience with big data technologies (e.g., Hadoop, Spark) and cloud platforms (e.g., AWS, Azure, GCP).
 * Proficient in at least one programming language (e.g., Python, Java, Scala).
 * Familiarity with data visualization tools (e.g., Tableau, Power BI) is a plus.
 * Strong problem-solving skills and the ability to work independently and in a team environment.
 * Excellent communication skills, both written and verbal.
 * Highly communicative, detail-oriented, and career-minded with the ability to multitask.
 * Customer service-oriented with a positive attitude, always willing to tackle any task and go the extra mile.
 * Excellent communication skills
 * Resourcefulness and troubleshooting aptitude
 * Attention to detail
 * Ability to follow detailed instructions
 * Verbal and written communication Skills
 * Time Management Skills
 * Teamwork
   
   

Required Education And Experience


 * BSc/BA in Computer Science, Engineering or a related field.
   
   

Preferred Experience/Competencies


 * Experience with industrial data sources and IoT data such as SCADA/DCS, PLC, or process control.
 * Knowledge of data warehousing concepts and technologies (e.g., Redshift, Snowflake).
 * Understanding of machine learning concepts and experience with model deployment.
 * Certifications in relevant technologies and platforms.
   
   

Apperture is a federal contractor and, as such, is required to solicit the race, gender, disability status and protected veteran status of candidates. Thus, you are required to answer self-identification questions as part of your application process. These questions are part of Apperture’s Affirmative Action Plan and the completion of these questions will not have any effect on any consideration of your application materials.

In compliance with the ADA Amendments Act (ADAAA), if you have a disability and need to request an accommodation in order to apply for a position with Apperture, please call our office at (704) 375-4465.",Other
4144308499,1586.0,"Data Engineer, WWASFT","Description

WorldWide Amazon Stores FinTech (WWASFT) team is looking for an outstanding Data Engineer who is data-driven, uncompromisingly detail oriented, smart, efficient, and driven to help our business succeed. You have passion for technology. You are keen to leverage existing skills while trying new approaches. You are not tool-centric; you determine what technology works best for the problem at hand and apply it accordingly. You can explain complex concepts to your non-technical customers in simple terms.

As a Data Engineer, you will be working in one of the world's largest and most complex data warehouse environments. You will design, implement and support scalable data infrastructure solutions to integrate with multi heterogeneous data sources, aggregate and retrieve data in a fast and safe mode, curate data that can be used in reporting, analysis, machine learning models and ad-hoc data requests. You will be exposed to cutting edge AWS big data technologies. You should have excellent business and communication skills to be able to work with business owners and Tech leaders to gather infrastructure requirements, design data infrastructure, build up data pipelines and data-sets to meet business needs. You stay abreast of emerging technologies, investigating and implementing where appropriate.

Key job responsibilities


 * Design and develop the pipelines required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, Python and AWS big data technologies.
 * Oversee and continually improve production operations, including optimizing data delivery, re-designing infrastructure for greater scalability, code deployments, bug fixes and overall release management and coordination.
 * Establish and maintain best practices for the design, development and support of data integration solutions, including documentation.
 * Work closely with Product teams, Finance Teams, Software developers and Business Intelligence Engineer to explore new data sources and deliver the data.
 * Able to read, write, and debug data processing and orchestration code written Python/Scala etc following best coding standards (e.g. version controlled, code reviewed, etc.)
   
   

Basic Qualifications


 * 3+ years of data engineering experience
 * Experience with data modeling, warehousing and building ETL pipelines
 * Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets
 * Experience in at least one modern scripting or programming language, such as Python, Java, Scala, or NodeJS
   
   

Preferred Qualifications


 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
 * Experience working on and delivering end to end projects independently
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com Services LLC

Job ID: A2839788",Full-time
4124384454,3493.0,Data Engineer,"Conagra Brands is building an Enterprise Data Platform to deliver best-in-class data solutions. Join our Enterprise Data Engineering team and contribute to shaping and delivering data products that empower our business. Leverage cutting-edge technologies like Databricks, Snowflake, and Palantir to drive data-driven innovation.

As a Data Engineer, reporting to the Director of Information Technology, you will play a vital role in developing, maintaining, and optimizing data pipelines and workflows within our Enterprise Data Platform. Your work will help ensure data accuracy, reliability, and accessibility, enabling teams across the organization to make informed decisions.

This position offers an opportunity to grow your technical skills and collaborate with cross-functional teams to solve data challenges and create impactful solutions.

You Will (Position Responsibilities)


 * Develop and maintain data pipelines to process and integrate data from multiple sources into the Enterprise Data Platform.
 * Collaborate with data scientists, analysts, and business teams to gather and understand data requirements.
 * Build and optimize SQL queries and data transformations to support business use cases.
 * Create and manage data models and validate them with business stakeholders and data architects.
 * Perform data validation and troubleshooting to ensure data accuracy and consistency.
 * Automate workflows to improve data processing efficiency and reduce manual effort.
 * Monitor and optimize the performance of data pipelines and queries.
 * Participate in Agile ceremonies to plan, estimate, and deliver work efficiently.
 * Assist in creating documentation for data workflows, transformations, and standards.
   
   
   

You Have (Position Qualifications)


 * Bachelor’s degree in Computer Science, Information Systems, or a related field (or equivalent experience).
 * 2-4 years of experience in a data engineering or related role.
 * Proficiency in SQL for data transformation and analysis.
 * Familiarity with cloud-based data platforms such as Snowflake, Databricks, or similar tools.
 * Experience with ETL tools and frameworks like Informatica, Talend, or equivalent.
 * Knowledge of Python or PySpark for data processing is preferred.
 * Understanding of data modeling concepts and database design principles.
 * Strong problem-solving and analytical skills with attention to detail.
 * Excellent communication skills and ability to work in a collaborative team environment.
 * This position requires working from our Omaha or Chicago office 3 days a week in a hybrid work model.
   
   
   

Compensation

Pay Range:$71,300-$104,600

The annual salary listed above is the expected offering for this position. An employee’s actual annual salary will be based on but not limited to: location, relevant experience/level and skillset, while balancing internal Conagra employees’ equity. Conagra Brands will comply with applicable law regarding minimum salaries for exempt employees.

Our Benefits

We care about your total well-being and will support you with the following, subject to your location and role:


 * Health: Comprehensive healthcare plans, wellness incentive program, mental wellbeing support and fitness reimbursement
 * Wealth: Great pay, bonus incentive opportunity, matching 401(k) and stock purchase plan
 * Growth: Career development opportunities, employee resource groups, on-demand learning and tuition reimbursement
 * Balance: Paid-time off, parental leave, flexible work-schedules (subject to your location and role) and volunteer opportunities
   
   
   

Our Company

At Conagra Brands, we have a rich heritage of making great food. We aspire to have the most impactful, energized and inclusive culture in food. As a member of our 18,000+ person team across 40+ locations, you are empowered to reach your potential, make an impact and own your career. We're in the business of building champions – within our people and our iconic brands like Birds Eye ®, Slim Jim® and Reddi-Wip®.

Our focus on innovation extends beyond making great food, it also reflects our commitment to embracing new solutions that positively impact our team, the communities we serve and the health of our planet. Foodies Welcome.

Conagra Brands is an equal opportunity employer and considers qualified applicants for employment without regard to sex, race, color, religion, ethnic or national origin, gender, sexual orientation, gender identity or expression, age, pregnancy, leave status, disability, veteran status, genetic information and/or any other characteristic or status protected by national, federal, state or local law. Reasonable accommodation may be made upon request.

",Full-time
4125073020,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4075864846,3088.0,"Data Engineer 1 (Python, SQL, AWS)","Who Are We?

Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.

Compensation Overview

The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.

Salary Range

$106,300.00 - $175,400.00

Target Openings

1

What Is the Opportunity?

Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate the stories found in data. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.

What Will You Do?


 * Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.
 * Design data solutions.
 * Analyze sources to determine value and recommend data to include in analytical processes.
 * Incorporate core data management competencies including data governance, data security and data quality.
 * Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.
 * Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.
 * Test data movement, transformation code, and data components.
 * Perform other duties as assigned.
   
   

What Will Our Ideal Candidate Have?


 * Bachelor’s Degree in STEM related field or equivalent
 * Six years of related experience
 * Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices.
 * The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.
 * Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.
 * Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.
 * Strong verbal and written communication skills with the ability to interact with team members and business partners.
 * Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.
   
   

What is a Must Have?


 * Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
 * Four years of data engineering or equivalent experience.
   
   

What Is in It for You?


 * Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.
 * Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
 * Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
 * Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs.
 * Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.
   
   

Employment Practices

Travelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.

In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions.

If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.

Travelers reserves the right to fill this position at a level above or below the level included in this posting.

To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.",Full-time
4137787408,3358364.0,Data Engineer,"Artifact Uprising is looking for an experienced and highly motivated Data Engineer to join our Data & Analytics team. This role will focus on building and maintaining data pipelines, ensuring seamless integration of data sources, and enabling data accessibility across the organization. As a key member of the team, you will leverage AWS, Snowflake, DBT, Fivetran, Segment, and Looker to transform data into actionable insights.

Job Responsibilities


 * Data Pipeline Development: Design, build, and maintain reliable and scalable ETL/ELT data pipelines to integrate data from internal and external sources into Snowflake. Current toolset includes Fivetran, DBT, Segment, as well as Python scripts
 * Data Modeling and Architecture: Implement efficient data models in Snowflake, ensuring data is structured, organized, and optimized for analytics and business intelligence
 * Data Quality & Governance: Develop monitoring and validation tools to maintain the accuracy and consistency of data flowing through our pipelines
 * Scalable Solutions: Work with teams and stakeholders to create efficient and automated integrations of first and third party data in a sustainable manner
 * Collaboration with Teams: Work closely with analysts and business stakeholders to understand data requirements and implement solutions that empower data-driven decision-making
 * Optimization & Performance Tuning: Optimize data pipeline performance and ensure smooth operations by addressing bottlenecks and implementing best practices for scaling
   
   
   

Qualifications


 * 3+ years of experience in data engineering, data architecture, or a related technical role
 * Strong proficiency in SQL and experience with data querying and manipulation
 * Proficient in Python, particularly in writing custom scripts for data extraction, transformation, and integration
 * Experience with ETL processes and data pipeline orchestration tools (e.g. one of dbt, Apache Airflow, Talend, etc.)
 * Knowledge of data storage solutions such as cloud-based platforms (AWS, Azure, Google Cloud), relational databases (PostgreSQL, MySQL, etc.), and NoSQL databases (DynamoDB, MongoDB, Cassandra, etc.)
 * Solid understanding of data modeling principles and how to apply them in modern cloud-based data systems
 * Familiarity with data visualization and reporting tools like Looker, Tableau, or Power BI is a plus
   
   
   

Artifact Uprising® is a Colorado-based company that creates premium quality, customizable photo goods for your digital photos. Driven by the mission to empower people to tell their stories effortlessly, beautifully and often, the company is known for elevated design and thoughtfully sourced materials. Signature products include the Layflat Album touting ultra-thick pages and foil-stamped covers, textured matte Everyday Prints, and a line of customizable frames.

Artifact Uprising was recently named on the Built In Colorado’s 2024 Best Places to Work list. We are a tight-knit team who works with some of the latest technology to delight and inspire our customers.

Job Perks

Industry leading health, vision and dental insurance for families (Plans cover 100% for employees and up to 95% for dependents), flexible vacation policy, Gym partnership with ClassPass, 401(k) matching plan, Year-End Company Bonus Plan.

Why Artifact Uprising?

Creative Freedom We value the creative process and look to our employees to speak into Artifact Uprising products, identity and approach – regardless of position or title. We look for driven people who demonstrate initiative to take the company to the next level.

The Working Life

We strive to create a workplace where everyone works hard but also has the flexibility and balance to enjoy life outside of the office.

It Won’t Be Boring

We are a small company with big ideas - and we recognize it will take every last one of us to reinvent the way brands approach business. We believe a good workplace empowers its team to rise to new challenges, expand their skill sets and think outside of the box. Through this, we foster a company culture that is always growing, always reaching, and always looking to see things differently.

Interested in this position?

Tell us why you want to work at Artifact Uprising and what we should know about you.

Artifact Uprising is an Equal Employment Opportunity (EEO) employer. We do not discriminate based upon race, color, sexual orientation, gender identity, religion, national origin, age, disability, or veteran status.",Full-time
4138643143,3965520.0,Senior Software/Data Engineer,"Checchi Capital Advisers, LLC (“CCA”) is a quantitatively driven, independent Registered Investment Adviser (RIA) looking for a Senior Software/Data Engineer to join our talented and experienced team. You will collaborate directly with our Senior Data Scientists, Heads of Engineering, Product Development and Research to implement internally facing tools and processes to support our various investment strategies and research objectives. This position requires excellent communication skills, the ability to work on self-directed and group projects, the willingness to wear multiple hats and the motivation to contribute to the team’s needs.

Primary Responsibilities

·        Develop and maintain tools to support our core asset trading and portfolio analysis processes

·        Build tools to analyze new investment strategies and expand our robust simulation tools

·        Assist in development of tools to streamline the creation of data association mappings between disparate data sets

·        Research new data source possibilities and test the integration of the new sources with our existing tools

·        Support team needs with ad hoc data research

·        Spearhead data cleaning, organization and analysis

·        Lead architectural design initiatives for the data and computing needs of the firm, focusing on solutions that seamlessly integrate our technology stack

Abilities

·        Highly driven individual that works well in collaborative and independent environments

·        Ability to ingest, clean and validate large data sets

·        Exceptionally adaptable with new skills and technologies

·        Experience with market and investment data as well as APIs is a plus (via Bloomberg, CRB, Datastream, Refinitiv, LSEG, etc.)

Preferred Tech Stack

·        Operating System: Linux, Debian/Ubuntu

·        Language: Python3

·        Packages: Numpy, Pandas, Flask

·        Database: Mongo DB, PostgreSQL

·        Viz: Plotly Dash, Django, React

Applicable Experience

·        Bachelor’s degree in computer science or related field/similar level of education and experience

·        3+ years of experience in a pivotal Software/Data Engineering role, with deep exposure to modern data stacks

·        Experience with performing data analysis, data ingestion and data integration

Compensation Structure

At CCA, we carefully consider a wide range of factors when determining compensation. In accordance with CA law, we expect the base salary for this position to be in the range of $120,000 to $200,000. Actual base salaries may vary based on factors including but not limited to education, training, experience, and other job-related factors. Base salary is just one component of total compensation at CCA which may include, depending on eligibility: benefits, 401(k) retirement plan and ongoing share of team bonus structure.

Other Benefits

·        Hybrid work schedule available

·        CCA covers 100% of health, vision, and dental insurance

·        401(k) with generous company match

·        Start-up environment with state-of-the-art technology resources

﻿Please note: CCA does not currently sponsor H1B visas.








",Full-time
4117851034,523382.0,Data Engineer,"Your Job

As a Data Engineer at INVISTA, you will be a vital contributor to our Enterprise Data Platform, responsible for designing and implementing data pipelines, optimizing data workflows, and ensuring data reliability and accessibility. Your work will be instrumental in empowering our organization to make data-driven decisions and fueling innovation across the company.

Our Team

Joining our Data and Analytics team means becoming a key player in a dynamic and innovative group of professionals dedicated to unlocking the power of data. Here, you'll find a diverse and collaborative environment where your ideas and expertise will shape the future of our data-driven organization. We pride ourselves on fostering a culture of continuous learning, creativity, and teamwork, and we're looking for individuals who are eager to contribute their skills and passion to our shared mission.

This role may work a hybrid schedule out of our Wichita (KS) or Katy (TX) office location.

What You Will Do


 * Collaborate closely with business partners and data scientists to align data engineering efforts with their specific needs and objectives, ensuring that data solutions contribute effectively to the organization's overall goals. This includes proposing alternative solutions, with their pros and cons, to help guide the workstream forward.
 * Understand, develop, maintain/troubleshoot, automate, and optimize orchestration and data pipelines using tools such as Snowflake, dbt, GitHub, AWS, Power BI, and Neo4J.
 * Implement data integration strategies for streaming, event driven, and batch data sources.
 * Design and implement data modeling and ETL/ELT processes to ensure data quality, consistency, availability and data centricity.
 * Manage and maintain data warehouses and ensure data security and compliance with company policies and relevant regulations.
 * Perform data transformations, aggregations, and data cleansing to support analytics and reporting needs.
 * Document data engineering processes, pipelines, and architecture for knowledge sharing and compliance.
 * Stay up to date with industry best practices, emerging technologies, and trends in data engineering.
   
   
   

Who You Are (Basic Qualifications)


 * Experience in data modeling with SQL
 * Experience collaborating with a Finance team or in the Financial Services industry
 * Experience programming in Python
 * Ability to travel up to 20% of the time
 * This role is not eligible for visa sponsorship
   
   
   

What Will Put You Ahead


 * Experience with Snowflake data warehouse technology
 * Proficiency in designing software and data solutions that scale
 * Proficiency in Power BI, strong in DAX and analytics report building
 * Hands-on experience with AWS cloud computing platform
 * SAP Financial domain knowledge – Financial accounting and controlling modules
 * Experience with DevOps practices and tools, such as continuous integration (CI) and continuous deployment (CD) pipelines, version control systems (e.g., Git)
 * Knowledge of data governance and compliance best practices
   
   
   

At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.

Hiring Philosophy

All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here.

Who We Are

As a Koch company, INVISTA has a long history of working to make the world around you a better place. From parts for the automotive industry to medical equipment, air bags, food packaging and clothing, our ingredients in the nylon 6,6 and polypropylene value chains help bring many of life’s essential products to market.

At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.

Our Benefits

Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength - focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes - medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.

Additionally, everyone has individual work and personal needs. We seek to enable the best work environment that helps you and the business work together to produce superior results.

Equal Opportunities

Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, some offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please click here for additional information. (For Illinois E-Verify information click here, aquí, or tu).

",Full-time
4127772210,226644.0,Data Engineer,"Job Title: Data Engineer

Location: Charlotte/ Remote

Department: GTS- Technology

Reports to:  Head of Technology and Product




At Leaders Group, we rely on powerfully insightful data to inform our systems and solutions, and we’re seeking an experienced pipeline-centric data engineer to put it to good use. The ideal candidate will have the expected mathematical and statistical expertise, combined with a rare curiosity and creativity. This person will wear many hats in the role, but much of the focus will be on building out our Python ETL processes and writing superb SQL. Beyond technical prowess, the data engineer will need soft skills for clearly communicating highly complex data trends to organizational leaders. We’re looking for someone willing to jump right in and help the company get the most from its data.

Objectives of this role

 * Work with data to solve business problems, building and maintaining the infrastructure to answer questions and improve processes
 * Help streamline our data workflows, adding value to our product offerings and building out the customer lifecycle and retention models
 * Work closely with the data and business intelligence team to develop data models and pipelines for research, reporting, and machine learning
 * Be an advocate for best practices and continued learning

 

Responsibilities

 * Work closely with our business intelligence team to help build complex algorithms that provide unique insights into our data
 * Use agile software development processes to make iterative improvements to our back-end systems
 * Model front-end and back-end data sources to help draw a more comprehensive picture of user flows throughout the system and to enable powerful data analysis
 * Build data pipelines that clean, transform, and aggregate data from disparate sources
 * Develop models that can be used to make predictions and answer questions for the overall business
 * Additional responsibilities as assigned

 

Required skills and qualifications

 * Three or more years of experience with Python, SQL, Snowflake, Tableau, and other data visualization/exploration tools
 * Familiarity with the Azure ecosystem, specifically Logic Apps
 * Communication skills, especially for explaining technical concepts to nontechnical business leaders
 * Ability to work on a dynamic, research-oriented team that works within the Agile methodology with concurrent projects

 

Preferred skills and qualifications

 * Bachelor’s degree (or equivalent) in computer science, information technology, engineering, or related discipline
 * Experience in building or maintaining ETL processes
 * Professional certification




Working Conditions and Physical Requirements:

 * General office environment. Extensive computer use required. Ability to work flexible work schedules, including nights, weekends and holidays, as needed.

 

 

Leaders Group Holdings LLC is an Equal Opportunity Employer. The Company considers applicants for all positions without regard to race, color, religion, national origin, gender, age, marital status, disability, veteran status, sexual orientation, genetic information, or any other characteristic protected by applicable city, state, or federal law.",Full-time
4148830630,18059273.0,Senior Data Engineer - ETL/ Big Data/ Hadoop,"About Us

Energize your career with one of Information Technology’s fastest growing companies.

You dream of a great career with a great company – where you can make an impact and help people. We dream of giving you the opportunity to do just this. And with the incredible growth of our business, it’s a dream that definitely can come true. Already one of the world’s leading IT companies, MNJ SOFTWARE is restlessly pursuing new ways to operate our service centers, improve our service levels and help people lead healthier lives. We live for the opportunity to make a difference and right now, we are living it up.

MNJ SOFTWARE is an IT services, business solutions and outsourcing organization that delivers real results to global businesses, ensuring a level of certainty no other firm can match.

MNJ SOFTWARE offers a consulting-led, integrated portfolio of IT and IT-enabled services delivered through its unique Global Network Delivery Model, recognized as the benchmark of excellence in software development.

MNJ SOFTWARE service offerings span business and technology consulting, application services, systems integration, product engineering, custom software development, maintenance, re-engineering, independent testing and validation services, IT infrastructure services and business process outsourcing.

MNJ SOFTWARE takes pride in building strategic long-term client relationships.

MNJ SOFTWARE is only hiring those authorized to work in the India and unable to provide visa sponsorship at this time.

Job Details

MNJ SOFTWARE is looking for talented individuals who are interested to be part of ""Our"" journey to build a best-in-class organization, driving to deliver real results to global businesses, ensuring a level of certainty no other firm can match.

Senior Data Engineer - ETL/ Big Data/ Hadoop at MNJ SOFTWARE, you will participate in design, development and implementation of architectural deliverables of custom projects and products of MNJ SOFTWARE. The role includes working closely with lead, testers, customers, project/product managers and designers.

JobID

J0136

Title

Senior Data Engineer - ETL/ Big Data/ Hadoop

Experience

3-6 yrs

Job Type

Permanent / Contract [Depends on Project Needs or C2H]

Position Type

Full time [Monday – Friday]. Employees are required to have flexibility to work any of our 9-hour shift schedules during our normal business hours of (6am - 10pm IST) or (6pm to 6am IST). It may be necessary, given the business need, to work occasional overtime [unpaid].

Qualification

ME/M.TECH/BE/B.TECH/MCA/M.Sc(IT) etc

Technical/Functional Skills


 * Commercial experience leading on client-facing projects, including working in close-knit teams.
 * 5 + Years of experience working on projects within the cloud ideally AWS or Azure.
 * 5 + Years of experience working with streaming architectures and patterns like Kafka, Kinesis, Flink, or Confluent.
 * Experience with open-source tools like Apache Airflow and Griffin.
 * Experience with DevOps and DataOps patterns and tools like Jenkins, Kubernetes, Docker and Terraform.
 * Data Warehousing experience with cloud products like Snowflake, Azure DW, or Redshift.
 * Experience building operational ETL data pipelines across a number of sources and constructing relational and dimensional data models.
 * Experience building automated data quality and testing into data pipelines.
   
   

Roles & Responsibilities


 * You have experience with client projects and in handling vast amounts of data - working on database design and development, data integration and ingestion, designing ETL architectures using a variety of ETL tools and techniques.
 * You are someone with a drive to implement the best possible solutions for clients and work closely with a highly skilled Data Science team.
 * Lead on projects from a data engineering perspective, working with our clients to model their data landscape, obtain data extracts and define secure data exchange approaches.
 * Plan and execute secure, good practise data integration strategies and approaches.
 * Acquire, Ingest and Process data from multiple sources and systems into Big Data platforms.
 * Create and manage data environments in the Cloud.
   
   

Personal Attributes


 * Must be Analytical and possess good problem-solving capabilities
 * Independent thinker
   
   

Process

Aptitude Tests, Technical Tests, Interviews, Medical Health Checkup.

Reimbursement

Best in Industry

Certification

Optional

Location

Remote (Work From Home)

Competencies

Professionalism – Knowledge of general office and administrative support including MNJ SOFTWARE administrative policies, processes and procedures. Demonstrates professional competence and mastery of subject matter; is conscientious and efficient in meeting commitments, observing deadlines and achieving results; remains calm in stressful situations. Commitment to implementing the goal of gender equality by ensuring equal participation and full involvement of women and men in all aspects of work.

Teamwork – Works collaboratively with colleagues to achieve organizational goals; solicits input by genuinely valuing others’ ideas and expertise; is willing to learn from others; places team agenda before personal agenda; shares credit for team accomplishments and accepts joint responsibility for team shortcomings; ability to work beyond normal hours.

Planning and Organizing – Develops clear goals that are consistent with agreed strategies; identifies priority activities and assignments; adjusts priorities as required; allocates appropriate amount of time and resources for completing work; foresees risks and allows for contingencies when planning; uses time efficiently.

Assessment

Evaluation of qualified candidates may include an assessment exercise which may be followed by competency-based interview.

Languages

English is the working language of this above stated post. For this post, fluency in oral and written English is required.

Note

We're an Equal Opportunity Employer: You will receive consideration for employment without regard to race, sex, color, religion, sexual orientation, gender identity, national origin, protected veteran status, or on the basis of disability.

No Fee

THE MNJ SOFTWARE DOES NOT CHARGE A FEE AT ANY STAGE OF THE RECRUITMENT PROCESS (APPLICATION, INTERVIEW MEETING, PROCESSING, OR TRAINING).

General Considerations

According to policies and processes of MNJ SOFTWARE, the paramount consideration in the employment of the staff is the necessity of securing the highest standards of efficiency, competence, and integrity. Candidates will not be considered for employment with the MNJ SOFTWARE if they have committed violations of national / international human rights law, violations of national / international humanitarian law, sexual exploitation, sexual abuse, or sexual harassment, or if there are reasonable grounds to believe that they have been involved in the commission of any of these acts. The term “sexual exploitation” means any actual or attempted abuse of a position of vulnerability, differential power, or trust, for sexual purposes, including, but not limited to, profiting monetarily, socially or politically from the sexual exploitation of another. The term “sexual abuse” means the actual or threatened physical intrusion of a sexual nature, whether by force or under unequal or coercive conditions. The term “sexual harassment” means any unwelcome conduct of a sexual nature that might reasonably be expected or be perceived to cause offence or humiliation, when such conduct interferes with work, is made a condition of employment or creates an intimidating, hostile or offensive work environment, and when the gravity of the conduct warrants the termination of the perpetrator’s working relationship. Candidates who have committed crimes other than minor traffic offences may not be considered for employment.

Due regard will be paid to the importance of recruiting the staff on as wide a geographical basis as possible. The MNJ SOFTWARE places no restrictions on the eligibility of men and women to participate in any capacity and under conditions of equality in its principal and subsidiary organs. The MNJ SOFTWARE OFFICE is a non-smoking environment.

The paramount consideration in the appointment, transfer, or promotion of staff shall be the necessity of securing the highest standards of efficiency, competence, and integrity. By accepting an offer of appointment, MNJ SOFTWARE staff members are subject to the authority of the Managers and assignment by him or her to any activities or offices of the MNJ SOFTWARE in accordance with staff regulation In this context, all internationally recruited staff members shall be required to move periodically to discharge new functions within or across duty stations under conditions established by the MNJ SOFTWARE.

The evaluation of applicants will be conducted on the basis of the information submitted in the application according to the evaluation criteria of the job opening and the applicable internal legislations of the MNJ SOFTWARE, the Staff Regulations and Rules, administrative issuances and guidelines. Applicants must provide complete and accurate information pertaining to their personal profile and qualifications according to the instructions provided in inspira to be considered for the current job opening. No amendment, addition, deletion, revision or modification shall be made to applications that have been submitted. Candidates under serious consideration for selection will be subject to reference checks to verify the information provided in the application.

Openings

Apply

Add to Cart",Full-time
4125073023,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4151656739,67435.0,Data Engineer,"Are you ready to join Connecticut Innovation’s vibrant community of innovators? Connecticut Innovations (“CI”) is Connecticut’s strategic venture capital arm, and we are passionate about serving our portfolio of 220+ companies across various industries, with strengths in life sciences, technology, and climate tech.




Come join Noteworthy AI - Routine fleet operations. Extraordinary grid insights as a Data Engineer!




Noteworthy AI Overview




At Noteworthy AI, our mission is to improve the reliability, resiliency, and safety of the electric grid. Our vehicle-mounted cameras and AI help utilities and other grid operators increase their situational awareness of their assets while reducing costs. Our platform autonomously geolocates, photographs, and analyzes grid infrastructure as vehicles drive during routine operations, enabling more proactive grid management.




We’ve gained significant market traction, validation, and support from customers like Florida Power & Light, FirstEnergy Corp, and Alabama Power, investors like Earthshot Ventures and Techstars, and partners like Nvidia - so we are looking for great people to come and join our growing team! 🚀




We plan to expand our office space in New Haven, CT, later this year to enable more in-person collaboration and expect this role to follow a hybrid schedule.




About You




You are excited to roll up your sleeves at a fast-growing startup that is playing a critical role in helping to keep the electric grid energized and resilient.




You’re experienced writing Python and enabling machine-learning model development by processing and handling data




You want to grow your career by working with a dynamic research team on cutting-edge applied AI research and development, contributing to novel ML research, and learning key skills for AI and ML engineering




Responsibilities




 * Process and handle data to enable machine-learning (ML) and AI development tasks (i.e., dataset curation, labeling, training, inference, evaluation) and maintain a traceable, automated ML operations workflow
 * Lead analyses and experiments to identify salient data for ML development and characterize the performance of (ML) models.
 * Design, build, and improve data pipelines, interfaces, visualizations, and associated code infrastructure
 * Maintain databases and data lakes for ML development while ensuring data integrity and security
 * Support and interface with internal stakeholders to generate high-quality deliverables for customers
 * Contribute to internal documentation, code, and data standards and tooling




Minimum Qualifications




 * Bachelor's degree in Computer Science, Engineering, Mathematics, Statistics, or a related field OR commensurate experience in software development, data science, math, and statistics
 * Strong proficiency and recent experience in Python and standard data science libraries (numpy, pandas, scikit-learn, matplotlib, seaborn)
 * Demonstrated ability to write efficient and reliable software following best practices in software design, testing, review, and documentation
 * Strong technical communication skills
 * Ability to collaborate and work effectively on complex software systems in a team setting
 * A growth mindset, a willingness to take ownership of your work, and an ability to adapt to the challenges of a fast-paced startup environment




Preferred Qualifications




 * Experience designing data pipelines, handling large volumes of data, and generating compelling visualizations
 * Experience in SQL, relational databases, and/or related topics (i.e., database design, query optimization, NoSQL, RDSMS, etc.)
 * Experience with Amazon Web Service (AWS) products (e.g., S3, Redshift, DynamoDB, Lambda, Sagemaker) or equivalent cloud services (Microsoft Azure, Google Cloud Platform)
 * Experience and/or strong technical foundations in computer vision, like cameras and image capture, image encoding and storage, image processing and filtering, 3D vision, feature extraction
 * Experience and/or strong technical foundations in machine learning, supervised learning, optimization, neural networks, applications in computer vision (image classification, object detection, semantic segmentation, keypoint detection, tracking, etc.)
 * Hands-on experience writing ML training and/or inference code in Python and common libraries (e.g., PyTorch, Tensorflow, Keras, scikit-learn, Huggingface, Weights & Biases, Tensorboard)
 * Knowledge of ML operations and best practices for production-grade ML model development




What We Offer




 * Competitive salary, equity, and benefits
 * Opportunity to make an impact with AI in the increasingly important energy sector
 * Professional development and leadership opportunities
 * Flexible work hours in a hybrid setting




Location: This is a hybrid role. We prefer Connecticut-based candidates who can work from our office in New Haven several days per week.




Diversity, Equity and Inclusiveness




Noteworthy AI is committed to building an inclusive organization that reflects the diverse communities our team works to serve. We believe that diversity in all its forms (gender, race, ethnicity, age, sexual orientation, religion, veteran's status, disability and more) is essential to imagining and actively building a more just and sustainable future for all. We also actively promote diversity outside our organization, through the partnerships we enter into and the business decisions we make.",Full-time
4125069012,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4125059532,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4151529910,4725.0,IT Data Engineer - Remote,"City Rochester

State MN

Remote YES

Department Information Technology

Why Mayo Clinic

Mayo Clinic is top-ranked in more specialties than any other care provider according to U.S. News & World Report. As we work together to put the needs of the patient first, we are also dedicated to our employees, investing in competitive compensation and comprehensive benefit plans – to take care of you and your family, now and in the future. And with continuing education and advancement opportunities at every turn, you can build a long, successful career with Mayo Clinic. You’ll thrive in an environment that supports innovation, is committed to ending racism and supporting diversity, equity and inclusion, and provides the resources you need to succeed.

Responsibilities

Data Engineer gains access to data across the organization and provides ongoing analysis of the data by monitoring, profiling and analyzing databases. Requires a mix of functional, data and technical skills. The right candidate must be able to understand business requirements, translate them into information needs and implement those requirements using data available. The hire will be responsible for expanding and optimizing data architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems. The Data Engineer will support our software developers, database architects, and data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.

Core Job Duties Include


 * Assemble large, complex data sets that meet functional / non-functional business requirements.
 * Strong knowledge of SQL required. Ability to identify sets and subsets of information across multiple joins or unions of tables is preferred in addition to writing and troubleshooting SQL queries for data mining.
 * Strong knowledge of Python required. Ability to build, deploy and maintain data pipelines in a cloud infrastructure is preferred.
 * Perform complex data analysis and investigation for customer requests to explain results and to make appropriate recommendations.
 * Strong understanding of data modeling concepts.
 * Problem solver with the initiative to think critically to identify improvement opportunities (error detection, error correction, root cause analysis).
 * Understand ETL that will aid in verification and testing of data.
 * Build processes supporting data transformation, data structures, metadata, dependency and workload management.
 * A successful history of manipulating, processing and extracting value from large disconnected datasets.
 * Analyze business objectives and develop data solutions to meet customer needs.
 * Demonstrated ability to effectively participate in multiple, concurrent projects.
 * Improve and customize current data solutions to meet business functional and non-functional requirements.
 * Research new and existing data sources in order to contribute to new development, improve data management processes, and make recommendations for data quality initiatives.
 * Perform periodic data quality reviews for internal and external data.
 * Ensure timely resolution of queries and data issues.
 * Look for new ways to find and collect data by researching potential new sources of information.
 * Work with data and analytics experts to strive for greater functionality in our data systems.
   
   

Qualifications

Bachelor's degree in Computer Science or Engineering from an accredited University or College; OR an Associate’s degree in Computer Science or Engineering from an accredited University or College with 2 years of experience.

Demonstrated ability to analyze and profile data as a means to address various business problems through leveraging advanced data modeling, source system databases, or data mining techniques, is required. May provide consultative services to departments/divisions and committees. Demonstrated application of several problem-solving methodologies, planning techniques, continuous improvement methods, and analytical tools and methodologies (e.g. data analysis, data profiling, modeling, etc.) required. Incumbent must have ability to manage a varied workload of projects with multiple priorities and stay current on healthcare trends and enterprise changes. Interpersonal skills and time management skills are required. Requires strong analytical skills and the ability to identify and recommend solutions, advanced computer application skills and a commitment to customer service. Experience with data analysis, quality, and profiling; including data exploration tools including but not limited to Rapid SQL, AQT, Information Analyzer, and Informatics.

Preferred Qualifications


 * Experience with one or more GCP data engineering technologies (Data Fusion, DataFlow, Cloud Composer, BigQuery)
 * Experience with cloud data infrastructure technologies such as Terraform
 * Experience coding with Python
   
   

Authorization to work and remain in the United States, without necessity for Mayo Clinic sponsorship now, or in the future (for example, be a U.S. Citizen, national, or permanent resident, refugee, or asylee). Also, Mayo Clinic does not participate in the F-1 STEM OPT extension program.

Exemption Status

Exempt

Compensation Detail

$97,884.80 - $137,030.40 / year

Benefits Eligible

Yes

Schedule

Full Time

Hours/Pay Period

80

Schedule Details

Monday - Friday; 8:00 am - 5:00 pm

Weekend Schedule

As needed

International Assignment

No

Site Description

Just as our reputation has spread beyond our Minnesota roots, so have our locations. Today, our employees are located at our three major campuses in Phoenix/Scottsdale, Arizona, Jacksonville, Florida, Rochester, Minnesota, and at Mayo Clinic Health System campuses throughout Midwestern communities, and at our international locations. Each Mayo Clinic location is a special place where our employees thrive in both their work and personal lives. Learn more about what each unique Mayo Clinic campus has to offer, and where your best fit is.

Affirmative Action and Equal Opportunity Employer

As an Affirmative Action and Equal Opportunity Employer Mayo Clinic is committed to creating an inclusive environment that values the diversity of its employees and does not discriminate against any employee or candidate. Women, minorities, veterans, people from the LGBTQ communities and people with disabilities are strongly encouraged to apply to join our teams. Reasonable accommodations to access job openings or to apply for a job are available.

Recruiter

Miranda Grabner",Full-time
3970353535,3650502.0,Data Engineer,"Figma is growing our team of passionate people on a mission to make design accessible to all. Born on the Web, Figma helps entire product teams brainstorm, design and build better products — from start to finish. Whether it’s consolidating tools, simplifying workflows, or collaborating across teams and time zones, Figma makes the design process faster, more efficient, and fun while keeping everyone on the same page. From great products to long-lasting companies, we believe that nothing great is made alone—come make with us!

We are looking for an experienced Data Engineer to partner with our Data Science and Data Infrastructure teams to own and scale our data pipelines. You’ll also work closely with stakeholders across business teams including sales, marketing, and finance to ensure that the data they need arrives promptly and reliably. You’ll play an integral role in building the metrics and self-serve reporting capabilities to unlock Figma’s next phase of growth.

This is a great role for an individual who is passionate about working with data and data systems, and who loves solving problems. You’ll have a good sense for when it makes sense to build fast, scrappy solutions to unblock a key stakeholder vs. when to push back or bring in an outside service. The ideal candidate will be a great communicator who can help coordinate across multiple internal and external teams and takes pride in building end-to-end projects.

What you'll do at Figma:


 * Own, build, and maintain scalable data pipelines that connect various cloud data sources.
 * Develop a deep understanding of Figma’s core data models and optimize data pipelines for scale.
 * Partner with the Data Science and Data Infrastructure teams to build new foundational data sets that are trusted, well understood, and enable self-service.
 * Work with a wide range of cross-functional stakeholders to derive requirements and architect shared datasets; ability to document, simplify and explain complex problems to different types of audiences.
 * Establish best practices for the development of specialized data sets for analytics and modeling.
   
   

We'd love to hear from you if you have:


 * 4+ years in a relevant field
 * Fluency with both SQL and Python
 * Familiarity with Snowflake, dbt, Dagster, and ETL/reverse ETL tools.
 * Excellent judgment and creative problem solving skills
 * A self-starting mindset along with strong communication and collaboration skills
   
   

While not required, it’s an added plus if you also have:


 * Knowledge in data modeling methodologies to design and build robust data architectures for insightful analytics
 * Experience with business systems such as Salesforce, Customer IO, Stripe, NetSuite is a big plus.
   
   

At Figma, one of our values is Grow as you go. We believe in hiring smart, curious people who are excited to learn and develop their skills. If you’re excited about this role but your past experience doesn’t align perfectly with the points outlined in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles.

Pay Transparency Disclosure

If based in Figma’s San Francisco or New York hub offices, this role has the annual base salary range stated below.

Job level and actual compensation will be decided based on factors including, but not limited to, individual qualifications objectively assessed during the interview process (including skills and prior relevant experience, potential impact, and scope of role), market demands, and specific work location. The listed range is a guideline, and the range for this role may be modified. For roles that are available to be filled remotely, the pay range is localized according to employee work location by a factor of between 80% and 100% of range. Please discuss your specific work location with your recruiter for more information.

Figma offers equity to employees, as well a competitive package of additional benefits, including health, dental & vision, retirement with company contribution, parental leave & reproductive or family planning support, mental health & wellness benefits, generous PTO, company recharge days, a learning & development stipend, a work from home stipend, and cell phone reimbursement. Figma also offers sales incentive pay for most sales roles. Figma’s compensation and benefits are subject to change and may be modified in the future. You may view our Pay Transparency Policy by clicking on the corresponding link.

Annual Base Salary Range (SF/NY Hub):

$164,000—$338,000 USD

At Figma we celebrate and support our differences. We know employing a team rich in diverse thoughts, experiences, and opinions allows our employees, our product and our community to flourish. Figma is an equal opportunity workplace - we are dedicated to equal employment opportunities regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity/expression, veteran status, or any other characteristic protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.

We will work to ensure individuals with disabilities are provided reasonable accommodation to apply for a role, participate in the interview process, perform essential job functions, and receive other benefits and privileges of employment. If you require accommodation, please reach out to accommodations-ext@figma.com. These modifications enable an individual with a disability to have an equal opportunity not only to get a job, but successfully perform their job tasks to the same extent as people without disabilities.

Examples of accommodations include but are not limited to:


 * Holding interviews in an accessible location
 * Enabling closed captioning on video conferencing
 * Ensuring all written communication be compatible with screen readers
 * Changing the mode or format of interviews
   
   

By applying for this job, the candidate acknowledges and agrees that any personal data contained in their application or supporting materials will be processed in accordance with the applicable candidate section of Figma's Privacy Policy.",Full-time
4005089120,46623.0,Data Engineer,"Description

Your role at GEI.

GEI Consultants has an opening in our Operational Development Team for a qualified Data Engineer to support a variety of systems and data engineering tasks focused on data flow activities. The majority of our systems are based in MS SQL Server, Tableau Server, Azure, and FastField Forms. This person will primarily work closely with members of the Operational Development Team and with members of our IT staff. The ideal candidate will be focused, detail-oriented, and driven to attain and maintain very high standards for efficiency and accuracy in data acquisition and integration into our systems. The ideal candidate will have more than 3 years of data engineering experience in the AEC industry or in similar science and/or engineering environments. GEI seeks a committed, self-motivated, organized and detail-oriented individual who anticipates issues and thrives on creative, independent problem solving within a rapid, deadline-driven environment.

Essential Responsibilities & Duties


 * ETL of data from a wide variety of sources
 * Database and Data Warehouse design/expansion/backup & recovery
 * Index management and optimization
 * Support data sources for Tableau Server, Power BI, and ArcGIS
 * Stored procedure development and maintenance
 * Identify new opportunities within GEI where existing business approaches to data can be replaced with a more efficient/automated data flow and presentation of data for analysis
 * Develop and optimize ETL/SSIS packages to facilitate data transfer between FTP, remote data loggers, Azure, and on-premises databases
 * Troubleshoot SSIS package permission issues related to execute-as/data source read/write access
 * SQL Agent Job development and monitoring
 * Develop data reporting and visualizations as specified by clients using Tableau, SSRS, etc
 * Perform DML and DDL via tsql/stored procedures executed directly within SSMS and remotely via SSIS
 * Develop test plans, implementation plans, and project timelines for various data engineering projects
 * Define, prioritize, communicate, and foster shared understanding of project objectives and scope
 * Coordinate the development of standard operating procedures (SOPs), technical training programs, and QA/QC procedures for staff and work product
 * Team with all staff necessary to complete assignments
 * Collaborate with technical team members to ensure the solution design satisfies project objectives and business requirements
 * Other duties as assigned
   
   

Minimum Qualifications


 * 3+ years of experience in a position performing similar data engineering tasks
 * Proven record of ability to design, manage, and support MS SQL Server and Azure databases
 * Ability to work with the following programming/mark-up/scripting languages preferred: VB.net, python, XML, javascript, and R
 * Bachelor's Degree, from an accredited college or university
 * MS SQL Server/Azure certification preferred
 * Ability to develop project plans and meet deadlines
 * Self-starter with attention to detail and stakeholder needs
 * Able to critically analyze and solve problems of a complex nature
 * Excellent Communication skills
 * Able to work on multiple projects of moderate complexity simultaneously and independently
 * Proficient in organization and time management skills
 * Familiarity with engineering, environmental science, and/or chemistry subject matter preferred.
 * Able to work effectively in GEI’s partnership model, including a team environment, building rapport and relationships.
   
   

We are GEI.

Some of the world’s most pressing problems - from climate change to sustainable development, to critical infrastructure and the future of our energy supply - need our brightest and diverse minds working together to create safer, more resilient communities for tomorrow.

We are technical experts, collaborators, and entrepreneurs who draw from diverse backgrounds to solve our clients’ most complex challenges.

With nearly 60 offices across North America, we offer a range of engineering, science, and technical consulting services. Our range of expertise, project types, and culture make us the choice for top talent in the AEC industry.

Employee-owned. Employee-focused.

As a 100% employee-owned company, our employees support our flat leadership structure, have a say in how our business operates and benefit from our financial success. We are committed to employee growth with career development opportunities, competitive total rewards, a well-being program, flexible work arrangements and more. Our company culture is driven by our 4 Cs - we are Client-Centered, Curious, Collaborative, and Community Minded - which support our focus on sustainability, safety, diversity, equity and inclusion. Get to know us better by visiting GEI’s career site here.

GEI’s Total Rewards Package


 * Market-Competitive Compensation, including Eligibility for an Annual Performance Bonus
 * Pay Range For This Position: $33.65-72.11/hour
 * Comprehensive Benefits Program, including Medical, Dental, Vision, Life, Disability and More
 * Well-Being Program and Paid Parental Leave
 * Commuter Benefits
 * Hybrid Work Schedules and Cell Phone Stipends
 * GEI University (GEIU) with Continuing Education Assistance and Tuition Reimbursement
 * Connecting Conversation Program with a Focus on Professional Development and Opportunities for Advancement
 * Support and Financial Rewards for Publication Awards, Professional Dues, and Professional Licenses
 * Paid Holidays and Generous Paid Time Off Program
 * Rewards and Recognition
 * GEI-Funded Profit Sharing and 401(k)
 * Opportunity to be an Owner and Shareholder (Learn more here)
 * A Vibrant Culture that is Focused on Partnership, Sustainability, Giving Back to Our Communities and Diversity, Equity and Inclusion
 * And More…
   
   

Physical Job Requirements

Sedentary

X

Light

Medium

Other

Activity Level Throughout Workday

Physical Activity Requirements

Occasional

(0-35% of day)

Frequent

(33-66% of day)

Continuous

(67-100% of day)

Not Applicable

Sitting

X

Standing

X

Walking

X

Climbing

X

Lifting (floor to waist level) (in pounds)

X

Lifting (waist level and above) (in pounds)

X

Carrying objects

X

Push/pull

X

Twisting

X

Bending

X

Reaching forward

X

Reaching overhead

X

Squat/kneel/crawl

X

Wrist position deviation

X

Pinching/fine motor skills

X

Keyboard use/repetitive motion

X

Taste or smell (taste=never)

X

Talk or hear

X

Accurate 20/40

Very Accurate 20/20

Not Applicable

Near Vision

X

Far Vision

X

Yes

No

Not Applicable

Color Vision (ability to identify and distinguish colors)

X

Sensory Requirements

Minimal

Moderate

Accurate

Not Applicable

Depth perception

X

Hearing

X

Environmental Requirements

Occupational Exposure Risk Potential

Reasonably Anticipated

Not Anticipated

Blood borne pathogens

X

Chemical

X

Airborne communicable diseases

X

Extreme temperatures

X

Radiation

X

Uneven surfaces or elevations

X

Extreme noise levels

X

Dust/particular matter

X

Other (exposure Risks)

Usual workday hours:

X

8

10

12

Other work hours

GEI is an AA/equal opportunity employer, including disabled and veterans.",Full-time
4125060555,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4144189912,71664418.0,Data Engineer,"About VRGL

VRGL is a high-growth software and data analytics company serving the wealth management industry. Its products and services revolutionize the way RIAs and wealth managers attract, grow, and retain revenue through quantitatively assessing a client’s current investment portfolio across five core investment pillars and providing relevant comparisons. This immediate transparency allows financial advisors, wealth managers and anyone with brokerage and custodial statements to instantly extract data and quantify what is and can happen in their current portfolio and what would happen with a transition of assets. Through VRGL’s “5 Pillars,” a financial advisor can quickly help a prospective client identify the advantage of a switch. No more steak dinners and golf outings over years to develop a relationship, go straight to the heart of your value add.




Data Engineer

As a Data Engineer, you will be the cornerstone of VRGL’s data operations. You will manage critical data pipelines, ensure data quality, and collaborate with internal teams to optimize our analytics infrastructure. This hands-on role requires expertise in data engineering, problem-solving, and collaboration with cross-functional teams.




Responsibilities

Data Integration and Management:

 * Oversee and manage multiple data streams, including:
 * FTP files from ICE and Morningstar.
 * API calls to ICE Remote Plus and other fundamental data sources.
 * Internal scraping software for SEC EDGAR filings.
 * Monitor and troubleshoot data ingestion pipelines to ensure seamless operations.




Data Quality Assurance:

 * Validate fund data from sources like Morningstar against the internal database and resolve mismatches.
 * Ensure the accuracy and completeness of all records across data sources.
 * Perform systematic checks on data integrity, addressing issues such as missing records or incorrect data ingestion.




Pipeline and Workflow Optimization:

 * Maintain and improve data pipelines, especially for high-volume streams like ICE market data.
 * Ensure nightly risk calculation processes run smoothly for a database of 7M+ securities, encompassing bonds, stocks, and other asset classes.
 * Build and refine processes to account for unique scenarios like distributions, splits, and corporate actions.




Collaboration and Stakeholder Engagement:

Act as the primary point of contact for all data-related issues, working closely with:

 * Product teams to align data solutions with business goals.
 * Analytics teams to support their modeling and analysis needs.
 * Client Experience teams to address data complaints and ensure client satisfaction.
 * Development teams for troubleshooting and improving data ingestion systems.




Technical Proficiency:

 * Use PostgreSQL and Snowflake to manage databases and optimize data storage and retrieval.
 * Write and execute SQL queries for data analysis and troubleshooting.
 * Implement dbt (Data Build Tool) to standardize and streamline data transformation workflows.




Data Governance and Ownership:

 * Take full ownership of data systems, ensuring all processes run efficiently and data is reliable.
 * Regularly audit pipelines and proactively fix broken processes or suboptimal workflows.
 * Maintain documentation of all data streams, processes, and troubleshooting steps for internal use.




Scalability and Innovation:

• Contribute to the scalability of data systems to handle increasing data volumes and new data sources as VRGL grows.

• Stay up-to-date with industry trends and technologies, incorporating best practices into the organization’s data strategy.




Position Requirements

Experience and Skills:

 * 3+ years of experience as a Data Engineer or similar role.
 * Experience with equity and fixed income markets data required
 * Expertise in databases such as PostgreSQL and Snowflake.
 * Strong SQL skills for data querying and troubleshooting.
 * Experience with dbt or willingness to learn on the job.
 * Familiarity with alternative investments like Private Equity and Hedge Funds is a plus
 * Systematic thinker with a proactive problem-solving mindset.




Preferred Skills:

 * Knowledge of financial technologies and market data.
 * Experience in a fast-paced startup or high-growth environment.




Why VRGL?

Join a collaborative team at the forefront of wealth management technology. Be part of an organization that values innovation, transparency, and impactful work.







VRGL is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: VRGL does not discriminate in employment on the basis of race, color, religion, sex (including pregnancy and gender identity), national origin, political affiliation, sexual orientation, marital status, disability, genetic information, age, membership in an employee organization, retaliation, parental status, military service or other non-merit factor.",Full-time
3787726033,29550.0,Data Engineer -  IDELIC,"About Idelic

Idelic uses cutting-edge technology and beautifully designed interfaces to help predict and prevent trucking accidents and reduce driver turnover to ensure drivers get home safely each and every night. Our SaaS solutions are radically transforming the way in which the transportation industry manages safety through advanced Machine Learning (ML) and our driver management platform.

We believe that people do their best work while part of a culture that fosters inclusion, innovation, professional development, and teamwork. Together, we can fulfill our mission to make our roads and highways safer for everyone.

About Our Team

We are a venture-backed start-up company filled with people who are passionate about our product and seek to deliver the best experience for our clients. At Idelic, we’re committed to our mission, our customers, our teammates, and fostering a “work hard, play hard” culture.

Considering joining our team? You will be a part of an engaging, energetic, and entrepreneurial work environment headquartered in the heart of the technology boom within Pittsburgh, PA. We hire optimistic, results-oriented, innovative, and adaptable individuals with the desire to help our clients and one another succeed.

Overview Of The Role

Deploying a reliable and scalable machine learning project requires a lot of software engineering and devops work. Mathematical algorithms are typically a small portion of the overall deployment. The data engineer will assist data scientists and machine learning engineers with both coding and devops in order to build and deploy machine learning models.

You are not expected to have machine learning experience but you will be in charge of many of the tasks involved in running machine learning code in production. This will include implementing distributed systems such as microservices and task queues, as well as automating various data ingestion and preprocessing steps.

You should be comfortable with day-to-day operations and DBA tasks like launching EC2 instances, installing packages, writing shell scripts, and running SQL migrations.

What You’ll Do


 * Design and implement microservices to run machine learning models
 * Help implement the next version of a distributed task queue for data processing
 * Support data access layers and data ingestion for PostgreSQL databases
 * Assist with devops and automation prior to full production releases
 * Work on any task and help solve problems when needed — be humble and scrappy!
   
   

What You’ll Need To Succeed In The Role


 * 3+ years of experience building backend architecture for distributed systems
 * Bachelor’s or equivalent degree in computer science, or a related field
 * Experience with Python, SQL
 * Comfortable with Linux, BASH, git
 * Experience working within AWS and AWS technologies (e.g. EC2, RDS, VPC, etc.)
 * Analytical and Problem Solving Skills
 * Proven ability to work in a collaborative and fast-paced environment
   
   

What Will Set You Apart


 * Experience deploying machine learning models in production
 * Familiarity with training machine learning models
 * Experience with containerization and Kubernetes
 * Experience with TensorFlow Serving
   
   

THINGS THAT MAKE IDELIC A GREAT PLACE TO WORK


 * Competitive Compensation Package Including Options
 * Medical, Dental, Vision and Life Insurance
 * 401(k) with Company Matching Funds
 * Regular Company Outings and Events
 * Kickstarter Company Breakfast every Monday / Company Lunch Every Friday
 * A Dynamic and Supportive Environment
 * Professional Development Opportunities
 * Be Part of a Small Team (to Start)— Which Translates To You Having A Big Personal Impact
   
   

Please forward qualified resumes to: https://idelic.com/company/careers/

TYPICAL PHYSICAL DEMANDS

The physical demands that are described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

While performing the duties of this job, the employee is regularly required to hear and see. The employee is regularly required to stand and sit. The employee is regularly required to practice manual dexterity sufficient to operate standard office equipment. Specific vision abilities required by this job include close vision and distant vision.

WORKING CONDITIONS:

While performing the duties of this job, the employee is exposed to standard office equipment. The noise level in the work environment is generally moderate. Occasionally called upon to work hours in excess of your normal daily schedule.

Idelic is an equal opportunity employer. Our success depends heavily on the effective utilization of qualified people, regardless of their race, ancestry, religion, color, sex, age, national origin, sexual orientation, gender identity, disability, veteran’s status, or any characteristic protected by law.

Powered by JazzHR

kWd37va4Zi",Full-time
4119933863,69639337.0,Data Engineer,"BeaconFire is based in Central NJ, specializing in Software Development, Web

Development, and Business Intelligence; looking for candidates who are good communicators and self-motivated. You will play a key role in building, maintaining, and operating integrations,

reporting pipelines, and data transformation systems.




Qualifications:

● Passion for data and a deep desire to learn.

● Master’s Degree in Computer Science/Information Technology, Data Analytics/Data

Science, or related discipline.

● Intermediate Python. Experience in data processing is a plus. (Numpy, Pandas, etc)

● Experience with relational databases (SQL Server, Oracle, MySQL, etc.)

● Strong written and verbal communication skills.

● Ability to work both independently and as part of a team.




Responsibilities:

● Collaborate with the analytics team to find reliable data solutions to meet the business

needs.

● Design and implement scalable ETL or ELT processes to support the business demand for

data.

● Perform data extraction, manipulation, and production from database tables.

● Build utilities, user-defined functions, and frameworks to better enable data flow patterns.

● Build and incorporate automated unit tests, participate in integration testing efforts.

● Work with teams to resolve operational & performance issues.

● Work with architecture/engineering leads and other teams to ensure quality solutions are

implemented, and engineering best practices are defined and adhered to.




Compensation: $65,000.00 to $80,000.00 /year

BeaconFire is an e-verified company. Work visa sponsorship is available.",Full-time
4148737279,76322470.0,Data Engineer,"Why N-able

IT doesn’t get better than this! N-able isn’t just another software company – we’re going places, and we’d love for you to be a part of that journey. With N- ablites in more than 15 countries around the world, you’re adding your unique voice to a diverse team of people who are supporting our customers, and one another. The Way We Work, our hybrid working model based on trust and flexibility, allows you to maximize your contributions while growing your career. Join a team where you can make a difference!

What You'll Do


 * Be a key contributor to the buildout of core enterprise data solutions, including our enterprise Data Lakehouse
 * Collaborate with your team to refine, design, peer review, test and deploy incremental data features
 * Solve complex data problems to make data readily available, trusted, and easy to consume
 * Work with stakeholders to understand what is fixed and flexible in user stories to help meet user needs in innovative ways
 * Work collaboratively with cross-functional teams in an Agile environment
 * Own production issues and lead resolution efforts when production support teams require assistance
   
   
   

What You'll Bring


 * 2+ years data engineering experience
 * 2+ years of experience with SQL, Python, ETL, data warehousing, APIs, cloud computing, and big data technologies
 * Experience implementing service-oriented architecture
 * Experience with software development practices including git, modularity, containerization, test driven development, CI/CD, unit testing
 * Familiarity with data visualization tools, Tableau, Power BI
 * Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience
   
   
   

Purple Perks

What do we offer you?


 * Medical, dental and vision – for employee , partner , and children!
 * Generous PTO and observed holidays
 * 2 Paid VoluNteer Days per year
 * Pension Plan with company-contribution
 * Employee Stock Purchase Program
 * Discounted gym access at several local facilities
 * FuN -raising opportunities as part of our giving program
 * N-ablite Learning – custom learning experience as part of our investment in you
 * The Way We Work – our hybrid working model based on trust and flexibility
   
   
   

About N-able

At N-able, Inc. (NYSE: NABL), we are a global software company that turns IT possibilities into capabilities. That means we partner with technology leaders who support companies around the world by offering secure infrastructure and tools to navigate their evolving IT needs. We build strong relationships with our customers to help them thrive at every stage of growth, and at the heart of this effort is our network of N-ablites—a global team of extraordinary, diverse creators who are dedicated to making a difference in how our partners do IT.

",Full-time
4109073488,72143958.0,Data Engineer (057-24),"Data Engineer | Make an Impact with Anglicotech!




We seek a Data Engineer who will thrive in a challenging, rewarding, process-oriented environment. You will be part of a team supporting the USINDOPACOM Commander in implementing the National Defense Strategy in the Indo-Pacific region by identifying processes that will benefit from the use of technology goals to improve collaboration within the command and across the DoD and integrate new capabilities into the existing operational framework to support decision-making capabilities.




Location:

 * This position is located in Pearl Harbor, HI.




Salary:

 * A salary range of $122,000 - $205,000 is available for this position commensurate with education, years of experience, and qualifications.




Responsibilities:

 * Configure and ingest designated structured, unstructured, and semi-structured data repositories.
 * Design, implement, and manage databases and data delivery systems for insights, analysis, and reporting.
 * Apply expertise in database design and implementation tools, such as entity-relationship data modeling and SQL, distributed computing architectures, operating systems, storage technologies, memory management and networking.
 * Perform streaming and batch data processing, ETL, data wrangling, data ingest, and data access.
 * Support the identification, coordination, harvesting, and exposure of data sources across multiple domains and classification levels for ingestion.




Security Clearance:

 * US Citizenship required
 * Ability to obtain and maintain a US Security clearance at the minimum level of Secret




Education and Experience:

 * Bachelor of Science Degree in Data Science, Computer Science, Software Engineering, or similar
 * 3+ years of experience in data science, specifically in the DoD or other large business




Preferred Additional Skills:

 * Experience with DoD
 * 10+ years of experience in Data Science
 * MA/MS in Data Science, Data Analytics, Data Engineering or similar
 * Good organization skills to balance and prioritize work
 * Analytical and problem-solving skills to troubleshoot systems problems
 * Excellent communication skills, both written and verbal
 * Ability to work independently and as part of a team




**




ANGLICOTECH, LLC is an established, rapidly growing, veteran-owned small business providing Global Logistics and Supply Chain management, systems and analysis, Cybersecurity and NIST SP 800-171 compliance solutioning as well as Enterprise Information Technology Implementation and Services.




Anglicotech, LLC is an Equal Opportunity Employer with a strong commitment to supporting and retaining a diverse and talented workforce. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.




Anglicotech, LLC offers competitive compensation, benefits, and great long-term career opportunities.




The Benefits of Working with Us:

 * Competitive Salary & Bonuses – Your expertise matters, and we value that.
 * Opportunities for Growth – We believe in investing in our team’s future.
 * Health & Wellness – Comprehensive medical, dental, vision, and life insurance plans.
 * Work-Life Balance – We support flexible working hours and 24x7 team collaboration when needed. You bring the talent; we’ll support your well-being.
 * Make a Difference Today! Your next career move could be the one that makes an impact on a global scale. At Anglicotech, we’re not just hiring an Oracle EBS Technical Developer—we’re looking for a game changer. Are you ready to elevate your career and support those who protect and serve?




For more information or to apply, visit our website at www.anglicotech.com/career.

",Full-time
4126615988,1586.0,"Data Engineer, Ads Finance","Description

Ads Central FP&A Finance is seeking a Data Engineer with strong database, analytical skills and big data technology experience who is passionate about building scalable next generation tools and data infrastructure to support science and automation.

As a key data solution provider, you will be partnering with Finance and Business leaders to design, build, expand and optimize centralized data solutions. You will be working with massive amount of data, and your big data solutions will be supporting our rapidly growing Ads Business and dynamic business demand for data.

In this role, you will be able to stretch your technical and analytical skills in developing Data frameworks and large database architecture for building orchestration layers and GenAI solutions for reporting tools and statistical models needed to provide key performance indicators and insights for our high-growth businesses.

Key job responsibilities


 * Develop data products, infrastructure and data pipelines leveraging AWS services (such as Redshift, Kinesis, EMR, Lambda etc.) and internal Amazon tools.
 * Improve existing solutions and come up with next generation Ads Finance Data Architecture to improve scale, quality, timeliness, coverage, monitoring and security.
 * Develop new data models and end to end data pipelines.
 * Develop a deep understanding of our vast data sources and know exactly how, when, and which data to use to solve particular business problems.
   
   

Basic Qualifications


 * 2+ years of data engineering experience
 * Experience with SQL
 * Experience with data modeling, warehousing and building ETL pipelines
 * Experience with at least one modern language such as Java, Python, C++, or C# including object-oriented design
 * Knowledge of software engineering best practices across the development life cycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations
   
   

Preferred Qualifications


 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience writing and optimizing SQL queries with large-scale, complex datasets
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $91,200/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com Services LLC

Job ID: A2874541",Full-time
4128478242,3088.0,Data Engineer I,"Who Are We?

Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.

Compensation Overview

The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.

Salary Range

$106,300.00 - $175,400.00

Target Openings

1

What Is the Opportunity?

Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate the stories found in data. You will leverage your ability for the team members supporting Enterprise Underwriting, they will be helping to reinvent global underwriting analytics at Travelers. They will be curating the data to support the proverbial cockpit controls in an airplane that senior leaders will use to make underwriting decisions at Travelers.

What Will You Do?


 * Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.
 * Design data solutions.
 * Analyze sources to determine value and recommend data to include in analytical processes.
 * Incorporate core data management competencies including data governance, data security and data quality.
 * Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.
 * Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.
 * Test data movement, transformation code, and data components.
 * Perform other duties as assigned.
   
   

What Will Our Ideal Candidate Have?


 * Bachelor’s Degree in STEM related field or equivalent
 * Six years of related experience
 * Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices.
 * The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.
 * Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.
 * Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.
 * Strong verbal and written communication skills with the ability to interact with team members and business partners.
 * Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.
 * Experience with some of the following tools & platforms (or similar): AWS (s3, Lambda, Kinesis, API Gateway, IAM, Glue, SNS, SQS, EventBridge, EKS, VPC, Step Functions, ECS/EKS, DynamoDB, etc.), Databricks, Python, JavaScript, Kafka, dbt, Terraform, Snowflake, SQL, Jenkins, Github, Airflow, OpenSearch (Elasticsearch & Kibana), Talend, Alation, Neo4j, Hashicorp Vault / AWS Secrets Manager, Docker / OpenShift / Open Cloud Foundry, MongoDB, Docker, BlackDuck, SonarQube
 * Knowledge and experience with the some of the following concepts: Real-time & Batch Data Processing, Workload Orchestration, Cloud, Datalakes, Data Security, Networking, Serverless, Testing/Test Automation (Unit, Integration, Performance, etc.), WebServices, DevOps, Logging, Monitoring, and Alerting, Containerization, Encryption / Decryption, Data Masking, Cost & Performance Optimization.
   
   

What is a Must Have?


 * Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
 * Four years of data engineering or equivalent experience.
   
   

What Is in It for You?


 * Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.
 * Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
 * Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
 * Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs.
 * Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.
   
   

Employment Practices

Travelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.

In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions.

If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.

Travelers reserves the right to fill this position at a level above or below the level included in this posting.

To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.",Full-time
4067136205,72008814.0,Data Engineer,"Company Background

Ownwell helps property owners reduce the costs of owning real estate. Our proprietary software automatically identifies property owners that are overpaying on real estate expenses. We then manage the end-to-end process of reducing bills through tax appeals, exemptions, and corrections.

Over $40 billion is overpaid in property taxes every year, and inaccurate tax assessments disproportionately affect people of color, immigrants, as well as low-income communities.

We're dedicated to making the costs of property ownership more transparent and equitable. We believe that regardless of status or level of real estate expertise, everyone should have access to the information, tools, and resources to manage their real estate with confidence.

Ownwell is well-funded and venture-backed by some of the best investors in the world. Our customer base has grown by more than 1000% year-over-year with exceptional feedback demonstrating clear product market fit. We are looking for driven and passionate team members who thrive in a collaborative, positive culture where we all win together. If this sounds like the place for you, come help us change the way everyday homeowners manage their real estate across the country.

Our Culture

People are our superpower! Centered in everything we do is a true sense of team. We listen and we learn from each other. We are on this rocketship together and embrace a fast-paced, truly collaborative environment. We are here to win as a team and as a company.

We've brought together General Appraisers, Certified Public Accountants, Property Tax Consultants, Data scientists, PhDs, best-in-class customer support representatives, and more to deliver top results for our customers.

Our core values are our guiding principles in everything we do


 * Customer Obsession
 * Take Ownership
 * Do The Right Thing
 * Go Far Together
 * Accelerate Innovation
   
   

The Role:

As a data engineer at Ownwell, you'll support core business functions by maintaining and expanding upon the highest fidelity real estate data in the industry. You'll build and manage Ownwell's data orchestration system that feeds our algorithms and downstream analytics. The scope of this role spans marketing, product, ops, and finance. If you love solving large scale data problems and designing data systems with some of the brightest engineers, then this is the role for you!

Responsibilities:


 * Be a subject matter expert on data modeling, data pipelines, data quality and data warehousing.
 * Design, build and maintain data ETL/ELT pipelines to source and aggregate data for various data analysis and reporting needs.
 * Develop integrations with third party systems to source, qualify and ingest various datasets.
 * Continually improve the operations, monitoring and performance of the data warehouse.
 * Provide data analytics and visualization tools to extract valuable insights from the data to enable data-driven decisions.
 * Productionize analytics pipelines on AWS cloud platforms through well-structured, reproducible code and workflows.
 * Understand and implement required development guidelines, design standards and best practices always.
 * Understand in detail the business operational process both before and after the impact of any software changes.
 * Take responsibility through analysis, design, development, and code reviews to ensure due diligence is applied consistently to all software changes.
 * Work to identify risks and enhance control across the business.
   
   

Requirements:


 * 3+ years of professional data engineering experience.
 * Experience building and productionizing analytics pipelines, machine learning models and/or ETL processes on cloud platforms like AWS.
 * Proficiency with Python and SQL (PostgreSQL, MySQL) programming languages. Optional experience with Scala.
 * Experience with the AWS Cloud Ecosystem (e.g., EC2, RDS, Redshift, Glue).
 * Analytical mindset with the ability to understand and translate business needs from departments like marketing, product, and sales into scalable data solutions.
   
   

We offer a competitive salary, comprehensive benefits package, and opportunities for professional growth and development. If you're passionate about turning data into insights that drive business decisions, we'd love to hear from you.

Ownwell offerings


 * Entrepreneurial culture. Own your career; we are here to support you in the journey.
 * Access to First Round Network to build your community outside of Ownwell.
 * Flexible PTO. We believe in giving you the flexibility to own your time off. In addition to flexible time off, you will get 11 company holidays. We offer the last week of the year to recharge and reset.
 * Competitive health benefits. We care for you and your family's health, as reflected in our benefits coverage.
 * Learning support through a $1,000 stipend per year to enable investing in your individual learning needs.
 * Supporting parental journey. We offer up to 16 weeks of fully paid parental and bonding leave to support your journey as a new parent.
 * As applicable complimentary real estate and tax consulting licensing and renewal
   
   

Ownwell's vision is to democratize access to real estate expertise. When we say we want to provide access, we mean providing access to everyone. To do that well, we need a team that's broadly representative. We welcome people from all backgrounds, ethnicities, cultures, and experiences. Ownwell is an equal opportunity employer. We do not discriminate on the basis of race, color, ancestry, religion, national origin, sexual orientation, age, citizenship, marital or family status, disability, gender identity or expression, veteran status, or any other status.",Full-time
4056152068,81777085.0,Data Engineer,"Job Title: Data Engineer

Location: Remote

Role Overview

We are looking for a skilled Data Engineer to design, develop, and maintain scalable data pipelines and data management systems. You will collaborate closely with data scientists, analysts, and other engineers to build efficient data infrastructure for both operational and analytical needs.

Key Responsibilities


 * Design, build, and manage scalable, reliable, and efficient data pipelines.
 * Integrate data from various sources into a unified data warehouse and maintain ETL processes.
 * Optimize performance of data delivery and create solutions for data management and governance.
 * Collaborate with Data Scientists and Analysts to ensure data availability for analytical projects.
 * Ensure data quality, reliability, and security are maintained at all times.
 * Automate processes for data ingestion, transformation, and validation.
 * Troubleshoot and resolve any issues in data pipelines.
 * Continuously evaluate new tools and technologies to improve data architecture and pipeline efficiency.
   
   

Requirements


 * Bachelor's degree in Computer Science, Engineering, or related field.
 * Proven experience as a Data Engineer or in a similar role.
 * Strong experience with ETL processes and tools (e.g., Apache Airflow, Talend, etc.).
 * Proficient in SQL and databases like PostgreSQL, MySQL, or similar.
 * Experience with cloud platforms (AWS, GCP, or Azure).
 * Experience in working with big data technologies (e.g., Spark, Hadoop).
 * Proficiency in programming languages like Python, Scala, or Java.
 * Familiarity with containerization (Docker, Kubernetes) is a plus.
 * Excellent problem-solving and communication skills.",Full-time
4126025006,13703.0,Data Engineer,"What We Offer

At Magna, you can expect an engaging and dynamic environment where you can help to develop industry-leading automotive technologies. We invest in our employees, providing them with the support and resources they need to succeed. As a member of our global team, you can expect exciting, varied responsibilities as well as a wide range of development prospects. Because we believe that your career path should be as unique as you are.

Group Summary

Magna is more than one of the world’s largest suppliers in the automotive space. We are a mobility technology company built to innovate, with a global, entrepreneurial-minded team. With 65+ years of expertise, our ecosystem of interconnected products combined with our complete vehicle expertise uniquely positions us to advance mobility in an expanded transportation landscape.

Job Responsibilities

Magna New Mobility is seeking a Data Engineer to join our Software Platform team. As a Backend Developer with cloud experience, you will be responsible for designing, developing, and maintaining the server-side components of our applications. You will work closely with cross-functional teams to ensure our systems are scalable, reliable, and secure. Your expertise in cloud platforms will be crucial in optimizing our infrastructure and deploying solutions that leverage cloud-native features. This role will be onsite 3 days per week in our Lowell, MA office.

Your Responsibilities


 * Design & Development: Develop robust, scalable, and high-performance backend systems and APIs. Design and implement server-side logic and integrate with front-end components.
    * Cloud Integration: Leverage cloud platforms (e.g., AWS, Azure, Google Cloud) to deploy, manage, and scale applications. Implement cloud-based solutions for storage, computing, and networking.
    * Database Management: Design and maintain databases, ensuring data integrity, security, and performance. Work with both SQL and NoSQL databases as needed.
    * Security: Implement and maintain security best practices, including authentication, authorization, and data protection.
    * Performance Optimization: Identify and resolve performance bottlenecks. Monitor application performance and implement improvements as needed.
    * Collaboration: Work with product managers, front-end developers, and other stakeholders to understand requirements and deliver solutions. Participate in code reviews and contribute to team knowledge sharing.
    * Troubleshooting: Diagnose and resolve issues related to backend systems and cloud infrastructure. Provide support for production environments and ensure high availability
      

Who We Are Looking For


 * Bachelor's Degree or Equivalent Experience in Computer Science or a relevant technical field
 * Experience with Microservices: Knowledge and experience with microservices architecture.
 * 3+ years of experience in backend development with a strong focus on cloud technologies.
 * Technical Skills: Proficiency in backend programming languages such as Go lang, Python, Node.js, C/C++ or Java. Experience with any cloud platforms (AWS, Azure, Google Cloud) and related services (e.g., EC2, Lambda, S3, CloudFormation). Experience in building scalable ETL pipelines on industry standard ETL orchestration tools (Airflow, Dagster, Luigi, Google Cloud Composer, etc.) with deep expertise in SQL, PySpark, or Scala.
 * Database Knowledge: Experience with relational databases (e.g., MySQL, PostgreSQL) and NoSQL databases (e.g., MongoDB). Expertise in SQL and using big data technologies (e.g. Hive, Presto, Spark, Iceberg, Flink, Databricks etc) on medium to large-scale data.
 * DevOps: Familiarity with CI/CD pipelines, infrastructure as code (IaC), containerization (Docker), and orchestration tools (Kubernetes).
   
   

Preferred Qualifications


 * Cloud certifications (e.g., AWS Certified Solutions Architect, Microsoft Certified: Azure Developer Associate) are a plus.
 * Prior experience working in a start-up environment or product development from scratch will be a plus.
 * Experience building data pipelines for an IoT infrastructure is a plus.
   
   

Awareness, Unity, Empowerment

At Magna, we believe that a diverse workforce is critical to our success. That’s why we are proud to be an equal opportunity employer. We hire on the basis of experience and qualifications, and in consideration of job requirements, regardless of, in particular, color, ancestry, religion, gender, origin, sexual orientation, age, citizenship, marital status, disability or gender identity. Magna takes the privacy of your personal information seriously. We discourage you from sending applications via email to comply with GDPR requirements and your local Data Privacy Law.

Worker Type

Regular / Permanent

Group

Magna Corporate

",Full-time
4108589304,9240.0,Data Engineer 2,"Overview

We are seeking a full-time Data Engineer 2 in our Olathe, KS Support Center location. In this role, you will support Garmin's Operations team by transforming raw operational data into curated analytics datasets, which will drive reporting and Data Science activities.

Essential Functions


 * Provide technical input to feature development plans and concept documents
 * Understand production and operations issues as they relate to engineering
 * Interact/collaborate with business leadership to develop projects from an idea to implemented solution
 * Design/create SQL tables for data warehouse using star schema principles
 * Investigate/optimize complex SQL queries used in data loads
 * Administer/maintain a container-based Airflow installation
 * Participate in design, code, test, maintenance, enhance and decommission phases throughout software life cycle to contribute technical expertise and to identify issues
 * Participate in and help guide research POCs, including design, coding, and performance and efficacy measurement
 * Demonstrate broad understanding of Garmin's business model
 * Contribute to and triages major incident troubleshooting involving multiple disciplines
 * Apply technical expertise and analysis to initiatives and contribute input to broader technology solutions outside of discipline
 * Provide 24x7 on call support
   
   
   

Basic Qualifications


 * Bachelor’s Degree in Computer Science, Information Technology, Management Information Systems, Business or related field AND a minimum of 1 year relevant experience
 * Excellent academics (cumulative GPA greater than or equal to 3.0 as a general rule)
 * In-depth knowledge of Airflow, Kafka, and pySpark
 * Experience working with Docker, Kubernetes and Linux systems
 * Experience using Hadoop and various components
 * Consistently demonstrates quality and effectiveness in work documentation and organization and demonstrates ability to implement new technologies effectively
   
   
   

Desired Qualifications


 * Outstanding academics (cumulative GPA greater than or equal to 3.5)
 * Deep knowledge of star schema modeling and other data warehousing concepts
 * Passionate about data engineering concepts and tools, and willing to devote time towards continued learning
 * Humble and let's results speak for themselves
 * A strong team player that cares about collective team success
 * Undeterred by hard work
 * Drive to understand the business units supported, Product Support, Product Quality, Manufacturing and Logistics teams
 * Experience with Hadoop, NoSQL, ElasticSearch, OpenSearch, S3 and Cassandra
   
   
   

Garmin International is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, citizenship, sex, sexual orientation, gender identity, veteran’s status, age or disability.

This position is eligible for Garmin's benefit program. Details can be found here: Garmin Benefits",Full-time
4145881896,74742192.0,Engineering - Data Engineer,"About Us:

Read AI is a leading productivity AI company focused on helping individuals and businesses optimize their workflows across meetings, messages, and email. With seamless cross-platform integration with Microsoft Teams, Google Meet, Zoom, Slack, Hubspot, and Salesforce, Read AI revolutionizes how teams connect and collaborate by providing an AI copilot wherever they work.

We’re excited to share that we recently closed a $50 million Series B funding round, led by Smash Capital, with continued support from existing investors Madrona and Goodwater Capital. This new funding brings our total to $81 million, just six months after our Series A. We're just getting started, so if you're passionate about shipping early, often, and impacting millions, we'd love for you to join our growing team!

The Role:

As a Data Engineer at Read AI, your contributions will directly impact the functionality, scalability and reliability of our product. Our team is responsible for owning the data flows and ML infrastructure across the company, which includes realtime audio/video processing, interactions with third party llm providers, data processing orchestration, database management, data APIs, inferencing services, and transcription services.

Responsibilities:


 * Collaborate with cross-functional teams to design and develop scalable and reliable backend services and APIs that power our platform.
 * Take ownership of critical components of our system, from conception to deployment and maintenance.
 * Practice quality assurance best practices including unit and integration testing.
 * Optimize data processing pipelines and storage solutions.
 * Integrate third-party services and data sources seamlessly into our platform.
 * Monitor, troubleshoot, and resolve issues related to infrastructure and operations to ensure maximum uptime and reliability.
 * Continuously evaluate and implement best practices, tools, and technologies to enhance the scalability, reliability, and maintainability of our systems.
   
   

Requirements:


 * Bachelor's degree or higher in Computer Science/Engineering, or 3+ years of relevant industry experience.
 * Proven experience in backend development, with proficiency in one or more programming languages such as Python, Java, or Go.
 * Strong understanding of distributed systems, microservices architecture, and cloud computing platforms (e.g., AWS, GCP).
 * Familiarity with relational and non-relational databases, along with expertise in data modeling and database management.
 * Excellent problem-solving skills with a pragmatic and results-driven approach.
 * Ability to thrive in a fast-paced startup environment with a high degree of autonomy and accountability.
 * Excellent communication and collaboration skills, with the ability to work effectively in cross-functional teams.
   
   

Nice to Have:


 * Experience with containerization and orchestration tools such as Docker and Kubernetes.
 * Experience with big data processing tools such as Flink and Spark.
 * Experience with Python, Pydantic, FastAPI, and SQLAlchemy.
 * Familiarity with CI/CD pipelines and DevOps practices.
 * Prior experience in a startup or fast-growing environment.
   
   

Software Engineer positions offer a base pay range of $110,000 - $180,000, plus equity and benefits. Please note that the base pay shown is a guideline, and individual total compensation will vary based on factors such as qualifications, skill level, competencies, and work location. We also offer low deductible health plans, as well as flexible time away and family leave programs.",Full-time
4125067661,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4125439276,9240985.0,Data Engineer,"Description

Company Overview

Shamrock Trading Corporation is the parent company for a family of brands in transportation services, finance and technology. Headquartered in Overland Park, KS, Shamrock is frequently recognized among the “Best Places to Work” in Kansas City and Chicago and was most recently recognized as one of America’s top 100 “Most Loved Workplaces” by Newsweek. We also have offices in Atlanta, Chicago, Dallas, Ft. Lauderdale, Houston, Laredo, Nashville, Philadelphia and Phoenix. Overland Park is a great place to live, work and play, being conveniently located within driving distance of everything Kansas City has to offer. Housed within the heart of Overland Park, our offices include 4 gorgeous towers on the East and West sides of Metcalf Ave. With a heavy community presence and a winning culture, Shamrock is a great place to work in Overland Park!

With an average annual revenue growth of 25% over several decades, Shamrock’s success is attributed to three key factors: hiring the best people, cultivating long-term relationships with our customers and continually evolving in the marketplace.

Responsibilities

Shamrock Trading Corporation is looking for a Data Engineer who wants to utilize their expertise in data warehousing, data pipeline creation/support and analytical reporting skills by joining our Data Services team. This role is responsible for gathering and analyzing data from several internal and external sources, designing a cloud-focused data platform for analytics and business intelligence, reliably providing data to our analysts. This role requires significant understanding of data mining and analytical techniques. An ideal candidate will have strong technical capabilities, business acumen, and the ability to work effectively with cross-functional teams. Responsibilies include but are not limited to:


 * Work with Data architects to understand current data models, to build pipelines for data ingestion and transformation.
 * Design, build, and maintain a framework for pipeline observation and monitoring, focusing on reliability and performance of jobs.
 * Surface data integration errors to the proper teams focusing on:
    * Ensuring timely processing of new data
    * Performance of data pipelines
    * Integrity and quality of source data

 * Hands-on experience building data-lake style infrastructures using streaming data set technologies (particularly with Apache Kafka)
   
   

Qualifications


 * Bachelor’s degree in computer science, data science or related technical field, or equivalent practical experience
 * Experience building and maintaining AWS based data pipelines: currently utilizing AWS Lambda, Docker / ECS, MSK, Airflow, Databricks, Unity Catalog
 * Development experience utilizing two or more of the following:
    * Python: (Pandas/Numpy, Boto3, SimpleSalesforce)
    * Databricks (pySpark, pySQL, DLT)
    * Apache Spark
    * Kafka and the Kafka Connect ecosystem (schema registry and Avro)
    * Terraform (or other infrastructure as code platform)

 * Enthusiasm for working directly with customer teams (Business units and internal IT)
   
   

Preferred Qualifications


 * Proven experience with relational and NoSQL databases (e.g. Postgres, Redshift, MongoDB)
 * Experience with version control (git) and peer code reviews
 * Familiarity with data visualization techniques using tools such as Grafana, PowerBI, AWS Quick Sight, and Excel.
   
   
   

Benefits Package

At Shamrock we hire bright, ambitious people and give them the tools they need to be successful. By investing in training and development, we hope to become a long-term career for employees, where there are always opportunities for advancement. Shamrock also offers a premier set of benefits for employees and their families:


 * Medical: Fully paid healthcare, dental and vision premiums for employees and eligible dependents
 * Work-Life Balance: Competitive PTO and paid leave policies
 * Financial: Generous company 401(k) contributions and employee stock ownership after one year
 * Wellness: Onsite gym and discounted membership to select fitness centers. Jogging trails available at Overland Park offices",Full-time
4139680329,3076.0,Data Engineer,"Responsibilities

Kforce has a client that is seeking a Data Engineer in Austin, TX. What You'll Do:


 * Data Engineer will design and optimize data storage and transformation workflows to meet specific use cases, ensuring an effective balance between security, accessibility, reliability, cost-efficiency, and traceability
 * Design, develop, and optimize strategic business intelligence tools that support operations and drive continuous improvement
 * Participate in code reviews for data and software engineers working on sprint deliverables
 * Perform data analysis and communicate meaningful insights to internal stakeholders to support strategic decision making, drive efficiencies, and enhance our customer experience
 * As a Data Engineer, you will derive and publish technical requirements and operating procedures, mapped from business requirements, to clearly identify source data, calculations, and workflow for data products
 * Partner with Security and Infrastructure teams to ensure data security and reliability
 * Stay current with emerging technologies in data and analytics, evaluating and recommending tools to enhance capabilities
   
   

Requirements


 * Bachelor's degree in Data Science, Statistics, Math, Information Systems, Engineering, Computer Science, or related field
 * Minimum of 5 years of experience with data, analytics, and reporting solutions
 * Experience with Azure Data & Analytics SaaS and PaaS Services
 * Advanced SQL (PL/SQL, T-SQL) and performance tuning experience
 * Experience creating Power BI reports
 * Skilled in writing DAX queries
 * Data modeling in cloud data storage platforms
 * Agile development supported by JIRA, Confluence, and Git
 * Initiative to conduct detail-oriented problem solving in a collaborative environment
 * Skilled in clear and concise communication, both written and verbal, and able to effectively discuss complex technical concepts with executive and non-technical stakeholders
   
   

The pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.

We offer comprehensive benefits including medical/dental/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.

Note: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.

This job is not eligible for bonuses, incentives or commissions.

Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.

By clicking “Apply Today” you agree to receive calls, AI-generated calls, text messages or emails from Kforce and its affiliates, and service providers. Note that if you choose to communicate with Kforce via text messaging the frequency may vary, and message and data rates may apply. Carriers are not liable for delayed or undelivered messages. You will always have the right to cease communicating via text by using key words such as STOP.",Full-time
4131908589,9344338.0,Data Engineer,"This role is an office hybrid position based in Louisville, Kentucky.

What the Role Is

The Data Engineer, reporting to the Director of Data Services, will use their SQL and related skills to provide data engineering support to the business, mostly at a Tier 2 Level.

IT has undergone a transformation into new ways of working, and the Data Services team is a key component of this effort. We are a team of data scientists and data engineers working on large-scale projects changing how Heaven Hill does business and makes decisions.

This role will help by providing Tier 2 support while assisting with larger-scale projects, process improvement, and documentation tasks. This support should lead to a deeper understanding of our process and systems, allowing this person to grow in their impact over their first year.

How You Will Spend Your Time?


 * Providing support to systems users (Tier 2 Support)
    * SSRS, SSIS, & SQL
       * Troubleshooting existing views, stored procedures, and queries
       * Troubleshooting SSRS reports as well as updates and modifications therein
       * Troubleshooting SSIS packages and jobs
       * Writing new queries, views, and procedures
       * Writing code and troubleshooting historic code to fix issues or provide new features while working directly with the business.
   
    * Custom Applications such as BIC (Barrel Inventory Control)

 * Improving our Tools and Processes
    * Helping maintain systems
       * Updating code as needed
       * Documenting and fixing processes

 * Assisting as needed with project work (Tier 3)
    * Helping support data services projects, such as package development for new data flows.
      

Who You Are…


 * Bachelor's degree in Computer Science or related field or may substitute equivalent experience.
 * Minimum 2 years of experience creating and managing data pipelines (ETL).
 * Minimum 2 years of experience with database administration (SQL, Oracle).
 * SQL Knowledge is a must-have in this role – writing and understanding SQL code at an intermediate level.
 * Knowledge of SSRS and SSIS.
 * Knowledge of MS SQL Server.
 * Experience working with version control.
 * An attitude of collaboration, continuous improvement, and eagerness to learn.
 * A team player with excellent interpersonal skills
   
   

Required Skills

Valued but not Required Skills and Experience:


 * Basic Knowledge of MS Fabris
 * SSAS experience
 * Oracle database experience
 * Interacting with and querying ERP systems (we use IFS)
 * R and Python experience
 * Familiarity with PowerBI and with R Shiny Applications
 * Understanding of the RStudio Team set of applications
 * Familiarity with data sources used in the spirits industry (Nielsen, NABCA, SRS, etc.)
   
   

Physical Requirements

While performing duties of job, the employee is occasionally required to stand; walk; use hands and fingers to handle, or feel objects, and use of computer; reach with hands and arms. Employee must occasionally lift and/or move up to 50 pounds.

Benefits


 * Paid Vacation
 * 11 Paid Holidays
 * Health, Dental & Vision eligibility from day one
 * FSA/HSA
 * 401K match
 * EAP
 * Maternity/Paternity Leave
   
   

Heaven Hill and its affiliates are committed to fostering a diverse workforce as an Equal Employment Opportunity company. We invite applications from candidates of all backgrounds, without regard to race, religion, color, sex, sexual orientation, natural origin, gender identity or expression, age, disability, veteran status, or any other legally protected characteristic.",Full-time
4151565450,11400117.0,Senior Data Engineer,"Looking for a Senior Data Engineer, with a strong focus on building data models and managing data dictionaries.

 * Proven experience with Power BI, including building complex data models, optimizing performance, and creating dashboards with DAX/PowerQuery.
 * Strong SQL skills for data querying and manipulation, with experience in database management and ETL processes.

",Full-time
4107714101,5001964.0,Data Engineer,"Responsibilities


 * Design and implement ETL pipelines ensuring secure, reliable, and scalable pipelines to transfer data based on business requirements or user stories
 * Estimate and plan development work, track, and report on task progress, and deliver work on schedule
 * Take ownership of projects, driving them from conception to completion
 * Test and debug code to ensure it meets business requirements
 * Document programming tasks and procedures for future reference and troubleshooting.
 * Work closely with the team to understand the requirements and develop solutions that align with the company's objectives.
 * Design, implement, and manage scalable data pipelines and environments using SQL Server SSIS, Azure Data Factory
 * Design and implement Azure DevOps CI/CD pipeline
 * Identify, design, and implement internal process improvements: optimizing data delivery, re-designing infrastructure for scalability etc.
 * Manage, support/create, administration of SharePoint site
   
   

Qualifications


 * Bachelor’s or Master’s degree in computer science, engineering or related field
 * Experience with design and implementation of data warehouses
 * Strong understanding of Azure technologies (Azure SQL, ADF, Key Vault, DevOps CI/CD etc.)
 * Minimum of 5 years of experience in handling data processing and implementing ETL pipelines
 * Able to write complex SQL queries, design relational databases
 * Experience in SSIS, C#, ASP.NET, REST API, SharePoint and SharePoint Online and Azure ADF
 * Experience in Agile methodologies is a plus
 * Excellent problem-solving techniques, attention to detail and able to trouble shoot issue in effective manner.
 * Self-motivated and able to work independently with minimum supervision, able to work well with team
 * Excellent in communication
 * Strong analytical and problem-solving skills
   
   

Why Work for Us?

We offer competitive pay, paid holidays, benefits, paid time off and a work/life balance. Not only that, but we also offer paid parental leave, recognition programs, promotion opportunities, a comprehensive training program to enhance your career, and employee prescription discounts. Our Core Values consist of ICARE; Integrity, Communication, Accountability, Relationships and Excellence, and we take pride in you embodying those traits. Curant Health is an equal opportunity employer.",Full-time
4049569809,68021109.0,SQL Data Engineer,"Position: SQL Data Engineer

Location: Dallas, TX

Duration: 12+ months

Rate: Open

Skills

Bachelor's degree 5.+years of experience with ETL and advanced SQL skills


 * Adept at queries, report writing and presenting findings
 * Expertise in Data Analysis, Data Profiling, and SQL Tuning
   
   

SSIS & SQL Server Database experience


 * Expertise in translating business requirements to project design, development, and execution
 * Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.
   
   

Ability to clearly communicate capabilities, opportunities, and recommendations to both technical and nontechnical audiences


 * Experience working in Data warehouse ETL & BI platforms and have a good understanding of related development activities and challenges
 * Strong knowledge of and experience with reporting, databases (SQL etc), programming ( ETL frameworks)
   
   

Experience with PostgreSQL


 * Experience in understanding the source data from various platforms and mapping them into Entity relationship model(ER) for data integration and reporting.",Full-time
4067535454,15749701.0,Data Engineer,"KDA Consulting is a Disabled Veteran, Woman-Owned, Certified Disadvantaged Small Business, comprised of a diverse team of professionals driven to tackle the demanding National Defense and Intelligence challenges through IT solutions. We emphasize teamwork and focus on achieving goals to complete deliverables efficiently, on-time, and under budget.

We are currently seeking a Data Engineer to join our team to support our Government Partner.

Requirements

Primary Job Duties and Required Work Experience:


 * Design, build, and maintain data pipelines that efficiently ingest, process, and transform data from various sources for analysis
 * Collaborate with data scientists and analysts to understand data requirements and ensure data quality and accessibility
 * Develop and implement data governance policies and procedures to ensure data integrity and security
 * Stay current on emerging data engineering technologies and tools to optimize data pipelines and workflows
   
   
   

Desired Skills:


 * Experience with Splunk, Cribl, Databricks and Apache Spark for big data processing and analysis
 * Data Visualization: Proficiency in creating interactive dashboards and visual representations of data, potentially using tools like Tableau
 * Experience with data lake and data lake technologies and best practices
   
   
   

Job Requirements


 * Active TS/SCI + Full Scope Poly U.S. Government Security is required
 * Education and Years of Experience Requirement: candidate must possess a minimum of 11 years' relevant work experience plus a bachelor's degree -OR- 9 years' relevant work experience and a master's degree.
 * Ability to maintain discretion and confidentiality
 * Strong interpersonal skills, especially the ability to network and establish professional relationships
 * Ability to prioritize, demonstrated strong organizational skills, and ability to meet or exceed deadlines
   
   
   

Physical Demands: Position will require frequent sitting, standing, and/or mobility within an office setting. Employee must be able to use hands to complete work at a workstation/computer, be able to reach, type and manipulate with hands, fingers, and arms; lift and/or move up to 20 pounds; talk, see and hear.

Work Environment: Work is performed on client site in a professional office environment with moderate stress and noise levels. Position requires employee to effectively use a computer, potentially for long periods of time, and to accommodate potentially frequent interruptions. Candidate should be both customer-focused and present a team approach to overall work.

Schedule: Business core hours are Monday through Friday, 0930AM -1430PM.

Standard work hours may vary for this position based upon contract requirements. Position will be located onsite at a customer facility in Herndon, VA.

Americans with Disabilities Act (ADA): KDA is committed to the full inclusion of all qualified individuals. As part of this commitment, KDA will ensure that persons with disabilities are provided reasonable accommodations in the hiring process. We encourage qualified individuals with disabilities to apply. If a reasonable accommodation is needed to participate in the job application or interview process or to perform essential job functions, please contact our hiring team by email hr@kda-consulting.com. For persons who are deaf, hard of hearing, deafblind, or deaf-disabled, KDA will provide an American Sign Language (ASL) interpreter where needed as a reasonable accommodation for the hiring processes.

EEOC: KDA is an equal opportunity employer.",Full-time
4143426836,18043.0,Data Engineer,"Looking for a FULLY ONSITE Data Analyst Engineer here in Houston TX, to bridge the gap between data engineering and data analysis. Their responsibilities will involve designing, building, and maintaining data infrastructure while ensuring the data is usable, reliable, and insightful for analysis and decision-making.




Key Responsibilities:

 * Data Pipeline Development:
 * Build and maintain ETL/ELT pipelines to collect, transform, and store data.
 * Ensure data flows efficiently from source systems (e.g., databases, APIs, SaaS platforms) to data warehouses, lakes, or marts.
 * Data Integration and Modeling:
 * Integrate data from multiple sources into unified schemas for reporting and analytics.
 * Design and develop data models, including star and snowflake schemas, for fact and dimension tables.
 * Create staging and transformation layers to ensure clean, organized data.
 * Data Quality Assurance:
 * Implement data validation rules and monitor data accuracy.
 * Set up processes to identify and resolve data inconsistencies, duplicates, or missing information.
 * Establish data governance practices to ensure proper access, security, and compliance.
 * Collaboration with Teams:
 * Work closely with data scientists, business analysts, and stakeholders to understand their needs.
 * Provide datasets, create dashboards, and support advanced analytics use cases.
 * Serve as a liaison between technical and non-technical teams.
 * Performance Optimization:
 * Optimize query performance and ensure efficient data retrieval for analysis.
 * Use tools like indexing, partitioning, or caching to manage large datasets effectively.
 * Reporting and Visualization:
 * Create reports and dashboards for stakeholders, translating data into actionable insights.
 * Utilize tools like Tableau, Power BI, or Looker alongside SQL to present results.
 * Technology Evaluation and Implementation:
 * Assess and implement new tools or technologies (e.g., dbt, Apache Spark, Airflow) to improve data workflows.
 * Maintain familiarity with cloud platforms like AWS, Azure, or GCP for data storage and processing.
 * Documentation and Training:
 * Document processes, pipelines, and data models for transparency and maintainability.
 * Train team members on how to access and interpret data




Skills Required:

 * Technical Skills:
 * SQL, Python, or R for data manipulation and analysis.
 * Data engineering tools (e.g., dbt, Apache Airflow, Kafka).
 * Familiarity with cloud platforms and data warehouses (e.g., Snowflake, BigQuery, Databricks).
 * Proficiency with visualization tools (e.g., Power BI, Tableau, Looker).
 * Analytical Skills:
 * Strong problem-solving abilities to address complex data issues.
 * Ability to translate business needs into data requirements and solutions.",Full-time
4119108782,300092.0,Data Engineer,"Company Description


wowbrands is a premiere small business solution provider based in Columbus, Ohio, offering affordable and customized digital marketing services. The agency specializes in website design, online and print marketing/branding, naming and logo design, as well as incorporation assistance. wowbrands caters to individuals starting small to medium businesses and existing companies looking to enhance their online presence through holistic digital marketing strategies.


Role Description


This is a full-time remote role for a Data Engineer at wowbrands. The Data Engineer will be responsible for tasks such as data modeling, ETL processes, data warehousing, and data analytics. They will play a key role in managing and optimizing data processes to support the company's digital marketing strategies.


Qualifications

 * Data Engineering and Data Modeling skills
 * Experience in Extract Transform Load (ETL) processes
 * Data Warehousing and Data Analytics capabilities
 * Strong problem-solving and analytical skills
 * Proficiency in SQL and other database technologies
 * Excellent communication and collaboration abilities
 * Experience with digital marketing data is a plus
 * Bachelor's or Master's degree in Computer Science, Data Science, or related field",Contract
4129950100,66321745.0,Data Engineer (Junior Level),"Since 2010 Synergisticit has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this Job market also, our candidates are able to achieve multiple job offers and $100k &plus; salaries.

Please Check The Below Links

Synergisticit Pics /Salaries of Successful Candidates

Synergisticit at Oracle Cloudworld 2023

Synergisticit at Gartner Data & Analytics summit

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

Required Skills

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, Gen AI, LLM, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full Stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java , javascript , C&plus;&plus; or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Full-time
4125063292,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4142269222,35590008.0,Data Engineer,"Rockwoods is Hiring: Mid-Level Marketing Data Engineer (McLean, VA - Hybrid)



Rockwoods is looking for a Mid-Level Marketing Data Engineer to join our team! We need someone who is both business-savvy and technically proficient—able to understand marketing and business KPIs and translate them into effective technical solutions. The ideal candidate is a self-starter, ready to dive in, think creatively, and communicate insights effectively.



Key Details:

Location: Hybrid role requiring 3 days onsite in McLean, VA

Role Focus: Building and maintaining data infrastructure for marketing data, collaborating closely with marketing teams to support their data needs



Ideal Candidate Profile:

 * Experience: 3-5 years in a data engineering or similar role
 * Technical Skills: Proficient in SQL & Python (3-5 years)
 * Data Warehousing: Strong understanding of data warehousing concepts & methodologies
 * Snowflake Expertise: 1-3 years of hands-on experience
 * API Integration: Experience with system connections via API integrations
 * Marketing Data Experience: Preferred experience with Adobe Campaign, Google Analytics, or Salesforce Marketing Cloud

If you’re passionate about bridging the gap between marketing and data engineering, we’d love to hear from you!",Contract
4142641497,2833966.0,Data Engineer- Java/Spark/SQL,"Location: Jersey City New Jersey

Must Have Skills


 * Java/Spring + Spark/SQL/AWS, should be very good in building data pipelines – Primary Skillset, MUST HAVE
 * They will be working in a Java stack, but they MUST BE very strong on the Spark/Data Engineering side of things
 * Datalake/Snowflake/Kubernetes – These are a HUGE plus – They use these daily
 * Proficient in Core Java development skills as well as multiple design techniques
 * Working proficiency in Core Java development toolset to design, develop, test, deploy, maintain and improve software
 * Strong understanding of Agile methodologies with ability to work in at least one of the common frameworks
 * Strong understanding of techniques such as Continuous Integration, Continuous Delivery, Test Driven Development, Cloud Development, application resiliency and security
 * Proficiency in one or more general purpose programming languages
 * Working proficiency in a portion of software engineering disciplines and demonstrates understanding of overall software skills including business analysis, development, testing, deployment, maintenance and",Contract
4081433962,2646.0,(USA) Data Engineer III,"Position Summary...

What you'll do...

About Team

Data Ventures exists to unlock the full value of Walmart’s data by developing

and productizing B2B data initiatives that empower merchants and suppliers to

make better, faster decisions for the business. As part of this transformation, we’re

seeking entrepreneurial individuals to help drive data productization from concept

to deployment.

What You'll Do

Demonstrates up-to-date expertise and applies this to the development,

execution, and improvement of action plans by providing expert advice and

guidance to others. Supporting and aligning efforts to meet customer, business

needs and building commitment for perspectives and rationales.

Create software design and architecture for next software solution. This will be

your channel to communicate your ideas with rest of the team. Not just one but

evaluate multiple solutions

Analyze competing requirements and articulate tradeoffs and lead discussions

with business and development team, leading white board sessions with team.

Drives the execution of multiple business plans and projects by identifying

customer and operational needs. Developing and communicating business

plans and priorities, removing barriers and obstacles that impact performance.

Demonstrating adaptability and supporting continuous learning.

Creates training documentation. Oversees the tasks of less experienced

programmers and stipulates system troubleshooting supports.

What You'll Bring

Experience with Minimum 6+ Years


 * Hadoop, Spark, Cloud, Scala, Streaming, Kafka
 * SQL / Data warehousing
 * BI and Looker Views, Models, Explores, Looks/Charts
 * DS and Algorithm
 * CI/CD
 * Data Modeling
 * Airflow
 * 
 * Knowledge of
 * Cloud (GCP/Azure)
 * Backend, Spring
 * Python
   
   

About Walmart Global Tech

Imagine working in an environment where one line of code can make life easier for

hundreds of millions of people. That’s what we do at Walmart Global Tech. We’re a

team of software engineers, data scientists, cybersecurity expert's and service

professionals within the world’s leading retailer who make an epic impact and are at

the forefront of the next retail disruption. People are why we innovate, and people

power our innovations. We are people-led and tech-empowered.

We train our team in the skillsets of the future and bring in experts like you to help

us grow. We have roles for those chasing their first opportunity as well as those

looking for the opportunity that will define their career. Here, you can kickstart a

great career in tech, gain new skills and experience for virtually every industry, or

leverage your expertise to innovate at scale, impact millions and reimagine the

future of retail.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎

You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎

Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For Information About Benefits And Eligibility, See One.Walmart.

‎

The annual salary range for this position is $117,000.00-$234,000.00

‎

Additional Compensation Includes Annual Or Quarterly Performance Bonuses.

‎

Additional Compensation For Certain Positions May Also Include

‎

‎


 * Stock
   
   

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelor’s degree in Computer Science and 2 years' experience in software engineering or related field. Option 2: 4 years’ experience in

software engineering or related field. Option 3: Master's degree in Computer Science.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, Master’s degree in Computer Science or related field and 2 years' experience in software engineering or related field, We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

680 West California Avenue, Sunnyvale, CA 94086-4834, United States of America",Full-time
4143030357,101021.0,Data Engineer,"On-site Location: Springfield, VA

Home office: Arlington, VA

Clearance: TS/SCI with willingness to sit for CI Polygraph

Elder Research Inc. is a recognized leader in data science, machine learning and AI. We pride ourselves in our ability to find creative, cutting-edge solutions to real-world problems. We are looking for innovative and inquisitive self-starters who enjoy understanding a problem space and building fast, efficient, and tractable data infrastructure to deliver real value for our clients.

Description

Description:

We are looking for a Data Engineer to join our team! This work will primarily be a data engineering role with some entry level data science/data visualization work. In this role, the data engineer guides robust and repeatable data manipulation, large scale infrastructure for data ingestion, and stunning data visualization for custom client applications. You will work on building automated data pipelines and transform data to be used for analytics and data science. You will build and maintain data systems and construct datasets that are easy to analyze and support customer requirements, implement methods to improve data reliability and quality, combine raw information from different sources to create consistent and machine-readable formats, develop and test architectures that enable data extraction and transformation for predictive or prescriptive modeling, and develop and deploy Application Programming Interfaces (API) to expose IDST maintained data to the enterprise.

Come join our team!

Roles & Responsibilities


 * Consult with stakeholders to understand their business needs and identify potential process improvements
 * Lead individual projects, including technical execution, client engagement, and project management
 * Provide technical leadership throughout the data engineering lifecycle and understands benefits and tradeoffs of various languages and platforms
 * Write well-documented and maintainable code using good data engineering practices
 * Deliver new features to the customer upon request
 * Prioritize development tasks and issues using agile methodology and the Atlassian Tool Suite (JIRA, Confluence, Bitbucket)
   
   

Required Qualifications


 * Active TS/SCI with willingness to sit for the CI Polygraph, or active TS/SCI with CI Polygraph
 * B.S. in technical field with 1-3 years work experience
 * Experience using version control systems like Git, SVN, or Mercurial
 * Proficiency in one or more of the following languages: Python, TypeScript, JavaScript and SQL
 * Experience building and maintaining ETL pipelines
 * Excellent verbal and written communication skills to consult with customers, understand their business needs, and identify potential process improvement
   
   

Desired


 * Experience working with NumPy, Pandas, scikit-learn, or similar data science / analytics libraries
 * Explore and analyze new/unstructured data sources and deliver insights to customers
 * Depth of knowledge in multiple languages and tools
 * Experience developing REST APIs with web frameworks based in Node.js or Python (e.g. Fastify, Aiohttp, or similar)
 * Experience working with relational databases and writing/maintaining SQL scripts for data-driven web applications
   
   

About Elder Research, Inc.

Elder Research is a growing consulting firm specializing in data (analytics, data science, AI and machine learning), and related strategy and training. Our organization has over 25 years of experience and 100+ practitioners that have partnered with hundreds of organizations to achieve significant value through innovative applications of data, analytics, and people-centered processes.

We are tackling hard problems, big and small, where off-the-shelf solutions don’t work or don’t exist. To achieve success, we value humble, hardworking teammates with the ability to be flexible, think critically and experiment.

At Elder Research, you’ll be part of a fun, friendly, and supportive community where we need each other to succeed, your point of view matters, and asking questions with a beginner’s mindset is applauded. In keeping with our entrepreneurial spirit, we want candidates that are self-motivated with an innate curiosity and strong team work ethic. We are constantly learning and offer teammates free access to a wide range of learning opportunities including Elder’s own platform statistics.com and technical mentors or sponsors. Broadening and deepening your technical and consulting skills both on the job and off is something we are passionate about, and we pay you to do it.

To achieve success on defense, intelligence and security work we frequently bring together the expertise of decision-makers, analysts, agents, investigators, and even behavioral scientists. Our team enjoys great variety in the type of work they do and exposure to a wide range of analytic techniques and tools.

Elder Research, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.",Full-time
4151630958,445839.0,Junior Software Engineer (Python),"We are searching for cleared professionals who are passionate about their work and ready to take the next step in their careers! The talented individuals we hire at Synergy are provided with a multitude of contract opportunities from developing tip-of-the-spear capabilities to providing support for ongoing mission-critical operations. With high demand from our National Security customers for our talent and expertise, our employees are shaping the future in support of our customer’s most critical needs and are working with some of the best and brightest in the industry.

What You Will Be Doing

Synergy is seeking a Junior level Software Engineer proficient with Python, C++, and MATLAB to work on an exciting new mission-focused contract. If you're ready to step into a new role as part of skilled team, we want to hear from you and learn more about your experiences!

Requirements

Requires a Bachelors degree and seven (7) years of experience as a SWE in program and contracts of similar scope, type, and complexity. Four (4) years of additional SWE experience on projects may be substituted for a bachelors degree.

Required Capabilities


 * Python
 * C++
 * MATLAB
 * Linux
   
   

Desired Capabilities


 * Background with RF and signals processing
 * DSP algorithms
 * REDHAWK
 * Docker
   
   

Clearance Required


 * Must be fully cleared with the appropriate Polygraph.
   
   

Benefits


 * Compensation: We offer highly competitive compensation so everyone can share in the growth of the company as we build its success together!
 * Health & Retirement: We offer a comprehensive Health Benefits package and 401K Retirement plan so you can take care of yourself and your family, now and in the future. Other health-related benefits include an employee Gym wellness benefit.
 * Education: Individual growth is a priority at Synergy. Employees are encouraged to take advantage of our company-sponsored continuing education program so they can get their degree or that next certification needed to propel them towards the next level.
 * Work/Life Balance: A healthy work/life balance is essential for building and executing your work effectively at Synergy, but it’s also necessary to allow you the room to pursue everything you want to develop in your personal life. We offer a generous Paid Time Off benefit and 11 paid holidays a year. Synergy also provides flexible work options that work with your schedule and lifestyle.
 * Great Corporate Facilities: Come by our corporate office and enjoy a weekly happy hour, take a drive to nearby restaurants, grab a snack or coffee in our café, or utilize our collaborative office space and conference rooms.
   
   

About Us

Formed in July of 2007 and headquartered in Columbia, MD, our talented, dedicated staff provide a broad range of services in cybersecurity, software, data transport solutions, systems engineering, and IT services to the U.S. Intelligence and Defense Communities. We deliver critical and innovative capabilities to high-level decision makers that enhance our nation’s security. In an ultra-competitive environment, Synergy ECP has thrived by adhering to our name, making sure excellence is displayed by our Employees, to our Customers and by continually improving Performance (ECP). This is what sets us apart and enables us to be an autonomous yet agile business delivering huge results and meeting our customers’ evolving demands. Synergy ECP has earned a client list that includes numerous Fortune 100 companies, in addition to multiple branches of the US government and military services.

Synergy ECP is an equal opportunity employer and considers qualified applicants for employment without regard to race, color, creed, religion, national origin, sex, sexual orientation, gender identity and expression, age, disability, veteran status, or any other protected class.

If you are interested in learning more about Synergy and what opportunities may be available to you, let’s start a conversation together! Our team is happy to speak with you about your experience and goals so that they may work with you in finding the kinds of positions that you are most interested in. Feel free to drop off your resume with us via our website or send it along to staffing@synergyecp.com. Apply today and start your new career at Synergy!",Full-time
4062253521,66321745.0,Data Engineer - Remote (Entry/Junor),"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you need

Position open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, IT enthusiasts, Python/Java developers, Data analysts/ Data Scientists.

We welcome candidates with all visas and citizens to apply.

Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates looking to make their careers in IT Industry

We assist in filing for STEM extension and also for H1b and Green card filing.

Candidates who are serious about their future in the IT Industry and have set big goals for themselves.

Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience which our clients need with great outcomes

Candidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancement

Candidates Who Lack Experience

Have had a break in careers

Lack Technical Competency

Different visa candidates who want to get employed and settle down in the USA

Please Also Check The Below Links

https://www.synergisticit.com/candidate-outcomes/

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

How Can Recently Laid Off Tech People Get Employed Again? | SynergisticIT

If not a match candidates can opt for Skill enhancement.

REQUIRED SKILLS For Java/Software Programmers


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Core Java , javascript , C++ or software programming
 * Spring boot, Microservices and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, Python, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, Time series analysis

Please understand skills are required by clients for selection even if its Junior or entry level position the additional skills are the only way a candidate can be picked by clients.

No third party candidates or c2c candidates

Please understand skills are required by clients for selection even if its Junior or entry level position the additional skills are the only way a candidate can be picked by clients.

Please apply to the posting

No phone calls please. Shortlisted candidates would be reached out",Contract
4142625139,3076.0,Data Engineer,"Responsibilities

Kforce has a client that is seeking a Data Engineer in Westlake, TX. Duties Include:


 * Data Engineer will design robust batch and streaming programs and adhering to standards and best-practices for these databases
 * Ensures alignment with enterprise data architecture strategies
 * Improves data availability via APIs and shared services and recommends optimization solutions using cloud technologies for data processing, storage, and advanced analytics
 * Provides technical mentorship for cyber security on database technologies
 * Performs risk assessments and implement validation of data processing system to ensure app functionality and security measures
 * As a Data Engineer, you will perform independent and sophisticated technical and functional analysis for multiple projects supporting several divisional initiatives
 * Building technical infrastructure required for efficient Extraction, Transformation, and Loading (ETL) of data from a wide variety of data sources by improving, object-oriented/object function scripting languages such as Python
 * Collaborate with business and technology groups and should be able to present formal and informal presentations in various settings: one-on-one, small, and large groups, with peers, and senior management
   
   

Requirements


 * Bachelor's or master's degree or equivalent experience in a technology related field like Computer Science or Engineering with consistent track record
 * Object oriented Python programming and proven experience with machine learning libraries - Pandas, NumPy, Scikit-learn, TensorFlow, etc.
 * Hands on event-based systems, functional programming, new technologies and messaging frameworks such as Kafka
 * Expertise with relational databases, Splunk, Snowflake, YugabyteDB, Aerospike, S3 and similar data management platforms
 * Experience with DB2, writing and stored procedures to process data
 * Data parsing/analytics experience in large data sets using Python, scripting, and other similar technologies, integrating with and consuming APIs
 * Familiarity with quantitative techniques and methods, statistics, econometrics - including probability, linear regression, time series data analysis and optimizations
 * Knowledge of hybrid on-prem and cloud data architectures and services, especially data streaming, storage and processing functionality
 * Strong analytical skills and ability to tackle issues and work through ambiguous situations by making timely decisions based on facts, knowledge, experience and judgment
 * Good interpersonal and client-handling skills with the ability to handle expectations and explain technical detail
 * Multitask, prioritizes tasks, and quickly adjusts in a constantly evolving environment
 * Ability to navigate organizationally to accomplish tasks and work on multiple efforts simultaneously and ability to work with multi-functional teams located across geographies
 * Excellent conflict management and negotiation skills; eager to learn and continuously develop personal and technical capabilities
   
   

The pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.

We offer comprehensive benefits including medical/dental/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.

Note: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.

This job is not eligible for bonuses, incentives or commissions.

Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.

By clicking “Apply Today” you agree to receive calls, AI-generated calls, text messages or emails from Kforce and its affiliates, and service providers. Note that if you choose to communicate with Kforce via text messaging the frequency may vary, and message and data rates may apply. Carriers are not liable for delayed or undelivered messages. You will always have the right to cease communicating via text by using key words such as STOP.",Contract
4125058929,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4113536565,66321745.0,Junior Data Engineer,"SYNERGISTICIT is aware that the Job Market is Challenging because of Tech Layoffs due to which The Job market is flooded with hundreds and thousands of laid off Jobseekers who are competing with existing Jobseekers. For entry level Job seekers to get client interviews and jobs they need to differentiate themselves by ensuring they have exceptional skills and technologies to be noticed by clients.

Since 2010 we have helped Jobseekers differentiate themselves by providing the clients with candidates who have the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers. All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few. We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates looking to make their careers in IT Industry We welcome candidates with all visas and citizens to apply. We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

Candidates can benefit from skill enhancement if they fall into the below categories.

Candidates who Lack Experience or are freshers with No actual on Job experience with projects with clients Have had a break in careers Lack Technical Competency or skills being demanded by clients Different visa candidates (Like OPT/H4EAD/L2EAD ) who want to get employed and settle down in the USA please check the below links to see success outcomes of our candidates https://www.synergisticit.com/candidate-outcomes/

Synergisticit Pics /Salaries of Successful Candidates

Synergisticit at Oracle Cloudworld 2023

Synergisticit at Gartner Data & Analytics summit

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

REQUIRED SKILLS For Java /Software Programmers


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Project work on the skills
 * Knowledge of Core Java , javascript , C+
 * or software programming
 * Spring boot, Microservices, Docker, Jenkins and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Project work on the technologies needed
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, PowerBI, Time series analysis

Please understand skills and relevant experience on real world projects are required by clients for selection even if its Junior or entry level position the additional skills and Project work with hands on experience building projects at client site are the only way a candidate can be picked by clients. If not having the skills or hands on project work at client site then candidates can opt for skill enhancement to gain the required skills and project work. No third party candidates or c2c candidates

please only apply to the posting

No phone calls please. Shortlisted candidates would be reached out.",Contract
4125061490,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4125063409,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4068422830,2833966.0,Data Engineer,"Job Responsibilities

Be a technical expert on all aspects of Snowflake, Python and AWS services

Deploy Snowflake objects following best practices for configuration, optimization, documentation and support

Maintain deep understanding of complementary technologies and help organizations leverage Snowflake as part of their larger technology stack

Foster collaboration with software product development, architecture, and IT teams to ensure releases are delivered with repeatable and audit-able processes.

Monitoring health, tuning, and growth of cloud databases

Provides release management support for Warehouse, databases and related applications

Interface with engineers, product managers & architecture to understand data needs and help build & migrate data projects onto Snowflake data warehouse

Support the set-up of roles, schemas, & data pipelines while adhering to security policies and overcoming security restrictions.

Support and troubleshoot scalability, high availability, performance, monitoring, backup and restores of different environments.

Ideal candidates will have a deep understanding of technical and functional designs for Databases, Data Warehousing, Reporting, and Data Mining areas

Familiar with SDLC and Release Management

Create documentation reflecting current platforms architecture

Qualifications

A minimum of bachelor's degree in computer science or equivalent.

Experience with Informatica IICS, Airflow, and Snowflake in an admin/ developer role

Experience with SQL/Python & relational data including exposure to complex data models

5-7 Years of Experience with scripting languages use (Python, R, Java, Scala).

3-5 Years of Experience AWS services (VPC, EC2, SQS, SNS, Lambda, IAM, RDS).

Demonstrated knowledge and hands-on experience with AWS alerting/monitoring tools

Experience in managing a GIT based Source control Git/GitHub/Bitbucket

Experience with CI/CD technologies and tools like Jenkins, Ant or Gradle

Ability to work well both independently and with other team members

Ability to multi-task required and provide rapid support in production",Contract
4123110702,69639337.0,Data Engineer,"BeaconFire is looking for candidates who are good communicators and self-motivated. You will play a key role in building, maintaining, and operating integrations, reporting pipelines, and data transformation




Qualifications:

 * Passion for data and a deep desire to learn.
 * Bachelor’s Degree in Computer Science/Information Technology, Data Analytics/ Data Science, or related discipline.
 * Intermediate Python. Experience in data processing is a plus. (Numpy, Pandas, etc)
 * Strong written and verbal communication skills.
 * Ability to work both independently and as part of a team.




Responsibilities

 * Collaborate with analytics team to find reliable data solutions to meet the business needs.
 * Design and implement scalable ETL or ELT processes to support the business demand for data.
 * Perform data extraction, manipulation, and production from database tables.
 * Build utilities, user-defined functions, and frameworks to better enable data flow patterns.
 * Build and incorporate automated unit tests, participate in integration testing efforts.
 * Work with teams to resolve operational & performance issues.
 * Work with architecture/engineering leads and other teams to ensure quality solutions are implemented, and engineering best practices are defined and adhered to.




Location: Remote to start

Salary: $65,000.00 to $80,000.00 /year

BeaconFire is an e-verified company, and we provide H1B visa sponsorship to all qualified international candidates.",Contract
4116239425,30324.0,Data Engineer,"Job Title: Data Engineer

Location: Dublin, CA (100% Onsite)






Key Responsibilities:

• Design and develop robust data pipelines to ingest, transform, and load data from various sources.

• Perform comprehensive data analysis to uncover trends, patterns, and actionable insights.

• Utilize advanced data analytics tools to process and interpret large datasets.

• Collaborate with data lakes to gather, store, and manage structured and unstructured data.

• Address business inquiries and challenges through detailed data engineering solutions.



Must-Have Skills:

• Strong analytical skills with a knack for problem-solving.

• Proven ability to work independently and drive projects forward.

• Hands-on experience with Snowflake and proficiency in Azure.

• Familiarity with Azure Data Factory (ADF) for data integration and orchestration.

• Experience in designing and implementing data pipelines for efficient data processing.

• Banking domain experience.",Contract
4125059681,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4125065179,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4034306310,81777085.0,Data Engineer,"Job Title: Data Engineer

Location: Remote

Role Overview

We are looking for a skilled Data Engineer to design, develop, and maintain scalable data pipelines and data management systems. You will collaborate closely with data scientists, analysts, and other engineers to build efficient data infrastructure for both operational and analytical needs.

Key Responsibilities


 * Design, build, and manage scalable, reliable, and efficient data pipelines.
 * Integrate data from various sources into a unified data warehouse and maintain ETL processes.
 * Optimize performance of data delivery and create solutions for data management and governance.
 * Collaborate with Data Scientists and Analysts to ensure data availability for analytical projects.
 * Ensure data quality, reliability, and security are maintained at all times.
 * Automate processes for data ingestion, transformation, and validation.
 * Troubleshoot and resolve any issues in data pipelines.
 * Continuously evaluate new tools and technologies to improve data architecture and pipeline efficiency.
   
   

Requirements


 * Bachelor's degree in Computer Science, Engineering, or related field.
 * Proven experience as a Data Engineer or in a similar role.
 * Strong experience with ETL processes and tools (e.g., Apache Airflow, Talend, etc.).
 * Proficient in SQL and databases like PostgreSQL, MySQL, or similar.
 * Experience with cloud platforms (AWS, GCP, or Azure).
 * Experience in working with big data technologies (e.g., Spark, Hadoop).
 * Proficiency in programming languages like Python, Scala, or Java.
 * Familiarity with containerization (Docker, Kubernetes) is a plus.
 * Excellent problem-solving and communication skills.",Full-time
4148897486,90439523.0,Software Engineer - Database Engineering,"Build the future of the AI Data Cloud. Join the Snowflake team.

We’re hiring talented Software Engineers to join the Snowflake Database Engineering team! In this role you will work directly with our team to evolve our elastic, large scale, high-performance data processing system. We need smart engineers who can pick up and understand complex technical areas quickly – and who are enthusiastic about building new technologies!

As a Software Engineer At Snowflake, You Will


 * Design, develop, and support a petabyte-scale cloud database that is highly parallel and fault-tolerant.
 * Build high-quality and highly reliable software to meet the needs of some of the largest companies on the planet.
 * Analyze and understand performance and scalability bottlenecks in the system and solve them.
 * Pinpoint problems, instrument relevant components as needed, and ultimately implement solutions.
 * Design and implement novel query optimization or distributed data processing algorithms which allow Snowflake to provide industry leading data warehousing capabilities.
 * Design and implement the new service architecture required to enable the Snowflake Data Cloud
 * Develop tools for improving our customers' insights into their workloads.
   
   

Our Ideal Software Engineer Will Have


 * 2+ years industry experience working on commercial or open-source software.
 * Fluency in Java or C++.
 * Familiarity with development in a Linux environment.
 * Excellent problem solving skills, and strong CS fundamentals including data structures, algorithms, and distributed systems.
 * Systems programming skills including multi-threading, concurrency, etc.
 * Experience with implementation testing, debugging and documentation.
 * Bachelor’s degree or foreign equivalent in Computer Science, Software Engineering or related field; Masters or PhD preferred.
 * Ability to work on-site in our San Mateo / Bellevue / Berlin office.
   
   

Bonus Points For Experience With The Following


 * SQL or other database technologies including internal design and implementation.
 * Query optimization, query execution, compiler design and implementation.
 * Experience with internals of distributed key value stores like FoundationDB and storage engines like RocksDB, InnoDB, BerkeleyDB etc.
 * Experience with MySQL, PostgreSQL internals
 * Data warehouse design, database systems, and large-scale data processing solutions like Hadoop and Spark.
 * Large scale distributed systems, transactions and consistency models.
 * Experience in database replication technology
 * Big data storage technologies and their applications, e.g., HDFS, Cassandra, Columnar Databases, etc.
   
   

Every Snowflake employee is expected to follow the company’s confidentiality and security standards for handling sensitive data. Snowflake employees must abide by the company’s data security plan as an essential part of their duties. It is every employee's duty to keep customer information secure and confidential.

Snowflake is growing fast, and we’re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.

How do you want to make your impact?

The following represents the expected range of compensation for this role:


 * The estimated base salary range for this role is $157,000 - $230,000.
 * Additionally, this role is eligible to participate in Snowflake’s bonus and equity plan.
   
   

The successful candidate’s starting salary will be determined based on permissible, non-discriminatory factors such as skills, experience, and geographic location. This role is also eligible for a competitive benefits package that includes: medical, dental, vision, life, and disability insurance; 401(k) retirement plan; flexible spending & health savings account; at least 12 paid holidays; paid time off; parental leave; employee assistance program; and other company benefits.

Snowflake is growing fast, and we’re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.

How do you want to make your impact?",Full-time
4125928584,96308949.0,Data Engineer,"About Elicit

Elicit is an AI research assistant that uses language models to help researchers figure out what’s true and make better decisions, starting with common research tasks like literature review.

What We're Aiming For


 * Elicit radically increases the amount of good reasoning in the world.
    * For experts, Elicit pushes the frontier forward.
    * For non-experts, Elicit makes good reasoning more affordable. People who don't have the tools, expertise, time, or mental energy to make well-reasoned decisions on their own can do so with Elicit.

 * Elicit is a scalable ML system based on human-understandable task decompositions, with supervision of process, not outcomes. This expands our collective understanding of safe AGI architectures.
   

Visit our Twitter to learn more about how Elicit is helping researchers and making progress on our mission.

Why we're hiring for this role

Our users responded enthusiastically to the latest evolution of Elicit which we launched in late 2023. We introduced Elicit Plus and Pro—our monthly subscription plans—and added thousands of paying users in a matter of months as well as hundreds of thousands of new sign-ups. This has been energizing for our team, but we want to ship more useful functionality to our users even faster.

Our academic research paper search pipeline is at the heart of Elicit's capabilities, and we need a skilled Data Engineer to take it to the next level.

Our mission is to make Elicit the most complete and up-to-date database of scholarly sources. As we continue to add new data sources and expand our coverage of academic literature, we face challenges in efficiently processing, deduplicating, and indexing hundreds of millions of research papers. In addition, enterprise customers will need to be able to upload, process, and manage their own documents in private corpora for their teams to use.

We're looking for someone who can architect and implement robust, scalable solutions to handle our growing data needs while maintaining high performance and data quality.

Our tech stack


 * Data pipeline: Python, Flyte, Spark
 * Frontend: Next.js, TypeScript, and Tailwind
 * Backend: Node and Python
 * We like static type checking in Python and TypeScript
 * All infrastructure runs in Kubernetes across a couple of clouds
 * We use GitHub for code reviews and CI
   
   

Am I a good fit?

Consider The Questions


 * How would you optimize a Spark job that's processing a large amount of data but running slowly?
 * What are the differences between RDD, DataFrame, and Dataset in Spark? When would you use each?
 * How does data partitioning work in distributed systems, and why is it important?
 * How would you implement a data pipeline to handle regular updates from multiple academic paper sources, ensuring efficient deduplication?
   
   

If you have a solid answer for these—without reference to documentation—then we should chat!

Location and travel

We have a lovely office in Oakland, CA, but we don't all work from there all the time. It's important to us to spend time with our teammates, however, so we ask that all Elicians spend 1 week out of every 6 with teammates.


 * We have a quarterly team retreat, normally in and around the SF bay area.
 * We have quarterly co-working weeks (offset from the team retreats) in our Oakland office.
 * If you come to the retreats and co-working weeks, you'll meet our expectations for in-person time!
 * There is flexibility around the specifics here: if you're not sure you can make this work, get in touch.
   
   

What you'll bring to the role


 * 5+ years of experience as a data engineer building core datasets and supporting business verticals with high data volumes
 * Strong proficiency in Python (5+ years experience)
 * Experience with architecting and optimizing large data pipelines with Spark
 * Strong SQL skills, including understanding of aggregation functions, window functions, UDFs, self-joins, partitioning, and clustering approaches
 * Experience with Parquet file formats and other columnar data storage formats
 * Strong data quality management skills
 * Ability to balance technical expertise with creative problem-solving
 * Excited to interact with product/web app and help ship new features (e.g., real-time updates, advanced filtering options)
 * Experience shipping scalable data solutions in the cloud (e.g., AWS, GCP, Azure), across multiple data stores and methodologies
   
   

Nice to Have


 * Familiarity with web crawling technologies and best practices for data extraction from websites
 * Experience in developing deduplication processes for large datasets
 * Hands-on experience with full-text extraction and processing from various document formats (PDF, HTML, XML, etc.)
 * Experience working with academic research databases or scientific literature
 * Familiarity with machine learning concepts and their application in search technologies
 * Experience with distributed computing frameworks beyond Spark (e.g., Dask, Ray)
 * Knowledge of academic publishing processes and metadata standards
 * Hands-on experience with Airflow, DBT, or Hadoop
   
   

What you'll do

You'll Own


 * Building and optimizing our academic research paper pipeline
    * You'll architect and implement robust, scalable solutions to handle our growing data needs while maintaining high performance and data quality.
    * You'll work on efficiently processing, deduplicating, and indexing hundreds of millions of research papers.
    * Your goal will be to make Elicit the most complete and up-to-date database of scholarly sources.

 * Enhancing Elicit's data infrastructure
    * You'll optimize our Spark jobs and data pipelines to handle large amounts of data efficiently.
    * You'll implement data partitioning strategies in our distributed systems to improve performance.
    * You'll develop processes to handle regular updates from multiple academic paper sources, ensuring efficient deduplication.

 * Maintaining and improving data quality
    * You'll implement robust data quality management processes to ensure the accuracy and reliability of our academic database.
    * You'll work on developing defenses against unexpected changes from publishers to maintain data integrity.
      

Your First Week


 * Start building foundational context
    * Get to know your team, our stack (including Python, Flyte, and Spark), and the product roadmap.
    * Familiarize yourself with our current data pipeline architecture and identify areas for potential improvement.

 * Make your first contribution to Elicit
    * Complete your first Linear issue related to our data pipeline or academic paper processing.
    * Have a PR merged into our monorepo, demonstrating your understanding of our development workflow.
    * Gain understanding of our CI/CD pipeline, monitoring, and logging tools specific to our data infrastructure.
      

Your First Month


 * You'll complete your first multi-issue project
    * Tackle a significant data pipeline optimization or enhancement project.
    * Collaborate with the team to implement improvements in our academic paper processing workflow.

 * You're actively improving the team
    * Contribute to regular team meetings and hack days, sharing insights from your data engineering expertise.
    * Add documentation or diagrams explaining our data pipeline architecture and best practices.
    * Suggest improvements to our data processing and storage methodologies.
      

Your First Quarter


 * You're flying solo
    * Independently implement significant enhancements to our data pipeline, improving efficiency and scalability.
    * Make impactful decisions regarding our data architecture and processing strategies.

 * You've developed an area of expertise
    * Become the go-to resource for questions related to our academic paper processing pipeline and data infrastructure.
    * Lead discussions on optimizing our data storage and retrieval processes for academic literature.

 * You actively research and improve the product
    * Propose and scope improvements to make Elicit more comprehensive and up-to-date in terms of scholarly sources.
    * Identify and implement technical improvements to surpass competitors like Google Scholar in terms of coverage and data quality.
      

Who you'll work with

Role

This role will report directly to James, our Head of Engineering, and work very closely with the rest of the engineering team:


 * Luke (AI engineer, full-stack)
 * Panda (AI engineer, infra)
 * Justin (ML Engineer)
   
   

You'll also spend a lot of time collaborating with Kevin (Head of Product), and co-founders Jungwon & Andreas.

Compensation, Benefits, And Perks

In addition to working on important problems as part of a productive and positive team, we also offer great benefits (with some variation based on location):


 * Flexible work environment: work from our office in Oakland or remotely with time zone overlap (between GMT and GMT-8), as long as you can travel for in-person retreats and coworking events
 * Fully covered health, dental, vision, and life insurance for you, generous coverage for the rest of your family
 * Flexible vacation policy, with a minimum recommendation of 20 days/year + company holidays
 * 401K with a 6% employer match
 * $2,000 device budget to start, with more accumulating for each month of work
 * $500 / year personal development budget
 * A team administrative assistant who can help you with personal and work tasks
 * You can find more reasons to work with us in this thread!
   
   

For all roles at Elicit, we use a data-backed compensation framework to keep salaries market-competitive, equitable, and simple to understand.


 * This role starts between $195-230K + equity, depending on your level. We're optimizing for a hire who can contribute at a L4/senior-level or above.",Full-time
4143854772,16167895.0,Data Engineer,"***Candidate Must Hold Current Authorization To Work W2, Without The Need Of Future Sponsorship, Cannot Work C2C***




Agility Partners is seeking a qualified Data Engineer to fill an open position with a leading grocer in the Cincinnati area. This is an exciting opportunity to utilize your skills in Data modeling and advanced SQL techniques. This will give an engineer the opportunity to use their skills in cloud migration methodologies and processes.




Key Responsibilities:




 * SQL, Python, Spark, Databricks
 * DBT
 * Working with varied data file formats (Avro, json, csv) using PySpark for ingesting and transformation
 * DevOps process and Terraform scripting
 * Leadership skills: must be able to put together and deliver presentation.
 * Solid communication while working with PMO. Must be able to translate what product is asking for and regurgitate to team.
 * The Ideal Candidate




Qualifications:




 * Experience in Data modeling and advanced SQL techniques
 * Experience working on cloud migration methodologies and processes including tools like Databricks, Azure Data Factory, Azure Functions, and other Azure data services
 * Expert in SQL, Python, Spark, Databricks
 * Experience working with varied data file formats (Avro, json, csv) using PySpark for ingesting and transformation
 * Experience with DevOps process and understanding of Terraform scripting
 * Understanding the benefits of data warehousing, data architecture, data quality processes, data warehousing design and implementation, table structure, fact and dimension tables, logical and physical database design
 * Experience designing and implementing ingestion processes for unstructured and structured data sets
 * Experience designing and developing data cleansing routines utilizing standard data operations
 * Knowledge of data, master data, metadata related standards, and processes
 * Experience working with multi-Terabyte data sets, troubleshooting issues, performance tuning of Spark and SQL queries
 * Experience using Azure DevOps/Github actions CI/CD pipelines to deploy code
 * Microsoft Azure certifications are a plus
 * Minimum of 7 years of hands-on experience working on design, configuration, implementation, and data migration for medium to large sized enterprise data platforms.
 * Reasons to Love It
 * Work within a collaborative team environment where ideas and creativity are welcomed! Family and Work Life balance are important to this organization and valued for the employees.
 * Working for an organization that focuses on company culture, inclusion and diversity
 * 50% medical coverage for you and your entire family, short/long term disability and life insurance options
 * 401(k)
 * Life Insurance
 * Disability coverage",Contract
4107126071,34209.0,Data Engineer,"Company And Culture

Created in 2002 by Marc Eckō, Complex is a leading global youth entertainment network showcasing the evolution of major pop culture categories, including streetwear and style, music, sneakers, and sports. Complex is a juggernaut in the content and culture space, delivering unprecedented global reach.

Complex is the world’s definitive cultural commerce, content, and experiential platform. We have created an all-new operating system built for the next generation, seamlessly integrating discovery, inspiration, community, and shopping. The company represents an expansion of the original vision with a deep understanding of convergence culture and its impact on contemporary society.

Whether through video, long-form editorial, or social content, Complex tells stories that engage dynamic conversation with our communities. Our internet-breaking cover stories document the heroes of culture and take them to the next level through product collaboration and s hoppability.

Complex has become experts in creating immersive environments at our IRL experiences and cultural events. ComplexCon is our flagship festival bringing together the world’s most influential brands and artists for an unforgettable weekend of style, sneakers, art, design, food, music, inspiration and more.

Join us to help redefine the way people shop, while building a global marketplace that moves at the speed of culture. Complex is committed to building a high performing team that is passionate about what they do and the communities we serve.

Everyone at Complex truly believes in the company and its mission; it’s a requirement for working here. There is synergy within the teams that make Complex what it is, a well-oiled machine. Employees are at the forefront of the company's success because every one of us is given the opportunity to provide suggestions, feedback, and direction.

About The Role

We're seeking a Data Engineer to join our team who will be responsible for designing and building scalable data solutions that power our analytics and machine learning capabilities. In this role, you'll ensure data quality, reliability, and accessibility across the organization while working with various stakeholders to translate business requirements into technical solutions.

What You Will Do


 * Design and implement scalable data pipelines using SQL and Python while maintaining efficient data models
 * Develop comprehensive monitoring, testing, and alerting systems to ensure data quality
 * Deploy and manage data applications using AWS cloud technologies (S3, EC2, Lambda)
 * Support machine learning initiatives through feature engineering and data model optimization
 * Build tools and processes to improve team efficiency
 * Create and maintain technical documentation while collaborating with analysts and stakeholders
 * Work on analytics platform enhancement and cloud infrastructure management
 * Participate in cross-functional collaboration initiatives
   
   

Who You Are (Required)


 * Experienced professional with 3+ years of programming experience with SQL for data exploration and relational modeling
 * Proficient in Python with 3+ years of experience building and maintaining data pipelines
 * Well-versed in OLAP databases (Snowflake or Databricks)
 * Knowledgeable in AWS services (S3, EC2, Lambda)
 * Experienced with Apache Airflow or similar orchestration tools (Dagster, Prefect)
 * Understanding of big data frameworks like Apache SparkStrong analytical and critical thinking skills
 * Experience with data experimentation and statistical analysis
   
   

Who You Are (Preferred)


 * Experience with Shopify data integration
 * Background in machine learning feature engineering
 * Knowledge of data governance and security best practices
 * Experience with real-time data processing
 * Familiarity with data visualization tools
 * Experience working in an Agile environment
   
   

What We Offer


 * Best in class health, dental, and vision insurance
 * Healthcare FSA
 * Dependent Care FSA
 * Commuter Benefits FSA
 * Short-term/long-term disability and life insurance
 * Paid Parental leave
 * 401k with 4% match
 * Pet Insurance
 * Legal and Identity Theft Plans
 * Vacation time and sick days
   
   

$110,000 - $120,000 a year

The Pay Range, which consists of salary and commission, for this position is listed. Actual pay will vary based on factors including, but not limited to location, experience, and performance. The range listed is just one component of Complex Total Rewards offerings for employees.

We're an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.

The above statements cover what are generally believed to be principal and essential functions of the job. Specific circumstances may allow or require some incumbents assigned to the job to perform a different combination of duties.

Complex participates in E-Verify and will provide the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.",Full-time
4125063909,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4139912338,1337.0,"Senior Software Engineer, AI Platform","Company Description
LinkedIn is the world’s largest professional network, built to help members of all backgrounds and experiences achieve more in their careers. Our vision is to create economic opportunity for every member of the global workforce. Every day our members use our products to make connections, discover opportunities, build skills and gain insights. We believe amazing things happen when we work together in an environment where everyone feels a true sense of belonging, and that what matters most in a candidate is having the skills needed to succeed. It inspires us to invest in our talent and support career growth. Join us to challenge yourself with work that matters.

At LinkedIn, our approach to flexible work is centered on trust and optimized for culture, connection, clarity, and the evolving needs of our business. The work location of this role is hybrid, meaning it will be performed both from home and from a LinkedIn office on select days, as determined by the business needs of the team.

Job Description
This role can be based in Mountain View, CA, San Francisco, CA, or Bellevue, WA.

Join us to push the boundaries of scaling large models together. The team is responsible for scaling LinkedIn’s AI model training, feature engineering and serving with hundreds of billions of parameters models and large scale feature engineering infra for all AI use cases from recommendation models, large language models, to computer vision models. We optimize performance across algorithms, AI frameworks, data infra, compute software, and hardware to harness the power of our GPU fleet with thousands of latest GPU cards. The team also works closely with the open source community and has many open source committers (TensorFlow, Horovod, Ray, vLLM, Hugginface, DeepSpeed etc.) in the team. Additionally, this team focussed on technologies like LLMs, GNNs, Incremental Learning, Online Learning and Serving performance optimizations across billions of user queries

Model Training Infrastructure: As an engineer on the AI Training Infra team, you will play a crucial role in building the next-gen training infrastructure to power AI use cases. You will design and implement high performance data I/O, work with open source teams to identify and resolve issues in popular libraries like Huggingface, Horovod and PyTorch, enable distributed training over 100s of billions of parameter models, debug and optimize deep learning training, and provide advanced support for internal AI teams in areas like model parallelism, tensor parallelism, Zero++ etc. Finally, you will assist in and guide the development of containerized pipeline orchestration infrastructure, including developing and distributing stable base container images, providing advanced profiling and observability, and updating internally maintained versions of deep learning frameworks and their companion libraries like Tensorflow, PyTorch, DeepSpeed, GNNs, Flash Attention. PyTorch Lightning and more and more.

Feature Engineering: this team shapes the future of AI with the state-of-the-art Feature Platform, which empowers AI Users to effortlessly create, compute, store, consume, monitor, and govern features within online, offline, and nearline environments, optimizing the process for model training and serving. As an engineer in the team, you will explore and innovate within the online, offline, and nearline spaces at scale (millions of QPS, multi terabytes of data, etc), developing and refining the infrastructure necessary to transform raw data into valuable feature insights. Utilizing leading open-source technologies like Spark, Beam, and Flink and more, you will play a crucial role in processing and structuring feature data, ensuring its most optimal storage in the Feature Store, and serving feature data with high performance.

Model Serving Infrastructure: this team builds low latency high performance applications serving very large & complex models across LLM and Personalization models. As an engineer, you will build compute efficient infra on top of native cloud, enable GPU based inference for a large variety of use cases, cuda level optimizations for high performance, enable on-device and online training. Challenges include scale (10s of thousands of QPS, multiple terabytes of data, billions of model parameters), agility (experiment with hundreds of new ML models per quarter using thousands of features), and enabling GPU inference at scale.

ML Ops: The MLOps and Experimentation team is responsible for the infrastructure that runs MLOps and experimentation systems across LinkedIn. From Ramping to Observability, this org powers the AI products that define LinkedIn. This team, inside MLOps, is responsible for AI Metadata, Observability, Orchestration, Ramping and Experimentation for all models; building tools that enable our product and infrastructure engineers to optimize their models and deliver the best performance possible.


As a Senior Software Engineer, you will have first-hand opportunities to advance one of the most scalable AI platforms in the world. At the same time, you will work together with our talented teams of researchers and engineers to build your career and your personal brand in the AI industry.

Responsibilities

-Designing, implementing, and optimizing the performance of large-scale distributed serving or training for personalized recommendation as well as large language models.
-Improving the observability and understandability of various systems with a focus on improving developer productivity and system sustenance.
-Mentoring other engineers, defining our challenging technical culture, and helping to build a fast-growing team.
-Working closely with the open-source community to participate and influence cutting edge open-source projects (e.g., vLLMs, PyTorch, GNNs, DeepSpeed, Huggingface, etc.).

Basic Qualifications:
-Bachelor’s Degree in Computer Science or related technical discipline, or equivalent practical experience
-2+ years of experience in the industry with leading/ building deep learning systems.
-2+ years of experience with Java, C++, Python, Go, Rust, C# and/or Functional languages such as Scala or other relevant coding languages
-Hands-on experience developing distributed systems or other large-scale systems.

Preferred Qualifications:
-BS and 5+ years of relevant work experience, MS and 4+ years of relevant work experience, or PhD and 2+ years of relevant work experience
-Previous experience working with geographically distributed co-workers.
-Outstanding interpersonal communication skills (including listening, speaking, and writing) and ability to work well in a diverse, team-focused environment with other SRE/SWE Engineers, ---Project Managers, etc.
-Experience building ML applications, LLM serving, GPU serving.
-Experience with distributed data processing engines like Flink, Beam, Spark etc., feature engineering,
-Experience with search systems or similar large-scale distributed systems
-Expertise in machine learning infrastructure, including technologies like MLFlow, Kubeflow and large scale distributed systems
-Co-author or maintainer of any open-source projects
-Familiarity with containers and container orchestration systems
-Expertise in deep learning frameworks and tensor libraries like PyTorch, Tensorflow, JAX/FLAX

Suggested Skills:
-ML Algorithm Development
-Experience in Machine Learning and Deep Learning
-Experience in Information retrieval / recommendation systems / distributed serving / Big Data is a plus.



You will Benefit from our Culture:
We strongly believe in the well-being of our employees and their families. That is why we offer generous health and wellness programs and time away for employees of all levels.


LinkedIn is committed to fair and equitable compensation practices.
The pay range for this role is $128,000 - $210,000. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to skill set, depth of experience, certifications, and specific work location. This may be different in other locations due to differences in the cost of labor.

The total compensation package for this position may also include annual performance bonus, stock, benefits and/or other applicable incentive compensation plans. For additional information, visit: https://careers.linkedin.com/benefits


Equal Opportunity Statement
LinkedIn is committed to diversity in its workforce and is proud to be an equal opportunity employer. LinkedIn considers qualified applicants without regard to race, color, religion, creed, gender, national origin, age, disability, veteran status, marital status, pregnancy, sex, gender expression or identity, sexual orientation, citizenship, or any other legally protected class. LinkedIn is an Affirmative Action and Equal Opportunity Employer as described in our equal opportunity statement here: https://microsoft.sharepoint.com/:b:/t/LinkedInGCI/EeE8sk7CTIdFmEp9ONzFOTEBM62TPrWLMHs4J1C_QxVTbg?e=5hfhpE. Please reference https://www.eeoc.gov/sites/default/files/2023-06/22-088_EEOC_KnowYourRights6.12ScreenRdr.pdf and https://www.dol.gov/ofccp/regs/compliance/posters/pdf/OFCCP_EEO_Supplement_Final_JRF_QA_508c.pdf for more information.

LinkedIn is committed to offering an inclusive and accessible experience for all job seekers, including individuals with disabilities. Our goal is to foster an inclusive and accessible workplace where everyone has the opportunity to be successful.

If you need a reasonable accommodation to search for a job opening, apply for a position, or participate in the interview process, connect with us at accommodations@linkedin.com and describe the specific accommodation requested for a disability-related limitation.

Reasonable accommodations are modifications or adjustments to the application or hiring process that would enable you to fully participate in that process. Examples of reasonable accommodations include but are not limited to:

-Documents in alternate formats or read aloud to you
-Having interviews in an accessible location
-Being accompanied by a service dog
-Having a sign language interpreter present for the interview

A request for an accommodation will be responded to within three business days. However, non-disability related requests, such as following up on an application, will not receive a response.

LinkedIn will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by LinkedIn, or (c) consistent with LinkedIn's legal duty to furnish information.

Pay Transparency Policy Statement
As a federal contractor, LinkedIn follows the Pay Transparency and non-discrimination provisions described at this link: https://lnkd.in/paytransparency.

Global Data Privacy Notice for Job Candidates
This document provides transparency around the way in which LinkedIn handles personal data of employees and job applicants: https://lnkd.in/GlobalDataPrivacyNotice",Full-time
4138569745,106170142.0,Data Engineer,"About Us

Luxe Vision Consulting is a Wisconsin-based consulting firm dedicated to connecting top global talent with leading U.S. companies. We specialize in sourcing skilled professionals, conducting rigorous screening and technical assessments, and preparing candidates for opportunities in the U.S. job market.

Our mission is to bridge the gap between exceptional talent and top-tier businesses, ensuring the right fit for both candidates and clients. With a focus on quality, efficiency, and innovation, we help professionals unlock their potential and secure rewarding careers with prestigious U.S. organizations.

At Luxe Vision Consulting, we believe in integrity, excellence, and results-driven recruitment. Whether you're a company looking for the best talent or a professional seeking your next big opportunity, we are committed to making the connection that drives success.

The Role

Job Description

We are looking for a skilled Data Engineer to join our team. The ideal candidate will have strong experience in designing, building, and maintaining scalable data pipelines and architectures. You will play a critical role in managing data workflows, ensuring data integrity, and optimizing data processing.

Responsibilities


 * Data Pipeline Development: Design, build, and maintain scalable and efficient data pipelines to process and transform large datasets.
 * ETL & Data Integration: Develop and optimize ETL (Extract, Transform, Load) workflows for structured and unstructured data sources.
 * Big Data Processing: Work with PySpark and Pandas to handle large-scale data processing tasks.
 * Database Management: Design, implement, and manage relational (SQL) and non-relational databases for data storage and retrieval.
 * Cloud Technologies: Leverage cloud platforms such as AWS, GCP, or Azure to deploy and manage data infrastructure.
 * Collaboration: Work closely with data scientists, analysts, and software engineers to support analytical and machine learning projects.
 * Data Quality & Performance Optimization: Ensure data accuracy, consistency, and security while optimizing performance.
 * Monitoring & Troubleshooting: Identify and resolve data pipeline performance bottlenecks and failures.
   
   

Ideal Profile

Required Work Experience


 * 2+ years of experience in data engineering or a related field.
 * Proven experience developing ETL pipelines and data processing workflows.
 * Hands-on experience with PySpark, Pandas, and SQL.
 * Experience working with big data technologies such as Apache Spark, Hadoop, or Kafka (preferred).
 * Familiarity with cloud data solutions (AWS, GCP, or Azure).
   
   

Required Skills


 * Programming: Strong proficiency in Python (PySpark, Pandas) or Scala.
 * Data Modeling & Storage: Experience with relational databases (PostgreSQL, MySQL, SQL Server) and NoSQL databases (MongoDB, Cassandra).
 * Big Data & Distributed Computing: Knowledge of Apache Spark, Hadoop, or Kafka.
 * ETL & Data Integration: Ability to develop efficient ETL processes and manage data pipelines.
 * Cloud Computing: Experience with AWS (S3, Redshift, Glue), GCP (BigQuery), or Azure (Data Factory, Synapse).
 * Data Warehousing: Understanding of data warehousing concepts and best practices.
 * Problem-Solving: Strong analytical skills to troubleshoot and optimize data pipelines.
 * Communication: Must be proficient in spoken English to collaborate with US-based teams.
   
   

Education Requirements


 * Bachelor’s degree in Computer Science, Data Engineering, Information Technology, or a related field (preferred).
 * Equivalent work experience in data engineering will also be considered.
   
   

Fill out the application form here: https://forms.gle/nefgwYRFYE7mffdA7

Alternatively, feel free to message us directly here on the page or email your resume to hiring@ luxevisionconsulting com

📑Subject: Position - First and Last Name

Only shortlisted candidates will be contacted. We look forward to hearing from you!

What's on Offer?


 * Work within a company with a solid track record of success
 * Attractive salary & benefits
 * Excellent career development opportunities",Full-time
4064737217,3088.0,"Data Engineer I (AWS, Python, SQL)","Who Are We?

Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.

Compensation Overview

The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.

Salary Range

$106,300.00 - $175,400.00

Target Openings

1

What Is the Opportunity?

Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate the stories found in data. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.

What Will You Do?


 * Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.
 * Design data solutions.
 * Analyze sources to determine value and recommend data to include in analytical processes.
 * Incorporate core data management competencies including data governance, data security and data quality.
 * Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.
 * Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.
 * Test data movement, transformation code, and data components.
 * Perform other duties as assigned.
   
   

What Will Our Ideal Candidate Have?


 * Bachelor’s Degree in STEM related field or equivalent
 * Six years of related experience
 * Looking for a Cloud data engineer, well versed in designing, building, and supporting Cloud Data Pipelines.
 * Experience in writing scripts in Python and SQL
 * Nice to have experience in Spark (Databricks) processing
 * Experience in Data platforms like AWS Data Lake and Snowflake would be a huge plus
 * AWS Services that’ll be commonly used include AWS Glue, Lambda, S3, IAM, KMS, EMR, Step Functions etc.
 * It is highly desirable to have an experience in building IaC modules using Terraform.
 * Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices.
 * The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.
 * Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.
 * Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.
 * Strong verbal and written communication skills with the ability to interact with team members and business partners.
 * Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.
   
   

What is a Must Have?


 * Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
 * Four years of data engineering or equivalent experience.
   
   

What Is in It for You?


 * Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.
 * Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
 * Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
 * Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs.
 * Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.
   
   

Employment Practices

Travelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.

In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions.

If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.

Travelers reserves the right to fill this position at a level above or below the level included in this posting.

To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.",Full-time
4116217130,24015.0,Data Engineer,"Our corporate activities are growing rapidly, and we are currently seeking a full-time, office-based Data Engineer to join our Information Technology team. This position will work on a team to accomplish tasks and projects that are instrumental to the company’s success. If you want an exciting career where you use your previous expertise and can develop and grow your career even further, then this is the opportunity for you.

Responsibilities


 * Utilize skills in development areas including data warehousing, business intelligence, and databases (Snowflake, ANSI SQL, SQL Server, T-SQL);
 * Support programming/software development using Extract, Transform, and Load (ETL) and Extract, Load and Transform (ELT) tools, (dbt, Azure Data Factory, SSIS);
 * Design, develop, enhance and support business intelligence systems primarily using Microsoft Power BI;
 * Collect, analyze and document user requirements;
 * Participate in software validation process through development, review, and/or execution of test plan/cases/scripts;
 * Create software applications by following software development lifecycle process, which includes requirements gathering, design, development, testing, release, and maintenance;
 * Communicate with team members regarding projects, development, tools, and procedures; and
 * Provide end-user support including setup, installation, and maintenance for applications
   
   

Qualifications


 * Bachelor's Degree in Computer Science, Data Science, or a related field;
 * 3+ years of experience in Data Engineering;
 * Knowledge of developing dimensional data models and awareness of the advantages and limitations of Star Schema and Snowflake schema designs;
 * Solid ETL development, reporting knowledge based off intricate understanding of business process and measures;
 * Knowledge of Snowflake cloud data warehouse, Fivetran data integration and dbt transformations is preferred;
 * Knowledge of Python is preferred;
 * Knowledge of REST API;
 * Basic knowledge of SQL Server databases is required;
 * Knowledge of C#, Azure development is a bonus; and
 * Excellent analytical, written and oral communication skills.
   
   

Medpace Overview

Medpace is a full-service clinical contract research organization (CRO). We provide Phase I-IV clinical development services to the biotechnology, pharmaceutical and medical device industries. Our mission is to accelerate the global development of safe and effective medical therapeutics through its scientific and disciplined approach. We leverage local regulatory and therapeutic expertise across all major areas including oncology, cardiology, metabolic disease, endocrinology, central nervous system, anti-viral and anti-infective. Headquartered in Cincinnati, Ohio, employing more than 5,000 people across 40+ countries.

Why Medpace?

People. Purpose. Passion. Make a Difference Tomorrow. Join Us Today.

The work we’ve done over the past 30+ years has positively impacted the lives of countless patients and families who face hundreds of diseases across all key therapeutic areas. The work we do today will improve the lives of people living with illness and disease in the future.

Cincinnati Perks


 * Cincinnati Campus Overview
 * Flexible work environment
 * Competitive PTO packages, starting at 20+ days
 * Competitive compensation and benefits package
 * Company-sponsored employee appreciation events
 * Employee health and wellness initiatives
 * Community involvement with local nonprofit organizations
 * Discounts on local sports games, fitness gyms and attractions
 * Modern, ecofriendly campus with an on-site fitness center
 * Structured career paths with opportunities for professional growth
 * Discounted tuition for UC online programs
   
   

Awards


 * Named a Top Workplace in 2024 by The Cincinnati Enquirer
 * Recognized by Forbes as one of America's Most Successful Midsize Companies in 2021, 2022, 2023 and 2024
 * Continually recognized with CRO Leadership Awards from Life Science Leader magazine based on expertise, quality, capabilities, reliability, and compatibility
   
   

What To Expect Next

A Medpace team member will review your qualifications and, if interested, you will be contacted with details for next steps.

EO/AA Employer M/F/Disability/Vets",Full-time
4150881064,83745.0,Sr. Data Engineer I (5540),"As Sr. Data Engineer I, you’ll take a leadership role in architecting, building, and optimizing our data pipelines, data warehouses, and data lakes. Your deep technical expertise and extensive experience will drive the development of scalable, efficient, and reliable data solutions that empower our analytics and business intelligence initiatives. You will collaborate closely with cross-functional teams including data scientists, analysts, and software engineers to ensure our data ecosystem meets both current and future requirements.


We know that you can’t have great technology services without amazing people. At MetroStar, we are obsessed with our people and have led a two-decade legacy of building the best and brightest teams. Because we know our future relies on our deep understanding and relentless focus on our people, we live by our mission: A passion for our people. Value for our customers.


If you think you can see yourself delivering our mission and pursuing our goals with us, then check out the job description below!


What you’ll do:


   
   
 * Lead the design and implementation of complex, end-to-end data pipelines to collect, process, and transform data from various sources into usable formats.
   
   
 * Develop and maintain ETL/ELT processes to ensure data integrity, accuracy, and availability for downstream applications.
   
   
 * Collaborate with data scientists and analysts to understand data requirements and assist in the creation of data models, dashboards, and visualizations.
   
   
 * Optimize data infrastructure for performance, scalability, and cost-effectiveness, making use of both traditional relational databases and modern big data technologies.
   
   
 * Ensure data security and compliance with relevant data protection regulations throughout the data lifecycle.
   
   
 * Identify and resolve data-related issues, troubleshoot performance bottlenecks, and provide timely support to maintain data operations.
   
   
 * Mentor and guide junior data engineers, providing technical leadership and fostering a culture of continuous learning.
   
   


What you’ll need to succeed:


   
   
 * Possess an active U.S. Government issued Secret security clearance.
   
   
 * Bachelor's or Master's degree in Computer Science, Information Technology, or a related field.
   
   
 * Minimum of 5 years of professional experience in data engineering, with a proven track record of designing and implementing robust data solutions.
   
   
 * Expertise in building and maintaining data pipelines using tools such as Talend.
   
   
 * Experience implementing data integration within tools such as Pentaho.
   
   
 * Strong programming skills in languages such as Python, Java, Scala, or SQL for data processing and manipulation.
   
   
 * Proficiency in working with CI/CD (e.g. Jenkins) and containerization technologies (e.g., Docker, Kubernetes) to deploy data platforms such as Talend and Pentaho.
   
   
 * Experience with data warehousing solutions and data modeling concepts.
   
   
 * Familiarity with version control systems (e.g., Git) and collaborative development practices.
   
   
 * Excellent problem-solving skills and the ability to tackle complex technical challenges.
   
   
 * Strong communication skills to collaborate effectively with cross-functional teams and present technical concepts to non-technical stakeholders.
   
   

Like we said, we are big fans of our people. That’s why we offer a generous benefits package, professional growth, and valuable time to recharge. Learn more about our company culture code and benefits. Plus, check out our accolades.


Commitment to Non-DiscriminationAll qualified applicants will receive consideration for employment based on merit and without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, status as a protected veteran, or any other status protected by applicable federal, state, local, or international law.


 What we want you to know:


In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire.


 Not ready to apply now? 


Sign up to join our newsletter here.",Full-time
4148118932,207470.0,Data Engineer II - Music,"We are looking for an experienced Data Engineer to become a part of the Music Promotion & S4A Studio, building the most powerful tools available to allow artists & labels to see all the data on how their music is performing on Spotify in one place with tools and insights to help them identify ways to take action on growth trends and amplify their music on the platform.

CAMP is a data and full-stack web team focused on building out the canonical metrics for Spotify for Artists. We build, serve, and maintain comprehensive music consumption datasets with the goal of giving artists tools to understand and take valuable action to build their audience and their career.

Our team manages hundreds of pipelines transforming raw information about user streams into aggregations that tell a story about listening behavior and audience growth and engagement over time, an orchestration layer that fetches, calculates, and filters that data for relevance, and the front end surfaces and features that render the analytics visuals on Spotify for Artists.

What You'll Do


 * Build and scale batch data pipelines on Scio and GCP
 * Collaborate and advise on backend services.
 * Work with Product and Design to define and develop what metrics are most important to artists, labels, and marketing teams in knowing definitively how their music is resonating with fans and new listeners.
 * Help us prioritize and address technical debt to ensure our systems are built for stability, cost efficiency, and timely delivery.
 * Help drive optimization, testing, and tooling to improve data quality.
 * Collaborate with other engineers, product managers, data scientists, and specialists, taking learning and leadership opportunities that will arise every single day.
 * Work in agile teams to continuously experiment, iterate and deliver on new product objectives and enhance tooling for squads within our product area.
   
   

Who You Are


 * You have worked with large-scale heterogeneous data, preferably with distributed systems such as Hadoop, BigTable, or Cassandra.
 * You know how to write distributed data pipelines in Java or Scala.
 * You are knowledgeable about data modeling, data access, and data storage techniques.
 * You advocate for agile software processes, data-driven development, reliability, blameless incident response, and responsible experimentation.
 * You understand the value of collaboration and coordination across teams.
 * You are committed to making your team the best version of itself through mentorship and constructive accountability.
   
   

Where You'll Be


 * We offer you the flexibility to work where you work best! For this role, you can be within the Americas region as long as we have a work location.
 * This team operates within the Eastern time zone for collaboration.
   
   

The United States base range for this position is $122,716.00 - $175,308, plus equity. The benefits available for this position include health insurance, six month paid parental leave, 401(k) retirement plan, monthly meal allowance, 23 paid days off, 13 paid flexible holidays. This range encompasses multiple levels. Leveling is determined during the interview process. Placement in a level depends on relevant work history and interview performance. These ranges may be modified in the future.

Today, we are the world’s most popular audio streaming subscription service.",Full-time
4144544485,2610.0,Data Engineer Intern,"Overview

Do you want to join a team that's changing the world? Then we're looking for you! Check out the job description and apply now! Put your skills to meaningful use, gain unique experience, and work with world-class team members with diverse backgrounds and expertise who share the same vision. Join the Panasonic team today!

Responsibilities

What You'll Do:

Assist the business intelligence team in day to day activities and projects. One of the primary projects is to assist with the data management process to collect, clean, transform and store data from relevant data sources into our data storage and analytic environment.


 * May assist with data scientist and project manager to review and optimize machine learning models
 * Additional tasks may include the exploration and experimentation of new workflows and technology solutions to enhance our analytic activities
   
   

Program Details


 * The program will be a full-time paid summer internship
 * The program will be 12 weeks in length, and is planned to occur between Monday, May 19th and Friday, August 8th
   
   

Program Requirement(s)


 * Must be currently pursuing an undergraduate or graduate degree throughout the entirety of the internship
 * Must be able to attend the entirety of the internship
   
   

Qualifications

What You’ll Bring:

Education And Experience


 * Currently pursuing a bachelor's or master's degree in analytics or computer science
 * Savvy with data analysis and software technology including strong Excel skill
 * Data science and data engineering skills are highly preferred
 * Python, SQL database and data modeling knowledge preferred
 * Exposure to modern BI technologies, PowerBI, Tableau, Qlik, etc, prefered. Reasonable business acumen to understand the business user roles and needs
 * Fast learner to develop general awareness of business data and environment
 * Clear communication skill is required to work with stakeholders and various departments
 * Strong written and oral communication capabilities are required
   
   

Where You'll Be

For our hybrid and onsite roles, Panasonic is committed to fostering an ideal working environment that goes beyond the conventional. We understand the significance of moments that matter in your onsite experience, and we prioritize creating a workspace that not only promotes productivity but also ensures a fulfilling and positive work atmosphere. Join us at Panasonic, where your onsite presence is valued, and we strive to make each moment count in your professional journey.

Who We Are

Meet Panasonic! At Panasonic, we are pioneering technologies that not only move us forward but also make a positive impact.

Your work here goes beyond conventional boundaries, aligning with our commitment to doing work that matters. Whether it's in the realm of sustainable energy solutions or cutting-edge automotive technology, we provide an environment where innovative thinkers can soar.

Our dedication to addressing climate impact is ingrained in our approach, ensuring that we create technologies while actively working to reduce our environmental footprint. Joining us means experiencing career growth in more ways than one, with opportunities for professional development and advancement.

At Panasonic, we care about what you care about, fostering a culture where your expertise contributes to the creation of technologies that not only move us but also drive positive change for the planet.

Be part of a team that values your contributions, encourages innovation, and actively contributes to shaping a more sustainable and technologically advanced future.

We Take Opportunity Seriously

At Panasonic, we are committed to a workplace that genuinely fosters inclusion and belonging. Fairness and Honesty have been part of our core values for more than 100 years and we are proud of our diverse culture as an equal opportunity employer.

We understand that your career search may look different than others and embrace the professional, personal, educational, and volunteer opportunities through which people gain experience. If you are actively looking or starting to explore new opportunities, send us your application!

Panasonic is an Equal Opportunity/Affirmative Action employer, and all qualified applicants will receive consideration for employment without regard to: race, color, religion, sex, sexual orientation, gender identity, national origin, age, genetic information, disability status, protected veteran status, or any other characteristic protected by law. All qualified individuals are required to perform the essential functions of the job with or without reasonable accommodation.

Hourly Range: $17-$38

The minimum hourly wage for this role will be the greater of the posted range, or minimum wage for the location where the employee will be working, subject to local minimum wage requirements.

Due to the high volume of responses, we will only be able to respond to candidates of interest.

All candidates must have valid authorization to work in the U.S.

Thank you for your interest in Panasonic.

REQ-150087

",Internship
4033089164,482314.0,Data Engineer 4,"Join our dynamic team at our energy partner as a Data Engineer 4, where you will play a pivotal role in harnessing the power of data to optimize operations, enhance decision-making processes, and drive innovation in the rapidly evolving energy sector. As a seasoned professional, you will leverage your expertise to design, implement, and maintain robust data pipelines, ensuring the seamless flow of information critical to powering the future of sustainable energy solutions

Core Responsibilities


 * Provides technical direction, guides the team on key technical aspects and responsible for product tech delivery
 * Lead the Design, Build, Test and Deployment of components
 * Where applicable in collaboration with Lead Developers (Data Engineer, Software Engineer, Data Scientist, Technical Test Lead)
 * Understand requirements / use case to outline technical scope and lead delivery of technical solution
 * Confirm required developers and skillsets specific to product
 * Provides leadership, direction, peer review and accountability to developers on the product (key responsibility)
 * Works closely with the Product Owner to align on delivery goals and timing
 * Assists Product Owner with prioritizing and managing team backlog
 * Collaborates with Data and Solution architects on key technical decisions
 * The architecture and design to deliver the requirements and functionality
   
   

Core Experience And Abilities


 * Power Systems engineering experience
 * DER Dispatch experience
 * Automated fault analysis systems experience
 * Ability to perform hands on development and peer review for certain components / tech stack on the product
 * Standing up of development instances and migration path (with required security, access/roles)
 * Develop components and related processes (e.g. data pipelines and associated ETL processes, workflows)
 * Lead implementation of integrated data quality framework
 * Ensures optimal framework design and load testing scope to optimize performance (specifically for Big Data)
 * Supports data scientist with test and validation of models
 * Performs impact analysis and identifies risk to design changes
 * Ability to build new data pipelines, identify existing data gaps and provide automated solutions to deliver analytical capabilities and enriched data to applications
 * Ensures Test Driven development
 * Experience leading teams to deliver complex products
 * Strong technical skills and communication skills
 * Strong skills with business stakeholder interactions
 * Strong solutioning and architecture skills
 * Experience building real time data ingestion streams (event driven)
 * Ensure data security and permissions solutions, including data encryption, user access controls and logging
   
   

Core Technical Skills


 * Experience with native AWS technologies for data and analytics such as Athena, S3, Lambda, Glue, EMR, Kinesis, SNS, CloudWatch, etc.
 * Tools and Languages such as Django, Python, Java, Scala, Pandas
 * Infrastructure as Code technology such as Terraform
 * AWS services such as S3, EMR, Glue, Lambda, Athena, Kinesis, EC2, SNS, SQS, Cloudwatch
 * Experience with databases such as Redshift, Document DB, DynamoDB and Mongo DB
 * Experience transitioning on premise big data platforms into cloud based platforms such as AWS
   
   

Additional Technical Skills (nice to have, but not required for the role)


 * Hadoop platform (Hive; HBase; Druid)
 * Spark
 * PySpark
 * SQL
 * Workflow Automation
 * DevOps pipeline (CI/CD); Bitbucket; Concourse
 * API frameworks",Full-time
4045414207,66321745.0,Junior/Entry Level Data Engineer,"Since 2010 Synergisticit has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience, and technical competence to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this Job market also, our candidates can achieve multiple job offers and $100k &plus; salaries.

please check the below links to see the success outcomes and salaries of our candidates.

https://www.synergisticit.com/candidate-outcomes/

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

We regularly interact with the Top Tech companies to give our candidates a competitive advantage visit the below videos exhibiting at Oracle Cloud World/Oracle Java One (Las Vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergistic understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like Apple, google, Paypal, Western Union, Client, visa, Walmart labs etc to name a few.

Currently, We are looking for entry-level software programmers, Java full-stack developers, Python/Java developers, Data analysts/ Data Scientists, and Machine Learning engineers for full-time positions with clients.

Who Should Apply Recent Computer Science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and are looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

Required Skills

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, Gen AI, LLM, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full Stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java, Javascript, C&plus;&plus;, or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernetes, and REST API experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team and only connect with candidates who match client requirements.

No phone calls, please. Shortlisted candidates would be reached out. No third-party or agency candidates or C2C candidates",Full-time
4125067257,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4130354813,854801.0,Data Engineer,"Description

Welcome to Interclypse, where innovation meets passion. Every team member is a vital piece of our success story. We are not just a company, but a dynamic community driven by the shared vision of redefining excellence. At Interclypse, you will find more than a career – you will discover a vibrant ecosystem where your talents are celebrated, your ideas are embraced, and your potential is achieved. Every Interclypse team member can benefit based on their efforts and collectively benefit through the overall company’s success. Join our mission to positively impact society, community, industry, and individuals by always “Doing What is Right”. Together, let's pioneer a future where greatness is achieved and exceeded.

To actualize this vision, Interclypse employs a growth mindset culture that empowers employees to rise in their careers by providing them with tools, mentorship, and a supportive environment to ensure long-term success.

Interclypse is supporting several Maryland state agencies in the modernization and sustainment of critical systems. This exciting opportunity provides candidates with the ability to contribute to the long-term health and success of the state while continuing to learn and grow professionally within Interclypse’s growth mindset culture.

All positions are required to be onsite at various locations in Maryland.

Make a difference. Join our team by applying today!

Responsibilities

Responsible for designing, building, and maintaining data pipelines and infrastructure to support data-driven decisions and analytics. The individual is responsible for the following tasks:


 * Design, develop and maintain data pipelines, and extract, transform, load (ETL) processes to collect, process and store structured and unstructured data
 * Build data architecture and storage solutions, including data lakehouses, data lakes, data warehouse, and data marts to support analytics and reporting
 * Develop data reliability, efficiency, and qualify checks and processes
 * Prepare data for data modeling
 * Monitor and optimize data architecture and data processing systems
 * Collaboration with multiple teams to understand requirements and objectives
 * Administer testing and troubleshooting related to performance, reliability, and scalability
 * Create and update documentation
   
   

Requirements

Required Qualifications


 * Bachelor’s or Master's degree from an accredited college or university with a major in computer science, statistics, mathematics, economics, or related field
 * Three (3) years of experience as a data engineer
 * Experience as data engineer or similar role with a strong understanding of data architecture and ETL processes
 * Proficient in programming languages for data processing and knowledgeable of distributed computing and parallel processing
   
   

Why You Will Love Interclypse


 * You want to work for an adaptive company that moves at your speed.
 * You want a healthy work-life balance.
 * You want to work with a passionate team on an important mission.
 * You want to work for an organization that values and appreciates you.
 * You want to work for an organization that invests in your growth.
 * You want the option for career mentorship, both in technology and in business.
 * You value a company with a strong culture of growth and support.
   
   

Employee Impact Program

Every employee has the opportunity to be rewarded for the contributions they can make toward the long-term health of the company, our customers, and employees. This program in combination with our comprehensive benefits, time off and leave programs allow you to design a career and compensation program that enables unmatched flexibility while ensuring company, customer, and employee health and prosperity.

Benefits


 * Personal Time Off (PTO) for vacations, holidays, illnesses
 * Parental Leave
 * Bereavement Leave
 * Jury Duty Leave
 * Retirement: Unlimited 401K match up to 8% of your salary up to the federal maximum
 * Financial education and planning support
 * Health Insurance (Medical, Dental, Vision)
 * Health Savings Account (HSA)
 * Medical and Dependent Care Flexible Spending Accounts (FSA)
 * Employee Assistance Program
 * Life Insurance
 * Accidental Death and Dismemberment Insurance
 * Disability: Short-term and long-term disability coverage
 * Educational support
 * Company apparel
 * Social events: Holiday Party, Spring Picnic, Fall Picnic, happy hours and more.
 * Access to group rates for voluntary benefits such as Accident, Hospital Indemnity, Critical Illness, Pet Insurance, and Identity Theft Protection
   
   

EOE AA M/F/Vet/Disability

Interclypse is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, or protected Veteran status.

The base salary range provided is not adjusted for geographic differences associated with where the work is being performed. Actual salaries will vary depending on factors including but not limited to location, candidate’s experience and education/training, internal peer equity, and market and business consideration.",Full-time
4136582865,349016.0,Data Engineer,"SBLI is seeking a skilled and motivated Data Engineer to join our team. In this role, you will work at the intersection of technology and business to design, develop, and optimize data infrastructure, enabling our organization to leverage data for strategic decision-making. This is an exciting opportunity to be part of a dynamic team, supporting SBLI's mission to deliver innovative life insurance solutions.




Roles and Responsibilities:

• SQL Expertise: Develop and execute SQL queries for data extraction, transformation, and loading; create and maintain views, materialized views, stored procedures, and functions.

• Business Requirements: Collaborate with stakeholders to gather requirements and translate them into functional code.

• Data Modeling: Skilled in designing data models with attributes, metrics, and dates to represent data structures and relationships.

• Data Warehousing: Proficient in star schema, snowflake schema, fact/dimension tables, and data warehouse design.

• ETL Development: Expertise in ETL tools for data extraction, transformation, and loading.

• Unix Scripting: Write and maintain shell scripts for data handling and automation.

• Troubleshooting: Debug and optimize SQL queries and ETL processes to resolve issues and improve performance.

• Communication: Effectively convey technical ideas, progress, and challenges to stakeholders and team members.

• Collaboration: Partner with developers, analysts, and business stakeholders to create integrated and effective data solutions.




Qualifications:




• Bachelor’s degree in computer science, information technology, or a related field

• 4+ years developing Database Warehousing, Analytics and ETL Development

• Experienced in software development life cycle (SDLC)

• Experienced in writing SQL queries using PL/SQL

• Experienced in Data modeling

• Experience in using ETL tools like Oracle Data Integrator (ODI) or any other tools

• Experienced in collecting requirements through stakeholder collaboration

• Experienced with Unix scripting

• Experienced working with Oracle and MS SQL Server databases




Key Products/Software:

• SQL Developer/Toad

• Microsoft SQL Server

• Oracle Analytics Cloud (OAC)

• Oracle Data Integrator (ODI)

• Oracle Data Visualizer/Tableau

• Salesforce

• Microsoft Fabric

",Full-time
4045412732,66321745.0,Remote Software Engineer (Junior/Entry),"Since 2010 and almost 14 years SynergisticIT has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients.

Post Covid the tech Layoffs have been massive—In 2022 there were 165,269 tech layoffs, In 2023 there were 264,220 tech layoffs and so far in 2024 there have been 126,382 tech layoffs. (Source Layoffs.fyi ) -Total layoffs as per this 555,871 tech layoffs.

Client, Dell and Cisco have announced 15,000/12,500 and 4000 tech layoffs respectively in August.

The Job market is hyper-competitive. For 1 position 500-2000 candidates or more are applying and laid off job seekers are also competing for entry level Job positions.

Acquiring the right technology skillsets which are being demanded by clients and getting yourself in front of clients is the way to get to get Interviews and eventually a Job Offer. Survival of the Fittest is the only way to get a tech Job in this job market.

In this Layoffs fueled market also SynergisticIT's candidates are able to achieve multiple job offers and $100k &plus; salaries once they acquire the required skills.

please check the below links to see success outcomes, salaries of our candidates .

https://www.synergisticit.com/candidate-outcomes/

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please visit the below videos exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, we are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Data Engineers, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

Required Skills

REQUIRED SKILLS For Java /Full stack/Devops Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Knowledge of Core Java , javascript , C&plus;&plus; or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

For data Science/Data Analyst/AI/Machine learning Positions

Required Skills

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude

Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Full-time
3875376626,46623.0,Jr. Web Application Data Engineer,"Description

Your role at GEI.

The Jr. Web Application Data Engineer position is responsible for the development and support of web applications that are highly data centric. This position goes beyond the typical web programmer and will design and support objects within Microsoft SQL Server. The person hired for this position will work with a team of Web programmers, Data Engineers, Data Architects, GISPs, Power BI designers, and subject-matter experts that are located on the east coast.

Required Qualifications


 * Practical experience with .Net framework for web development, C#, ASP.net, jquery, HTML/ razer, Linq, javaScript, and git or other version control management software.
 * Expertise in SDLC.
 * Ability to provide off-hour deployments and support for bug-fixes.
 * Major in computer-related field (computer science/engineering)
 * Able to work during east coast schedule.
   
   

Preferred Qualifications


 * Experience using Entity Framework Core
 * Experience with Microsoft SQL Server via SSMS - DDL and DML, relationships, indexing, view, and stored procedure development.
 * Knowledge of .Net Core
 * Azure authentication
 * Azure Blob storage integration
 * Power BI cloud service
 * Experience with VB.net for desktop applications, XML, XSD for supporting non-web applications.
   
   

Essential Duties


 * Design, program, test, deploy, and document web applications.
 * Design and build SQL Server schema.
 * Collaborate with data architects and data engineers.
 * Develop a strong understanding of the subject matter for each application to assist with troubleshooting.
 * Provide programming and data engineering assistance for desktop applications.
   
   

Soft Skills


 * Applicant should be self-motivated, detail-oriented, and organized.
 * Must be a quick learner.
 * Work well in a team environment but be self-directed and be able to work independently.
 * Experience in providing high quality deliverables on time.
 * Provide clear concise documentation for developed applications.
 * Ability to research coding solutions and best practices via websites or the resources.
   
   

We are GEI.

Some of the world’s most pressing problems - from climate change to sustainable development, to critical infrastructure and the future of our energy supply - need our brightest and diverse minds working together to create safer, more resilient communities for tomorrow.

We are technical experts, collaborators, and entrepreneurs who draw from diverse backgrounds to solve our clients’ most complex challenges.

With nearly 60 offices across North America, we offer a range of engineering, science, and technical consulting services. Our range of expertise, project types, and culture make us the choice for top talent in the AEC industry.

Employee-owned. Employee-focused.

As a 100% employee-owned company, our employees support our flat leadership structure, have a say in how our business operates and benefit from our financial success. We are committed to employee growth with career development opportunities, competitive total rewards, a well-being program, flexible work arrangements and more. Our company culture is driven by our 4 Cs - we are Client-Centered, Curious, Collaborative, and Community Minded - which support our focus on sustainability, safety, diversity, equity and inclusion. Get to know us better by visiting GEI’s career site here.

GEI’s Total Rewards Package Includes


 * Market-Competitive Compensation, including Eligibility for an Annual Performance Bonus
 * Pay Range For This Position: $25.00-32.00/hour dependent upon experience
 * Comprehensive Benefits Program, including Medical, Dental, Vision, Life, Disability and More
 * Well-Being Program and Paid Parental Leave
 * Commuter Benefits
 * Hybrid Work Schedules and Cell Phone Stipends
 * GEI University (GEIU) with Continuing Education Assistance and Tuition Reimbursement
 * Connecting Conversation Program with a Focus on Professional Development and Opportunities for Advancement
 * Support and Financial Rewards for Publication Awards, Professional Dues, and Professional Licenses
 * Paid Holidays and Generous Paid Time Off Program
 * Rewards and Recognition
 * GEI-Funded Profit Sharing and 401(k)
 * Opportunity to be an Owner and Shareholder (Learn more here)
 * A Vibrant Culture that is Focused on Partnership, Sustainability, Giving Back to Our Communities and Diversity, Equity and Inclusion
 * And More…",Full-time
4134392409,1222117.0,Data Engineer (Hybrid; Austin or Salt Lake City),"What is the Opportunity?

At Ovivo, we offer you the opportunity to expand your skills and professional experience while collaborating with worldwide experts in water treatment. As a Data Engineer at Ovivo, you will be joining a group driving data analysis within a company full of brilliant minds in an environment that promotes and drives innovation! Our goal is to enable and support data driven decision making throughout all aspects of Ovivo.

Joining Ovivo means being part of a global team of innovative and passionate professionals who are committed to preserving water, our planet's most critical resource. It also means combining our efforts and talents towards a more sustainable future - together.

The role is based in our Round Rock, TX or Salt Lake City, UT where we enjoy a hybrid work schedule.

What is the role?


 * Design, develop, and maintain data pipelines using modern ETL/ELT tools to integrate data from multiple sources such as CRM systems, ERP Systems, marketing platforms, and other third-party data sources.
 * Build and optimize scalable data infrastructure, ensuring that data is stored, processed, and delivered efficiently to meet marketing and business requirements.
 * Work within Microsoft ecosystem to build scalable, high-performance data models and workflows that support marketing insights.
 * Perform data transformation and cleaning to ensure high-quality, accurate data is available for marketing analytics, dashboards, and reporting.
 * Collaborate with marketing and analytics teams to understand data requirements and provide actionable data insights for campaign optimization and reporting.
 * Monitor, optimize, and troubleshoot data pipeline performance to ensure reliable and timely data delivery for marketing operations.
   
   

Does this look like you?

Essential Qualifications


 * BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
 * 2+ years experience with data modeling, warehousing and building ETL pipelines
 * 3+ years of experience in developing software and/or data products, with programming experience including Python. Strong skills in algorithms, data structures, technical design and software architecture
 * 3+ years of experience in SQL, relational databases, and good understanding of relational concepts
 * Ability to deliver adequate results on deadline, and make compromises to enable scalability and productization of algorithms
   
   

Preferred Qualifications


 * Experience working within a Microsoft/Azure Ecosystem
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
 * Ability to effectively manage projects, prioritize tasks, and meet deadlines
   
   

Would be nice


 * Experience working with ERP, CRM, or IOT Sensor Data
   
   

Don't meet every single requirement? If you carry a strong sense of ownership and teamwork in everything you do, we'd like to hear from you any way.

Why work at Ovivo?


 * Medical, Dental and Vision benefits
 * 401k Match
 * Company paid life insurance along with company paid short and long-term disability
 * 11 paid holidays
 * Three weeks of PTO to start (hire date determines number of PTO hours for the first year)
 * Roll over of 40 PTO hours to the following year
 * Sixteen personal hours (hire date determines number of personal hours for the first year)
 * Days off between Christmas Eve and New Year's Day - paid by the company with no impact to PTO balance.
 * Profit sharing
   
   

At Ovivo we are committed to providing working environments where everyone is included and treated fairly and with respect.

Dive in - Apply Today! Let's change the future of water together.

About Ovivo

Ovivo is a global provider of equipment, technology, and systems producing among the purest water and treating some of the most challenging wastewater in the industry. Ovivo is a powerful global brand with renowned trademarks, possessing more than 150 years of expertise and references in water treatment, supported by its proprietary products, advanced technologies, and extensive system integration knowhow. Ovivo delivers conventional to highly technological water treatment solutions for the industrial and municipal markets and leverages its large installed base of equipment around the world to offer parts and services to its customers. Ovivo is dedicated to innovation in an industry that is in constant evolution and offers water treatment solutions that are cost-effective, energy-efficient, and environmentally sustainable.

Visit our website to learn more about Ovivo : https://careers.ovivowater.com/

Job Posted by ApplicantPro",Full-time
4040237080,346779.0,Data Engineer - Onsite,"We are a proud work-from-office company. If you're ready to work on-site in a dynamic, global company, we’d love to hear from you.

Position Summary

Do you have a passion for building data architectures that enable smooth and seamless product experiences? Are you an all-around data enthusiast with a knack for ETL? We're hiring Data Engineers to help build and optimize the foundational architecture of our product's data.

We’ve built a strong data engineering team to date, but have a lot of work ahead of us, including:


 * Migrating from relational databases to a streaming and big data architecture, including a complete overhaul of our data feeds
 * Defining streaming event data feeds required for real-time analytics and reporting
 * Leveling up our platform, including enhancing our automation, test coverage, observability, alerting, and performance
   
   

As a Data Engineer, you will work with the development team to construct a data streaming platform and data warehouse that serves as the data foundations for our product.

Help us scale our business to meet the needs of our growing customer base and develop new products on our platform. You'll be a critical part of our growing company, working on a cross-functional team to implement best practices in technology, architecture, and process. You’ll have the chance to work in an open and collaborative environment, receive hands-on mentorship and have ample opportunities to grow and accelerate your career!

Responsibilities


 * Build our next generation data warehouse
 * Build our event stream platform
 * Translate user requirements for reporting and analysis into actionable deliverables
 * Enhance automation, operation, and expansion of real-time and batch data environment
 * Manage numerous projects in an ever-changing work environment
 * Extract, transform, and load complex data into the data warehouse using cutting-edge technologies
 * Build processes for topnotch security, performance, reliability, and accuracy
 * Provide mentorship and collaborate with fellow team members
   
   

Qualifications


 * Bachelor’s or Master’s degree in Computer Science, Information Systems, Operations Research, or related field required
 * 3+ years of experience building data pipelines
 * 3+ years of experience building data frameworks for unit testing, data lineage tracking, and automation
 * Fluency in Scala is required
 * Working knowledge of Apache Spark
 * Familiarity with streaming technologies (e.g., Kafka, Kinesis, Flink)
   
   

Nice-to-Haves


 * Experience with Machine Learning
 * Familiarity with Looker a plus
 * Knowledge of additional server-side programming languages (e.g. Golang, C#, Ruby)
   
   

PrismHR is a fast-paced SaaS company which provides customers with a cloud-based payroll process software application. PrismHR also provides professional services including system implementation consulting, custom configurations, and training. Lastly, via the Company’s Marketplace platform customers and end users access other human resources and employee benefits applications from PrismHR’s Marketplace Partners.

Diversity, Equity And Inclusion Program/Affirmative Action Plan

We have transformed our company into an inclusive environment where individuals are valued for their talents and empowered to reach their fullest potential. At PrismHR, we strive to continually lead with our values and beliefs that enable our employees to develop their potential, bring their full self to work, and engage in a world of inclusion.

Ensuring an inclusive environment for our employees is an integral part of the PrismHR culture. We aren't just checking a box, we are truly committed to creating a workplace that celebrates the diversity of our employees and fosters a sense of belonging for everyone. This is essential to our success. We are dedicated to building a diverse, inclusive, and authentic workplace, so if you’re excited about our roles but your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for these open roles or other open roles. We particularly encourage applicants from traditionally under-represented groups as we seek to increase the diversity of our workforce and provide fair opportunities for all.

As a proud Equal Opportunity and Affirmative Action Employer, PrismHR encourages talent from all backgrounds to join our team. Employment decisions are based on an individual’s qualifications as they relate to the job under consideration. The Company’s policy prohibits unlawful discrimination based on sex (which includes pregnancy, childbirth, breastfeeding, or related medical conditions, the actual sex of the individual, or the gender identity or gender expression), race, color, religion, including religious dress practices and religious grooming practices, sexual orientation, national origin, ancestry, citizenship, marital status, familial status, age, physical disability, mental disability, medical condition, genetic information, protected veteran or military status, or any other consideration made unlawful by federal, state or local laws, ordinances, or regulations.

The Company is committed to complying with all applicable laws providing equal employment opportunities. This commitment applies to all persons involved in the operations of the Company and prohibits unlawful discrimination by any employee of the Company, including supervisors and co-workers.

Privacy Policy: For information about how we collect and use your personal information, please see our privacy statement available at https://www.prismhr.com/about/privacy-policy.

PrismHR provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. If you have any difficulty using our online system and you need a reasonable accommodation due to a disability, you may use the following alternative email address to contact us about your interest in employment at PrismHR: taglobal@prismhr.com. Please indicate in the subject line of your email that you are requesting accommodation. Only candidates being considered for a position who require an accommodation will receive a follow-up response.

",Full-time
4082899440,242227.0,Data Engineer,"SECU is seeking a Data Engineer. This is a remote position for candidates ideally living in the EST time zone. Occasional in-person meetings and commitments throughout the year may be required.

Applicants must be authorized to work for ANY employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time.

The Data Engineer develops and maintains data structures and pipelines within Snowflake to facilitate the development of reports, visualizations, data sets and analytical models used by analysts and other business stakeholders across the organization. The Data Engineer ensures that datasets are of high integrity while in proper alignment with business needs. This role will identify opportunities for efficiency, create recommendations, and enact solutions to automate and streamline existing processes. This Data Engineer also maintains a strong understanding of Data Analysis and will support the Data Analysts in complex analysis and reporting needs.

A Day In Your Life Might Include


 * Implement data structures and pipelines within Snowflake to facilitate the development of reports, visualizations, data sets and analytical models.
 * Identify opportunities to automate and enact solutions that streamline existing processes as well as identifying ways to ensure date quality
 * Perform extensive quality control on all data pipelines through automated process and manual analysis, including check-ins with subject matter experts as needed.
 * Maintain continual understanding of current data engineering technology and methods within the analytics world and how it compares with SECU’s current capabilities.
 * Interview business users and analysts to understand the cases that integration solutions must support.
 * Provide SQL, Python and other programming-specific technical guidance to other engineers and analysts to support continued learning and development throughout the organization.
 * Solve data questions requiring advanced transforms, custom queries, statistical analyses, or other related tasks.
 * Collaborate with various groups and individuals within the organization to identify and understand their business needs and how key data sources for analytics will help meet their business challenges.
 * Communicate results that address the requestor’s core business questions and provide key insights and relevant action items.
 * Document the process undertaken for auditing and future reproducibility.
   
   

Education Requirements


 * Bachelor’s degree or greater in any of the following or similar areas: Data Science, Computer Science, Management Information Science, etc. Equivalent professional experience may be substituted in lieu of a degree.
   
   

Experience Requirements


 * 3 - 5 years of data-centric programming experience as a software/data engineer, including at least one year of experience implementing data pipelines using modern tools
 * Demonstrated experience with self-directed work on large and complex problems.
 * Experience working in a highly collaborative, team environment.
 * Experience communicating among multiple stakeholders and balancing multiple projects.
 * Advanced SQL Skills
 * Snowflake and SnowSQL a plus
 * Familiar with transformation and orchestration tools (e.g., DBT, Qlik replicate, etc.)
 * Advanced and experienced with PowerBI or similar
 * Software/data engineering experience with Python
 * Experience with modern data warehouse frameworks, tools and architectures
 * Basic understanding of statistical techniques and concepts
 * Innovative, creative and forward thinking; solutions-driven
 * Strong interpersonal and communication skills
 * Ability to work alone or in teams as appropriate
 * Familiarity with cloud platforms (ie., AWS, Azure)
 * Familiarity with GitHub/Azure Repos
   
   

Compensation Information: Offers will be commensurate with experience and education. Please Note: We typically hire at or below mid-point, which is $115,100 for this role.


 * Salary: Min. $88,500 – Max. $141,700
   
   

Other Compensation Includes


 * Annual corporate-wide incentives
   
   

We provide comprehensive benefits, with a focus on total well-being:


 * Medical, vision, dental benefits
 * 401k plan with company matching
 * Generous sick, vacation and personal leave
 * And more...2025 SECU Benefit Guide
   
   

SECU is committed to fostering a diverse, equitable, and inclusive workforce where all individuals are valued and respected. We take pride in providing equal opportunities for all qualified applicants regardless of race, ethnicity, national origin, gender, sexual orientation, gender identity or expression, religion, military or veteran status, or any other characteristics protected by law.",Full-time
4146999043,9089.0,Data Engineer,"Job Title: Data Engineer

Location: Issaquah, WA Hybrid (onsite 3 days per week)

Direct Hire Opportunity




Notes: Data engineer will be working on analytics, lifecycle management and observability, fitting into the existing team and program and working closely with the WW team to drive automation and infrastructure as code.




Position Summary

Responsible for developing and operationalizing data pipelines to make data available for consumption (reports and advanced analytics). This includes data ingestion, data transformation, data validation / quality, data visualization, data pipeline optimization, orchestration; and engaging with DevOps Engineers during CI / CD. The role requires grounding in programming and SQL, followed by expertise in data storage, modeling, cloud, data warehousing, and data lakes.

The Data Engineer is responsible for data across the IS Sustainability stack. This is a new team and will be fast paced, highly visible, supporting the business goals by being an industry leader in this space. This role is focused on data engineering to build and deliver automated data pipelines from a variety of internal and external data sources. The Data Engineer will partner with DevOps Engineers, product owners, engineering and data platform teams to design, build, test and automate data pipelines that are relied upon across the company as the single source of truth.

We are looking for a highly motivated, customer focused professional who wants to work in a fun and highly collaborative environment and willing to be the player as well as coach for the data science community within the organization.

*This position will be filled onsite in Issaquah, WA




Job Duties/Essential Functions

Develop and operationalize data pipelines to create enterprise certified data sets that are made available for consumption (BI, Advanced analytics, APIs/Services).

 * Identifies ways to improve data reliability, efficiency and quality of data management.
 * Works with area SMEs to design data pipelines and recommends ongoing optimization of data storage, data ingestion, data quality and orchestration.
 * Identifies, designs, and implements internal process improvements: automating manual processes, optimizing data delivery.
 * Identifies ways to improve data reliability, efficiency and quality of data management.
 * Conducts ad-hoc data retrieval for business reports and dashboards.
 * Assesses the integrity of data from multiple sources.
 * Designs, develops, & implements ETL/ELT processes using Informatica Intelligent Cloud Services (IICS) and Azure Data Factory (ADF).
 * Uses Azure services such as Databricks, Azure SQL DW (Synapse), Data Lake Storage, Azure Event Hub, Cosmos, Delta-Lake to improve and speed up delivery of our data products and services.
 * Develop and implement PowerBI reports and applications
 * Implements big data and NoSQL solutions by developing scalable data processing platforms to drive high-value insights to the organization.
 * Leads the analysis by applying statistics, machine learning and analytic approaches to predict and optimize business outcomes.
 * Designs and builds ML/DL models to solve business problems.
 * Correctly frames a problem and comes up with a hypothesis.
 * Communicates technical concepts to non-technical audiences both in written and verbal form.
 * Regular and reliable workplace attendance at your assigned location.







Experience, Skills, Education & Licenses/Certifications

 * Required:Experience engineering and operationalizing data pipelines with large and complex datasets.
 * Hands-on experience with Informatica PowerCenter and/or IICS.
 * Experience with Cribl, Confluent/Kafka, Big Panda.
 * Experience working with Cloud technologies such as ADLS, Azure Databricks, Spark, Azure Synapse, Cosmos DB and other big data technologies.
 * Extensive experience working with various data sources (DB2, SQL, Oracle, flat files (csv, delimited), APIs, XML, JSON.
 * Advanced SQL skills required. Solid understanding of relational databases and business data; ability to write complex SQL queries against a variety of data sources.
 * Experience with Data Modeling, ETL, and Data Warehousing.
 * Strong understanding of database storage concepts (data lake, relational databases, NoSQL, Graph, data warehousing).
 * Experience in delivering business insights using advanced statistical and machine learning models and visualization.
 * Proficiency in working with diverse databases and other data sources.
 * Experience with Git / Azure DevOps.
 * Experience delivering data solutions through agile software development methodologies.
 * Graduate degree in Computer Science, Data Science, and Statistics/Mathematics or related field.




Recommended:

Azure, GCP Certifications.

 * Experience implementing data integration techniques such as event/message-based integration (Kafka, Azure Event Hub), ETL.
 * Exposure to the retail industry.
 * Experience with UC4 Job Scheduler.
 * Strong proficiency in Machine Learning, Statistical and Reporting tools (Python, R, SQL, PowerBI).
 * Knowledge of Deep Learning and Neural Networks, and its applications.
 * Strong experience working in Cloud (Azure, GCP) based analytics platform.
 * Knowledge of Agile software development.
 * Experience in software development.
 * Excellent verbal and written communication skills.

",Full-time
4145946996,18434905.0,Data Engineer,"Description

Evolus is a performance beauty company with a customer-centric approach focused on delivering breakthrough products. We are looking for an enthusiastic person with strong data engineering and analytical skills to join our team and support data and analytics initiatives across Evolus's global business functions. The Data Engineer’s role is to integrate data from a variety of internal and external sources into a common warehouse data model. This is a technical role that involves building and maintaining ELT data pipelines, recommend and implement appropriate data models and be comfortable in a DataOps environment. We are looking for someone with a consultative mindset to be able to interact with business and analytics team and help drive value to business. Data ecosystem is an evolving space, and we expect and encourage innovation and thought leadership. If you are looking for an opportunity to showcase your abilities while growing in your career, then look no further! In this role, you will be challenged to drive the success of Evolus in building a brand like no other.

Let’s talk about some of the key responsibilities of the role:


 * Collaborate with team members to collect business requirements, define successful analytics outcomes, and design data models
 * Design, develop Snowflake data warehouse using dbt or any other ELT tool to extend the Enterprise Dimensional Model
 * Contribute to planning and prioritization discussion
 * Break down and architect the most complex data engineering problems to deliver insights that meets and ideally exceeds business needs
 * Own and deliver solutions - from ingestion of sources to data products for end user consumption, from conceptual iteration to production support
 * Deliver and ensure sustained performance of all data engineering pipelines and remediate where required
 * Own source code management, documentation (technical and end user), and release planning for data engineering products; lean-in to DataOps, DevOps, and CI/CD to deliver reliable, tested, and scalable functionality through automation
 * Identify and proactively manage risks to the data engineering platform
 * Other duties as assigned
   
   

Your Skills and Qualifications:


 * Bachelor’s degree required
 * 6+ years of experience in enterprise data solutions
 * 4+ years in cloud-based data warehousing with strong SQL experience (Snowflake preferred)
 * Experience building data pipelines using python and data orchestration tools like Apache Airflow
 * Data extraction/transformation/orchestration tools such as Fivetran, dbt, Dataform, Airflow, Prefect, Kafka, Stitch and Matillion
 * Deep understanding of data analysis, data modeling for visualization, and reporting
 * Experience in DataOps and git or AzureDevOps and CI/CD pipelines
 * Demonstrated experience with one or more of the following business subject areas: healthcare, marketing, finance, sales, product, customer success or engineering
 * Experience performing root cause analysis for production issues and identify opportunities for improvement
 * Passionate about writing clean, documented, and well-formed code and perform code reviews
 * Keen attention to detail in planning, organization, and execution of tasks, while still seeing the big picture and understanding how all the pieces fit together and affect one another
   
   

A Few Other Items Worth Mentioning:


 * Office Location: Newport Beach (hybrid onsite Tuesday, Wednesday and Thursday)
 * Position reports directly to our Executive Director, Data Engineering
   
   

Compensation & Total Rewards

The expected pay range for this position is $114,000 to $142,000. Your actual base salary will be determined on a case-by-case basis and may vary based on a number of considerations including but not limited to role relevant knowledge and skills, experience, education, certifications, and more.

We offer more than just a paycheck, and your base salary is just the start! Stay happy and healthy with our competitive suite of medical, dental and vision benefits to help you feel your best and be your best. We also provide those benefits you shouldn’t have to worry about, from employer covered life insurance to short-term disability. Take advantage of the 401k match offered by Evolus and let us invest in your future. You may also be eligible for new hire equity and long-term incentives in the form of RSUs, stock options, and/or discretionary bonuses. We offer mental health and wellbeing resources for you to develop skills to find your calm, boost your confidence, and show up as your best self in work and life. Travel or relax and come back feeling refreshed with our flexible paid time off program for exempt employees and a paid time off accrual plan for non-exempt employees. Did we mention the holiday soft closure between the Christmas and New Years holidays? We have that, too. Additional perks include regularly catered team meals at our Evolus Headquarters, a fully stocked kitchen (Kombucha & Coffee included), and the opportunity to join an organization where our values of Grit, Impact, Fun, and Transparency are displayed daily.

Evolus takes pride in being a company on the forefront of innovation, while being committed to conducting its business with the highest degrees of integrity, professionalism, and social responsibility. We are also committed to complying with all laws and regulations that apply to our business. Employee welfare is no different. Here at Evolus, we don’t just work together, we’ve built a culture of inclusion! Because of this, you’ll find yourself immersed in an environment that not only promotes respect, collaboration and team building, but a diverse community too. And that’s just the tip of the iceberg. Join our team and see for yourself! EOE M/F/D/V. For more information, please visit our website at www.evolus.com.

",Full-time
3997339352,445839.0,Junior Software Engineer,"SoftTech Solutions, LLC., a wholly owned subsidiary of Synergy ECP, is a custom software development firm that has specialized in serving Department of Defense customers for more than 15 years. Our highly skilled staff of Software Engineers provide expertise that strengthens and advances our clients projects, ensuring the delivery of solid, successful results. Well-versed in the latest technologies and knowledgeable in a broad spectrum of skills and programming languages, our engineers and computer sciences professionals offer scalable technology solutions for enterprises of all sizes.

Your Main Objective:

Work in a variety of environments to develop analytics based on data from multiple cyber sources, as well as classic SIGINT via data tagging.

Developing analytics to produce metrics based on data tagging efforts.

Develop prototypes, answering new questions, as well as providing better answers to existing questions.

Work directly with the customer in a highly collaborative, integrated fast-paced environment using leading technologies, developing innovative solutions.

Developing analytics using Java in a Linux environment

Research and work with AWS and other platforms for development.

Work in a cohesive, small team environment.

What Sets You Apart:

Bachelor's degree plus 2-years of relevant experience or Master's degree and no experience. An Associate's degree plus 4-years of relevant experience or high school diploma/GED plus 6-years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position

Computer Science (CS) degree or related field

TS/SCI clearance with polygraph

Software development/engineering experience including requirements analysis, installation, integration, evaluation, enhancement, maintenance, testing, and problem diagnosis/resolution.

Experience with Java Pig/MapReduce & Python

Experience with AWS

Experience with distributed scalable Big Data Store (NoSQL) such as H Base, CloudBase/Accumulo, Big Table, etc.

Experience with the Hadoop Distributed File System (HDFS); and technologies such as Hadoop, Hive, Pig, etc.

Experience with Serialization such as JSON and or BSON; developing restful services; and using source code management tools.

Experience with GHOSTMACHINE analytic development.

Experience with analytic development in a Linux environment.

CLEARANCE REQUIRED:

TS/SCI w/ Polygraph

Other Requirements:

U.S. Citizenship

Compensation Spotlight:

For this role, our typical salary range starts at $100,000 and stretches up to $150,000. But here's the deal – we're not about capping your potential. We're committed to snapping up the best and brightest, and we're ready to put our money where our mouth is. So, if you're one of the rare exceptions to the status quo with the education, experience, and that extra something special, we're not afraid to go above and beyond to secure your talent. Because for us, it's not just about a salary. It's about the complete rewards package, the culture, and the opportunity to make a real impact.

Taking Care of the People Who Take Care of The Nation

Compensation: We offer highly competitive compensation that is consistently recognized by our employees as being generous!

Health & Retirement: We offer top-notch group healthcare plans for medical, dental and vision insurance. SoftTech Solutions pays 100% of the monthly premiums up to $2,000/month. Employee coverage begins on the start date of employment. If the monthly premium is less than $1000/month then the employee will be paid the difference as a bonus amount quarterly. Employees who elect not use our healthcare plans are paid a bonus of $3000 per quarter/ $12,000 annually.

SoftTech Solutions, Inc. wants its employees to live comfortably in their retirement. To help achieve that goal, the company will contribute up to 10% of an employee’s earnings into their 401(k) plan. The first 4% of an employee’s contribution will be matched dollar-for-dollar by the company. In addition, SoftTech will contribute 6% of the employee’s earnings regardless of the employee’s contribution amount. All contributions to the plan are immediately vested.

Education: SoftTech Solutions, Inc. offers Professional Development funds of $5,250 for approved tuition, educational expenses and business equipment. Unused balances are paid to the employee as a bonus at the start of the following year.

Work/Life Balance: SoftTech Solutions, Inc. offers the opportunity for employees to select from 3 different compensation packages that include 25, 35 or 45 days of paid time off annually. Employees are allowed to carry over up to fifteen (15) days per year. Employees are also able to utilize leave without pay for any unworked days.

Additional Paid Time Off

SoftTech Solutions, Inc. offers additional paid time for Jury Duty (16 hours), Maternity/Paternity Leave (16 hours), and Bereavement (24 Hours).

Employee Appreciation Days

SoftTech Solutions, Inc. offers two days of paid Employee Appreciation time off annually. Employees are also able to utilize this at any point throughout the year, for the occasion(s) of their choosing. Unused Employee Appreciation Time is paid out to the employee at the end of the year.

SoftTech Solutions, Inc/Synergy ECP is an equal opportunity employer and considers qualified applicants for employment without regard to race, color, creed, religion, national origin, sex, sexual orientation, gender identity and expression, age, disability, veteran status, or any other protected class.",Full-time
4115180158,1309861.0,Data Engineer,"Are you ready to join a passionate community of people who are changing how health care is delivered? A place where you will find a career you love while truly making a difference building healthier communities. If this sounds like you, we would love to have you apply as Data Engineer, with Medical Home Network!




Founded in 2009 by the Comer Family Foundation, Medical Home Network unites health systems and providers around a vision to improve the health of patients and communities in Chicago. Today, as a Public Benefit Corporation (PBC), MHN has expanded its mission and impact to new markets and is a nationally recognized leader in transforming care within the safety net and building healthier communities across the country. Our whole person model of care, powered by proprietary technology, enhances collaboration across primary care and community-based organizations, leading to better outcomes, lower costs, and reduced health disparities.




THE PERKS

 * Fun, challenging, and collaborative work environment with passionate colleagues that care deeply about healthcare delivery.
 * Recognized as One of the Best Places to Work in Healthcare by Modern Healthcare.
 * Competitive benefits programs including Medical, Vision, Dental, HSA, FSA, and 401k.
 * Fitness reimbursement, commuter benefits, and tuition assistance.
 * Great work life benefits- Paid time off, sick time, and 12 paid holidays.
 * Hybrid schedule, 2 days on site 3 days remote. Open to fully remote in AK, AL, CA, FL, IL, IN, MI, MO, NC, NM, NV, NY, OK, TX, WI, or DC.




THE OPPORTUNITY:

Reporting to the Associate Vice President, Health Information Technology the Data Engineer will assist in our data modernization and optimization efforts. The Data Engineer is responsible for delivering data warehouse, business intelligence, and operational data solutions by developing data integration and ETL processes, data quality and master data management solutions, and administration of SQL Server, and Azure SQL.This individual works closely with end users and IT development staff to ensure that new and existing data models and databases are consistent with approved MHN data architecture standards and HIPAA security requirements.




WHAT YOU CAN LOOK FORWARD TO:

 * Develop software/data solutions using SQL and Python.
 * Perform development, modification, and implementation of software and data applications in both our existing stack (SQL Server on Azure VM, Python on Azure Linux VM) and coding for our planned future state (Azure SQL, Azure Linux VM, Master Data Management, etc.)
 * Development initiatives including data analysis, source-target mapping, data profiling, data quality, master data management, and performance tuning
 * Monitor system performance trends and identify opportunities for improvement
 * Document all programming changes and design, system modifications and their associated maintenance to all required applications
 * Design and support production job schedules, including alerting, monitoring, break fixes, and performance tuning




WHAT YOU’LL NEED TO SUCCEED:

 * Bachelor’s degree in Computer Science, or a related discipline or equivalent work experience.
 * Strong knowledge of T-SQL (DML & DDL), Stored Procedures, Indexes, user defined functions, etc.
 * Bachelor degree in computer science or related field or 5+ years equivalent experience
 * Python programming experience
 * Experience building/operating highly available, distributed systems of extraction, ingestion, and processing of large data sets both in near real time and batch processing.
 * Deep understanding of enterprise data hubs and data warehouses with deep experience in both types of environments
 * Working knowledge of Linux and Windows VMs
 * Working knowledge of Git, Bitbucket, or similar source code management software
 * Experience with a workload automation software package such as Active Batch
 * Working knowledge of Azure, Azure SQL and serverless compute environments
 * Experience developing Restful APIs
 * Experience with NoSQL databases such as MongoDB
 * Experience developing data warehouses or data integration in a healthcare environment
 * Experience developing data warehouses and data marts (Kimball, Inmon design models)
 * Support of self-service BI and reporting
 * Experience creating patient or provider web portals
 * Experience with HL7 data feeds
 * Use of JIRA, Confluence and Bitbucket
 * Creation of database solutions and projects in Visual Studio with automated builds




Medical Home Network is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, veteran status, or any other protected characteristic. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",Full-time
4139509984,96692.0,Data Engineer,"Primary Location: Cincinnati, Ohio

V-Soft Consulting is currently hiring for a Data Engineer for our premier client in Cincinnati, Ohio.

What You’ll Do

Job Responsibilities:

 * In this role the candidate will be required to manage the DBT Cloud environment, ensure DBT Core installs work with the latest versions of Python, troubleshoot issues application teams have within their DBT models, optimize other's DBT models, maintain shared DBT packages for performing functions needed across multiple application teams like flattening complicated JSON structures and decrypting encrypted sensitive fields etc.
 * The individual will also need to assist when application teams need to release new DBT models or versions among other DBT related responsibilities.

Interested?

Qualified candidates should send their resumes to hdaram@vsoftconsulting.com




V-Soft Consulting Group is recognized among the top 100 fastest growing staffing companies in North America, V-Soft Consulting Group is headquartered in Louisville, KY with strategic locations in India, Canada and the U.S. V-Soft is known as an agile, innovative technology services company holding several awards and distinctions and has a wide variety of partnerships across diverse technology stacks.

As a valued V-Soft Consultant, you’re eligible for full benefits (Medical, Dental, Vision), a 401(k) plan, competitive compensation and more. V-Soft is partnered with numerous Fortune 500 companies, exceptionally positioned to advance your career growth.

V-Soft Consulting provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

For more information or to view all our open jobs, please visit www.vsoftconsulting.com or call (844) 425-8425.",Contract
4087687943,11130470.0,"Software Engineer, Data Visualization","About The Team

The Data Visualization team at OpenAI is responsible for building and maintaining all the visualization tools used for analyzing various software and hardware aspects of our custom-built hyperscale supercomputers. This includes visualizing hardware (nodes, network, racks, etc.), monitoring how a user’s job is running on the platform, and assessing the health of the underlying systems. These tools allow us to analyze, improve, and operate the platform for running and training the world’s largest AI models. We work at the cutting edge of speed and scale, combining the traditions of High-Performance Computing (HPC) with a modern cloud and containerized environment.

Our team is incubated within OpenAI’s Research team, operating at the forefront of AI innovations. The Platform Visualization team complements the existing platform teams that ensure our researchers are minimally impacted by hardware faults. We maximize available supercomputing capacity for researchers and maintain the reliability, scalability, and user-friendliness of job lifecycle management, with an emphasis on efficient job scheduling, quota management, and job execution workflows.

About The Role

As a Software Engineer on the Platform Visualization team, you will play a critical role in designing, developing, and maintaining the full-stack visualization tools that are essential for analyzing the software and hardware aspects of OpenAI’s hyperscale supercomputers. Your work will involve creating intuitive front-end interfaces and back-end systems for visualizing hardware components, monitoring training job performance on the platform, and ensuring the health of underlying systems.

In this role, you will collaborate closely with other engineering and research teams to gather requirements, understand visualization needs, and deliver full-stack solutions that enhance our ability to analyze, improve, and operate the platform.

Key Responsibilities


 * Develop and maintain full-stack visualization tools for hardware and software analysis.
 * Design intuitive front-end interfaces and robust back-end systems for monitoring the performance and health of supercomputer systems.
 * Collaborate with researchers and engineers to understand their needs and deliver effective full-stack visualization solutions.
 * Ensure high performance, reliability, and scalability of visualization tools across both front-end and back-end systems.
 * Continuously improve existing tools and develop new features to meet evolving requirements.
   
   

Qualifications


 * Strong experience in full-stack software development, with a focus on building scientific or infrastructure visualization tools.
 * Proficiency in both front-end and back-end programming languages such as Python, JavaScript, SQL, or similar.
 * Familiar with front-end technologies like React and back-end technologies like Node.js, and databases like Snowflake.
 * Experience with visualization libraries and frameworks (e.g., Plotly, Grafana).
 * Strong understanding of full-stack architecture, design principles, and best practices.
 * Excellent problem-solving skills and attention to detail.
 * Strong communication skills and the ability to work collaboratively in a team environment.
 * Bonus: Prior experience technically leading a team of 4+ engineers, as this is a 0-1 effort with team growth on the horizon
 * Bonus if familiar with High-Performance Computing (HPC) environments and modern cloud/container technologies (e.g., Kubernetes, Azure).
   
   

This role offers the opportunity to work on some of the largest and most advanced AI infrastructure in the world, directly contributing to the success of OpenAI and the advancement of the field of AI. If you are passionate about cutting-edge technology and eager to tackle complex challenges, we would love to hear from you

About OpenAI

OpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.

We are an equal opportunity employer and do not discriminate on the basis of race, religion, national origin, gender, sexual orientation, age, veteran status, disability or any other legally protected status.

OpenAI Affirmative Action and Equal Employment Opportunity Policy Statement

For US Based Candidates: Pursuant to the San Francisco Fair Chance Ordinance, we will consider qualified applicants with arrest and conviction records.

We are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.

OpenAI Global Applicant Privacy Policy

At OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.",Full-time
4144085315,92956375.0,Data Engineer,"IntelliTech is seeking experienced Data Engineers to join our team. As a Data Engineer, you will play a crucial role in designing, developing, and maintaining our client's data infrastructure and systems. Your expertise in Python, and SQL along with experience working with data integration tools and frameworks like Databricks, Apache Spark, and other ETL tools will be essential in ensuring efficient data processing and analysis.

Responsibilities:


 * Collaborate with cross-functional teams are also important, as the role involves working closely with data scientists, analysts, and software developers
 * Developing, maintain, and optimize data pipelines that connect various systems and databases
 * Design, implement, and troubleshoot data integration solutions to meet the data needs
   
   

Requirements:


 * DoD Secret clearance is required;
 * Minimum of 2 years of demonstrated experience with data integration tools like Databricks, or similar platforms to design and manage data pipelines
 * Strong coding skills in languages such as Python, Java, or SQL to develop and maintain data connection scripts, transformations, and data manipulation
 * Solid understanding of various database systems (relational and NoSQL), data modeling, and query optimization techniques
 * Minimum of 2 years of demonstrated experience with ETL processes, including data extraction from various sources, data cleansing and loading into destination systems
 * Familiarity with working with APIs to connect and exchange data between different systems and applications
 * Proficiency in cloud platforms like AWS, Azure, or Google Cloud for setting up and managing data pipelines in a cloud environment.
 * Knowledge of version control systems like Git to manage and track changes to code and configurations
 * Understanding of data security best practices and experience implementing encryption, authentication, and authorization mechanisms in data connections
 * Ability to diagnose and resolve issues in data pipelines, including identifying bottlenecks, data quality problems, and performance optimization
 * Skill in setting up monitoring and logging systems to track the health and performance of data pipelines and detect anomalies
 * Effective communication and teamwork skills to collaborate with data scientists, analysts, and software engineers in cross-functional projects
 * Strong problem-solving skills to identify root causes of data integration challenges and devise effective solutions
 * Experience with automating data integration processes and managing them through continuous integration and continuous deployment (CI/CD) pipelines
 * Basic project management skills to plan, prioritize and execute data connection projects efficiently
 * Ability to learn and adapt to new technologies, tools, and techniques as the field of data engineering evolves
 * Excellent communication and collaboration skills, with the ability to work effectively with cross-functional teams.
 * Detail-oriented mindset with a commitment to delivering high-quality results
 * Must be in the DC Metro area and available to work onsite (Crystal City, VA and Alexandria, VA) 2-3 days per week or on an as-needed basis
   
   

Nice to Have:


 * Recent DoD or IC-related experience.
   
   

If you are passionate about leveraging your data engineering skills and working with cutting-edge technologies to enable efficient data analysis, we encourage you to apply. Join our team and be a part of our mission to provide streamlined and rapid access to critical information.

Interview Requirements:


 * Video Interview – Yes (may include technical assessment)
   
   

Interview Prep:


 * Candidates should be prepared to clearly articulate their experience creating data-related software applications from scratch (Recent evidence of this should be easily identifiable in their resume).
 * Candidates should be prepared to clearly articulate data problems that their applications have solved in their past.
 * Candidates should be prepared to discuss what technologies they have hands-on experience with and demonstrate in-depth understanding of those technologies during the technical assessment.
 * Candidates should be prepared to clearly articulate their experience working with very large data sets/Big Data, like that of large federal agency.
 * Candidates should be prepared to clearly articulate their proficiency with data and software-related programming languages and explain their thought processes related to problem solving.
 * Candidates should be prepared to discuss their availability to travel to the Washington, D.C, Metro Area.
   
   

Fully Remote Option:


 * Fully remote work schedules are not available at this time
   
   

Clearance Sponsorship:


 * We will only consider candidates that currently possess an active interim Secret security clearance or higher at this time.
 * Must be a U.S. Citizen
   
   

Pay Range and Benefits:

IntelliTech is committed to fair and equitable compensation practices. The pay range(s) for this role is $95,000 – $165,000 and represents a base salary range. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to job-related skills, depth of experience, relevant certifications and training, and specific work location. Based on the factors above, IntelliTech utilizes the full width of the range.

IntelliTech provides comprehensive benefits and perks that meet the needs of our employees, including comprehensive insurance, 401(k) matching, paid time off, professional development opportunities, and flexible work arrangements to support work-life balance.

About IntelliTech:

IntelliTech is a dynamic and forward-thinking small, disadvantaged minority-owned business specializing in Full Stack Engineering, Data Analytics, Cloud Solutions, and DevSecOps services. Our unwavering mission is to empower both government and commercial clients to overcome their most complex technical hurdles. With a dedication to innovation and excellence, we're here to make the impossible possible for our clients.

Equal Opportunity Statement:

At IntelliTech, we are committed to creating a diverse and inclusive workplace. We believe that a variety of perspectives and backgrounds leads to stronger teams and better solutions. IntelliTech is an Equal Opportunity Employer and does not discriminate on the basis of race, religion, gender, age, disability, or veteran status. We encourage all qualified candidates to apply.

Powered by JazzHR

aTSwV632Sv",Full-time
4125061970,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4101198629,521134.0,Data Engineer,"Position Title: Lead Data Engineer

Location: Seattle, WA(Onsite from Day 1)



Requirement:

 * Need Senior Data engineer With Dynamo, DB, Python, and Bigdata, Strong in Advance SQL, AWS, Apache airflow, Redshift.
 * Design a highly scalable ETL process using AWS Glue and Python for catalog screening from AWS Redshift to AWS S3.
 * Work on highly available, large-scale distributed systems (AWS EMR) to process and analyze large data.
 * Experience with at least one massively parallel processing data technology such as Redshift, Spark, or Hadoop-based big data solution.
 * Experience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, EC2, DynamoDB, Data-pipeline, and other big data technologies.
 * Coding proficiency in one modern programming language Python.

",Full-time
4129682269,69639337.0,Data Engineer,"BeaconFire is based in Central NJ, specializing in Software Development, Web Development,

and Business Intelligence; we are looking for candidates with a strong background in Software

Engineering or Computer Science for a Full Stack Web Developer position.




Responsibilities:

• Collaborate with analytics team to find reliable data solutions to meet the business needs.

• Design and implement scalable ETL or ELT processes to support the business demand for data.

• Perform data extraction, manipulation, and production from database tables.

• Build utilities, user-defined functions, and frameworks to better enable data flow patterns.

• Build and incorporate automated unit tests, participate in integration testing efforts.

• Work with teams to resolve operational & performance issues.

• Work with architecture/engineering leads and other teams to ensure quality solutions are implemented, and engineering best practices are defined and adhered to.




Qualifications:

• Passion for data and a deep desire to learn.

• Bachelor’s Degree in Computer Science/Information Technology, Data Analytics/Data Science, or related discipline.

• Intermediate Python. Experience in data processing is a plus. (Numpy, Pandas, etc)

• Strong written and verbal communication skills.

• Ability to work both independently and as part of a team.




Compensation: $65,000.00 to $80,000.00 /year




BeaconFire is an e-verified company. Work visa sponsorship is available.",Full-time
3970356046,3650502.0,Data Engineer,"Figma is growing our team of passionate people on a mission to make design accessible to all. Born on the Web, Figma helps entire product teams brainstorm, design and build better products — from start to finish. Whether it’s consolidating tools, simplifying workflows, or collaborating across teams and time zones, Figma makes the design process faster, more efficient, and fun while keeping everyone on the same page. From great products to long-lasting companies, we believe that nothing great is made alone—come make with us!

We are looking for an experienced Data Engineer to partner with our Data Science and Data Infrastructure teams to own and scale our data pipelines. You’ll also work closely with stakeholders across business teams including sales, marketing, and finance to ensure that the data they need arrives promptly and reliably. You’ll play an integral role in building the metrics and self-serve reporting capabilities to unlock Figma’s next phase of growth.

This is a great role for an individual who is passionate about working with data and data systems, and who loves solving problems. You’ll have a good sense for when it makes sense to build fast, scrappy solutions to unblock a key stakeholder vs. when to push back or bring in an outside service. The ideal candidate will be a great communicator who can help coordinate across multiple internal and external teams and takes pride in building end-to-end projects.

What you'll do at Figma:


 * Own, build, and maintain scalable data pipelines that connect various cloud data sources.
 * Develop a deep understanding of Figma’s core data models and optimize data pipelines for scale.
 * Partner with the Data Science and Data Infrastructure teams to build new foundational data sets that are trusted, well understood, and enable self-service.
 * Work with a wide range of cross-functional stakeholders to derive requirements and architect shared datasets; ability to document, simplify and explain complex problems to different types of audiences.
 * Establish best practices for the development of specialized data sets for analytics and modeling.
   
   

We'd love to hear from you if you have:


 * 4+ years in a relevant field
 * Fluency with both SQL and Python
 * Familiarity with Snowflake, dbt, Dagster, and ETL/reverse ETL tools.
 * Excellent judgment and creative problem solving skills
 * A self-starting mindset along with strong communication and collaboration skills
   
   

While not required, it’s an added plus if you also have:


 * Knowledge in data modeling methodologies to design and build robust data architectures for insightful analytics
 * Experience with business systems such as Salesforce, Customer IO, Stripe, NetSuite is a big plus.
   
   

At Figma, one of our values is Grow as you go. We believe in hiring smart, curious people who are excited to learn and develop their skills. If you’re excited about this role but your past experience doesn’t align perfectly with the points outlined in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles.

Pay Transparency Disclosure

If based in Figma’s San Francisco or New York hub offices, this role has the annual base salary range stated below.

Job level and actual compensation will be decided based on factors including, but not limited to, individual qualifications objectively assessed during the interview process (including skills and prior relevant experience, potential impact, and scope of role), market demands, and specific work location. The listed range is a guideline, and the range for this role may be modified. For roles that are available to be filled remotely, the pay range is localized according to employee work location by a factor of between 80% and 100% of range. Please discuss your specific work location with your recruiter for more information.

Figma offers equity to employees, as well a competitive package of additional benefits, including health, dental & vision, retirement with company contribution, parental leave & reproductive or family planning support, mental health & wellness benefits, generous PTO, company recharge days, a learning & development stipend, a work from home stipend, and cell phone reimbursement. Figma also offers sales incentive pay for most sales roles. Figma’s compensation and benefits are subject to change and may be modified in the future. You may view our Pay Transparency Policy by clicking on the corresponding link.

Annual Base Salary Range (SF/NY Hub):

$164,000—$338,000 USD

At Figma we celebrate and support our differences. We know employing a team rich in diverse thoughts, experiences, and opinions allows our employees, our product and our community to flourish. Figma is an equal opportunity workplace - we are dedicated to equal employment opportunities regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity/expression, veteran status, or any other characteristic protected by law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.

We will work to ensure individuals with disabilities are provided reasonable accommodation to apply for a role, participate in the interview process, perform essential job functions, and receive other benefits and privileges of employment. If you require accommodation, please reach out to accommodations-ext@figma.com. These modifications enable an individual with a disability to have an equal opportunity not only to get a job, but successfully perform their job tasks to the same extent as people without disabilities.

Examples of accommodations include but are not limited to:


 * Holding interviews in an accessible location
 * Enabling closed captioning on video conferencing
 * Ensuring all written communication be compatible with screen readers
 * Changing the mode or format of interviews
   
   

By applying for this job, the candidate acknowledges and agrees that any personal data contained in their application or supporting materials will be processed in accordance with the applicable candidate section of Figma's Privacy Policy.",Full-time
4118880350,1798546.0,Data Engineer,"About Us

Foodsmart is the leading telenutrition and foodcare solution, backed by a robust network of Registered Dietitians. Our platform is designed to foster healthier food choices, drive lasting behavior change, and deliver long-term health outcomes. Through our highly personalized, digital platform, we guide our 2.2 million members—including those in employer-sponsored health plans, regional and national Medicaid managed care organizations, Medicare Advantage plans, and commercial insurers—on a tailored journey to eating well while saving time and money.

Foodsmart seamlessly integrates dietary assessments and nutrition counseling with online food ordering and cost-effective meal planning for the entire family, optimizing ingredients both at home and on the go. We partner with national and regional retailers across the U.S., many of whom accept SNAP/EBT, making healthier food more accessible. Additionally, we assist members with SNAP enrollment and management, providing tangible access to nutritious food.In 2024, Foodsmart secured a $200 million investment from TPG’s Rise Fund, which supports entrepreneurs dedicated to achieving the United Nations’ Sustainable Development Goals. This investment will help us expand our reach, particularly to low-income workers who are disproportionately affected by diet-related diseases.

At Foodsmart, Our Mission Is To Make Nutritious Food Accessible And Affordable For Everyone, Regardless Of Economic Status. We Are Committed To a Set Of Core Values That Shape Our Culture And Work Environment

Measured: We make data-driven, truth-seeking decisions.

Impactful: We are fueled by achieving our mission and vision.

Collaborative: We help each other be better and create a positive environment.

Hungry: We maintain a healthy growth mindset, seeking to overcome challenges with courage.

Joyful: We take joy in each other, our work, and the privilege of doing this work.

Whether you're a dietitian, a commercial leader, or a technologist, working at Foodsmart means being part of a team that is passionate, supportive, and driven by a shared purpose. Join us in transforming the way people access and enjoy healthy food.

About The Role

The Data Engineer is a critical role responsible for constructing and optimizing our data pipeline architecture, collaborating closely with data scientists and analysts to facilitate data-related functionalities. The Data Engineer will be pivotal in designing, building, and maintaining highly scalable data pipelines, optimizing data delivery, and automating data processes. They will work closely with cross-functional teams to ensure efficient data flow and contribute to the success of our data-driven initiatives.

You Will


 * Own the optimization of data delivery for various cross-functional teams.
 * Design, construct, install, test, and maintain highly scalable data pipelines.
 * Collaborate closely with data architects, data scientists, and analysts to fulfill data requirements.
 * Develop automated data processes for cleaning, validation, correction, and data mining.
 * Identify, implement, and enhance internal process improvements, automating manual processes, and enhancing scalability.
   
   

You Are


 * Proactive and act as a driving force for efficient data delivery and infrastructure.
 * Focused on quality and approach every data-related project with enthusiasm.
 * Diligent in ensuring secure and compliant handling of data in accordance with relevant regulations.
 * Collaborative and adept at addressing data-related technical issues and supporting stakeholders' data infrastructure needs.
 * An expert in data warehouse architecture, data modeling, and automated data pipelines.
   
   

You Have


 * A minimum of 3 years of experience in a Data Engineering role.
 * Hands-on experience with data warehouse solutions such as Snowflake or Redshift
 * Experience with cloud platforms such as AWS, GCP, or Azure
 * Advanced SQL knowledge and proficiency in working with relational databases.
 * Familiarity with data pipeline and workflow management tools like Apache Airflow or Luigi.
 * Strong analytical skills and the ability to thrive in a fast-paced environment.
 * Familiarity with healthcare data standards like FHIR and HL7 is advantageous but not mandatory.
 * Bachelor’s degree in Computer Science, Engineering, Mathematics, or related field; Master’s degree is a plus.
   
   

$139,000 - $156,000 a year

Role: Data Engineer

Level: IC3-IC4

Location: Remote

Base Salary Range: $139,000/yr to $156,000/yr + equity + benefits

Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries at our headquarters in San Francisco, California. Individual pay is determined by work location, job-related skills, experience, and relevant education or training.

About Our Benefits And Perks

Remote-First Company

Unlimited PTO

Healthcare Coverage (Medical, Dental, Vision)

401k, bonus, & stock options

Gym reimbursement

Foodsmart is an equal opportunity employer and values diversity. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any other protected class.",Full-time
4150910058,18084.0,Backend Data Engineer,"In order to be considered for this role, after clicking ""Apply Now"" above and being redirected, you must fully complete the application process on the follow-up screen.

General Description

The Backend Data Engineer will be responsible for designing, developing, and maintaining data infrastructure, APIs, and integrations that support analytics, automation, and self-service capabilities across the organization. This role requires expertise in Python, SQL, Snowflake, and AWS (EC2, S3), along with experience in modern data tools such as DBT, Airbyte, and Census.

The ideal candidate will work closely with the Business Intelligence & Innovation team, ensuring seamless data access, efficient processing, and integration with various operational tools. The focus of this role is on server-side engineering, database optimization, and data pipeline automation.

RESPONSIBILITIES Include But Are Not Limited To

Data Engineering & Infrastructure


 * Design and maintain ETL pipelines using Python, DBT, Airbyte, and other modern data tools.
 * Optimize, query, and manage the Snowflake data warehouse to support BI reporting and applications.
 * Manage and interact with MySQL databases to support data-driven applications.
 * Work on data APIs and integrations to ensure seamless data accessibility across platforms.
   
   

Backend Development & API Integration


 * Develop and maintain backend services and APIs in Node.js/Express.js to facilitate data access.
 * Implement and optimize backend workflows, batch processes, and cron jobs using Python.
   
   

Cloud Services & Infrastructure Management


 * Deploy, manage, and optimize applications on AWS (EC2, S3, RDS).
 * Ensure cloud-based solutions are scalable, efficient, and cost-effective.
   
   

Collaboration & Documentation


 * Work closely with the Business Intelligence & Innovation team to support data needs for applications.
 * Document processes, workflows, and best practices for database management and backend development.
   
   

Demonstrates Our “One Team” Philosophy


 * Passion, Accountability, Customer Focus, and Teamwork.
   
   

Minimum Qualifications


 * Software Proficiency Requirements
 * 3+ years of experience in Python for data processing and ETL workflows.
 * Strong SQL skills, with experience working in Snowflake and MySQL.
 * Experience with modern data tools (DBT, Census, Airbyte) for pipeline automation.
 * 3+ years of experience developing backend APIs using Node.js/Express.js.
 * Proficiency in managing AWS services (EC2, S3, RDS).
 * Experience working with structured and semi-structured data formats (JSON, CSV, XML).
 * Familiarity with CI/CD pipelines, version control (Git), and API documentation best practices.
 * Skills and Functionalities
 * Strong grasp of Python, SQL and JavaScript concepts
 * Experience with REST APIs
 * Experience with database design and management best practices
 * Experience working with a variety of data sources via API
 * Server-side experience in NodeJS (Express and/or Next.js)
 * Comfortable balancing immediate and long-term development priorities.
 * Ability to accurately estimate and communicate project requirements
   
   

Physical & Mental Requirements


 * While performing the duties of the job, the employee is regularly required to stand, sit, walk, use handle or feel, reach, stoop, kneel, crouch or crawl, talk and hear.
 * The vision requirement includes close vision and ability to adjust focus.
 * Nature of position requires mobility and the ability to lift a minimum of 20 pounds.
 * Must have ability to adjust to changing work hours and locations as needed.
   
   

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, age, disability, gender identity, marital or veteran status, or any other protected class.",Full-time
3875373938,46623.0,Data Engineer,"Description

Your role at GEI.

GEI Consultants has an opening in our Operational Development Team for a qualified Data Engineer to support a variety of systems and data engineering tasks focused on data flow activities. The majority of our systems are based in MS SQL Server, Tableau Server, Azure, and FastField Forms. This person will primarily work closely with members of the Operational Development Team and with members of our IT staff. The ideal candidate will be focused, detail-oriented, and driven to attain and maintain very high standards for efficiency and accuracy in data acquisition and integration into our systems. The ideal candidate will have more than 3 years of data engineering experience in the AEC industry or in similar science and/or engineering environments. GEI seeks a committed, self-motivated, organized and detail-oriented individual who anticipates issues and thrives on creative, independent problem solving within a rapid, deadline-driven environment.

Essential Responsibilities & Duties


 * ETL of data from a wide variety of sources
 * Database and Data Warehouse design/expansion/backup & recovery
 * Index management and optimization
 * Support data sources for Tableau Server, Power BI, and ArcGIS
 * Stored procedure development and maintenance
 * Identify new opportunities within GEI where existing business approaches to data can be replaced with a more efficient/automated data flow and presentation of data for analysis
 * Develop and optimize ETL/SSIS packages to facilitate data transfer between FTP, remote data loggers, Azure, and on-premises databases
 * Troubleshoot SSIS package permission issues related to execute-as/data source read/write access
 * SQL Agent Job development and monitoring
 * Develop data reporting and visualizations as specified by clients using Tableau, SSRS, etc
 * Perform DML and DDL via tsql/stored procedures executed directly within SSMS and remotely via SSIS
 * Develop test plans, implementation plans, and project timelines for various data engineering projects
 * Define, prioritize, communicate, and foster shared understanding of project objectives and scope
 * Coordinate the development of standard operating procedures (SOPs), technical training programs, and QA/QC procedures for staff and work product
 * Team with all staff necessary to complete assignments
 * Collaborate with technical team members to ensure the solution design satisfies project objectives and business requirements
 * Other duties as assigned
   
   

Minimum Qualifications


 * 3+ years of experience in a position performing similar data engineering tasks
 * Proven record of ability to design, manage, and support MS SQL Server and Azure databases
 * Ability to work with the following programming/mark-up/scripting languages preferred: VB.net, python, XML, javascript, and R
 * Bachelor's Degree, from an accredited college or university
 * MS SQL Server/Azure certification preferred
 * Ability to develop project plans and meet deadlines
 * Self-starter with attention to detail and stakeholder needs
 * Able to critically analyze and solve problems of a complex nature
 * Excellent Communication skills
 * Able to work on multiple projects of moderate complexity simultaneously and independently
 * Proficient in organization and time management skills
 * Familiarity with engineering, environmental science, and/or chemistry subject matter preferred.
 * Able to work effectively in GEI’s partnership model, including a team environment, building rapport and relationships.
   
   

We are GEI.

Some of the world’s most pressing problems - from climate change to sustainable development, to critical infrastructure and the future of our energy supply - need our brightest and diverse minds working together to create safer, more resilient communities for tomorrow.

We are technical experts, collaborators, and entrepreneurs who draw from diverse backgrounds to solve our clients’ most complex challenges.

With nearly 60 offices across North America, we offer a range of engineering, science, and technical consulting services. Our range of expertise, project types, and culture make us the choice for top talent in the AEC industry.

Employee-owned. Employee-focused.

As a 100% employee-owned company, our employees support our flat leadership structure, have a say in how our business operates and benefit from our financial success. We are committed to employee growth with career development opportunities, competitive total rewards, a well-being program, flexible work arrangements and more. Our company culture is driven by our 4 Cs - we are Client-Centered, Curious, Collaborative, and Community Minded - which support our focus on sustainability, safety, diversity, equity and inclusion. Get to know us better by visiting GEI’s career site here.

GEI’s Total Rewards Package


 * Market-Competitive Compensation, including Eligibility for an Annual Performance Bonus
 * Pay Range For This Position: $33.65-72.11/hour
 * Comprehensive Benefits Program, including Medical, Dental, Vision, Life, Disability and More
 * Well-Being Program and Paid Parental Leave
 * Commuter Benefits
 * Hybrid Work Schedules and Cell Phone Stipends
 * GEI University (GEIU) with Continuing Education Assistance and Tuition Reimbursement
 * Connecting Conversation Program with a Focus on Professional Development and Opportunities for Advancement
 * Support and Financial Rewards for Publication Awards, Professional Dues, and Professional Licenses
 * Paid Holidays and Generous Paid Time Off Program
 * Rewards and Recognition
 * GEI-Funded Profit Sharing and 401(k)
 * Opportunity to be an Owner and Shareholder (Learn more here)
 * A Vibrant Culture that is Focused on Partnership, Sustainability, Giving Back to Our Communities and Diversity, Equity and Inclusion
 * And More…
   
   

Physical Job Requirements

Sedentary

X

Light

Medium

Other

Activity Level Throughout Workday

Physical Activity Requirements

Occasional

(0-35% of day)

Frequent

(33-66% of day)

Continuous

(67-100% of day)

Not Applicable

Sitting

X

Standing

X

Walking

X

Climbing

X

Lifting (floor to waist level) (in pounds)

X

Lifting (waist level and above) (in pounds)

X

Carrying objects

X

Push/pull

X

Twisting

X

Bending

X

Reaching forward

X

Reaching overhead

X

Squat/kneel/crawl

X

Wrist position deviation

X

Pinching/fine motor skills

X

Keyboard use/repetitive motion

X

Taste or smell (taste=never)

X

Talk or hear

X

Accurate 20/40

Very Accurate 20/20

Not Applicable

Near Vision

X

Far Vision

X

Yes

No

Not Applicable

Color Vision (ability to identify and distinguish colors)

X

Sensory Requirements

Minimal

Moderate

Accurate

Not Applicable

Depth perception

X

Hearing

X

Environmental Requirements

Occupational Exposure Risk Potential

Reasonably Anticipated

Not Anticipated

Blood borne pathogens

X

Chemical

X

Airborne communicable diseases

X

Extreme temperatures

X

Radiation

X

Uneven surfaces or elevations

X

Extreme noise levels

X

Dust/particular matter

X

Other (exposure Risks)

Usual workday hours:

X

8

10

12

Other work hours

GEI is an AA/equal opportunity employer, including disabled and veterans.",Full-time
4124666132,11213376.0,Data Engineer,"ORBIS is seeking an innovative Data Engineer with a TS/SCI and polygraph clearance. They will be responsible for interfacing with upstream and downstream data providers and consumers and will advise (and potentially help implement) on architectures to make the data useful and accessible. The Consultant will support a variety of efforts not restricted to a singular geographic region or language (existing natural language processes operate on 8 languages from across the globe, and more will likely be required). On this project, you’ll have the opportunity to demonstrate your intellectual agility by aiding development of key performance insights and identifying dataflows and techniques to measure their success and will work closely with stakeholders to ensure that data science processes are aligned with mission objectives. This project features the opportunity to interact with a wide range of key stakeholders, including those at senior levels, and has the potential for travel. There are multiple locations to work out of including Chantilly, VA, McLean, VA, and Bethesda, MD. This is an exciting opportunity for an intellectually curious, energetic data scientist looking for more ""hands-on"" experience to work on a project with real impact helping our client develop ways to understand and improve performance of activities that support delivery of the mission.

Duties/Responsibilities


 * Assist with stakeholder education on quantitative capabilities, helping them to understand strengths and weaknesses of different approaches and what problems are suitable and unsuitable for data science.
 * Identify what data is already available and determine what mission-oriented questions we can answer using that data.
 * Extract insights from bulk semi-structured data using data analysis techniques.
 * Consult with internal and external stakeholders on the development, prioritization and implementation of process improvement and impact evaluations tasks.
 * Develop and implement practical strategies for measuring performance of models and processes, to include development of performance measures, design of actionable methods for collecting and analyzing performance metrics, and implementation of capture and analysis strategies with refinement as needed.
 * Analyze both quantitative and qualitative information to provide customers with comprehensive insights into organizational strengths and opportunities for growth.
 * Prepare engaging presentations of analysis through data visualization and analytic narratives.
 * Brief senior-level customers on research plans, activities, findings and recommendations.
   
   

Supervisory Responsibilities

This position has no supervisory responsibilities.

Education and Experience


 * A Bachelor’s degree is required for this position
 * Minimum of 5 years' experience in a consulting role in the IC
 * Master’s degree in business, social science, or behavioral science preferred but not required for this position
   
   

Required Skills/Abilities


 * U.S. Citizenship
 * Active TS/SCI clearance with Polygraph
 * ETL
    * Ability to perform extract, transform, load (ETL) development for data pipelines
    * Ability to integrate and update lab-to-factory services into data pipeline
    * Ability to integrate and update workflow orchestration

 * Parsing
    * Ability to perform API Service Development

 * General
    * Working knowledge of ELK Stack (elastic search, logstash, and kibana) - ingestion, management, and access control
    * Python
    * Bash Scripting - ad-hoc processing, cron jobs, etc.
    * Experience working on cloud environments

Physical Requirements


 * Prolonged periods of sitting at a desk and working on a computer.
 * Routine video conference and/or in-person meetings.
 * Ability to attend planned meetings within the Washington Metro Area region.
   
   

We are an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender identity, sexual orientation, national origin, disability, or protected veteran status.",Full-time
4024748271,62869757.0,Data Engineer,"We are actively hiring for Data Engineer

Location: Jersey City, NJ OR Columbus OH

Skills: Python, Pyspark, AWS


 * Design and develop backend APIs using Pyspark, Python based API frameworks, which requires strong proficiency with Python and data manipulation libraries like Pandas, Numpy, Matplotlib, plotly.
 * Strong experience in AWS
 * Develop clean, scalable, maintainable, and testable application code, while also being familiar with CI/CD Pipelines.
 * Implement robust database connections and transform data between the application and the database , which requires proficiency with NoSQL and SQL databases.
 * Responsible for collaborating with teams across shores to understand the functional requirements and translate them into work products , with an underlying need for demonstration of team oriented personality with excellent interpersonal and communication skills",Contract
4125869370,19256.0,Data Engineer,"Data Engineer / Analyst (""Data Generalist"" with a focus on tech)

Direct Hire W2 (No H1, No C2C, No EAD)

Hybrid (2 days WFH) - City of Industry, CA




Primary Responsibilities

 * Build, test, and deploy ETL and ELT patterns in an efficient, organized manner.
 * Serve as the in-house specialist for data acquisition, transformation, modeling, and lineage.
 * In addition to your expertise in data engineering, support the team by acting as a powerful ""Data Generalist"": as needed, perform advertising performance analysis, website analytics, customer segmentation, survey design and analysis, ROI modeling, lifetime value analysis, cross channel analysis, and media mix analysis.




Qualifications

 * Experience in a data-focused or technical application support role
 * Demonstrated expertise in SQL (any variant).
 * Demonstrated expertise in one or more of the following: Python, JavaScript, PHP, .NET.
 * Experience building, optimizing, and maintaining data pipelines.
 * Experience creating queries, visualizations, and reports using common dashboarding and BI tools is a plus (Looker, Sigma, Tableau, Mode, Metabase).
 * Expert level experience in Excel: Pivot Tables, vlookups, etc.

",Full-time
4084319724,66321745.0,Junior Data Engineer,"2024 is almost over and we hope the Job market improves . Almost 600,000 tech employees have been laid off since 2022 and it's still ongoing. The effect of this has led hundreds of thousands of laid off Tech employees competing with existing Jobseekers.

Entry level Job seekers struggle to get responses to their applications, are getting ghosted after interviews. In such a scenario the Job seekers need to differentiate themselves by ensuring to obtain exceptional skills and technologies so that they can wear multiple roles at a client as clients now would want to expand roles and responsibilities assigned to a particular job to save costs.

Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.

All Positions are open for all visas and US citizens

We are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this challenging economy every client wants to save $$$ 's and they want the best value for their money. Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs as Clients now post covid can also hire remote workers which increases even more competition for jobseekers

.We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few

.We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients

.Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry

.We assist in filing for STEM extension and also for H1b and Green card filing to Candidate

sPlease Check The Below Link

shttps://www.synergisticit.com/candidate-outcomes

/https://synergisticit.wistia.com/medias/o5gmv7i9e

uhttps://www.youtube.com/playlist?list=PLJgkOBQ51j5AHT5I6n29glr0q6trzkxY

Dhttps://synergisticit.wistia.com/medias/k6t6a1n4k

bWhy do Tech Companies not Hire recent Computer Science Graduates | SynergisticI

TTechnical Skills or Experience? | Which one is important to get a Job? | SynergisticI

TFor preparing for interviews please visit https://www.synergisticit.com/interview-questions

/We are looking for the right matching candidates for our client

sPlease apply via the job postin

gREQUIRED SKILLS For Java /Full Stack/Software Programme


 * r Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, I
 * T Highly motivated, self-learner, and technically inquisitiv
 * e Experience in programming language Java and understanding of the software development life cycl
 * e Project work on the skill
 * s Knowledge of Core Java , javascript , C++ or software programmin
 * g Spring boot, Microservices, Docker, Jenkins and REST API's experienc
 * e Excellent written and verbal communication skill
   
   

sFor data Science/Machine learning Position

sRequired Skill


 * s Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, I
 * T Project work on the technologies neede
 * d Highly motivated, self-learner, and technically inquisitiv
 * e Experience in programming language Java and understanding of the software development life cycl
 * e Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tool
 * s Excellent written and verbal communication skill
   
   

sPreferred skills: NLP, Text mining, Tableau, PowerBI, SAS, Tensorflo

wIf you get emails from our skill enhancement team please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements

.No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Contract
4137192238,33318412.0,Data Engineer,"Who We Are

Through a partnership-based approach, Coterie helps insurance professionals unlock untapped revenue in the small commercial space. With an innovative quoting platform that delivers accurate pricing and bindable quotes in less than one minute, Coterie makes small business insurance effortless.

We are on a mission to build and foster a world-class team to bring speed, simplicity, and service to commercial insurance. We value integrity, humility, passion, and intelligence. If you want to push yourself, promote social good, and reshape a $200B+ market, we’re excited to talk to you!

What will the Data Engineer do?

Data is the foundation of what we do. It’s what made insurance one of the first industries to make computers a standard in doing business. But it’s time to help our industry make a leap, and to do that we need data from all kinds of sources in all sorts of data types to feed into our host of applications and risk engines. It’s this kind of data that will allow us to create newer and more equitable risk metrics to eventually take insurance away from its antiquated proxies for risk and into something more accurate, and more human.

As a part of the growing data engineering team at Coterie, you will be responsible for helping build the critical ETL pipelines, data stores, and delivery mechanisms that will power our contemporary cloud-first environment. This work will allow us to provide better risk, power dynamic data visualizations for our partners and clients, and fuel the next generation of insurance coverage. As a result of our data-hungry approach, you’ll be faced with scraping, integrating, munging, cleaning, and helping organize information from a litany of traditional and non-traditional sources. It’s this variability that will be key, rather than purely thinking in terms of Big Data centered scale. This is about being nimble and everywhere.

What We Are Looking For


 * 2+ years' experience building and/or maintaining robust and modular ETL/ELT processes (working with parameters, smart dynamic content)
 * Experience working with version control (i.e., GitHub)
 * Experience working in a cloud-based data environment (Azure preferred)
 * Experience coding in a notebook-style environment
 * Strong documentation skills
 * Experience working with relational databases and data warehouses
 * Strong skills in SQL and Python
 * Understand data consumer personas, i.e., data scientists, data analysts, business stakeholders
 * Strong communication skills
   
   

What Will Set You Apart


 * Experience with insurance data (e.g., policy administration, claims, etc.)
   
   

What To Expect

Our hiring process generally consists of 4 phases. The goal is to provide an opportunity for us to learn more about our candidates while allowing them to get to know us as well!


 * Phase 1: Qualified candidates will first meet with a member of our People Operations team for a phone interview. This discussion is a high-level conversation to understand more about your background and interests and for us to share more about Coterie and the position.
 * Phase 2: Selected candidates will be invited to participate in our PDP survey and meet with our Hiring Manager for a 2nd interview via Teams video. This interview is designed to be more detail oriented and allows you to learn more about the role and expected to be 30 minutes in length.
 * Phase 3: Top candidates will be invited to participate in an experiential exercise. This exercise designed to assess technical fit and will include 1-hour project deep dive interview where you can discuss your project in detail and showcase your approach with the hiring manager.
 * Phase 4: Final candidates will receive an invite to our final interview series. This series will include 1:1 interview with additional team members. The final series is roughly 1-1.5 hours in total.
   
   

What's In It For You

Coterie has excellent benefits for all full-time employees. We offer the following:


 * 100% remote
 * Health insurance through Aetna (we pay 100% of premiums)
 * Dental and vision insurance through Guardian (we pay 100% of premiums)
 * Basic life insurance (we pay 100% of premiums)
 * Access to flexible spending account (FSA) or health savings account (HSA) (for those using HSA eligible plans)
 * 401K plan (up 4% match with immediate vest)
 * Flexible PTO and 12 company-paid holidays each year
 * Continuing education annual stipend
 * Annual salary estimated between 90,000-120,000 based on national data. Candidates who meet all the minimum requirements and possess additional relevant experience, as outlined in the job description, may be considered for a salary above the midpoint of the above range. Salary is based on internal equity; internal salary ranges; market data/ranges; applicant’s skills; prior relevant experience; degrees or certifications, etc.
   
   

Work Authorization

At this time, Coterie Insurance is unable to consider candidates who require current or future visa sponsorship. Applicants must have authorization to work in the United States without the need for sponsorship now or in the future. Falsification of an application, including work authorization status, is immediate grounds for dismissal from consideration.",Full-time
4144923231,25204.0,Data Engineer,"If you are considering a career with one of the largest diversified suppliers in the foodservice industry. Golden State Foods sets the Gold Standard by focusing on it’s Creed and Values, putting customers first and continually innovating. GSF associates are also deeply committed to the communities where they live and work, as much as an 80% participate in the GSF Foundation, where 100% of the associate proceeds go to helping children and families in need.




The Business Intelligence Data Engineer will be responsible for the scripts and processes required to extract, transform, clean and move data and metadata so they can be loaded into a data warehouse, data mart or operational data store. Reads, analyzes and digests what the company wants to accomplish with its data, and designs the best possible ETL process around those goals. Capable of managing remote workers. Must have hands on client experience. This is a hybrid remote position for Southern California - requires 3 days in office each week.

ESSENTIAL FUNCTIONS

(% of time may vary depending on assignments/projects)




1. Business Requirements - 75%

 * Collect and document business requirements using: interviews, document analysis, requirements workshops, surveys, site visits, business process descriptions, user stories, use cases, scenarios, business-process and workflow analysis.
 * Critically evaluate information gathered from multiple sources and reconcile conflicts.
 * Proactively communicate and collaborate with external and internal customers to understand processes, analyze information needs and define functional requirements.
 * Serve as the conduit between the business unit and the BI development team.
 * Successfully engage in multiple initiatives simultaneously and able to meet project deliverable deadlines.
 * Work independently with users to define concepts.
 * Review and edit requirements, specifications, business processes and recommendations related to proposed solution.
 * Lead and perform complex analysis in an evolving data environment.
 * Extract and analyze data, patterns, and related trends as needed, with the subsequent ability to synthesize the data into information consumable by organization.
 * Provide data extraction, reports, dashboards, analysis and consultation services across organization.
 * Design and roll out Business Intelligence solutions to end users.
 * Ensure high levels of Business Intelligence availability through support functions and in-depth testing.
 * Participate in strategic design, implementation, and maintenance of Business Intelligence software and systems, including integration with databases and data warehouses.

Business Intelligence Data Engineer Analyst Tasks

 * Provide application analysis and data modeling design to collect data for centralized data warehouse.
 * Extract data from databases and data warehouses for reporting and to facilitate sharing between multiple data systems.
 * Proficient in the use of query and reporting analysis tools.
 * Standardize data collection by developing methods for database design and validation reports.
 * Work with business requirements to identify and understand source data systems; provide resolutions to all data issues and coordinate with data analyst to validate all requirements, perform interviews with all users and developers.
 * Map source system data to data warehouse tables
 * Develop and perform tests and validate all data flows and prepare all ETL processes according to business requirements and incorporate all business requirements into all design specifications.
 * Define and capture metadata and rules associated with ETL processes
 * Adapt ETL processes to accommodate changes in source systems and new business user requirements
 * Collaborate with all developers and business users to gather required data and execute all ETL programs and scripts on systems and implement all data warehouse activities and prepare reports for same.
 * Provide support and maintenance on ETL processes and documentation
 * Build partnerships across the application, business, and infrastructure teams
 * Strive to continuously improve the software delivery processes and practices
 * Champion company standards and best practices




2. Additional Responsibilities - 25%

 * Accountable for properly following all IT standards, processes and methodologies as applicable including but not limited to Quality Assurance (QA),
 * Other responsibilities and accountabilities may be assigned based on business and organization needs.
 * Sets priorities for other team members on a particular initiative or project.
 * Manages user expectations regarding appropriate milestones and deadlines.
 * Will assist in orientation, training, work assignment and checking of less experienced developers and analysts.
 * Serves as technical consultation to leaders in the IT organization and functional user groups.
 * Provides documentation and status updates on behalf of a larger IT group or work stream.
 * Collaborates with customers and stakeholders as well as other members of IT.
 * Provide continuous improvement and implementation of ideas
 * Accountable for properly following all IT standards, processes and methodologies as applicable including but not limited to Quality Assurance (QA),
 * Other responsibilities and accountabilities may be assigned based on business and organization needs.

MINIMUM QUALIFICATIONS




Education/Certification

 * Four year college or commensurate work experience. Advanced degree in Science and Technology related field preferred
 * 5+ years - Knowledge of AWS Infrastructure including S3, Redshift and RDS. Must have hands on client experience.
 * Expertise in MS Excel.
 * Expertise in SQL and relational databases
 * Strong communication (verbal and written) and interpersonal skills to translate key insights from complex analyses into actionable business insights
 * Proven ability of looking at solutions in unconventional ways- seeing opportunities to innovate and leading the way
 * Strong proficiency in SQL
 * Creative in finding new solutions and designing innovative methods, systems and processes
 * Experience with building multi-dimensional data models to serve as a foundation for future analyses
 * Experience with predictive modeling
 * Experience with IoT, Machine Learning, and AI- Strong analytic skills for working with unstructured datasets
 * Experience with connecting data sets to data visualization tools and creating reports using Tableau and Power BI
 * Strong project management and organizational skills, experience working on complex initiatives with cross-functional teams in a dynamic environment
 * Experience with Dell Boomi
 * Experience with data visualization tools like Tableau and Microsoft Power BI

Preferred Qualifications

 * Expert in ETL and/or other data manipulation languages such as Python, SAS and R
 * Experienced knowledge of AWS Infrastructure including S3, Redshift and RDS
 * Industry experience as a Data Engineer or related specialty (e.g. Software Engineer, Business Intelligence Engineer, and Data Scientist) with extensive professional experience and a proven track record in a role focused on understanding, manipulating, processing and extracting value from large disconnected datasets.
 * 3+ years of analysis experience
 * Desire to create and build new predictive/optimization tools for structuring datasets




At GSF, we believe that investing in our associates strengthens our culture and fuels our growth. We care about your well-being,and will support you with the following:

 * Paid time off subject to eligibility, including paid leave (in compliance with state and local regulations), vacation, sick, holiday, jury duty, and bereavement.•Comprehensive benefits package to support our associates and their families, subject to elections and eligibility: Medical, Dental, Vision, 401(k), Disability, Health and Dependent Care Reimbursement Accounts, Employee Assistance Program (EAP), Voluntary Insurance (Accident, Critical Illness, Hospital Indemnity, Legal, Life, and AD&D), Retirement Plan.
 * Associate Development via Education Reimbursement and/or Scholarships, virtual courses, or classroom development experiences.
 * Flexible work schedules (subject to your location and role).
 * Please note that the compensation details listed in postings reflect the base pay only.
 * Additional compensation including bonuses and car allowances are subject to eligibility.




The expected range for this position is $120,000–$140,000/year (For Salaried, Exempt Roles & Salaried, Non-Exempt Roles)




Location, confirmed job-related skills, education, experience, and relevant training will be considered in setting the actual starting salary.

",Full-time
4144813986,1798047.0,Data Engineer,"Job Title: Data Engineer

Position Type: Contract

Location: Remote (US)

Pay Range: DOE

Company Summary

Digital marketing agency that specializes in providing enterprise-level strategies combined with local market activation for global brands. Established over two decades ago, the agency has developed a proprietary platform that enhances local digital marketing efforts, particularly for franchise systems and multi-location businesses. Their services include optimizing media planning, increasing ROI, and leveraging data-driven strategies to support business growth. The team is known for blending innovative technology with experienced professionals who understand the complexities of multi-unit business models

Project Overview

Building and scaling a team for maintaining and updating an internal legacy system, which is the organization’s primary enterprise local marketing platform. Role will be to support stability and necessary updates for legacy platform.

Primary Responsibilities


 * Maintain data processing pipelines
 * Support analytics systems
 * Optimize data operations
 * Manage partner data integrations
   
   

Technical Requirements


 * Strong SQL and data modeling skills
 * ETL pipeline experience
 * Analytics platform knowledge (GA4)
 * Data integration expertise
 * Performance optimization skills
   
   

Focus Areas


 * 119 data/analytics items
 * Partner data imports
 * Reporting system maintenance
 * Data quality and integrity
   
   

Equal Opportunity Employer

Associate Staffing is an Equal Opportunity Employer and does not discriminate against any employee or applicant for employment based on race, color, religion, sex, national origin, age, disability, veteran status, sexual orientation, gender identity, or any other protected status under applicable law. We are committed to creating a diverse and inclusive work environment and welcome applicants from all backgrounds to apply for open positions with our company.

",Contract
4125070440,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4143584213,18758749.0,Data Engineer,"Job Summary:




A Data Engineer at TempWorks is responsible for delivering data-driven insights to innovate and drive business success. The Data Engineer plays a crucial role in designing, developing, and maintaining our data architecture to support our growing data needs. The Data Engineer collaborates closely with cross-functional teams including data scientists, analysts, and software engineers to ensure the reliability, scalability, and performance of our data systems.




General Responsibilities:

 * Designing and implementing scalable and efficient data pipelines to ingest, process, and transform data from various sources.
 * Building and maintaining robust data warehousing solutions to support analytical and reporting requirements.
 * Optimizing database performance and ensuring data quality and integrity.
 * Developing and maintaining ETL processes to enable efficient data movement across systems.
 * Implementing data security and privacy measures to ensure compliance with regulations and company policies.
 * Evaluating and adopting new technologies and tools to enhance our data infrastructure and analytics capabilities.
 * Performing other related duties as assigned.

Required Skills and Abilities:

 * Hands-on experience with SQL database design.
 * A deep understanding of relational databases (e.g., MySQL, PostgreSQL).
 * Experience with Azure data storage solutions such as Azure SQL Database, Azure Cosmos DB, and Azure Data Lake Storage.
 * Knowledge of data integration and analysis tools such as Azure Data Factory, Azure Databricks, Azure Synapse, and Power BI.
 * Understanding of data modeling and schema design principles.
 * Ability to work with large datasets and perform data analysis.
 * Strong experience in common data warehouse modelling principles.
 * Knowledge of Dev-Ops processes (including CI/CD).
 * Experience in developing NO SQL solutions is desirable.

Education and Experience:

 * Bachelor's degree or higher in Computer Science, Engineering preferred.
 * 5+ years of SQL experience (No-SQL experience is a plus).
 * 5+ years of experience with schema design and dimensional data modeling.
 * Experience designing, building, and maintaining data processing systems.

Physical Requirements:

 * Prolonged periods sitting and/or standing at desk and working on a computer.
 * Must be able to lift to 10 pounds at times.







TempWorks Software offers a comprehensive benefits package and provides eligible employees with an opportunity to enroll in various benefit programs, subject to applicable waiting periods. This includes the following:

 * Paid Time Off
 * Holiday Pay
 * Volunteer Time Off
 * Medical Insurance
 * Health Savings Account with Employer Contribution
 * Dental Insurance
 * Vision Insurance
 * 401(k) with Employer Match
 * Life Insurance and AD&D
 * Short-Term and Long-Term Disability Insurance
 * Paid and Unpaid Leave of Absences

",Full-time
4139519498,520950.0,Data Engineer,"As a 100% Employee-Owned company, Robert E. Mason & Associates, Inc. believes our Associates are the foundation of both our customers’ and our success. Our strong company culture, and belief in continued investment in our Associates, has helped us realize long Associate tenures, as well as long lasting relationships with our customers. Under the Robert E. Mason & Associates, Inc. umbrella there are two divisions: R.E. Mason and Apperture Solutions.

R.E. Mason is an Emerson Impact Partner covering North Carolina, South Carolina, and Virginia. Emerson is the global leader of process systems and solutions. R.E. Mason provides industry-leading process equipment and service for process control, automation, safety, and reliability. The industries served include Chemical, Pharmaceutical & Life Sciences, Power & Utilities, Food & Beverage, and Pulp & Paper.

Apperture Solutions is a technology independent, professional consulting, and implementation services firm. Apperture Solutions offers Data Enablement, Production Optimization, Operations Management, and Other Value-Added Services. Apperture Solutions partners with other providers to offer our customers the technologies and solutions that fit their needs.

What Apperture Offers Associates

Apperture is a 100% employee-owned company that offers a comprehensive, industry leading benefits package to all eligible Associates:


 * Participation in the Employee Stock Ownership Program (ESOP)
 * Retirement plan, including a Safe Harbor contribution
 * Medical / Dental / Vision Insurance
 * Employer paid Life Insurance and Long-Term Disability Insurance
 * Generous paid leave options that include vacation time, sick leave, personal leave time, R.E. Mason Way Half Day, paid Jury Duty, and paid Bereavement Leave
 * Paid Parental Leave
 * Paid company holidays
 * Career Development Program
 * Retirement and Financial Wellness program
 * Employee Assistance Program (EAP)
 * Alternative/Hybrid Work Schedules
   
   

General Description

The Data Engineer will play a crucial role in leveraging data analytics platforms to transform raw data into actionable insights. This position requires a strong background in data engineering, experience with Seeq Analytics, and a passion for solving complex data problems.

Specific Responsibilities


 * Develop, implement, and maintain data pipelines and ETL processes to ensure efficient data flow and transformation.
 * Utilize Seeq Analytics to analyze time-series data, generate insights, and support decision-making processes.
 * Experience in a data visualization tool such as PowerBI or related.
 * Collaborate with data scientists, analysts, and other stakeholders to understand data requirements and deliver solutions.
 * Optimize and tune data systems for performance and reliability.
 * Ensure data quality and integrity across various data sources.
 * Create and maintain documentation related to data engineering processes and workflows.
 * Assist in the deployment and management of machine learning models and advanced analytics solutions.
 * Troubleshoot and resolve data-related issues in a timely manner.
 * Support internal customers by developing innovative solutions to meet their data needs.
 * Enhance and support the CI/CD automation needs of the business.
 * Previous experience as an active SCRUM team member.
   
   

Required Competencies


 * Bachelor's degree in Computer Science, Information Technology, Engineering, or a related field.
 * 3-5 years of experience in data engineering or a similar role.
 * Proficiency in Seeq Analytics, including experience with its core functionalities and features.
 * Strong SQL skills and experience with relational databases (e.g., MySQL, PostgreSQL).
 * Experience with big data technologies (e.g., Hadoop, Spark) and cloud platforms (e.g., AWS, Azure, GCP).
 * Proficient in at least one programming language (e.g., Python, Java, Scala).
 * Familiarity with data visualization tools (e.g., Tableau, Power BI) is a plus.
 * Strong problem-solving skills and the ability to work independently and in a team environment.
 * Excellent communication skills, both written and verbal.
 * Highly communicative, detail-oriented, and career-minded with the ability to multitask.
 * Customer service-oriented with a positive attitude, always willing to tackle any task and go the extra mile.
 * Excellent communication skills
 * Resourcefulness and troubleshooting aptitude
 * Attention to detail
 * Ability to follow detailed instructions
 * Verbal and written communication Skills
 * Time Management Skills
 * Teamwork
   
   

Required Education And Experience


 * BSc/BA in Computer Science, Engineering or a related field.
   
   

Preferred Experience/Competencies


 * Experience with industrial data sources and IoT data such as SCADA/DCS, PLC, or process control.
 * Knowledge of data warehousing concepts and technologies (e.g., Redshift, Snowflake).
 * Understanding of machine learning concepts and experience with model deployment.
 * Certifications in relevant technologies and platforms.
   
   

Apperture is a federal contractor and, as such, is required to solicit the race, gender, disability status and protected veteran status of candidates. Thus, you are required to answer self-identification questions as part of your application process. These questions are part of Apperture’s Affirmative Action Plan and the completion of these questions will not have any effect on any consideration of your application materials.

In compliance with the ADA Amendments Act (ADAAA), if you have a disability and need to request an accommodation in order to apply for a position with Apperture, please call our office at (704) 375-4465.",Other
4139503782,83745.0,Data Engineer (5640),"As Data Engineer, you’ll clean, optimize, and manage data from a wide variety of network data sources. The ideal candidate will have experience with ETL processes, Python programming, Elasticsearch, and data visualization tools. This role involves designing and maintaining data pipelines, ensuring data quality, and creating optimized datasets for analysis and visualization. Familiarity with Army networking is a significant advantage.


We know that you can’t have great technology services without amazing people. At MetroStar, we are obsessed with our people and have led a two-decade legacy of building the best and brightest teams. Because we know our future relies on our deep understanding and relentless focus on our people, we live by our mission: A passion for our people. Value for our customers.


If you think you can see yourself delivering our mission and pursuing our goals with us, then check out the job description below!


What you’ll do:


   
   
 * Build and maintain ETL workflows to extract and transform data from various network data sources.
   
   
 * Clean and optimize large datasets to ensure they are ready for analysis and visualization.
   
   
 * Manage and query Elasticsearch indexes to support data retrieval and reporting needs.
   
   
 * Collaborate with data analysts and stakeholders to design and deliver interactive dashboards.
   
   
 * Monitor and troubleshoot data pipelines to ensure reliability and accuracy.
   
   
 * Develop Python scripts and automation tools to streamline data processing tasks.
   
   
 * Document workflows, pipelines, and data models to support operational continuity and scalability.
   
   
 * Research and recommend tools or techniques to improve data engineering practices and outcomes.
   
   


What you’ll need to succeed:


   
   
 * An active DoD Secret clearance
   
   
 * Bachelor’s degree in Data Engineering, Computer Science, Information Systems, or a related field.
   
   
 * 3-5 years of experience in data engineering or a related field, with a focus on managing and optimizing data pipelines.
   
   
 * Proficiency in Python for data processing and automation.
   
   
 * Strong knowledge of ETL processes and tools for data integration and transformation.
   
   
 * Experience with Elasticsearch for indexing, querying, and analyzing data.
   
   
 * Familiarity with data visualization tools such as Tableau, Power BI, or Kibana.
   
   
 * Knowledge of data modeling, schema design, and performance optimization techniques.
   
   
 * Strong problem-solving skills with a focus on data quality and efficiency.
   
   
 * Excellent communication skills and the ability to work collaboratively in cross-functional teams.
   
   

Like we said, we are big fans of our people. That’s why we offer a generous benefits package, professional growth, and valuable time to recharge. Learn more about our company culture code and benefits. Plus, check out our accolades.


Commitment to Non-DiscriminationAll qualified applicants will receive consideration for employment based on merit and without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, status as a protected veteran, or any other status protected by applicable federal, state, local, or international law.


 What we want you to know:


In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire.


 Not ready to apply now? 


Sign up to join our newsletter here.",Full-time
4139684028,3076.0,Data Engineer,"Responsibilities

Kforce has a client that is seeking a Data Engineer in Minneapolis, MN. Overview: Engineers in Product Platforms work collaboratively on small, autonomous teams reporting to a Development Manager. We create products or enable data consumption for end users as well as frameworks and tools used by developers across the organization. Teams and engineers are empowered to create solutions and find the right tools for the job. We use a variety of modern technologies to solve complex problems across a wide range of business domains for users all over the world. In this Development community there are quarterly hackathons (during business hours) that all engineers are encouraged to participate in as a way of exploring new technologies and solutions outside of their assigned product and daily backlog. Additionally, there are innovation days on the last Friday of every month that all engineers are encouraged to participate in to improve their technical skills or collaborate on solutions outside of their daily backlog. Team and project specific details: We are looking for a candidate who has an interest in back end development, DevOps, ETL, and cloud engineering. We are specifically looking for a candidate who has experience with GCP and/or AWS. We would like the candidate to have experience with ETL using the service catalogue offerings of either AWS or GCP. Team Digital Triplet manages the data lake, modeling, and a number of cloud accounts associated with various LIMS instances. Digital Triplet will be creating a pipeline between AWS and a (new to Bayer) data warehouse in Google Big Query, configuring multiple accounts, and investigating new technologies that we could utilize to more efficiently manage the lake, ETL, and reporting capabilities for our users and for our full stack development teams. We are looking for a candidate that wants to continuously improve by introducing new ideas, tools, and solutions to this space.

Requirements

7+ years of professional experience working with:


 * NodeJS, Python, Java, SQL
 * Databases (Oracle, MSSQL, Postgres, etc.)
 * AWS
 * S3
 * EC2
 * Lambda
 * SQS
 * Codebuild
 * PostgreSQL
 * Mongo Atlas
 * DynamoDB
 * CloudFormation
 * Docker
 * Fargate
 * GCP
 * GBQ
 * Cloud Data Fusion
   
   

The pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.

We offer comprehensive benefits including medical/dental/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.

Note: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.

This job is not eligible for bonuses, incentives or commissions.

Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.

By clicking “Apply Today” you agree to receive calls, AI-generated calls, text messages or emails from Kforce and its affiliates, and service providers. Note that if you choose to communicate with Kforce via text messaging the frequency may vary, and message and data rates may apply. Carriers are not liable for delayed or undelivered messages. You will always have the right to cease communicating via text by using key words such as STOP.",Contract
4125061356,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4103529909,10813033.0,Data Engineer II,"About The Role

Data Engineers at Hinge Health are software engineers with expertise in data pipelines, OLTP & data warehouse schema design, data governance, ETL, RDBMS and NoSQL systems. Data Engineers are hands-on, building self-service tools and automation that enable application engineers and data analysts to manage, maintain, and secure their data systems with autonomy while adhering to best practices in a HIPAA environment. The ideal candidate thrives in a highly collaborative, cross functional environment.

Our stack: DBT, Python, SQL, Airflow, PostgreSQL, MySQL, REST, Aptible, Docker, Tonic.ai, Terraform, Spark, Kafka, Fivetran, Databricks, AWS (S3, Lambda, Kinesis, RDS, Glue). Our workflow is trunk-based CI/CD, and our security/compliance posture is at the highest standards of healthcare, including HIPAA, HITRUST, SOC 2, CCPA.

What You'll Accomplish


 * Create compliance strategies (HIPAA, GDPR, CCPA), tooling, processes, and coaching that enables service and application teams to take full ownership of their data in a growing organization
 * Architect and build data pipelines and data aggregation systems to deliver quality real-time and batch analytical reports
 * Participate in hiring and mentoring of team members
 * Assist and coach teams to optimize poorly performing data pipelines
 * Work with the SRE team to establish best practices around database monitoring, alerting, and availability
   
   

Hinge Health Hybrid Model

We believe that remote work and in-person work have their own advantages and disadvantages, and we want to be able to leverage the best of both worlds. Employees in hybrid roles are required to be in the office 3 days/week. The San Francisco office has a dog-friendly workplace program.

Basic Qualifications


 * 2+ years of experience working with broad spectrum of data stores like PostgreSQL, MySQL, MongoDB, Redis, Snowflake and Redshift
 * 1+ years of experience in processing and storing large scale data using distributed systems as well as a mastery of database designs and data warehousing
 * 1+ years of experience building data pipelines using Spark, Kafka, Airflow
 * At least two years of software engineering experience and/or 2+ in data engineering
   
   

Preferred Qualifications


 * Bachelor’s Degree in Computer Science or related technical degree
 * Mastery of SQL and Python
   
   

Compensation

This position will have an annual salary, plus equity and benefits. Please note the annual salary range is a guideline, and individual total compensation will vary based on factors such as qualifications, skill level, competencies, and work location. The annual salary range for this position is $133,800-200,600.

About Hinge Health

Hinge Health is moving people beyond pain by transforming the way it is treated and prevented. Connecting people digitally and in-person with expert clinical care, we combine advanced technology, AI and a care team of experts to guide people through personalized care directly from their phone. Our approach is proven to reduce pain by 68%, prevent 42% of new opioid prescriptions, and avoid more than half of joint replacement surgeries. Available to 18M people, Hinge Health is trusted by leading health plans and employers, including Land O’Lakes, L.L. Bean, Salesforce, Self-Insured Schools of California, Southern Company, City of Boston, US Foods, and Verizon. Learn more at http://www.hingehealth.com

What You'll Love About Us


 * Inclusive healthcare and benefits: On top of comprehensive medical, dental, and vision coverage, we offer employees and their family members help with gender-affirming care, tools for family and fertility planning, and travel reimbursements if healthcare isn’t available where you live.
 * Planning for the future: Start saving for the future with our traditional or Roth 401k retirement plan options which include a 2% company match.
 * Modern life stipends: Manage your own learning and development
   
   

Diversity and Inclusion

We’re committed to building diverse teams that reflect the communities we serve. Visit hingehealth.com/diversity-equity-and-inclusion to learn more about what moves us.

Hinge Health is an equal opportunity employer and prohibits discrimination and harassment of any kind. We make employment decisions without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, age, veteran status, disability status, pregnancy, or any other basis protected by federal, state or local law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.

We provide reasonable accommodations for candidates with disabilities. If you feel you need assistance or an accommodation due to a disability, let us know by reaching out to your recruiter.

Workday ID

JR1234",Full-time
4150341019,628480.0,Data Engineer II,"At PDI Technologies, we empower some of the world's leading convenience retail and petroleum brands with cutting-edge technology solutions that drive growth and operational efficiency.



By “Connecting Convenience” across the globe, we empower businesses to increase productivity, make more informed decisions, and engage faster with customers through loyalty programs, shopper insights, and unmatched real-time market intelligence via mobile applications, such as GasBuddy.  We’re a global team committed to excellence, collaboration, and driving real impact. Explore our opportunities and become part of a company that values diversity, integrity, and growth.



Role Overview



PDI is seeking a talented and motivated Full Time Data Engineer II to join our elite agile data services team responsible for developing and maintaining our industry-leading cloud-based big data and data analytics infrastructure serving major global fortune 500 companies.



The ideal candidate will have hands-on experience in coding data pipelines, administering databases, and working with business users to understand and meet their data requirements. This role involves maintaining high performance and security of our data systems, performing quality assurance, and supporting the company’s data infrastructure, primarily using AWS, Snowflake and DBT.






Key Responsibilities
 * Develop and optimize data pipelines and ETL processes
 * Implement data integration solutions
 * Collaborate with data analysts and data scientists to support their data needs
 * Maintain and enhance data systems to ensure high performance and reliability
 * Perform data validation and quality assurance
 * Document data workflows and processes
 * Participate in agile teams to provide technical expertise and feedback
 * Adhere to project development and deployment processes
 * Ensure compliance with industry standards and best practices
 * Maintain data security and integrity
 * Provide on-call support as needed
 * Estimate effort and resources for new data projects
 * Work with stakeholders to understand data requirements and deliver solutions
 * Monitor and optimize data storage and processing capabilities
 * Troubleshoot and resolve data issues
   




Qualifications
 * Proficient in SQL and relational databases
 * Strong programming skills in Python or another language
 * Experience with data warehousing solutions like Snowflake
 * Proficiency in DBT (Data Build Tool)
 * Cloud experience, such as AWS, GCP or Azure
 * Good understanding of ETL processes and data integration
 * Strong analytical and problem-solving abilities
   




Preferred Qualifications
 * Certifications such as Snowflake SnowPro Core Certification, dbt Certification, AWS Certified Data Analytics are a plus
 * Bachelor’s degree in Computer Science, Information Technology, or a related field
   







PDI is committed to offering a well-rounded benefits program, designed to support and care for you, and your family throughout your life and career.  This includes a competitive salary, market-competitive benefits, and a quarterly perks program. We encourage a good work-life balance with ample time off [time away] and, where appropriate, hybrid working arrangements.  Employees have access to continuous learning, professional certifications, and leadership development opportunities. Our global culture fosters diversity, inclusion, and values authenticity, trust, curiosity, and diversity of thought, ensuring a supportive environment for all.",Full-time
4125067663,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4125065628,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4101229017,99282368.0,data engineer,"Role: Data Engineer

client: IRS

Location: Remote

Long Term

Task Description

We need a data engineer to work in a team environment for data discovery and curation.

Will be working with a legacy system hosted in a mainframe environment, but is an opportunity for modern techniques to create better value.

Experience with IBM DB2 Query Management Facility (QMF) and tools is pretty much a must.


 * Knowledge of database design and theories – 10+ years
 * Understanding of data science methodologies -- 5+
 * Best practices for data set curation for machine learning and model training -- 5+
 * Expert SQL skills and understanding of query tuning best practices -- 5+
 * Familiarity with agile methodologies and cloud-based platforms -- 5+
 * Knowledge of regulatory requirements relevant to data management
 * Proficiency in business intelligence tools and data visualization techniques. Pentaho experience is also required.
   
   

If you are interested or have any references please share resume at mukul@brightmindsol.com.",Contract
4150508142,5303930.0,Analytics Data Engineer,"About Us




Climb (NMLS# 1240013) is an innovative student payment platform that makes career-focused education more accessible and affordable. Driven by a mission to empower individuals to unlock their potential – no matter their credit profile – Climb identifies programs and schools that offer skill-based training programs, then provides learners with payment options that are structured to meet the unique needs of those seeking career training. Recognizing the dynamic and diverse nature of a rapidly-changing economy, Climb partners with schools that teach everything from cybersecurity to healthcare training, heavy machine operation to data science, and culinary arts to AI & Machine Learning. While status quo education pathways are struggling to meet the real-world needs of students and prospective employers, Climb and its partner schools are committed to an inspiring practicality that helps bridge the gap between people looking for career training and companies looking to build a skilled workforce. Through unconscious bias training, a series of values-based interview questions, and a focus on diversity-first job boards, we are committed to cultivating a team that recruits, retains, and celebrates a variety of backgrounds, perspectives, and skills. 




Overview of Role




We are looking for a skilled and motivated data engineering professional to expand the capabilities of our high-performing Data team. The ideal candidate will have extensive experience building scalable data pipelines, managing modern data platforms, and collaborating across business functions to deliver data-driven solutions. Previous experience in fintech (loan products, credit risk, or credit cards) would be a considerable bonus. Remote-friendly, but locality to NYC is a plus.




Responsibilities




This is a US-based remote position 

As part of the Data team, your responsibilities will include:




Data Engineering (70%):
 * Develop and maintain optimal data pipeline architecture using SQL and Python.
 * Design and implement scalable data models using dbt (Data Build Tool - dbtlabs.com).
 * Build infrastructure for the extraction, transformation, and loading (ETL) of data from various sources.
 * Configure and manage data ingestion tools such as Stitch.
 * Create analytics tools to provide actionable insights into customer acquisition, operational efficiency, portfolio performance, funding waterfalls, and other key metrics.
 * Troubleshoot and resolve technical issues within the data platform.




Technical Design and Architecture (10%):
 * Collaborate with teams to design robust and efficient data solutions that balance performance, security, and scalability.
 * Provide guidance on architectural decisions and evaluate technical implementations to ensure alignment with organizational strategies and best practices.
 * Stay updated on emerging technologies and recommend improvements to the data stack.




Collaboration and Communication (10%):
 * Work closely with stakeholders across Executive, Product, Data, and Design teams to understand and address their data needs.
 * Maintain clear and open communication to ensure alignment on data-related initiatives.
 * Support and mentor team members in data engineering best practices.




Project Management Support (5%):
 * Participate in sprint planning sessions, team meetings, and the overall data development lifecycle.
 * Assist in evaluating project scopes, estimating timelines, and ensuring deliverables meet deadlines and budgets.
 * Maintain accurate documentation of processes and projects.




Continuous Improvement (5%):
 * Identify and implement process improvements to optimize data delivery and infrastructure scalability.
 * Recommend automation opportunities and stay informed on industry trends, including advancements in cloud and AI tools.
 * Foster a culture of learning and knowledge sharing within the team.




Background and Skills

You may be an excellent fit for this position if you have:




Technical Expertise:
 * 5-7 years of experience in Data Lake or Data Warehouse environments as a data engineer or analytics engineer.
 * Proficiency in SQL-based data manipulation and transformation.
 * Experience with dbt (Data Build Tool - dbtlabs.com) and Python for scalable pipeline development.
 * Familiarity with cloud platforms such as Snowflake, Synapse Analytics, Google BigQuery, or AWS Redshift.
 * Knowledge of distributed source control using Git and comfort working in Agile environments.
 * Experience with BI tools like Power BI, Tableau, or Looker.
 * Experience and passion for simplifying data and operations processes through automation.
 * Exposure to Databricks is a plus.




Collaboration and Problem-Solving:
 * Strong analytical and troubleshooting skills to resolve complex data issues.
 * Proven ability to work collaboratively with cross-functional teams and stakeholders.
 * Commitment to creating inclusive environments where diverse identities and experiences thrive.

﻿

Nice to Have:
 * Experience in the fintech industry or related fields such as loan products or credit risk.
 * A passion for Climb’s mission to expand access to quality education.
 * Capacity to take on larger responsibilities as the company grows.







Join us in shaping the future of data-driven innovation at Climb! Apply today to be part of a dynamic and forward-thinking team.",Full-time
4145097610,56432.0,Data Engineer (Databricks preferred),"Onsite contract in Edison NJ area (4x per week)

Long term contract: 3 year commitment

Rate: 90-100/Hour USD

Previous experience working in Finance, ideally Capital Markets, required.




We’re looking for an experienced Data Engineer to join our client's team and drive the development of cutting-edge data solutions. If you have a passion for optimizing big data pipelines, working with cloud platforms, and delivering high-impact insights, this role is for you!




What You’ll Do:

 * Design and build scalable data pipelines for seamless ingestion, transformation, and integration across diverse sources.
 * Develop and optimize Spark applications in Databricks to process and analyze large datasets efficiently.
 * Implement Delta Lake, data modeling, and cloud-based warehousing solutions.
 * Write clean, efficient code in Python, SQL, and PySpark to support data processing needs.
 * Work with structured, semi-structured, and unstructured data in event-driven and streaming environments.
 * Ensure high performance and scalability of Databricks workloads, while troubleshooting and optimizing jobs.
 * Enforce best practices in data governance, security, and compliance across cloud-based platforms.
 * Conduct code reviews to ensure optimal execution and adherence to industry standards.




Must-Have Skills:

 * Expertise in Snowflake & Databricks
 * Advanced SQL & Python development
 * Hands-on experience with ADF & PySpark
 * Strong Data Warehouse architecture & modeling knowledge

Preferred Experience:

 * 8+ years of Python and SQL coding experience
 * ETL development using Databricks and PySpark
 * Familiarity with cloud data warehouses (Synapse, BigQuery, Redshift, Snowflake)
 * OLTP & OLAP, Dimensional Data Modeling expertise
 * Experience leading cloud data migrations and architecting scalable solutions
 * Cloud certifications are a plus!

",Contract
3937770264,309694.0,Staff Data Engineer,"Airbnb was born in 2007 when two Hosts welcomed three guests to their San Francisco home, and has since grown to over 4 million Hosts who have welcomed more than 1 billion guest arrivals in almost every country across the globe. Every day, Hosts offer unique stays and experiences that make it possible for guests to connect with communities in a more authentic way.

The Community You Will Join

At Airbnb, we need to ensure every area of the business has trustworthy data to fuel insight and innovation. Understanding the business need, securing the right data sources, designing usable data models, and building robust & dependable data pipelines are essential skills to meet this goal.

We Are Currently Hiring For The Following Teams

Communication and Connectivity: This team builds systems and tools for stays, experiences, and beyond that support first class rich communications and connections among all members of the Airbnb community. We create scalable and intelligent communication tools, including messaging and notifications. The data team utilizes industry-leading tools, builds scalable data systems and applies AI models to provide insights and support all products in CnC.

Users, Listings, and Marketplace Data and AI: This team is a group of passionate machine learning, data, and analytics engineers responsible for creating new data products for our Guests and Hosts, Sales, and Finance. You’ll be part of the overall Guest and Host organization that is responsible for the Airbnb web and native apps used by hundreds of millions of our guests and Hosts.

BizTech: This team is responsible for building scalable, high quality data sets and solutions for Finance, Airbnb’s Investor community, E-team and the rest of the Airbnb Data Community. You will have an opportunity to interact with cross functional stakeholders to collaborate and build solutions. You will join a world class data engineering team with a design first attitude, focus on building quality, scalable and testable code with rigor on data engineering practices. We are looking for strong engineers whom we can teach business context within a short amount of time.

The Difference You Will Make

Communication and Connectivity: You will partner with a cross-functional team, including product managers, frontend/backend engineers, data scientists, and machine learning engineers, to influence and build company-wide product releases. You will develop innovative data systems to empower partners in making critical business decisions, enable product engineers to create scalable online systems with optimized user experiences, and collaborate with machine learning engineers to build AI/ML systems. Additionally, you will work with our global sales team to develop business tools that optimize their workflow, making a significant impact on Airbnb's revenue.

Users, Listings, and Marketplaces are core entities to Airbnb and the quality of the data fundamental to Airbnb’s product and business. We have been growing our Data Engineering practice in these areas to improve data foundation and better leverage our data and ML models in our product. You will help us define and realize our vision for trustworthy data across the company and our products, shaping Data Engineering for not just the Users, Listings, and Marketplaces team but also across Airbnb. We need to ensure every area of the business and our products has trustworthy data to fuel insight and innovation. Understanding the business and product need, securing the right data sources, designing usable data models, and building robust & dependable data pipelines are essential skills to meet this goal.

BizTech: You will actively work on the most crucial Tier-1 Company wide metrics such as Gross Booking Value, Revenue which are externally reported, and acts as the pulse of Airbnb’s business. You will relentlessly push the bar on Data Quality higher without compromising Data availability to the extent possible. Few of our datasets have crossed petabyte scale, designing and architecting dataset with performance mindset will be key to success. Team is revamping a new green area called Unit of Economics, this helps Airbnb understand how platform activities affect our margins. These activities include -Customer Support Contact, Processing a Payment, Marketing to name a few. While you build and maintain significant parts of the critical FinTech data ecosystem, you will have an opportunity to contribute to Airbnb’s Data Engineering Paved Path. Your work on complex business problems at scale is valuable to meaningful shape engineering Paved path and tooling for the rest of the data community. We firmly believe in solving problems and contributing back to the Airbnb data community.

A Typical Day


 * Architect and productionize batch and real-time data systems to support various products and business needs.
 * Ensure the quality, performance, and stability of data systems through robust quality systems and monitoring practices.
 * Design and optimize data models for efficient storage and retrieval to meet critical product and business requirements.
 * Collaborate with cross-functional teams, including product managers, engineers, data scientists, and business partners, to align on data requirements and develop scalable systems.
 * Tune, productionize, and optimize data systems and machine learning models to enhance their effectiveness and efficiency.
 * Build and maintain strong relationships with partner engineering teams, including backend, client, data science, and ML teams, to ensure seamless integration and support.
 * Contribute to the development of long-term data strategies and roadmaps, and influence the technical direction of data engineering practices within the organization.
 * Mentor and coach team members, providing guidance and support to enhance their skills and performance.
   
   

Your Expertise


 * 9+ years of relevant industry experience with a Bachelor’s and/or Master’s degree in CS/EE, or equivalent experience, or 6+ years of experience with a PhD
 * Extensive experience designing, building, and operating robust distributed data platforms (e.g., Spark, Kafka, Flink, HBase) and handling data at the petabyte scale.
 * Strong knowledge of Java, Scala, or Python, and expertise with data processing technologies and query authoring (SQL).
 * Proven ability to design, productionize, and optimize batch and real-time data pipelines and systems, ensuring their quality, performance, and stability.
 * Excellent ability to collaborate with cross-functional teams, including product managers, engineers, data scientists, and business partners, to align on requirements and drive data-driven decision-making.
 * Advanced analytical and problem-solving skills with a focus on data quality, governance, and system reliability.
 * Exceptional written and verbal communication skills, capable of influencing stakeholders and conveying complex technical concepts effectively.
 * Expertise in data modeling, warehousing, and working with relational (e.g., PostgreSQL, MySQL) and columnar databases (e.g., Redshift, BigQuery).
 * Experience working with machine learning engineers to integrate ML models into data systems and products (preferred but optional).
 * Ability to provide technical leadership and mentorship, guiding teams on best practices and contributing to the development of data engineering strategies.
 * Flexibility and innovative thinking to evaluate and incorporate new technologies and methodologies to improve data processes and solutions.
   
   

Your Location:

This position is US - Remote Eligible. The role may include occasional work at an Airbnb office or attendance at offsites, as agreed to with your manager. While the position is Remote Eligible, you must live in a state where Airbnb, Inc. has a registered entity. Click here for the up-to-date list of excluded states. This list is continuously evolving, so please check back with us if the state you live in is on the exclusion list. If your position is employed by another Airbnb entity, your recruiter will inform you what states you are eligible to work from.

Our Commitment To Inclusion & Belonging

Airbnb is committed to working with the broadest talent pool possible. We believe diverse ideas foster innovation and engagement, and allow us to attract creatively-led people, and to develop the best products, services and solutions. All qualified individuals are encouraged to apply.

We strive to also provide a disability inclusive application and interview process. If you are a candidate with a disability and require reasonable accommodation in order to submit an application, please contact us at: reasonableaccommodations@airbnb.com. Please include your full name, the role you’re applying for and the accommodation necessary to assist you with the recruiting process.

We ask that you only reach out to us if you are a candidate whose disability prevents you from being able to complete our online application.

How We'll Take Care Of You

Our job titles may span more than one career level. The actual base pay is dependent upon many factors, such as: training, transferable skills, work experience, business needs and market demands. The base pay range is subject to change and may be modified in the future. This role may also be eligible for bonus, equity, benefits, and Employee Travel Credits.

Pay Range

$204,000—$259,000 USD",Full-time
4092397608,75530431.0,Data Engineer,"Interwell Health is a kidney care management company that partners with physicians on its mission to reimagine healthcare—with the expertise, scale, compassion, and vision to set the standard for the industry and help patients live their best lives. We are on a mission to help people and we know the work we do changes their lives. If there is a better way, we will create it. So, if our mission speaks to you, join us!

Interwell Health's Data Engineer role is responsible for corporate claims data acquisition, file loading and structure development. The ideal candidate will have a strong background in data engineering and will be responsible for designing and developing database systems, processes, and documentation. This includes collecting data, analyzing data, designing algorithms, drawing flowcharts, and implementing code, and maintaining the EDW databases.

The work you will do:


 * Collaborates effectively with the development groups to deliver projects to the satisfaction of the client in a timely fashion.
 * Maintains current knowledge of the latest and newest technologies in the areas of specific relevancy to the Data Architecture group for utilization as appropriate within the department. Identifies and researches enhancement options and process improvements, making suggestions to senior managers as needed and drive continued improvement and innovation.
 * Assist with schema design, code review, SQL query tuning.
 * Write and deploy SQL code.
 * Guide and mentor junior teammates acting as a resource with respect to the definition of development processes, methodologies and frameworks and other technical aspects of the projects and provides direction and assistance regarding working with users and the process and issues encountered with user interaction.
 * Become skilled with the architecture and technology supporting the Datawarehouse, to design and develop accordingly.
 * Ensure the distribution of knowledge for processes being designed and built within the team to ensure assigned jobs are completed accurately and according to schedule and that all deadlines are met.
 * Ensure the design of sufficient documentation for easy and smooth hand-over of projects.
 * Participate in the formulation and design of methodologies.
 * Trains in developing tools that are available with the Datawarehouse and Lakehouse infrastructure and help with development, where appropriate.
 * Monitor and troubleshoot data pipelines to identify and resolve performance issues, bottlenecks, and data anomalies.
   
   

The skills and qualifications you need:


 * 3-5 years related experience in data engineering with bachelor's degree; or a master's degree with 3 years' experience.
 * Ability to architect simple and complex solutions related to integration with other applications and design.
 * Excellent communication skills, both verbal and written.
 * Strong presentation skills. Ability to present formally to users and customers during gathering requirements, workshops, and feedback sessions.
 * Experience working under tight deadlines while maintaining high product relevance and quality.
 * Azure/SQL focus
 * Strong understanding of data lake and Lakehouse architecture principles, data modeling techniques, and data warehousing concepts.
 * 3-5 years' experience using Azure Data Factory pipelines and Databricks.
 * 5 years' experience working with Azure databases.
 * Extensive experience with MS SQL stack. (SSIS and ADF)
 * Extensive experience with Azure - Cloud migration.
 * Python experience.
   
   

Our mission is to reinvent healthcare to help patients live their best lives, and we proudly live our mission-driven values:


 * We care deeply about the people we serve.
 * We are better when we work together.
 * Humility is a source of our strength.
 * We bring joy to our work.
 * We deliver on our promises.
   
   

We are committed to diversity, equity, and inclusion throughout our recruiting practices. Everyone is welcome and included. We value our differences and learn from each other. Our team members come in all shapes, colors, and sizes. No matter how you identify your lifestyle, creed, or fandom, we value everyone's unique journey.

Oh, and one more thing … a recent study shows that men apply for a job or promotion when they meet only 60% of the qualifications, but women and other marginalized groups apply only if they meet 100% of them. So, if you think you'd be a great fit, but don't necessarily meet every single requirement on one of our job openings, please still apply. We'd love to consider your application!

Come join us and help our patients live their best lives. Learn more at www.interwellhealth.com.

It has come to our attention that some individuals or organizations are reaching out to job seekers and posing as potential employers presenting enticing employment offers. We want to emphasize that these offers are not associated with our company and may be fraudulent in nature. Please note that our organization will not extend a job offer without prior communication with our recruiting team, hiring managers and a formal interview process.",Full-time
4125057968,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4151573046,167750.0,Associate Data Engineer,"Location: Denver, Colorado - hybrid

Associate Data Engineer

As an Associate Data Engineer at Techstars you will be part of a high performing team building innovative software solutions for entrepreneurs worldwide. In this role, you will build backend streaming data pipelines, integrations with third party SaaS applications, complex analytics features and app facing platform data APIs. You will take part in architecture and solution design and help optimize solution performance and reliability. As a result, you will help Techstars serve founders, entrepreneurs, and startup communities better than ever before.

Responsibilities And Duties


 * Work with engineers to implement and maintain data models and pipelines
 * Build and deploy high quality data analytics, integrations, and API solutions
 * Ensure that all data solutions are secure, performant, reliable, observable, and testable
 * Contribute in a team environment with a collaborative, open-minded attitude
 * Continuously improve the quality of the products and solutions delivered
 * Create and update technical documentation for data systems and processes
 * Monitor pipelines and ETL processes to ensure data accuracy and completeness
 * Troubleshoot and resolve data-related issues in a timely manner
   
   
   

Qualifications And Skills


 * A passion for building data solutions, and an appreciation for dev/ops
 * Experience working with distributed systems and cloud infrastructure
 * Data engineering experience with ETL, streaming, data pipelines, cleansing and mastery
 * Experience with programming and query languages (ie. SQL, Python)
 * Familiarity working with relational database systems (ie. Postgres)
 * Capable of navigating and using command-line interfaces
 * Experience working in an agile development environment
 * Excellent communication and collaboration skills, a desire to learn
 * Ability to improvise, adapt, and work to deliver on commitments and address issues
 * Experience with financial/investment data is a plus
 * Experience developing with containerization technologies (Docker, Kubernetes etc.) preferred
   
   
   

Compensation: $65,000 - $75,000 with 10% bonus

Colorado Residents: In any materials you submit, you may redact or remove age-identifying information such as age, date of birth, or dates of school attendance or graduation. You will not be penalized for redacting or removing this information.

About Techstars

Techstars is the most active pre-seed investor in the world having invested through its accelerators in more than 3,700 companies. Founded in 2006, Techstars believes that entrepreneurs create a better future for everyone and great ideas can come from anywhere. Now we are on a mission to invest in an unprecedented number of startups per year enabling more capital to flow to more entrepreneurs around the world. We do this by operating accelerator programs and venture capital funds, as well as by connecting startups, investors, corporations, and cities to help build thriving startup communities. www.techstars.com

Techstars is an affirmative action, equal opportunity employer and does not discriminate on the basis of race, sex, age, national origin, religion, physical or mental handicaps or disabilities, marital status, Veteran status, sexual orientation, gender identity nor any other basis prohibited by law.

About

Techstars uses E-Verify to check the work authorization of all new hires. For more information about E-Verify, please see the following:

E-Verify Participation Poster (English and Spanish)

Right To Work Poster (English and Spanish)",Full-time
4151636813,10456809.0,Data Engineer,"Company Introduction

OneSource Regulatory Technology hosts a number of innovative solutions to enhance job performance in the Pharmaceutical space. OSR Technology is looking for an experienced and dedicated data engineer to join our product solutions team!

Job Description

OneSource Regulatory is trying to identify a full-time contractor with at least 4+ years of experience to assist us with ongoing R&D projects.

We are looking for a data engineer to pull data from various sources and do all the necessary steps to clean, normalize, possibly annotate, and finally load the data into databases. The candidate should be able to develop and implement a strategy for testing the data integrity of the collected data. This role requires extreme attention to detail to ensure data quality is top priority.

Responsibilities


 * Well versed in parsing and synthesizing of XML and/or JSON documents.
 * Curating of data that can involve some intermediate to advanced web scraping. (data may need to be fetched via SFTP, FTP, Wget, Curl, REST APIs, GraphQL queries from spots on the Internet)
 * Proficiency with Linux command line and various simple tools, such as grep, wc, sed, awk, find, ls, cat, piped commands and possibly some very light Bash shell scripting, setting up crontab schedules and programs
 * Must have basic knowledge of SQL with the following databases: PostGres, MySQL, Google BigQuery
 * Must have basic knowledge of No-SQL database knowledge such as MongoDB or similar
 * Familiarity with basic Cloud technology such as storage buckets, cloud serverless functions
 * Must have experience extracting text and images from PDF files
 * Knowledge of Puppeteer or other automatable web client technologies
 * Understanding JavaScript, HTML/CSS and HTTP methods (for understanding page structure for web scraping)
   
   

Skills


 * Solid experience with Python and Python Libraries such as Pandas, requests, etc
 * Skill set should match up with required responsibilities listed above
 * Strong English skills (e.g. grammatical analysis and rhetorical structure)
 * Team Player
 * Great communication skills
   
   

Bonus Skills


 * Experience within the Pharmaceutical Space
 * Ability to expose data via C# NETCore and/or GraphQL
 * Google Cloud Platform (Cloud Buckets, Google Cloud Functions (.NET, Python, Node.JS))
 * Ability to parallelize data manipulation and scraping via Python multi-threading, etc.
 * Python BeautifulSoup
 * Scrapy
 * Docker (setting up Kubernetes style processing if warranted for data scraping/data ingestion/normalization)
 * Multithreading concepts",Full-time
4130712616,10640787.0,Data Engineer,"Please note our client can only accept US Citizens and Green Card holders for this position

Full time salaried employee with Maven, with option to go full time with our customer

Job Title: Senior Data Engineer with Azure Databricks experience

Job Type: Remote with up to 25% travel




Make a Global Impact

As a Data Engineer, you will be at the forefront of applying AI and ML technologies in healthcare to improve patient lives worldwide. Your contributions will not only advance the field of healthcare technology but also ensure that the benefits of these innovations reach those who need them most. If you are ready to make a significant impact in a company that's reshaping healthcare, we encourage you to apply.




Position Summary

Join Maven as we continue to support an innovative and rapidly growing healthcare technology product company that is revolutionizing the way we approach wellness and patient support. By integrating advanced technological solutions with personalized patient engagement and education, this organization aims to significantly enhance health outcomes and reduce the need for acute care interventions. As a part of our dynamic team, you will be a data engineer supporting Azure AI/ML Ops Engineering focused on building a robust data platform and pipelines that enable advanced analytics. This role offers the unique opportunity to develop AI/ML-based applications that have a meaningful impact on people's lives globally.

Essential Duties

 * Utilize Azure Cognitive Technologies, Azure Machine Learning, and Azure Bot Services to design, create, and deploy AI/ML applications.
 * Seamlessly integrate AI components into data workflows, collaborating with data scientists and engineers.
 * Implement natural language processing (NLP), machine learning models, and algorithms using Azure AI services.
 * Collaborate with DevOps teams to automate the deployment and monitoring of AI models.
 * Leverage AI for process automation, including sentiment analysis, image identification, recommendation systems, and chatbots.
 * Develop and manage machine learning pipelines and workflows for scaling ML models in production.
 * Automate CI/CD pipelines for data, code, and model changes.
 * Monitor and update model performance as necessary.
 * Ensure the security and compliance of machine learning systems.
 * Collaborate with data scientists to enhance model performance and efficiency.

Position Requirements & Competencies

 * Bachelor’s Degree (BA/BS) in Information Systems, Computer Science, or a related field from a four-year college or university, plus 5+ years of development experience, or an equivalent combination of education and experience.
 * Willingness to travel up to 25%.
 * 3-6 years of experience in managing machine learning projects end-to-end, with a focus on MLOps in the last 18 months.
 * Strong programming skills in Python, Java, or other
 * Proficiency in TensorFlow, PyTorch, scikit-learn, or similar machine learning libraries and frameworks.
 * Experience with Docker, Kubernetes, and other containerization technologies.
 * Familiarity with ML model deployment tools like MLflow or Kubeflow.
 * Experienced in the Azure cloud platform and the automation of machine learning model deployment.

Working Conditions

This role is predominantly remote but involves going on client site a few times a year so some travel.",Full-time
4067743298,66321745.0,Junior Data Engineer,"SYNERGISTICIT is aware that the Job Market is Challenging because of Tech Layoffs due to which The Job market is flooded with hundreds and thousands of laid off Jobseekers who are competing with existing Jobseekers. For entry level Job seekers to get client interviews and jobs they need to differentiate themselves by ensuring they have exceptional skills and technologies to be noticed by clients.

Since 2010 we have helped Jobseekers differentiate themselves by providing the clients with candidates who have the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers. All Positions are open for all visas and US citizens We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few. We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers. Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates looking to make their careers in IT Industry We welcome candidates with all visas and citizens to apply. We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

Candidates can benefit from skill enhancement if they fall into the below categories.

Candidates who Lack Experience or are freshers with No actual on Job experience with projects with clients Have had a break in careers Lack Technical Competency or skills being demanded by clients Different visa candidates (Like OPT/H4EAD/L2EAD ) who want to get employed and settle down in the USA please check the below links to see success outcomes of our candidates https://www.synergisticit.com/candidate-outcomes/

If you have relevant skills and industry experience, please apply if not then candidates can opt for Skill enhancement.

https://www.synergisticit.com/candidate-outcomes/

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

REQUIRED SKILLS For Java /Software Programmers


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Project work on the skills
 * Knowledge of Core Java , javascript , C+
 * or software programming
 * Spring boot, Microservices, Docker, Jenkins and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Project work on the technologies needed
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, PowerBI, Time series analysis

Please understand skills and relevant experience on real world projects are required by clients for selection even if its Junior or entry level position the additional skills and Project work with hands on experience building projects at client site are the only way a candidate can be picked by clients. If not having the skills or hands on project work at client site then candidates can opt for skill enhancement to gain the required skills and project work. No third party candidates or c2c candidates

please only apply to the posting

No phone calls please. Shortlisted candidates would be reached out.",Contract
3875375280,46623.0,Data Engineer,"Description

Your role at GEI.

GEI Consultants has an opening in our Operational Development Team for a qualified Data Engineer to support a variety of systems and data engineering tasks focused on data flow activities. The majority of our systems are based in MS SQL Server, Tableau Server, Azure, and FastField Forms. This person will primarily work closely with members of the Operational Development Team and with members of our IT staff. The ideal candidate will be focused, detail-oriented, and driven to attain and maintain very high standards for efficiency and accuracy in data acquisition and integration into our systems. The ideal candidate will have more than 3 years of data engineering experience in the AEC industry or in similar science and/or engineering environments. GEI seeks a committed, self-motivated, organized and detail-oriented individual who anticipates issues and thrives on creative, independent problem solving within a rapid, deadline-driven environment.

Essential Responsibilities & Duties


 * ETL of data from a wide variety of sources
 * Database and Data Warehouse design/expansion/backup & recovery
 * Index management and optimization
 * Support data sources for Tableau Server, Power BI, and ArcGIS
 * Stored procedure development and maintenance
 * Identify new opportunities within GEI where existing business approaches to data can be replaced with a more efficient/automated data flow and presentation of data for analysis
 * Develop and optimize ETL/SSIS packages to facilitate data transfer between FTP, remote data loggers, Azure, and on-premises databases
 * Troubleshoot SSIS package permission issues related to execute-as/data source read/write access
 * SQL Agent Job development and monitoring
 * Develop data reporting and visualizations as specified by clients using Tableau, SSRS, etc
 * Perform DML and DDL via tsql/stored procedures executed directly within SSMS and remotely via SSIS
 * Develop test plans, implementation plans, and project timelines for various data engineering projects
 * Define, prioritize, communicate, and foster shared understanding of project objectives and scope
 * Coordinate the development of standard operating procedures (SOPs), technical training programs, and QA/QC procedures for staff and work product
 * Team with all staff necessary to complete assignments
 * Collaborate with technical team members to ensure the solution design satisfies project objectives and business requirements
 * Other duties as assigned
   
   

Minimum Qualifications


 * 3+ years of experience in a position performing similar data engineering tasks
 * Proven record of ability to design, manage, and support MS SQL Server and Azure databases
 * Ability to work with the following programming/mark-up/scripting languages preferred: VB.net, python, XML, javascript, and R
 * Bachelor's Degree, from an accredited college or university
 * MS SQL Server/Azure certification preferred
 * Ability to develop project plans and meet deadlines
 * Self-starter with attention to detail and stakeholder needs
 * Able to critically analyze and solve problems of a complex nature
 * Excellent Communication skills
 * Able to work on multiple projects of moderate complexity simultaneously and independently
 * Proficient in organization and time management skills
 * Familiarity with engineering, environmental science, and/or chemistry subject matter preferred.
 * Able to work effectively in GEI’s partnership model, including a team environment, building rapport and relationships.
   
   

We are GEI.

Some of the world’s most pressing problems - from climate change to sustainable development, to critical infrastructure and the future of our energy supply - need our brightest and diverse minds working together to create safer, more resilient communities for tomorrow.

We are technical experts, collaborators, and entrepreneurs who draw from diverse backgrounds to solve our clients’ most complex challenges.

With nearly 60 offices across North America, we offer a range of engineering, science, and technical consulting services. Our range of expertise, project types, and culture make us the choice for top talent in the AEC industry.

Employee-owned. Employee-focused.

As a 100% employee-owned company, our employees support our flat leadership structure, have a say in how our business operates and benefit from our financial success. We are committed to employee growth with career development opportunities, competitive total rewards, a well-being program, flexible work arrangements and more. Our company culture is driven by our 4 Cs - we are Client-Centered, Curious, Collaborative, and Community Minded - which support our focus on sustainability, safety, diversity, equity and inclusion. Get to know us better by visiting GEI’s career site here.

GEI’s Total Rewards Package


 * Market-Competitive Compensation, including Eligibility for an Annual Performance Bonus
 * Pay Range For This Position: $33.65-72.11/hour
 * Comprehensive Benefits Program, including Medical, Dental, Vision, Life, Disability and More
 * Well-Being Program and Paid Parental Leave
 * Commuter Benefits
 * Hybrid Work Schedules and Cell Phone Stipends
 * GEI University (GEIU) with Continuing Education Assistance and Tuition Reimbursement
 * Connecting Conversation Program with a Focus on Professional Development and Opportunities for Advancement
 * Support and Financial Rewards for Publication Awards, Professional Dues, and Professional Licenses
 * Paid Holidays and Generous Paid Time Off Program
 * Rewards and Recognition
 * GEI-Funded Profit Sharing and 401(k)
 * Opportunity to be an Owner and Shareholder (Learn more here)
 * A Vibrant Culture that is Focused on Partnership, Sustainability, Giving Back to Our Communities and Diversity, Equity and Inclusion
 * And More…
   
   

Physical Job Requirements

Sedentary

X

Light

Medium

Other

Activity Level Throughout Workday

Physical Activity Requirements

Occasional

(0-35% of day)

Frequent

(33-66% of day)

Continuous

(67-100% of day)

Not Applicable

Sitting

X

Standing

X

Walking

X

Climbing

X

Lifting (floor to waist level) (in pounds)

X

Lifting (waist level and above) (in pounds)

X

Carrying objects

X

Push/pull

X

Twisting

X

Bending

X

Reaching forward

X

Reaching overhead

X

Squat/kneel/crawl

X

Wrist position deviation

X

Pinching/fine motor skills

X

Keyboard use/repetitive motion

X

Taste or smell (taste=never)

X

Talk or hear

X

Accurate 20/40

Very Accurate 20/20

Not Applicable

Near Vision

X

Far Vision

X

Yes

No

Not Applicable

Color Vision (ability to identify and distinguish colors)

X

Sensory Requirements

Minimal

Moderate

Accurate

Not Applicable

Depth perception

X

Hearing

X

Environmental Requirements

Occupational Exposure Risk Potential

Reasonably Anticipated

Not Anticipated

Blood borne pathogens

X

Chemical

X

Airborne communicable diseases

X

Extreme temperatures

X

Radiation

X

Uneven surfaces or elevations

X

Extreme noise levels

X

Dust/particular matter

X

Other (exposure Risks)

Usual workday hours:

X

8

10

12

Other work hours

GEI is an AA/equal opportunity employer, including disabled and veterans.",Full-time
3959436313,90432789.0,Data Engineer,"Work options: Flexible

Options for onsite, hybrid, remote, or flexible work opportunities in the USA.

The Data Engineer will be responsible for designing, building, and maintaining the infrastructure required for data collection, processing, and storage. The ideal candidate should have experience in Java, Python or another programming language, database technologies and the ability to troubleshoot and optimize large datasets.

Responsibilities


 * Design and implement data processing pipelines, data warehouses, and data lakes.
 * Build distributed, scalable, and high-performance data infrastructure.
 * Collaborate with data scientists and analysts to optimize data retrieval and querying.
 * Develop data models and schemas that support data structure optimization and ease of data access.
 * Develop and maintain scripts and automation tools for data processing and analysis.
 * Develop and maintain data quality checks, validation and error-handling routines.
 * Monitor performance and provide solutions to optimize data pipelines, databases, and systems.
 * Collaborate with a cross-functional team to support business needs and generate insights.
 * Stay current with latest data technologies and trends.
   
   

Qualifications


 * Bachelor's or Master’s degree in Computer Science, Software Engineering, or related field.
 * 3+ years of experience in data engineering or a related field.
 * Experience with software development in Java or Python.
 * Experience with database technologies such as SQL and NoSQL.
 * Experience with ETL/ELT tools such as Airflow, NiFi, etc.
 * Excellent problem solving, troubleshooting, and analytical skills.
 * Strong communication and collaboration skills.
 * Familiarity with cloud computing platforms such as AWS, Azure or Google Cloud Platform.
   
   

The Data Engineer opportunity is used to fill high-volume roles or frequently hired positions to be used for future openings. By filling out an application you are joining our LiveMarket, where you have the opportunity to be matched with openings that are the right fit for you. The responsibilities and requirements of each role vary by opportunity. Our team will help guide you on how to best showcase your skills and match you to the right opportunity for you!",Contract
4143747836,28591920.0,Data Engineer,"About Us

At apexanalytix, we’re lifelong innovators! Since the date of our founding nearly four decades ago we’ve been consistently growing, profitable, and delivering the best procure-to-pay solutions to the world. We’re the perfect balance of established company and start-up. You will find a unique home here.

And you’ll recognize the names of our clients. Most of them are on The Global 2000. They trust us to give them the latest in controls, audit and analytics software every day. Industry analysts consistently rank us as a top supplier management solution, and you’ll be helping build that reputation.

Read more about apexanalytix - https://www.apexanalytix.com/about/

Quick Take -

We are seeking a highly technical and experienced Data Engineer to join our team. As a Data Engineer, you will be responsible for designing, developing, and maintaining large-scale data systems, architectures, and pipelines that drive business growth, improve operational efficiency, and inform strategic decisions. The ideal candidate will have a strong background in computer science, mathematics, or a related field, with expertise in data engineering and data analysis. Familiarity with supplier and item-level data sets, including purchase orders, invoices, and sales data, is a desirable asset.

The Work -


 * Develop and maintain data pipelines which will move from one system to another (MS SQL, Snowflake, email archives) to ensure data quality and integrity
 * Write efficient Python scripts to automate data processing, data cleaning, and data visualization tasks
 * Analyze large datasets to identify trends, opportunities, and challenges in retail operations
 * Optimize data processes and SQL queries to overcome challenges with massive datasets (billions of rows)
 * Utilize Large Language models (LLMs) via APIs to build text classifiers, extract information from email conversations, and perform other natural language processing tasks
 * Collaborate with data scientists to develop predictive models and identify opportunities for model improvement
 * Effectively communicate complex data insights and recommendations to non-technical stakeholders
   
   

The Must-Haves -


 * Associate degree (or higher) in Computer Science, Mathematics, Statistics, Physics or a related field
 * 2+ years of experience as a Data Analyst, Data Engineer, or similar role
 * Strong SQL skills, with experience in querying and manipulating large datasets
 * Proficiency in Python, with experience in data analysis and automation
 * Experience in Airflow or similar open-source workflow orchestrator
 * Experience in Airbyte or similar open-source integration tool
 * Knowledge of machine learning algorithms and experience with implementing them in a production environment
 * Ability to work in a fast-paced environment and meet deadlines
 * Strong analytical, problem-solving, and communication skills
   
   

The Nice-to-Haves


 * Experience in Snowflake
 * Experience working with retail data sets like PO, Invoice, and Sales at supplier and item level
 * Experience with containerization using Docker and orchestration using Kubernetes
 * Certification in data analysis or a related field
   
   

Over the years, we’ve discovered that the most effective and successful associates at apexanalytix are people who have a specific combination of values, skills, and behaviors that we call “The apex Way”. Read more about The apex Way - https://www.apexanalytix.com/careers/

Benefits

At apexanalytix we know that our associates are the reason behind our successes. We truly value you as an associate and part of our professional family. Our goal is to offer the very best benefits possible to you and your loved ones. When it comes to benefits, whether for yourself or your family the most important aspect is choice. And we get that. apexanalytix offers competitive benefits for the countries that we serve, in addition to our BeWell@apex initiative that encourages employees’ growth in six key wellness areas: Emotional, Physical, Community, Financial, Social, and Intelligence.

With resources such as a strong Mentor Program, Internal Training Portal, plus Education, Tuition, and Certification Assistance, we provide tools for our associates to grow and develop.

R&D - Archimedes

Greensboro, NC",Full-time
4034340380,99282368.0,ETL Data Engineer,"A Degree is required

Candidate needs to handle role independently, 5 yrs minimum.

This will be a multiple interview to selection at least 3 rounds, and last interview will be on site.

The need to have either 1 year of C# or Java Script is a Must Have

Hybrid environment 2days in office Downtown Houston, 3 days a week from home.

The background with Server work is not an absolute must have but a candidate with 5-10 years of exp should have some.

Most critical skills that are MUST HAVES: SQL, SSIS and Azure Data Factory

Green Card or US Citizens only

If you are interested or have any references please share resume at mukul@brightmindsol.com.",Contract
4137058734,10795459.0,Principal Data Engineer,"Strength in Trust

OneTrust unlocks the full potential of data and AI, securely and responsibly. Our platform enforces the secure handling of company data, empowering organizations to drive innovation responsibly while mitigating risks. With a comprehensive suite of solutions spanning data and AI security, privacy, governance, risk, ethics, and compliance, OneTrust enables seamless collaboration between data teams and risk teams to enable rapid and trusted innovation. Recognized as the market leader in trust, OneTrust boasts over 300 patents and serves more than 14,000 customers globally, ranging from industry giants to small businesses.

The Challenge

As a Principal Data Engineer, you will join our innovative enterprise data team. This team is dedicated to enabling trusted and secure data for our Marketing, Sales, Finance, Product, and Customer Experience teams. Your work will empower these teams to explore data and take actions that set us apart from our competition. You will design and develop robust data pipelines, build dimensional and semantic models, enable and manage our data catalog, and ensure security and compliance across all data and reporting solutions. Join us in supporting the growth of OneTrust through cutting-edge data solutions.

Your Mission

Inspire our Data Engineering and Insights team, drive innovation in data ingestion, transformation and management within our secure Business Technology environments.


 * Driving technical conversations with business stakeholders, data architects. business intelligence, and systems team to support critical reporting and analytics needs.
 * Defining and establishing scalable data models and supporting the tools and methods of populating data into various data lakes. data warehouses, data marts or data repositories.
 * Designing, building, and monitoring data pipelines that meet current business requirements but can scale gracefully for the future.
 * Building scalable semantic models and data solutions that will serve as analytics data products for self-service analytics.
 * Providing operational support and incident/problem management, including logging, instrumentation, analysis, and implementation of process improvements.
 * Coordinating with other IT teams to configure and implement security, monitoring, tooling, and related capabilities.
 * Work effectively using scrum with multiple team members to deliver value effectively
   
   

You Are

This hands-on technical role demands excellent knowledge and can demonstrate best practices in the industry.


 * Bachelor's degree or master's degree in computer science, Engineering or related field
 * 8+ years of experience in Technology, Data Engineering field in architecting, developing end-to-end scalable data applications and data pipelines; work with product manager and scrum master's and assist team with the story creations and sprint deliverables.
 * 8+ years of experience working in enterprise data warehouse solutions and platforms, and working knowledge of different databases (e.g., Snowflake, Databricks, MongoDB) and Storage Solutions
 * 6+ years of experience designing, implementing automated data solutions using Snowflake/Databricks Lakehouse; building workflows, developing, and orchestrating data pipelines using modern technologies
 * 6+ years of experience implementing data solutions by adopting, recommending and improving data security, auditing, change management, automation and CICD processes.
 * 6+ years of experience working with software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes and testing
 * You are a SQL expert. You thoroughly understand aggregate functions, window functions, UDFs, self-joins, partitioning and clustering approaches to run performant queries
 * You are an Engineer. You thoroughly understand object-oriented and procedural programming paradigms (like Python) and manipulation of various data formats for extraction and transformation.
   
   

Extra Awesome


 * Prior experience with full software development lifecycle, continuous integration and continuous deployment, release and change management
 * Prior experience in designing data models with Salesforce, Workday, Marketo, Gainsight and other applications.
 * Prior experience working with Snowflake, Databricks, AWS (S3), MongoDB, and other modern database technologies.
 * Prior experience working with data integration, data ingestion and data orchestration frameworks using Fivetran, Mulesoft, Apache Spark, Apache Kafka and Apache Airflow.
 * Prior experience working with data exploration and data transformation frameworks using DBT, HEX, Coalesce, SQL and Python.
 * AWS or Databricks or Snowflake certification is preferred
 * Problem-Solving Skills: Data Engineers look at an issue that needs to be solved and come up with solutions quickly.
 * Growth Learner: Desire to continue to learn about the future architecture of data technologies.
   
   

For California, Colorado, Connecticut, Nevada, New York, Rhode Island, and Washington-based candidates: the annual base pay range for this role is listed below. Within this range, individual pay is determined by several factors, including location, job-related skills, work experience, and relevant education and/or training. This role may also be eligible for discretionary bonuses, equity, and/or commissions, as well as benefits.

Salary Range

$123,750—$185,625 USD

Where we Work

OneTrust embraces a flexible working model. The underlying “why” for our workplace strategy is that we are intentional about the culture that we want to create together. That includes bringing teams together, in-person, throughout the year to collaborate, build connections, learn from each other, and celebrate our wins to Finish Stronger.

Each role may have specific flexible, hybrid, or in-office requirements, so we encourage you to verify the location of the role with your recruiter during your first interview.

Benefits

As an employee at OneTrust, you will be part of the OneTeam. That means you’ll receive support physically, mentally, and emotionally so that you can do your best work both in and out of the office. This includes comprehensive healthcare coverage, flexible PTO, equity stock options, annual performance bonus opportunities, retirement account support, 14+ weeks of paid parental leave, career development opportunities, company-paid privacy certification exam fees, and much more. Specific benefits differ by country. For more information, talk to your recruiter or visit onetrust.com/careers.

Resources

Check out the following to learn more about OneTrust and its people:


 * OneTrust Careers on YouTube
 * @LifeatOneTrust on Instagram
   
   

Your Data

You have the right to have your personal data updated or removed. You also have the right to have a copy of the information OneTrust holds about you. Further details about these rights are available on the website in our Privacy Overview. You can change your mind at any time and have your personal data removed from our database. In order to do this you must contact us and let us know you wish to be removed. The request should be made on the Data Subject Request Form.

Recruitment fraud warning: OneTrust is aware of scams involving false offers of employment with our company. The fraudulent jobs, interviews and job offers use fake websites, email addresses, group chat and text messages. Be aware that we never ask candidates for personal information, IDs or bank information during the interview process. We do not interview prospective candidates via instant message or group chat, and do not require candidates to purchase products or services, or process payments on our behalf as a condition of any employment offer. Please note that any legitimate interview availability requests will come directly from a OneTrust recruiter with an ""@onetrust.com"" email address. You may also receive legitimate emails from ""@us.greenhouse-mail.io"". Recruiters will only reach out to candidates who have applied for a role through our ATS (Greenhouse) or prospects via LinkedIn InMail. Job offers will come from a recruiter and may have a ""@docusign.net"" email address. For more information or if you have been targeted please reach out to askrecruiting@onetrust.com.

Our Commitment to You

When you join OneTrust you are stepping onto a launching pad — the countdown has begun. The destination? A career without boundaries working alongside a diverse and inclusive crew who is passionate about doing meaningful work. As a pioneer, your voice and expertise will help chart the direction of an entirely new industry — Trust. Our commitment to putting people first starts with you. Your growth is part of the mission. Our goal is to give you the power to embark on the next phase of your uniquely, unique career

OneTrust provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by local laws.",Full-time
4151464196,334570.0,Senior Data Engineer,"Intrepid sets the standard for delivering excellence in the federal marketplace and is known for treating employees like family. We provide our employees with a challenging and supportive work environment, paired with a competitive salary and an industry-leading 401k contribution. We are looking for a Senior Data Engineer to join our team in supporting the Program Assessment and Evaluation department.

Your Day-to-day Work Will Include


 * Providing data organization and accessibility to enable analysis in support of the Army's annual POM development and defense.
    * This includes but is not limited to developing digital data structures and supporting data visualization tool development in support of POM planning, POM build, and Program budget review.

 * Serving as the senior data engineer providing data structures and synchronization to bolster data storage and usage to enable development of the Program Objective Memorandum.
 * Developing space and structure for data science applications that address specific organizational needs, such as improving insights into programs, optimizing operations within the directorate, or enhancing decision-making processes.
 * Other duties as assigned.
   

At a Minimum You Should Have The Following


 * An active SECRET security clearance and the ability to maintain.
 * A bachelor's degree in a non-STEM field.
 * 10+ years of relevant experience.
 * Programming experience in R or Python with a specific emphasis on data analysis frameworks (Pandas, NumPy, Tidyverse).
 * Programming experience in data visualization frameworks (Shiny, Streamlit, Dash, Plotly, ggplot2) and SQL databases (Postgres, Oracle).
 * All employees may be called upon to provide their knowledge and/or expertise to proposal efforts including contract re-competes.
 * This job description is subject to change at any time.
   
   

Work Type: On-Site (National Capitol Region)

Estimated Salary: $125,000 - $145,000

The provided salary range serves as a broad reference. However, Intrepid takes various factors into account when establishing base salary offers, including the position's scope and responsibilities, as well as the candidate's experience, education, skills, and prevailing market conditions.

Work/Life at Intrepid

Wondering what it's like to work here? Let us give you a glimpse of our exceptional workplace culture.

Our employees have consistently nominated us for the Best Places to Work award and we take pride in our family-like environment, remarkable benefits, and go-the-extra-mile attitude.

The Hours

We sincerely value work-life balance. Our flexible-hours policy allows you to balance extra time during significant projects with days that are lighter. Moreover, we offer generous accrual of paid personal leave that doesn’t lose its value (no use it or lose it here!) as well as 11 paid holidays per year.

The Benefits

Our benefits are renowned, starting with our outstanding 401k program. No match required! We contribute 14% of your bi-weekly pay to your account regardless of your contribution. With our low-fee index funds from Fidelity, your retirement savings will grow substantially. Plus, your professional financial advisors are already covered!

Our top-notch health insurance plan through Blue Cross Blue Shield includes low deductibles ($200/year) and is mostly covered by Intrepid, or you can choose a high-deductible plan with an eligible HSA, the choice is yours! We also provide complimentary life insurance, affordable dental, vision, disability, critical illness, and pet insurance. Additionally, you can set aside pre-tax dollars for medical and dependent care expenses through an FSA. We even offer a $1000 scholarship for newborn or adopted children, as well as those enrolled in higher education.

The Perks

Enjoy typical perks like corporate discounts as well as unique experiences as an Intrepid employee. You'll be a VIP at our annual events, including the Chili Cook-Off, Thanksgiving Lunch & Lawn Games, Ice-Cream Social, Intrepig BBQ, and the grand end-of-year Christmas bash with amazing prizes! Remote workers have special virtual engagement opportunities and exclusive events so no one is left out of the fun.

Give Back

Giving back is ingrained in our values. Through our employee-managed charitable fund, the Intrepid Ideal Community Fund (ICF), we contribute tens of thousands of dollars each year to organizations that help people in need. Join us in various volunteer opportunities and help us make a difference in our communities. Our vision is to one day create ideal communities where every citizen's needs are met.

Join Us!

There's something for everyone at Intrepid. If our benefits, perks, values, and mission resonate with you, we're thrilled to meet you! Start your journey as an Intrepid employee by applying today. We can't wait to hear from you!

About Intrepid

Intrepid is a VEVRAA Federal Contractor and an Equal Opportunity Employer, committed to making employment decisions based on merit and value. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

#CJ",Full-time
4125061491,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4002288222,10217975.0,Data Engineer,"Founded in 2013, CACG is a privately held technology strategy and management consulting services firm that provides commercial and public-sector clients with innovative information technology services and solutions that optimize their return on investment.

Job Overview

We are looking for a Data Engineer to be responsible for providing data quality initiatives support to our Federal client program, ensuring consistent and accurate data across all systems and platforms. The Data Engineer conducts regular data audits and clean-up activities, documents the results and corrective actions, defines key data quality metrics and performance indicators, creates dashboards and reports that provide real-time insights into data quality, and shares data quality reports with stakeholders. The Data Engineer also implements data integration practices, standardizes data entry and processing procedures, develops and enforces data quality rules and standards, identifies and mitigates data quality risks, and leverages advanced technologies, such as machine learning and artificial intelligence, to enhance data quality monitoring and management. The Data Engineer supports data quality initiatives with technology and subject matter expertise.

Qualifications


 * Bachelor's degree in computer science, data science, or related field.
 * Minimum of 5 years of experience in data engineering, preferably in the defense or security sector.
 * Experience in conducting data audits and clean-up activities to ensure data quality and integrity.
 * Experience in defining and measuring data quality metrics and performance indicators.
 * Experience in creating and using data quality dashboards and reports.
 * Experience in implementing data integration practices and ensuring data consistency across systems and platforms.
 * Experience in standardizing data entry and processing procedures and reducing data errors.
 * Experience in developing and enforcing data quality rules and standards for data integration processes.
 * Experience in identifying and mitigating data quality risks and developing proactive strategies.
 * Experience in leveraging advanced technologies, such as machine learning and artificial intelligence, to enhance data quality monitoring and management.
 * Experience in implementing and integrating data quality software solutions and tools.
 * Experience in supporting data quality initiatives with technology and subject matter expertise.
 * Expertise in API construction, experience with data audits and cleansing, as well as proficiency with ETL tools and debugging abilities.
 * Excellent communication, collaboration, and analytical skills.
 * Ability to obtain and maintain a security clearance.
   
   

WHY CACG? This role offers the experience of working with a team of smart and driven professionals at one of the hottest growing consulting companies. You'll be involved in a fun and engaging team-oriented atmosphere where you can gain experience and skills in a wide array of areas. You'll have exposure to business issues and challenges in government contracting, providing an opportunity to leverage your computer knowledge, analytical, and client-facing skills.

CACG, LLC is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity/expression, national origin, disability, protected veteran status, or any other characteristic protected under federal, state or local law, where applicable, and those with criminal histories will be considered in a manner that is consistent with applicable laws.

Powered by JazzHR

WsKD64kUUW",Full-time
4132528897,5250800.0,"Data Engineer, Proprietary Research","About Proprietary Research

On our proprietary research team—Market Intelligence—you’ll partner with our investment professionals and Compliance team to uncover insights about companies, industries, and the broader economy through deep fundamental research and applying data science and engineering techniques to alternative data sets. You’ll work alongside a talented team with diverse skills, backgrounds, and perspectives. Our researchers, product managers, and data scientists and engineers work together to build compliant research products that answer the questions posed by our investment professionals. We look for other bright, motivated, and collaborative people to join our team and grow with us—more than 90% of the leaders in our group were promoted from within.

Role Summary

Data Engineers on the Proprietary Research team design and build solutions that enable investment professionals to effortlessly, extract insights from large, complex compliance approved structured and unstructured data sets. As a member of our Data Engineering team, you will work closely with investment professionals, researchers, and data scientists to design, build, and launch robust end-to-end data pipelines and tools that that help extract the most value out of Point72’s data assets. In this role, you will:


 * Develop and support big data processing pipelines including but not limited to ingestion, transformation, and end-customer delivery
 * Build out cloud-based infrastructure using distributed techniques for other data engineers / data scientists / researchers
 * Be at the forefront of new technology developments with respect to the handling and processing of big data and conduct proof of concepts evaluations of new technologies
 * Build and support visualization and exploration capabilities around our big data sets
   
   

What Excites Us


 * Excellent attention to detail, organization, and project management skills
 * Superb business intuition and a solution orientated, methodological approach to problem solving
 * Ability to collaborate and build relationships across multiple business units within the Firm
 * People who “elevate the room” through their work ethic, curiosity, and solution-orientated attitude
 * Adherence to the highest ethical standards working closely with the Firm’s Compliance team
   
   

What’s Required


 * Experience or demonstrated interest in big data technologies
 * 3+ years of experience in Data Engineering or related field
 * Strong experience in Python Development
 * Experience with Spark or Scala
 * Ability to devise novel and innovative solutions to challenges
 * Knowledge of/experience with graph databases is a plus
   
   

What Success Looks Like


 * Integrity – You demonstrate 100% commitment to the highest ethical standards
 * Ownership – You take charge of your work, uphold your commitments, and always do your best
 * Commerciality – You focus on what matters, ask necessary questions, and are diligent about not wasting time
 * Humility – You welcome and are receptive to feedback and learn from past mistakes
 * Adaptability – You can triage business needs and context switch quickly and efficiently
 * Admirability – You elevate the room through your work ethic, domain knowledge, and work product
   
   

We take care of our people

We invest in our people, their careers, their health, and their well-being. When you work here, we provide:


 * Fully-paid health care benefits
 * Generous parental and family leave policies
 * Mental and physical wellness programs
 * Volunteer opportunities
 * Non-profit matching gift program
 * Support for employee-led affinity groups representing women, minorities and the LGBTQ+ community
 * Tuition assistance
 * A 401(k) savings program with an employer match and more
   
   

About Point72

Point72 is a leading global alternative investment firm led by Steven A. Cohen. Building on more than 30 years of investing experience, Point72 seeks to deliver superior returns for its investors through fundamental and systematic investing strategies across asset classes and geographies. We aim to attract and retain the industry’s brightest talent by cultivating an investor-led culture and committing to our people’s long-term growth. For more information, visit www.Point72.com/about.

The annual base salary range for this role is $160,000-$220,000 (USD) , which does not include discretionary bonus compensation or our comprehensive benefits package. Actual compensation offered to the successful candidate may vary from posted hiring range based upon geographic location, work experience, education, and/or skill level, among other things.",Full-time
4120830016,2289109.0,"Data Engineer, Analytics (Technical Leadership)","Every month, billions of people leverage Meta products to connect with friends and loved ones from across the world. On the Data Engineering Team, our mission is to support these products both internally and externally by delivering the best data foundation that drives impact through informed decision making. As a highly collaborative organization, our data engineers work cross-functionally with software engineering, data science, and product management to optimize growth, strategy, and experience for our 3 billion plus users, as well as our internal employee community.We are looking for a technical leader in our Data Engineering team to work closely with Product Managers, Data Scientists and Software Engineers to support building out a great platform for the future of computing. In this role, you will see a direct correlation between your work, company growth, and user satisfaction. You’ll work with some of the brightest minds in the industry, work with one of the richest data sets in the world, use cutting edge technology, and see your efforts affect products and people on a regular basis.The ideal candidate will have strong data infrastructure and data architecture skills as well as experience in areas such as governing company wide data marts, enabling security and privacy data solutions, and full stack experience with analytical technologies. Candidates should also have a proven track record of leading and scaling efforts related to end-to-end analytics systems, strong operational skills to drive efficiency and speed, strong project management leadership, and a strong vision for how data can proactively improve companies.As we continue to expand and create, we have a lot of exciting work ahead of us!

Data Engineer, Analytics (Technical Leadership) Responsibilities:


 * Proactively drive the vision for data foundation and analytics to accelerate building and improvement of cross platform components across Instagram, and define and execute on plan to achieve that vision.
 * Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems.
 * Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve.
 * Build cross-functional relationships with Data Scientists, Product Managers and Software Engineers to understand data needs and deliver on those needs.
 * Define and manage SLA for all data sets in allocated areas of ownership.
 * Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership.
 * Design, build, and launch collections of sophisticated data models and visualizations that support use cases across different products or domains.
 * Solve our most challenging data integrations problems, utilizing optimal ETL patterns, frameworks, query techniques, sourcing from structured and unstructured data sources.
 * Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts.
 * Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts.
 * Influence product and cross-functional teams to identify data opportunities to drive impact.
 * Mentor team members by giving/receiving actionable feedback.
   
   

Minimum Qualifications:


 * Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.
 * 10+ years experience in the data warehouse space.
 * 10+ years experience in custom ETL design, implementation and maintenance.
 * 10+ years experience with object-oriented programming languages.
 * 10+ years experience with schema design and dimensional data modeling.
 * 10+ years experience in writing SQL statements.
 * Experience analyzing data to identify deliverables, gaps and inconsistencies.
 * Experience managing and communicating data warehouse plans to internal clients.
   
   

Preferred Qualifications:


 * BS/BA in Technical Field, Computer Science or Mathematics.
 * Experience working with either a MapReduce or an MPP system.
 * Knowledge and practical application of Python.
 * Experience working autonomously in global teams.
 * Experience influencing product decisions with data.
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$206,000/year to $281,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.

",Full-time
4135666879,93246786.0,Data Engineer - Databricks & Snowflake - Remote,"Data Engineer will design, implement, and maintain data infrastructure solutions using Databricks

Load and manage data products in Databricks

Collaborate with the team to eliminate repetitive data using Power Automate, starting with Finance

As a Data Engineer, you will support UAT testing and data consumption phases

Work on AI-enabled upselling and predictive ordering projects

Design, implement, and manage Snowflake Data Warehouse solutions",Contract
4152408062,34666.0,Data Engineer,"Job Description




Job Details

Job Location




Operations Center - Lubbock, TX







Remote Type




Optional Work from Home







Position Type




Full Time





































Description

Summary




This position will discover, design and construct enterprise data solutions across the Bank's data estate. The




successful candidate will be proficient in cloud data principles using a variety of tools. Selected candidates will




have a broad exposure to diverse data domains, application ecosystems, and data processing engines. The




ideal candidate will have 3-5 years of demonstrated experience delivering data solutions that collect, process,




store and analyze large data sets. Candidates must enjoy a fast moving environment where variability and




adaptability is the norm. Candidates must have strong technical acumen while able to effectively




communicate with business process owners. Having a mindset of guidance and support ensures business




success. Teamwork is a critical aspect of this role. The ability to deliver data solutions while following data




governance standards is an expectation. The final candidate will be dedicated to data quality and has a proven




track record of delivering business value.










Essential Duties




1. Proven experience with Data Lakes, Data Warehouses, Data Factories, Notebooks, LLM, ML.




2. Collects, transforms, analyzes, and interprets data from a variety of data sources.




3. Proves the accuracy of data models/analysis resulting in precise business decisions.




4. Develops visualization templates to increase data literacy across business teams.




5. Identifies and resolves data quality issue and data discrepancies/anomalies.




6. Builds, tests, and assesses predictive analytic models.




7. Implemented machine learning capabilities to increase business efficiency.




8. Investigates/proposes opportunities for the business throughout the data estate.




9. Performs segmentation analysis to identify useful attributes/behaviors.




10. Provides overlapping support for all ITSM/ITAM activities.




11. Uses analytics to support data needs and initiatives across all lines of business.




12. Stays current with emerging technologies and advancements within existing technologies.




13. Educates others within the organization in the areas of your expertise.




14. Maintains a strong adherence to City Bank Core Values.




15. Maintains a positive and teamwork-oriented attitude.










Equal Opportunity Employer/Veterans/Disabled







As an EEO/AA employer, City Bank will not discriminate in our employment practices based on an applicant's race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, genetic information or status as a protected veteran.",Full-time
4091039637,1586.0,"Data Engineer, GSF","Description

Over the past 20 years, Amazon has reinvented on behalf of customers and has become the largest internet retailer in the world. Amazon is now reinventing the global supply chain and international e-commerce and is recruiting a senior data engineer to help make this vision a reality. In this role, you will be responsible for the development and improvement of Workforce Planning Analytics platform used for planning, reporting, and forecasting purposes as well as dataset management. You will get the unique opportunity to work closely with a variety of stakeholders, including Business Analysts, Site Leads, and other Program Management teams. The candidate will also be in charge of driving strategic initiatives to improve reporting efficiency, develop new bridging workflow tools and establish new key performance metrics where appropriate.

The ideal candidate will not only raise the bar on Data engineering skills but demonstrates a strong curiosity to understand the business end-to-end and be comfortable working with ambiguity. The candidate will also have an eye for detail, be proficient/advanced in SQL/DWH/Python and invent for solving data and reporting challenges. The role requires good communication skills with other functional teams.

Key job responsibilities


 * Design, implement and support an analytical data infrastructure using AWS technologies
 * Build robust and scalable data integration (ETL) pipelines using SQL, and AWS data storage technologies like Aurora, Red Shift etc.
 * Design and develop Analytics applications using modern scripting languages (Python, R, PHP, etc) supporting critical business functions.
 * Gather business and functional requirements and translate these requirements into robust, scalable, operable solutions with a flexible and adaptable data architecture.
 * Lead architecture design and implementation of next generation BI solution
 * Continually improve ongoing reporting and analysis processes, automating or simplifying self-service modeling and production support for customers.
   
   

Basic Qualifications


 * 3+ years of data engineering experience
 * Experience with data modeling, warehousing and building ETL pipelines
   
   

Preferred Qualifications


 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com Services LLC

Job ID: A2838541",Full-time
4133406220,91447303.0,Data Engineer,"Job Description:
Must Have-

 * Bachelor's or master's degree in a technology related field like Computer Science or Engineering with 8+ years of experience
 * 8 years of experience in building semantic layer with Analytical tools (SAP Business Objects Universe, Oracle RPD) or other reporting tools
 * 3 years of experience in building visualizations with one or more tools like (Tableau, Power BI)
 * Proficiency with AtScale virtualization tool, building semantic layer and cubes is desirable
 * Knowledge on how to build data structure suitable for Analytics and visualization is highly desirable.
 * Understand the concept of star schema and knowledge of how data model works is desirable.
 * Advanced SQL knowledge and experience working with snowflake database.
 * Hands-on experience on SQL query optimization and tuning to improve performance is desirable.
 * Responsible for alignment to standards and controls, data quality, problem management, and change management requests.
 * ETL experience with proficiency in data transformation using applications like (Python, Informatica) is a plus
 * Experience with scheduling tool and willing to participate on weekend on call rotation
 * Experience in Agile methodologies (Kanban and SCRUM) is a plus.
   

Dexian is a leading provider of staffing, IT, and workforce solutions with over 12,000 employees and 70 locations worldwide. As one of the largest IT staffing companies and the 2nd largest minority-owned staffing company in the U.S., Dexian was formed in 2023 through the merger of DISYS and Signature Consultants. Combining the best elements of its core companies, Dexian's platform connects talent, technology, and organizations to produce game-changing results that help everyone achieve their ambitions and goals.


Dexian's brands include Dexian DISYS, Dexian Signature Consultants, Dexian Government Solutions, Dexian Talent Development and Dexian IT Solutions. Visit https://dexian.com/ to learn more.


Dexian is an Equal Opportunity Employer that recruits and hires qualified candidates without regard to race, religion, sex, sexual orientation, gender identity, age, national origin, ancestry, citizenship, disability, or veteran status.",Full-time
4127674883,9402.0,Data Engineer,"Job Summary

Job Description

We are seeking a Data Engineer to join our growing Applied AI team and play a key role in building scalable data platforms and pipelines that enable advanced AI and machine learning (ML) solutions across the enterprise. You’ll work closely with the Lead Data Engineer, data scientists, and AI engineers to support the development of AI/GenAI-powered solutions by creating efficient, secure, and high-quality data workflows. This role is ideal for someone who is passionate about data, loves solving technical challenges, and enjoys collaborating with cross-functional teams to deliver high-impact solutions.

Responsibilities


 * Data Pipeline Development: Build and maintain reliable, high-performance data pipelines to support batch, real-time, and streaming data use cases.
 * Data Preparation: Collaborate with data scientists to prepare, clean, and optimize structured and unstructured data (e.g., text, images, embeddings) for machine learning workflows.
 * Cloud-Native Infrastructure: Design and optimize data workflows using cloud services (AWS, Azure, GCP), ensuring scalability and efficiency.
 * Collaboration: Partner with the Lead Data Engineer and the AI team to enhance data quality, governance, and compliance.
 * Automation: Leverage infrastructure-as-code and CI/CD frameworks to automate data workflows and ensure fast, reproducible deployments.
 * Monitoring and Troubleshooting: Monitor the performance of data pipelines and resolve data-related issues promptly to maintain uptime and reliability.
   
   

Qualifications


 * Experience:
    * 3+ years of experience in data engineering or related roles, with a focus on building cloud-based data pipelines.
    * Proficiency in Python, SQL, and data orchestration tools (e.g., Airflow, Prefect).
    * Experience with distributed data processing frameworks (e.g., Spark, Databricks, or Snowflake).

 * Cloud Expertise:
    * Familiarity with cloud data storage services (e.g., AWS S3, Azure Data Lake, GCP BigQuery).
    * Understanding of containerized workflows (Docker, Kubernetes) is a plus.

 * Preferred (but not required):
    * Experience working with ML and GenAI data workflows (e.g., feature stores, embedding storage).
    * Familiarity with vector databases (e.g., Pinecone, Milvus).
      

Soft Skills


 * Strong communication and teamwork skills to collaborate effectively in a cross-functional environment.
 * Problem-solving mindset with the ability to troubleshoot and optimize complex data workflows.
   
   

Education

Bachelor’s degree in Computer Science, Engineering, or a related field.

Medline Industries, LP, and its subsidiaries, offer a competitive total rewards package, continuing education & training, and tremendous potential with a growing worldwide organization.

The Anticipated Salary Range For This Position

$115,440.00 - $173,160.00 Annual

The actual salary will vary based on applicant’s location, education, experience, skills, and abilities. This role is bonus and/or incentive eligible. Medline will not pay less than the applicable minimum wage or salary threshold.

Our benefit package includes health insurance, life and disability, 401(k) contributions, paid time off, etc., for employees working 30 or more hours per week on average. For a more comprehensive list of our benefits please click here. For roles where employees work less than 30 hours per week, benefits include 401(k) contributions as well as access to the Employee Assistance Program, Employee Resource Groups and the Employee Service Corp.

Every day, we’re focused on building a more diverse and inclusive company, one that recognizes, values and respects the differences we all bring to the workplace. From doing what’s right to delivering business results, together, we’re better. Explore our Diversity, Equity and Inclusion page here.

Medline Industries, LP is an equal opportunity employer. Medline evaluates qualified applicants without regard to race, color, religion, gender, national origin, age, sexual orientation, gender identity or expression, protected veteran status, disability/handicap status or any other legally protected characteristic.",Full-time
4125065298,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4138569541,11816115.0,Junior Data Platform Engineer,"Who we are:

Revelio Labs provides workforce intelligence. We absorb and standardize hundreds of millions of public employment records to create the world’s first universal HR database, allowing us to see current workforce composition and trends of any company. Our customers include investors, corporate strategists, HR teams, and governments.




About Data Platform Infrastructure Team:

The Data Platform Infrastructure Team at Revelio Labs is in charge of building the core infrastructure used by product teams to build micro-services which support our business. This includes defining and driving the vision necessary to achieve best of scale and availability. Some of the technologies that we work with include Kubernetes, Linux and AWS. We continuously invest in building new distributed services and scaling existing technologies while working with various teams to meet their current and future needs.

The Data Platform Infrastructure Team is composed of talented engineers that manage our OS components, cloud infrastructure, Linux servers, container orchestration, and deployments both on prem and on the cloud. As a Junior Engineer in this team, you will play a key role in enabling Revelio's infrastructure to power all of our products, and at scale. Your solutions will allow our business to scale and achieve a best in class price/performance ratio.




Responsibilities:

1. Assist in managing and maintaining our cloud-based infrastructure

2. Collaborate with the team on infrastructure automation projects

3. Help troubleshoot and resolve infrastructure-related issues

4. Contribute to the improvement of our CI/CD pipelines

5. Participate in code reviews and documentation efforts




Required Skills & Qualifications:

1. 2+ years of professional experience in a software development role

2. Experience using GitHub for collaboration and version control

3. Familiarity with containerization concepts and tools, particularly Docker

4. Programming experience with Python and SQL

5. Basic understanding of cloud platforms, with AWS experience preferred

6. Strong communication, collaboration, and problem-solving abilities



Preferred Skills & Qualifications:

1. Understanding of Kubernetes and container orchestration

2. Familiarity with CI/CD concepts and tools

3. Scripting skills using bash to create powerful automation tools

4. Understanding of monitoring tools and practices to ensure system health and performance

5. Proficiency in tools like Terraform for declarative infrastructure management




Location:

Our offices are based in New York City, but the position can be done remotely.




Salary:

The pay range for this position in New York City is $100,000 - $130,000 per year. The salary range for performing this role outside of New York City may differ. Base pay offered may vary depending on job-related knowledge, skills, and experience. Additionally, you may be eligible to participate in our company’s equity program, plus benefits, including medical, dental, vision, retirement, and other. The range above is for the expectations as laid out in the job description, however we are often open to a wide variety of profiles, and recognize that the person we hire may be more senior or have different experience than this job description as posted. If that ends up being the case, the updated salary range will be communicated to you as a candidate.




How you should reach us:

Please email your resume with a subject line ""Junior Data Platform Engineer"" to recruiting@reveliolabs.com as a PDF file. Please include your GitHub and highlight any projects that you’ve worked on that may be relevant.

",Full-time
4125059848,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4151658312,153364.0,Data Engineer,"Data Software Engineer

San Jose, CA




Job Description:

Our Client is seeking a Data Software Engineer to join their Data Quality team. In this role, you will focus on building and maintaining robust data pipelines and frameworks that ensure the accuracy, consistency, and reliability of our data assets. You will collaborate with data analysts, data scientists, and other stakeholders to develop data quality metrics and implement automated quality checks across our data systems.




*This role is fully onsite at our San Jose Office.*




Responsibilities:

 * Collaborate with the Infrastructure team to build and maintain scalable data pipelines to support data quality initiatives, ensuring data is accurately ingested and transformed
 * Develop and maintain data quality metrics and dashboards to monitor the health and accuracy of data across various platforms
 * Build and optimize ETL processes that include validation, cleansing, and transformation to enhance data quality
 * Work closely with data analysts and other teams to understand data quality requirements and deliver solutions that meet business needs
 * Implement automated data quality checks and alerts to proactively identify and resolve data issues
 * Conduct data profiling to assess data quality and identify anomalies or inconsistencies
 * Create and maintain comprehensive documentation for data quality processes, standards, and workflows
 * Participate in continuous improvement initiatives by recommending best practices and new tools to enhance data quality processes




Qualifications:

 * Bachelor's Degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience
 * 5+ years experience with object-oriented programming languages
 * 5+ years experience in custom ETL design, implementation and maintenance
 * 5+ years experience with schema design and dimensional data modeling
 * 5+ years experience in writing SQL statements
 * 5+ years hands on experience with Python Programming language
 * 5+ years hands on experience with Java Programming language
 * Strong expertise in handling and analyzing large datasets, including those in the terabyte range




Salary Range: $140,000 to $180,000 per year.




""We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.""",Full-time
4068070235,17933978.0,Software Engineer (Backend/Data),"Fathom is on a mission to use AI to understand and structure the world's medical data, starting by making sense of the terabytes of clinician notes contained within the electronic health records of the world's largest health systems. Our deep learning engine automates the translation of patient records into the billing codes used for healthcare provider reimbursement, a process today that costs hospitals in the US $15B+ annually and tens of billions more in errors and denied claims. We are a venture-backed company that completed a Series B round of financing for $46M in late 2022.

We are looking for a Software Engineer (Backend/Data) to work on data products that drive the core of our business. We want to work with teammates based in the San Francisco Bay area, who are excited about learning how to build and support machine learning pipelines that scale not just computationally, but in ways that are flexible, iterative, and geared for collaboration. If you'd like to become a backend expert who can unify data, and build systems that scale for both operations and organization, then Fathom is your next big opportunity!

Your role and responsibilities will include:


 * Developing data infrastructure to ingest, sanitize and normalize a broad range of medical data, such as electronics health records, journals, established medical ontologies, crowd-sourced labelling and other human inputs
 * Building performant and expressive interfaces to the data
 * Creating infrastructure to help us not only scale up data ingest, but large-scale cloud-based machine learning
   
   

We are looking for a teammate with:


 * 2+ years of software engineering experience in a company/production setting
 * Relevant experience developing backend, integrations, data pipelining, infrastructure, etc. projects in a production setting
 * Problem solving skills and first principles thinking
 * Strong computer science principles including: algorithms, data structures, logic, etc.
 * Hands-on backend coding and/or systems design using best practices in a company setting
 * Effective communication and exceptional collaboration skills
   
   
   
   

Bonus points if you have:


 * Proficiency in coding with python or another modern backend language
 * Expertise with wrangling healthcare data and/or HIPAA
 * Experience with managing large-scale data labelling and acquisition
   
   

Compensation:


 * Salary: $100,000 USD - $175,000 USD
 * Company Equity
   
   

Benefits:


 * PTO and Uncapped Sick Days
 * Medical/Dental/Vision Coverage
 * 401k Matching
 * $1,500 USD Home Office Budget
 * Virtual and Local Office (San Francisco, New York City and Toronto) Team Building Events
 * Annual Company Off-site",Full-time
4146021591,2025248.0,Data Engineer,"Title: Data Engineer 

Location: Remote (United States)

Job Type: Full-time 

Compensation: Base pay is anticipated to be between $80,000 - $120,000 per year based on experience 

 

Definable Solutions, Inc. (parent company of Munetrix and School Data Solutions) is an industry leader in education data management tools and performance analytics applications. We partner with K-12 school districts to transform their data into actionable insights. We are a team of mission-driven former educators, data scientists, and industry disruptors who are taking the company to its next stage of growth---and we’re looking for like-minded individuals to join us in our quest. Our flexible work environment values the importance of bringing diverse backgrounds and interests to the collaboration process. At Definable Solutions, you’ll get the opportunity to redefine a category. 

 

Position Description: 

Definable Solutions is expanding its presence in states across the country and looking for a Data Engineer with a track record of success in supporting growth stage companies. 

 

This is the job for you if you enjoy: 

 * Building and maintaining scalable, reliable data pipelines using AWS, SQL procedures, and functions 
 * Developing and enhancing backend database systems that support front end functionality 
 * Using SQL to support reporting and visualization requirements 
 * Designing and building proactive monitoring and alerting systems 
 * Working collaboratively with teammates across the organization to ensure the success of our school district customers and the students they serve 

 

The best candidates are: 

 * SQL natives, fluent reading and writing complex SQL 
 * Experienced working in Microsoft SQL Server as well as Postgres or MySQL 
 * Experienced writing Python/PySpark for AWS Glue jobs and Lambda functions  
 * Familiar with K12 education data systems (especially Student Information Systems and K12 financial systems), data uses, and data challenges. 
 * Experienced in C# and/or XSLT 
 * Happiest solving hard problems with creative and novel solutions 

 

Benefits 

Definable Solutions provides a comprehensive benefits program to eligible employees, including: 

 * Multiple health plans; HSA & FSA 
 * Dental and vision plans 
 * Employer paid life insurance 
 * Employer provided short and long-term disability insurance. 
 * Voluntary Life, AD&D, Critical Illness & Accident Insurance 
 * 401k plan with a company match 
 * 10 paid holidays 
 * 8 days vacation leave  
 * 9 days sick leave 
 * Additional Benefits: 
 * Employee Assistance Program 
 * Educational Assistance Program ($1,500 / year for qualifying expenses) 
 * Adoption Assistance Program ($5,000 for qualifying expenses) 
 * Caregiver Support Program 
 * MarketPlace Perks at Work 
 * Training & Development Resources 

 

Non-Discrimination Policy: 

Definable Solutions, Inc. is an equal opportunity employer regardless of race, color, religion, creed, sex, marital status, national origin, disability, age, veteran status, on-the-job injury, sexual orientation, political affiliation or belief. Employment decisions are made without consideration of these or any other factors that employers are prohibited by law from considering. Any discriminatory action can be a cause for disciplinary action. Definable Solutions, Inc. also prohibits discrimination against individuals with disabilities and will reasonably accommodate applicants with a disability, upon request, and will also ensure reasonable accommodation for employees with a disability. ",Full-time
4098837845,27191862.0,Data Engineer,"Job Overview

We are looking for a savvy Data Engineer to join our growing development team. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Responsibilities for Data Engineer


 * Create and maintain optimal data pipeline architecture, define and maintain ETL
 * Assemble large, complex data sets that meet functional / non-functional business requirements.
 * Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
 * Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Azure cloud technologies.
 * Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.
 * Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
 * Keep our data separated and secure across multiple data centers.
 * Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
 * Work with data and analytics experts to strive for greater functionality in our data systems.
   
   
   

Qualifications For Data Engineer


 * Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
 * Experience building and optimizing data pipelines, architectures and data sets.
 * Experience with programing to develop and code ETL.
 * Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
 * Strong analytic skills related to working with unstructured datasets.
 * Build processes supporting data transformation, data structures, metadata, dependency and workload management.
 * We are looking for a candidate with 3+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:
    * Experience with Database Administration/Maintenance
    * Experience with big data tools, distributed SQL: Azure Data Factory/Synapse.
    * Experience with relational SQL (NoSQL useful), including Postgres and SQL Server.
    * Experience with Analytics Tools: Power BI
    * Experience with Microsoft Azure cloud services
    * Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, Go, etc.
      ",Full-time
4125066945,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4076468844,217273.0,Data Engineer,"Bravens Inc., a wholly owned subsidiary of Ampcus Inc., is an information technology consulting and services company. Bravens is a leader in providing tailored staffing solutions across both IT and non-IT industries. We are in search of a highly motivated candidate to join our talented team and contribute to our ongoing success.

Job Title: Data Engineer

Location(s): Austin, TX

Requirements:


 * Experience as an enterprise Data Engineer from a consulting background
 * Proven experience in building/operating/maintaining fault tolerant and scalable data processing integrations using AWS
 * 3+ years experience in Python programming language
 * Software development experience working with Apache Airflow, Spark, MongoDB, MySQL
 * Strong capacity to manage numerous projects are a must
 * Experience using Docker or Kubernetes is a plus
 * BS/MS degree in Computer Science or equivalent industry experience
 * Ability to identify and resolve problems associated with production grade large scale data processing workflows
 * Excellent communication skills (we’re a geographically distributed team)
 * Experience creating and maintaining unit tests and continuous integration.
 * Passion for creating Intelligent data pipelines that customers love to use.
   
   

Special Consideration given for:


 * Experience & knowledge with Web Analytics or Digital Marketing
 * Experience & knowledge with Customer Data Platform (CDP) or Data Management Platform (DMP)
 * Experience & knowledge with Client Experience Cloud solutions
   
   

Bravens is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identify, national origin, age, protected veterans or individuals with disabilities.",Full-time
4109399704,74615750.0,"Software Engineer, Backend - Data Platform","Who We Are

Imprint is building a next-generation co-branded credit card company to serve America’s great brands. Some of our partners include H-E-B, Turkish Airlines, Brooks Brothers, and Eddie Bauer. Imprint is backed by Khosla Ventures, Kleiner Perkins, and Thrive Capital. We are focused on building a brilliant team who want to change payments and who embody our Operating Principles.

The Team

The Data Platform Engineering Team is dedicated to ensuring that our organization’s data assets are secure, reliable, and highly accessible for analytics, reporting, and operational needs. By managing our data infrastructure and processes with a focus on quality and governance, we empower data-driven decision-making across all teams at Imprint.

Location

This role will be a hybrid work format, with time split between working remotely and working onsite from either our San Francisco or New York offices, 2-3 days a week as required by your manager.

What You'll Do


 * Data Pipeline Development: Build, maintain, and optimize ETL/ELT pipelines for data ingestion, processing, and storage.
 * Data Infrastructure and Platform: Design and implement a scalable data platform to support rapidly evolving analytics and reporting needs.
 * Collaboration: Work closely with Data Scientists, Analysts, and Engineers to deliver reliable data solutions that drive business insights.
 * Performance Optimization: Monitor and enhance data processing performance to ensure efficiency and reliability.
 * Data Quality: Develop tools and workflows to validate and maintain data integrity across systems.
 * Guide technical decision-making and help choose technical solutions that will scale both with the company and with our user base.
 * Work with our leadership team to craft a diverse engineering culture that is both inclusive and innovative.
 * Work closely with product and design teams to craft delightful experiences for our customers.
   
   

What We Look For


 * 2+ years of software development experience
 * 2+ years of programming experience with at least one modern language like Python, Java, Scala or Go (preferably Python)
 * 1+ years of experience in developing data pipelines using Airflow (or similar orchestration tools)
 * 1+ years of experience contributing to the architecture and design of new and current systems (focusing on reliability, scalability and availability)
 * Strong knowledge of data structures, algorithms and system design
 * Strong sense of ownership, urgency, and drive
 * Experience with stream processing (preferably Apache Spark or Apache Flink)
 * Experience in building high-scale distributed systems that handle large volumes of structured and semi-structured data
 * Track record of building and delivering mission-critical, 24x7 production software systems
 * Excellent troubleshooting and debugging skills
 * Open-source project experience
   
   

Perks & Benefits


 * Competitive compensation and equity packages
 * Leading configured work computers of your choice
 * Flexible paid time off
 * Fully covered, high-quality healthcare including fully covered dependent coverage
 * Additional health coverage includes access to One Medical and option to enroll in an FSA
 * 16 weeks of paid parental leave for the primary caregiver and 8 weeks for all new parents
 * An understanding that successful hybrid work requires flexibility and an appreciation for asynchronous work
 * Access to industry-leading technology across all of our business units — stemming from our philosophy that we should invest in resources for our team that foster innovation, optimization, and productivity
   
   

Imprint is committed to a diverse and inclusive workplace. Imprint is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. Imprint welcomes talented individuals from all backgrounds who want to build the future of payments and rewards. If you are passionate about FinTech and eager to grow, let’s move the world forward, together.

Compensation Range: $140K - $180K

",Full-time
4146807226,36211.0,Data Engineer,"Why you will love working for a National Top Workplace

We are a global leader in loyalty marketing

We work with some of the most well-known brands in the world to deliver market-leading, end-to-end loyalty solutions to enable customer experiences. With a strategy-led, technology-enabled approach, we are consistently named an industry leader by Forrester. The programs we deliver reach more than 330M consumers through loyalty. The impact of these loyalty programs affords us deep brand partnerships, owning a niche in the loyalty space where outcomes matter most.



We are a mission and values driven company

Our mission is to grow enterprise value through loyalty for our clients. Every role within Kobie has a purpose and directly contributes to us achieving this mission.

We are values driven at every point. Over our 30+ year journey, we've created a fun, high-trust, transparent workplace. We believe in leadership and ownership. Our hybrid work environment, personal holidays, casual dress code and focus on diversity and inclusion add to a culture that makes our teammates proud. That pride shines through in the work we do for our clients.

About the team and what we'll build together

We find actionable insights in our clients' loyalty data that helps drive enterprise value. We create real time dashboards to inform internal and external stakeholders.

As a Data Engineer at Kobie, you will play a vital role within our data engineering team, under the direct supervision of the Manager of Data Engineering. Your expertise will be instrumental in implementing ETL/ELT processes and data integrations, populating Kimball style star schemas from a diverse range of data sources across multiple data warehouse implementations in support of our product. Your involvement will extend from requirements gathering to designing business processes and dimensional models. Your profound comprehension of OLTP, Data Vault, and star schemas will be crucial as you delve into source data analysis to assess its potential in addressing business needs. Your objective will be to create scalable, efficient, auditable, and as much as possible, reusable processes.



How you will make an impact


 * Ensure seamless production support of daily running ETL/ELT processes.
 * Develop, design, optimize, and maintain ETL/ELT processes.
 * Conduct data profiling, and source to target mappings, capturing ETL and business metadata for populating Kimball style dimensional models.
 * Design automated tests and audit logging processes for every stage of our data pipelines.
 * Document ETL processes comprehensively including process flow diagrams.
 * Conduct functional and performance testing to identify bottlenecks and data quality issues.
 * Implement slowly changing dimensions as well as transaction, accumulating snapshot, and periodic snapshot fact tables.
   
   

What you need to be successful


 * 4-5 years of Data Engineering experience, with a minimum of 2 operating in Snowflake.
 * Deep understanding of Modern Cloud Data Platforms (data sharing, data clean rooms, marketplace).
 * Understanding of Change Data Capture via Database Replication and how data should flow from OLTP database systems, ELT architecture and design.
 * The ability to work independently across multiple projects, communicating effectively to internal data stakeholders across the organization.
 * Understanding of Kimball style data marts and how they fit into Lakehouse design principles.
 * The ability to integrate with a wide range of data sources, including APIs messaging systems to capture and normalize streaming data.
 * Possess the ability to design data pipelines from end to end and train other team members in best practices and processes.
 * Have a good grasp of the Software Development Life Cycle (SDLC) and Agile Development processes.
 * Deep understanding of Event Driven Architectures, how they impact Data Pipeline designs and integrations.
 * Cloud Experience with Azure, AWS preferred.
 * Proficient in coding languages such as Python, SQL and JavaScript.
 * Experience with orchestration tools like Apache Airflow, Matillion is preferred.
   
   
   
   
   
   

Our teammates are at the heart of everything we do

Healthy people are happy people, which makes mental and physical health a top priority at Kobie. From robust health insurance and benefits options to free fitness programs like FitOn, to generous vacation time for yourself, we support your health needs fully. In today's job market, we know that employees are choosing only what works best for their life. For those that want career growth, Kobie is the perfect place. We have developed a comprehensive people strategy that helps every teammate know how to advance and progress on their career journey. Beyond title progression, Kobie's competitive pay, 401k matching, annual profit sharing and bonuses all make Kobie a perfect place to build your career.

Kobie a place for all

We don't just accept differences – we embrace, share, and celebrate them!

Employment at Kobie is based solely on a person's merit and qualifications, directly related to professional competence. We do not discriminate against any teammate or applicant because of race, creed, color, religion, gender, sexual orientation, gender identity/expression, national origin, disability, age, genetic information, veteran status, marital status, pregnancy or related condition (including breastfeeding), or any other basis under the law.

We are fiercely committed to fostering a workplace where teammates draw upon their own diverse backgrounds, experiences, and perspectives so that they feel welcomed to bring their authentic self to work every day. While our leadership team fully and completely supports our policy of nondiscrimination and equal opportunity, all teammates share the responsibility to ensure we incorporate the principles of equity, diversity, and inclusion throughout Kobie.",Full-time
4152466831,35690611.0,Data Engineer,"Job Details:

Position Title:

Data Engineer

Location:

Cupertino CA (Hybrid)




Data Analytics Engineer / Data Engineer / Big Data Engineer



Must-Have skill - SQL, Splunk, and Impala




Job Description (including duties, skills, education):

The Photos team at Apple is looking for a Data Analytics engineer. As part of this role, you will be developing analytics pipeline and dashboards for critical photos processing and user facing features. You will also be responsible for developing dashboards that provide us with proactive insights on the health and reliability of our features.



Skills:

1. 3 to 5 years of experience in the industry as a Data Analyst or Data Analytics Engineer

2. Prior experience with data infrastructure such as SQL databases, Splunk, and Impala

3. Prior experience developing dashboards in Tableau

4. Great communication skills

",Contract
4143464184,3088.0,"Data Engineer I (Python, AWS, Databricks)","Who Are We?

Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.

Compensation Overview

The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.

Salary Range

$106,300.00 - $175,400.00

Target Openings

1

What Is the Opportunity?

Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate the stories found in data. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.

What Will You Do?


 * Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.
 * Design data solutions.
 * Analyze sources to determine value and recommend data to include in analytical processes.
 * Incorporate core data management competencies including data governance, data security and data quality.
 * Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.
 * Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.
 * Test data movement, transformation code, and data components.
 * Perform other duties as assigned.
   
   

What Will Our Ideal Candidate Have?


 * Bachelor’s Degree in STEM related field or equivalent
 * Six years of related experience
 * Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices.
 * The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.
 * Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.
 * Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.
 * Strong verbal and written communication skills with the ability to interact with team members and business partners.
 * Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.
 * This role will focus on Data and AI product implementation for underwriting and operations models. We will be building and supporting new products to support our day to day risk management and operations.
 * Python, AWS, Databricks, Snowflake, SQL, Docker, Terraform, Git Actions
   
   

What is a Must Have?


 * Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
 * Four years of data engineering or equivalent experience.
   
   

What Is in It for You?


 * Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.
 * Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
 * Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
 * Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs.
 * Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.
   
   

Employment Practices

Travelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.

In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions.

If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.

Travelers reserves the right to fill this position at a level above or below the level included in this posting.

To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.",Full-time
4125058769,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4125068540,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4125059680,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4125066081,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4120823767,10667.0,Data Analytics Engineer,"As a Data Analytics Engineer at Meta Reality Labs' Customer Experience (CX) team, you'll be part of a global team that unlocks the power of customer feedback and insights to drive business improvements. Your background and experience in analytics will help us better understand our customers' needs, preferences, and behaviors, enabling us to deliver exceptional customer experiences. You'll also contribute to the development of data governance policies, data quality standards, and data visualization best practices, ensuring that our data assets are accurate, reliable, and actionable.We’re looking for a Data Analytics Engineer with demonstrated technical skills and functional understanding and background in customer experience insights with the focus on customer support and operations. This role will partner with various functions across the end-to-end customer journey to build and scale data and advanced analytics solutions to enhance customer satisfaction and build brand loyalty, while identifying opportunities to improve data foundations and analytics maturity. By analyzing complex data sets and identifying trends, patterns, and correlations, you'll help shape the future of our products and services.To be successful in this role, you'll have a passion for data, experience managing multiple projects concurrently, and enjoy a fast-moving organization. You’ll identify ways to tell a compelling story with data and design principles. You will thrive within cross-functional teams, excel at building and managing relationships with internal partners and stakeholders, and exhibit proven organizational and presentation skills.

Data Analytics Engineer Responsibilities:


 * Design, develop, integrate, launch and maintain collections of data models, queries, reports and visualizations that support multiple use cases across customer journeys
 * Work with various data sources, including customer interactions, feedback, and behavioral data, to identify trends, patterns, and provide actionable insights
 * Build and deploy predictive models to forecast customer behavior, identify potential issues, and optimize support processes
 * Create interactive and dynamic data visualizations that communicate complex insights to stakeholders
 * Work closely with customer service and operations, product, and engineering teams to integrate data insights into business decisions and drive customer experience improvements
 * Develop and track key performance indicators to measure the effectiveness of customer experience initiatives
 * Continuously update knowledge of advanced analytics techniques, tools, and methodologies to ensure best practices are applied
   
   

Minimum Qualifications:


 * Master's degree in Computer Science, Statistics, Mathematics, or related field
 * 5+ years of experience in data analytics, Business intelligence, data science, or related fields
 * Background and knowledge of CX and VoC space
 * Proficiency in programming languages such as Python, R, or SQL
 * Experience with machine learning concepts and experience working with machine learning libraries and frameworks (e.g. scikit-learn, TensorFlow)
 * Experience creating interactive dashboards with Tableau, Power BI, and others, with proven communication and presentation skills to deliver actionable insights
 * Experience managing time-sensitive projects through to completion while balancing evolving priorities and a diverse range of stakeholders
 * Experience working with operations functions
   
   

Preferred Qualifications:


 * Knowledge of natural language processing (NLP) techniques
 * Familiarity with customer support software (e.g., Salesforce)
 * Certification in data science or related field (e.g., Certified Data Scientist)
 * Familiarity with agile development methodologies and version control systems such as Git
 * Experience working in the high-volume consumer electronics industry
 * Experience working with operations functions, preferably in the customer experience or customer support operations space
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$124,000/year to $176,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4093671308,92634982.0,Data Engineer,"About Us

We are a global climate technologies company engineered for sustainability. We create sustainable and efficient residential, commercial and industrial spaces through HVACR technologies. We protect temperature-sensitive goods throughout the cold chain. And we bring comfort to people globally. Best-in-class engineering, design and manufacturing combined with category-leading brands in compression, controls, software and monitoring solutions result in next-generation climate technology that is built for the needs of the world ahead. 

Whether you are a professional looking for a career change, an undergraduate student exploring your first opportunity, or recent graduate with an advanced degree, we have opportunities that will allow you to innovate, be challenged and make an impact. Join our team and start your journey today!

Responsibilities

Software Development


 * Develops data pipelines and solutions that transfers/transforms data across various systems.
 * Maintains deep technical knowledge of various tools in the data warehouse, data hub, and analytical tools.
 * Ensures data is transformed and stored in efficient methods for retrieval and use.
 * Maintains data systems to ensure optimal performance.
 * Develops a deep understanding of underlying business systems involved with analytical systems.
 * Follows standard software development lifecycle, code control, code standards and process standards.
 * Maintains and develops technical knowledge by self-training of current toolsets and computing environments, participates in educational opportunities, maintains professional networks, and participates in professional organizations related to their tech skills.
   
   

Systems Analysis


 * Engages with customers to understand business needs and capture functional and technical requirements.
 * Offers ideas that simplify the design and complexity of solutions delivered.
 * Effectively communicates any expectations required of collaborators or other resources during solution delivery.
 * Develops and completes test plans to ensure a successful rollout of the solution, including accurate and high-quality data.
   
   

Service Management


 * Effectively communicates any obstacles that occur during solution delivery to collaborators and customers.
 * Defines and manages promised delivery dates.
 * Pro-actively research, analyzes, and predicts operational issues, informing leadership where appropriate.
 * Offers viable options to solve unexpected/unknown issues that occur during solution development and delivery.
   
   

Education / Job-related Technical Skills


 * Bachelor’s Degree in Computer Science/Information Technology or equivalent.
 * Ability to effectively communicate with others at all levels of the Company both verbally and in writing.
 * Demonstrates a courteous, tactful, and professional approach with employees and others.
 * Ability to work in a large, global corporate structure.
 * Advanced English level, advanced level of additional language is a plus.
 * Strong sense of ethics and alignment with company's core values.
 * Willingness to travel both domestically and internationally to support global implementations.
 * Demonstrated ability to clearly isolate and define problems, effectively evaluate alternative solutions, and make decisions in a timely manner.
 * Good decision-making ability, ability to operate in ambiguous situations and high analytical ability to judge pros-cons of approaches against objectives.
 * Candidate must have a minimum of (5) years of hands-on experience in a Data Engineer role, including the following tools/technologies:
    * Experience with relational (SQL) databases.
    * Experience with data warehouses like Oracle, SQL & Snowflake.
    * Experience with analytics, data modeling and segmentation techniques.
    * Experience with ETL/ELT tools like Pentaho Data Integration, Fivetran and dbt.
    * Experience with batch and real time data ingestion and processing frameworks.
    * Experience with languages like Python and Java.
    * Experience with at least one of the cloud platforms (Azure, AWS, GCP).
    * Proficiency in Git for source control to manage and collaborate on code.
    * Knowledge of additional cloud-based analytics solutions, along with Kafka, and Spark is a plus.
      

Behavior / Soft Skills


 * Professional skills, written technical concepts
 * Leads problem solving teams
 * Able to resolve conflict efficiently
 * Works with multiple multi-functional projects
 * Drives process mapping sessions
   
   

Flexible Work Schedule

This role has the flexibility of a remote work option up to three days a week and a core hour schedule. You can choose to flex your start and stop times given you are working during the core hours of 9:00am - 3:00pm. Our teams work together to ensure our chosen work schedules enable our creativity and productivity as we serve the needs of our customers.

Benefits

Copeland places a high value on ensuring that employees have a good work-life balance. We provide access to a competitive benefits package, including the following: medical insurance, dental and vision coverage, 401k participation with a competitive immediate match, fitness center, parental leave, and an online wellness rewards program. Immediate vacation and holiday leave are available. Employee resource groups, including a very active Diversity and Inclusion committee, ensure that the Copeland values are incorporated into everyday employee life.

#Hybrid

Our Commitment to Our People

Across the globe, we are united by a singular Purpose: Sustainability is no small ambition. That’s why everything we do is geared toward a sustainable future—for our generation and all those to come. Through groundbreaking innovations, HVACR technology and cold chain solutions, we are reducing carbon emissions and improving energy efficiency in spaces of all sizes, from residential to commercial to industrial.

Our employees are our greatest strength. We believe that our culture of passion, openness, and collaboration empowers us to work toward the same goal - to make the world a better place. We invest in the end-to-end development of our people, beginning at onboarding and through senior leadership, so they can thrive personally and professionally.

Flexible and competitive benefits plans offer the right options to meet your individual/family needs: medical insurance plans, dental and vision coverage, 401(k) and more. We provide employees with flexible time off plans, including paid parental leave, vacation and holiday leave. 

Together, we have the opportunity – and the power – to continue to revolutionize the technology behind air conditioning, heating and refrigeration, and cultivate a better future. Learn more about us and how you can join our team!

Our Commitment to Diversity, Equity & Inclusion

At Copeland, we believe having a diverse, equitable and inclusive environment is critical to our success. We are committed to creating a culture where every employee feels welcomed, heard, respected, and valued for their experiences, ideas, perspectives and expertise. Ultimately, our diverse and inclusive culture is the key to driving industry-leading innovation, better serving our customers and making a positive impact in the communities where we live. 

Work Authorization

Copeland will only employ those who are legally authorized to work in the United States. This is not a position for which sponsorship will be provided. Individuals with temporary visas such as E, F-1 with OPT or CPT, H-1, H-2, L-1, B, J or TN, or who need sponsorship for work authorization now or in the future, are not eligible for hire.

Equal Opportunity Employer

Copeland is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to sex, race, color, religion, national origin, age, marital status, political affiliation, sexual orientation, gender identity, genetic information, disability or protected veteran status. We are committed to providing a workplace free of any discrimination or harassment.

If you have a disability and are having difficulty accessing or using this website to apply for a position, please contact: copeland.careers@copeland.com

",Full-time
4116701966,2412133.0,Data Engineer,"Your Job

i360 is seeking a Data Engineer to join its Data Engineering team. With your technical expertise, you will architect, implement, and improve end to end pipelines, processes, procedures, and automation for all database-centric processes. You will maintain our relational and NoSQL systems for performance and reliability. You are responsible for tuning and configuring our databases and data platforms, as well as building tools and scripts to monitor, troubleshoot and automate our systems. You mentor the junior and mid-level engineers on our team and help set standards, frameworks, and best practices.

Our Team

The Data Engineering team plays a central role in our organization, given our focus on data. We collaborate closely with both our internal departments and external clients. Our primary responsibility involves designing, building, and upkeeping data pipelines and APIs to provide data to other teams, enabling them to create their products on that data.

What You Will Do


 * Design, architect, and build end to end SQL and NoSQL database solutions. This includes determining business requirements, recommending technologies, architecting, developing code, mentoring team members, and overseeing QA and deployment processes.
 * Load and process disparate data sets using technologies including but not limited to PostgreSQL, Elasticsearch, Snowflake, Spark, Java, and Python.
 * Work with business users to translate requirements into system flows, data flows, data mappings etc., and develop solutions to complex business problems.
 * Code applications that adhere to enterprise design patterns.
 * Resolve technical issues through debugging, research, and investigation.
   
   
   

Who You Are (Basic Qualifications)


 * BA/BS or Master’s degree in Computer Science, Computer Engineering, Information Science or Data Science/Statistics
 * Hands-on experience in data engineering, business intelligence, data modeling, building ETL pipelines and multi-dimensional data warehouses.
 * Hands-on experience with and strong understanding of RDBMS concepts and query optimization.
 * Strong coding experience in developing enterprise applications using Java and Python
 * Understanding of DevOps/DataOps and CI/CD toolset such as git, GitLab CI, GitHub Actions.
 * Experience building, scaling, and maintaining high volume systems.
 * Experience analyzing large complex data sets to resolve data quality and performance issues.
 * Experience mentoring a team of data engineers and helping set standards and frameworks.
   
   
   

What Will Put You Ahead


 * Experience with Cloud system architecture and design, large scale streaming data processing
 * Experience with Spring framework, AOP, JPA and REST
 * Experience with building RESTful web services
 * Experience with libraries like scikit-learn, keras and functional programming concepts.
   
   
   

At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.

Hiring Philosophy

All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here.

Who We Are

Koch Industries creates and innovates a wide spectrum of products and services that make life better. Our work spans a vast number of industries across the world, including engineered technology, refining, chemicals and polymers, pulp and paper, glass, electronics and many more. Headquartered in Wichita, Kansas, Koch employs 122,000+ employees across the globe.

At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.

Our Benefits

Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength - focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes - medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.

Equal Opportunities

Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf",Full-time
3950764417,2646.0,Data Engineer III,"Position Summary...

What you'll do...

We are seeking a highly motivated and talented Data Engineer to join our dynamic team. As a Data Engineer, you will play a critical role in designing, developing, and implementing data pipelines and data integration solutions using Spark, Scala, and Google Cloud Platform (GCP). You will be responsible for building scalable and efficient data processing systems, optimizing data workflows, and ensuring data quality and integrity.

About Team

Everyone has data, but the sheer volume of data at Walmart can be limitless. In the Data Engineering team, we help Walmart manage this data by building pipelines and data lakes to prepare big data for analysis and unlocking actionable insights in real-time. We also use cross-departmental data and machine learning to build a holistic view of true profitability, saving millions of dollars across item categories and geographies while assisting our leadership in making better decisions faster.

What You'll Do


 * Collaborate with cross-functional teams to understand data requirements and design data solutions that meet business needs
 * Develop and maintain data pipelines and ETL processes using Spark and Scala
 * Design, build, and optimize data models and data architecture for efficient data processing and storage
 * Implement data integration and data transformation workflows to ensure data quality and consistency
 * Monitor and troubleshoot data pipelines to ensure data availability and reliability
 * Conduct performance tuning and optimization of data processing systems for improved efficiency and scalability
 * Work closely with data scientists and analysts to provide them with the necessary data sets and tools for analysis and reporting
 * Stay up-to-date with the latest industry trends and technologies in data engineering and apply them to enhance the data infrastructure
   
   

What You'll Bring


 * Proven working experience as a Data Engineer with a minimum of 3 years in the field.
 * Strong programming skills in Scala and experience with Spark for data processing and analytics
 * Familiarity with Google Cloud Platform (GCP) services such as BigQuery, GCS, Dataproc, Pub/Sub, etc.
 * Experience with data modeling, data integration, and ETL processes
 * Strong knowledge of SQL and database systems
 * Understanding of data warehousing concepts and best practices
 * Proficiency in working with large-scale data sets and distributed computing frameworks
 * Strong problem-solving and analytical skills
 * Excellent communication and teamwork abilities
   
   

About Walmart Global Tech

Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. That’s what we do at Walmart Global Tech. We’re a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world’s leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.

Flexible, Hybrid Work

We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.

Benefits

Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.

Equal Opportunity Employer

Walmart, Inc. is an Equal Opportunity Employer – By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions – while being inclusive of all people.

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎

You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎

Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For Information About Benefits And Eligibility, See One.Walmart.

‎

The annual salary range for this position is $90,000.00-$180,000.00

‎

Additional Compensation Includes Annual Or Quarterly Performance Bonuses.

‎

Additional Compensation For Certain Positions May Also Include

‎

‎


 * Stock
   
   

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelor’s degree in Computer Science and 2 years' experience in software engineering or related field. Option 2: 4 years’ experience in

software engineering or related field. Option 3: Master's degree in Computer Science.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, Master’s degree in Computer Science or related field and 2 years' experience in software engineering or related field, We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

2501 Se J St, Ste A, Bentonville, AR 72716-3724, United States of America",Full-time
4151483850,1977526.0,Graduate Software Engineer- Seattle,"We are Rokt, a hyper-growth ecommerce leader. Rokt is the global leader in ecommerce, unlocking real-time relevance in the moment that matters most. Rokt's AI Brain and ecommerce Network powers billions of transactions connecting hundreds of millions of customers, and is trusted to do this by the world's leading companies.

We are a team of builders helping smart businesses find innovative ways to meet customer needs and generate incremental revenue. Leading companies drive 10-50% of additional revenue—and often all their profits—from the extra products or services they sell. This economic edge unleashes a world of possibilities for growth and innovation.

The Rokt engineering team builds best-in-class ecommerce technology that provides personalized and relevant experiences for customers globally and empowers marketers with sophisticated, AI-driven tooling to understand consumers better. Our bespoke platform handles millions of transactions per day. It considers billions of data points which give engineers the opportunity to build technology at scale, collaborate across teams, and gain exposure to a wide range of technology.

At Rokt, we practice transparency in career paths and compensation. At Rokt, we believe in transparency, which is why we have a well-defined career ladder with transparent compensation and clear career paths based on competency and ability. Rokt'stars constantly strive to raise the bar, pushing the envelope of what is possible.

We are looking for a Graduate Software Engineer.

Target total compensation ranges from $169,000 - $240,000, including a fixed annual salary of $150,000 - $170,000, an employee equity plan grant, and world-class benefits.

Equity grants are issued in good faith, subject to company policies, board approval, and individual eligibility.

We're looking for enthusiastic Graduate Software Engineers to join our engineering team at Rokt to start June 2025. You've studied hard, completed labs, and had some experience and now you're ready to start coding and ship. With Rokt we'll give you the tools, support and environment to get straight into coding. You will join a team of experienced engineers who are passionate about writing world-class code.

About The Role


 * You'll be joining any one of our many multi-disciplinary engineering teams, based on your skills and interests
 * In your first week, you'll have completed your first task
 * In your first month, you will have completed a number of fixes and features (at least one of which will be in production), started peer-reviewing your colleagues' code and participating in team task estimations and have a growing understanding of your team's systems.
 * By the end of your first year, you will have led design workshops, started to master a handful of technologies and taken primary responsibility for a small system (or a component in a larger system).
 * While you start with one engineering team, your opportunities will be throughout the engineering structure and you'll work with other teams to get exposure to the whole business.
   
   

Requirements

About you:


 * A Bachelor's degree in Computer Science or equivalent discipline that will be completed by May 2025
 * Demonstrable knowledge of data structures and basic algorithms
 * Solid coding fundamentals and strong logical skills
 * A desire to try anything, learn anything and contribute to a fast-paced team
 * Applications must include a tailored cover letter, resume, and academic transcripts.
 * You should also include links to any personal projects / GitHub repositories in your resume.
   
   

Benefits

About Rokt'stars:

As a mission-driven, hyper-growth community of curious explorers, our ambition is to unlock real-time relevancy in ecommerce and beyond. Our bias for action means we are not afraid to quickly venture into uncharted territories, take risks, or challenge the status quo; in doing so we either win or learn. We work together as one aligned team, never letting egos get in the way of brilliant ideas. We value diversity, transparency, and smart humble people who enjoy building a disruptive business together. We pride ourselves on being a force for good as we make the world better.

About The Benefits

We leverage best-in-class technology and market-leading innovation in AI and ML, with all of that being underlined by building and maintaining a fantastic and inclusive culture where people can be their authentic selves, and offering a great list of perks and benefits to go with it:


 * All employees have access to our LevelUp! program, providing opportunities for coaching, courses, and training to support career growth and development.
 * Become a shareholder. Every Rokt'star gets equity in the company
 * Enjoy catered lunch every day and healthy snacks in the office. Plus join the gym on us!
 * Access generous retirement plans like a 4% dollar-for-dollar 401K matching plan and get fully funded premium health insurance!
 * Dog-friendly office
 * Extra leave (bonus annual leave, sabbatical leave etc.)
 * Work with the greatest talent in town
 * See the world! We have offices in New York, Seattle, Sydney, Tokyo and London
   
   

We believe we're better together. We love spending time together and are in the office most days (teams are in the office 4 days per week). We also get that you need to balance your life and your commitments so you have the flexibility to manage your own hours and can spend up to a week of every quarter working from anywhere.

We at Rokt choose to create a company that is as diverse and inclusive as the world we live in by attracting, growing & keeping the best talent. Equal employment opportunities are available to all applicants without regard to race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

If this sounds like a role you'd enjoy, apply here, and you'll hear from our recruiting team.

Note: The first stage of the recruitment process for this role is to complete a 15-minute online aptitude test, which will be sent out to your application email. Successful candidates will be contacted to discuss the next steps",Full-time
4150493076,15258405.0,Senior Data Engineer," * Putting together large, intricate data sets to satisfy both functional and non-functional business needs.
 * Determining, creating, and implementing internal process improvements, such as redesigning infrastructure for increased scalability, improving data delivery, and automating manual procedures.
 * Building necessary infrastructure using AWS and SQL technologies. This will enable effective data extraction, transformation, and loading from a variety of data sources.
 * Reformulating existing frameworks to maximise their functioning.
 * Building analytical tools that make use of the data flow and offer a practical understanding of crucial company performance indicators like operational effectiveness and customer acquisition.
 * Helping stakeholders, including the data, design, product, and executive teams, with technical data difficulties.
 * Working on data-related technical challenges while collaborating with stakeholders, including the Executive, Product, Data, and Design teams, to support their data infrastructure needs.
 * Remaining up-to-date with developments in technology and industry norms can help you to produce higher-quality results

",Full-time
4081172525,1195377.0,Data Engineer (Remote),"Position Title: Data Engineer (remote)

Entity: KBRA Holdings

Employment Type: Full-Time

Location: NY, PA or Remote only for those located in the following states: (CA, CO, DC, FL, IL, MD, NJ, MA,SC, TX, VA)

Summary/Overview:

We are seeking a talented and motivated Mid-Level Data Engineer to join our development team. The ideal candidate will have a strong background in Python programming, experience building frontends in Python, and a passion for solving complex problems. You will work closely with cross-functional teams to design, develop, and maintain high-quality software solutions.

Job Responsibilities:


 * Develop, test, and maintain scalable Python applications.
 * Collaborate with product managers, designers, and other engineers to deliver high-quality software.
 * Write clean, efficient, and reusable code following best practices.
 * Participate in code reviews to ensure code quality and share knowledge with the team.
 * Troubleshoot and debug issues in a timely manner.
 * Contribute to the design and architecture of new features and systems.
 * Stay up-to-date with the latest industry trends and technologies.
   
   

Successful candidates will possess the following:

Required:


 * 3+ years of professional experience in Python development.
 * Strong understanding of the Python programming language.
 * Experience with web frameworks such as Django, Flask, and/or Dash.
 * Knowledge of relational databases (Snowflake preferred).
 * Experience with version control systems (e.g., Git).
 * Strong problem-solving skills and attention to detail.
 * Excellent communication and teamwork skills.
   
   

Nice to Have:


 * Experience with cloud platforms (e.g., AWS, Azure, Google Cloud).
 * Experience with Airflow.
 * Experience with Mongo DB.
 * Experience with Salesforce.
 * Knowledge of containerization and orchestration tools (e.g., Docker, Kubernetes).
 * Familiarity with CI/CD pipelines and DevOps practices.
 * Experience with RESTful APIs and microservices architecture.
 * Understanding of Agile methodologies.
   
   

Salary Range:

The anticipated annual base salary range for this full-time position is $100,000 to $130,000. Offer amounts are determined by factors such as experience, skills, geography, and other job-related factors.

Benefits:


 * Competitive benefits and paid time off
 * Paid family and disability leave
 * 401(k) plan, including employer match (100% vested)
 * Educational and professional development financial assistance
 * Employee referral bonus program
   
   

About Us:

KBRA is a full-service credit rating agency registered in the U.S., the EU and the UK, and is designated to provide structured finance ratings in Canada. KBRA's ratings can be used by investors for regulatory capital purposes in multiple jurisdictions.

More Info:

KBRA encourages applications from all qualified individuals without regard to race, color, religion, gender, sexual orientation, gender identity or expression, age, national origin, marital status, citizenship, disability, and veteran status or any other basis prohibited by federal, state or local law.

",Full-time
4111743967,66321745.0,Junior/Entry Data Engineer,"Are you passionate about coding or technology and ready to make your mark in tech? For more than 14 years, SynergisticIT has been helping aspiring developers like you excel in the tech industry. We focus on equipping you with the skills and experience needed to not only secure a job but to thrive in your career!

Why Partner with SynergisticIT?


 * Customized inputs to achieve the desired output :designed with industry needs in mind, ensuring you're equipped with the most sought-after skills.
 * Exclusive Opportunities: Our extensive network allows you to connect with leading tech firms.
 * Outstanding Outcomes: Many of our candidates land multiple job offers, often with starting salaries of $100k or more!
   
   

https://www.synergisticit.com/candidate-outcomes/

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://www.youtube.com/playlist?list=PLJgkOBQ51j5AHT5I6n29glr0q6trzkxYD

https://synergisticit.wistia.com/medias/k6t6a1n4kb

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

Who Should Apply? We're looking for recent grads in Mathematics, Statistics , Computer Science or Engineering or candidates with gaps in their career or people wanting to switch careers into tech. SynergisticIT is committed to supporting your journey!

Preferred SKILLS For Java /Full Stack/Devops Positions

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Knowledge of Core Java , javascript , C++ or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

For data Science/Data Analyst/AI/Machine learning Positions

Preferred SKILLS

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude

Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools

Candidates lacking technical skills or relevant experience can research our Job Placement Programs which can assist in landing a Job

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates

Embrace Your Future! We also assist with F1 OPT to transition into H1B and Green Card byproviding comprehensive support. All positions are open to candidates of all visa types and US citizens.

Are you ready to make an impact?",Contract
4138246433,16939.0,Data Engineer,"Information about #31949 Data Engineer

Work Location: This role can work remotely, within the continental US, provided that Eastern standard time core business hours are maintained




Formulated to Care

For more than 75 years, GOJO, Makers of PURELL® has been powered by people who are energized by helping the world experience greater health and well-being.

The positive impact of our PURELL® hand and surface hygiene solutions is driven by our global community of highly collaborative and talented team members who love to learn, innovate, care for each other, and deliver our Purpose of Saving Lives and Making Life Better.




Role Objective

The Data Engineer is primarily responsible for data movement and data availability within the enterprise. Under guidance from senior team members within the Data Team, the Data Engineer will work across the enterprise (Manufacturing, Finance, Quality, HR, etc.) to support the business data needs. Working with everyone from engineers on the shop floor to VPs, we must adjust our communication style to meet the needs of the business user, supporting manufacturing of product to enterprise level financial analysis. GOJO also has databases implemented in Azure, SQL Server and Oracle, requiring knowledge across multiple vendors.




Essential Functions and Responsibilities

 * Understand, write and modify SQL queries, stored procedures, materialized views and views in MS SQL Server, Oracle Database, Azure Database and Azure Synapse. Know the difference between the different technologies and what functions are available in which, ie. getdate() vs sysdate, substring vs substr, lpad vs left/replicate.
 * Monitor and manage scheduled jobs, addressing failures and communicating as appropriate. Jobs are in Azure Data Factory (ADF), SQL Server Agent (on-prem), and Oracle Enterprise Manager (OEM)
 * Design, develop, and maintain ETL and/or ELT (dependent upon requirements) processes for efficient data movement via Azure Data Factory
 * Assist users with connection issues/granting permissions. Follow security standards and ensure permissions are not granted without authorization
 * Publish/deploy Azure Data Factory code via DevOps Release Pipelines
 * Perform SQL Server database upgrades/migrations
 * Participate in afterhours/on-call support for production environments. This will include supporting upgrades or troubleshooting activities that must take place outside of standard working hours.
 * Collaborate with data analysts and business users to understand data requirements and assist in data modeling
 * Ability to multi-task and manage workload in accordance with priorities
 * Maintain Power BI Semantic Model and Design, Develop, Maintain Power BI dashboards as required
 * Creation of Power BI workspaces with applicable security
 * Backup for Database Administrators




Education and Experience

 * Minimum two (2) years of SQL experience required
 * Minimum four (4) years' experience in a technical role or a degree in a technical discipline (math included) required
 * ETL/ELT experience required
 * Familiarity with data visualization tools
 * Ability to be platform agnostic (Oracle, SQL Server, Azure)
 * Understanding of different platforms and the ability to bounce between them seamlessly
 * Manufacturing knowledge/understanding is a plus
 * SAP and/or Salesforce knowledge is a plus




Supervision/Coordination

 * Coordinates tasks, schedules, and projects
 * Guidance and direction provided by Data Architecture Manager
 * This role does not directly supervise other team members




Travel Requirements

Overnight Travel - sporadic - required.




To Apply:

To apply for this position, please complete the online application process. You will have an opportunity to include your resume and a cover letter. GOJO is an Affirmative Action/Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status or status as an individual with a disability. Applicants must be lawfully authorized to work in the United States.

Recruiters, Search Agencies or others referring candidates to GOJO Industries, Inc. without written authorization from GOJO Industries, Inc. Human Resources will not be compensated in any way for their online referral even if GOJO Industries, Inc. hires the candidate. GOJO does not seek or respond to unsolicited resumes for positions that are not listed in the Careers section.

",Full-time
4139909594,1337.0,Senior Software Engineer - Systems and Infrastructure,"Company Description
LinkedIn is the world’s largest professional network, built to create economic opportunity for every member of the global workforce. Our products help people make powerful connections, discover exciting opportunities, build necessary skills, and gain valuable insights every day. We’re also committed to providing transformational opportunities for our own employees by investing in their growth. We aspire to create a culture that’s built on trust, care, inclusion, and fun – where everyone can succeed.

Join us to transform the way the world works.

Job Description
This role can be based in Mountain View, CA, San Francisco, CA, or Bellevue, WA.

At LinkedIn, our approach to flexible work is centered on trust and optimized for culture, connection, clarity, and the evolving needs of our business. The work location of this role is hybrid, meaning it will be performed both from home and from a LinkedIn office on select days, as determined by the business needs of the team.

As part of our world-class software engineering team, you will be charged with building the next-generation infrastructure and platforms for LinkedIn, including but not limited to: an application and service delivery platform, compute platform, massively scalable data storage and replication systems, cutting-edge search platform, best-in-class AI platform, experimentation platform, privacy and compliance platform etc. You will work and learn among the best, putting to use your passion for distributed technologies and algorithms, API design and systems-design, and your passion for writing code that performs at an extreme scale. LinkedIn has already pioneered well-known open-source infrastructure projects like Apache Kafka, Pinot, Azkaban, Samza, Venice, Datahub, Feather, etc. We also work with industry standard open source infrastructure products like Kubernetes, GRPC and GraphQL - come join our infrastructure teams and share the knowledge with a broader community while making a real impact within our company.

Responsibilities
-You will design, implement, and optimize the performance of large-scale distributed systems with security and compliance in mind.
- You will participate in design and code reviews to maintain our high development standards.
- You will partner with peers, leads and internal customers to define scope, prioritize and build impactful features at a high velocity.
- You will mentor other engineers and will help build a fast-growing team.
- You will work closely with the open-source community to participate and influence cutting edge open-source projects (e.g., Apache Iceberg)


Basic Qualifications
- BA/BS Degree in Computer Science or related technical discipline, or related practical experience.
- 2+ years of industry experience in software design, development, and algorithm related solutions.
- 2+ years experience programming in object-oriented languages such as Java, C++, Python, Go, Rust, C# and/or Functional languages such as Scala or other relevant coding languages
- Hands on experience developing distributed systems, large-scale systems, databases and/or Backend APIs

Preferred Qualifications
- BS and 5+ years of relevant work experience, MS and 4+ years of relevant work experience, or PhD and 2+ years of relevant work experience
-Experience in architecting, building, and running large-scale distributed systems
-Experience with industry, opensource, and/or academic research in technologies such as Hadoop, Spark, Kubernetes, Feather, GraphQL, GRPC, Apache Kafka, Pinot, Samza or Venice
- Experience with open-source project management and governance

Suggested Skills
- Distributed systems
- Backend Systems Infrastructure
- Java/Golang/Rust/Python

You will Benefit from our Culture
We strongly believe in the well-being of our employees and their families. That is why we offer generous health and wellness programs and time away for employees of all levels.

LinkedIn is committed to fair and equitable compensation practices.

The pay range for this role is $128,000 - $210,000. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to skill set, depth of experience, certifications, and specific work location. This may be different in other locations due to differences in the cost of labor.

The total compensation package for this position may also include annual performance bonus, stock, benefits and/or other applicable incentive compensation plans. For additional information, visit: https://careers.linkedin.com/benefits.



Equal Opportunity Statement
LinkedIn is committed to diversity in its workforce and is proud to be an equal opportunity employer. LinkedIn considers qualified applicants without regard to race, color, religion, creed, gender, national origin, age, disability, veteran status, marital status, pregnancy, sex, gender expression or identity, sexual orientation, citizenship, or any other legally protected class. LinkedIn is an Affirmative Action and Equal Opportunity Employer as described in our equal opportunity statement here: https://microsoft.sharepoint.com/:b:/t/LinkedInGCI/EeE8sk7CTIdFmEp9ONzFOTEBM62TPrWLMHs4J1C_QxVTbg?e=5hfhpE. Please reference https://www.eeoc.gov/sites/default/files/2023-06/22-088_EEOC_KnowYourRights6.12ScreenRdr.pdf and https://www.dol.gov/ofccp/regs/compliance/posters/pdf/OFCCP_EEO_Supplement_Final_JRF_QA_508c.pdf for more information.

LinkedIn is committed to offering an inclusive and accessible experience for all job seekers, including individuals with disabilities. Our goal is to foster an inclusive and accessible workplace where everyone has the opportunity to be successful.

If you need a reasonable accommodation to search for a job opening, apply for a position, or participate in the interview process, connect with us at accommodations@linkedin.com and describe the specific accommodation requested for a disability-related limitation.

Reasonable accommodations are modifications or adjustments to the application or hiring process that would enable you to fully participate in that process. Examples of reasonable accommodations include but are not limited to:

-Documents in alternate formats or read aloud to you
-Having interviews in an accessible location
-Being accompanied by a service dog
-Having a sign language interpreter present for the interview

A request for an accommodation will be responded to within three business days. However, non-disability related requests, such as following up on an application, will not receive a response.

LinkedIn will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by LinkedIn, or (c) consistent with LinkedIn's legal duty to furnish information.

Pay Transparency Policy Statement
As a federal contractor, LinkedIn follows the Pay Transparency and non-discrimination provisions described at this link: https://lnkd.in/paytransparency.

Global Data Privacy Notice for Job Candidates
This document provides transparency around the way in which LinkedIn handles personal data of employees and job applicants: https://lnkd.in/GlobalDataPrivacyNotice",Full-time
4149495209,77158779.0,Data Engineer,"Data Engineer

Sunnyvale, CA

Fulltime Only




We are looking for an individual who would be responsible for the following:

· Work hand in hand across teams with data owners to gather, interpret, and visualize data to answer specific questions

· Build efficient SQL queries and dynamic reports in Tableau and Splunk

· Drive discussions with various domain experts to define proper analysis methodologies




Must-Have Skills

· BS or MS in Data Science, Computer Science, or 3+ years Data Science experience

· Experience in building data visualization in Tableau. Splunk experience is a plus.

· Experience using SQL. SQL with Cloudera Impala is a plus

· Strong ability to independently identify nuances and drive clarity in requirements starting with high level questions

· Excellent written and verbal communication skills and experience presenting data to cross-functional teams and/or management

· Strong attention to detail and ability to deep dive technically.







Best Regards

Lokesh

Technical Recruiter

VMC Soft Technologies inc.

EMail: lokesh2@vmcsofttech.com

Ph No: 602-666-1741",Full-time
4045412670,66321745.0,Entry Level Data Engineer - Remote,"Since 2010 Synergisticit has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this Job market also, our candidates are able to achieve multiple job offers and $100k &plus; salaries.

please check the below links to see success outcomes, salaries of our candidates .

https://www.synergisticit.com/candidate-outcomes/

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please visit the below videos exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

Required Skills

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, Gen AI, LLM, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full Stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java , javascript , C&plus;&plus; or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Full-time
4142791618,85645770.0,Data Engineer,"Figure is an AI Robotics company developing a general-purpose humanoid. Our humanoid is designed for corporate tasks targeting labor shortages and jobs that are undesirable or unsafe. We are based in Sunnyvale, CA, and require 5 days/week in-office collaboration. It’s time to build.

We are looking for an experienced Data Engineer to develop and optimize our data processing infrastructure and tools, enabling deep insights from robotic system logs.In this role you will transform robot logs and other sources of data to extract information, identify patterns, provide access to the data and visualization tools. Your work will help ensure that the robot is operating reliably at maximum performance, and inform engineering design trades and decisions.

Responsibilities


 * Develop and maintain pipelines and tools to transform robot logs to make it easier to access, visualize, and automatically detect events of interest.
 * Optimize data processing to reduce the time needed between data offload and the availability of the data to our engineering teams.
 * Design and optimize data storage solutions for handling complex, high-volume time-series and structured data.
 * Build and maintain database schemas and queries to support analytics and visualization of extracted patterns.
 * Support mechanical, electrical, software, integration and test engineers with their needs to extract and visualize data.
 * Develop dashboards and custom data visualizations tools to enable engineers to quickly extract information from the data and track robot performance.
 * Integrate your solutions with existing data pipelines and our robot testing framework.
   
   

Requirements


 * Bachelor's or Master’s degree in Computer Science, Data Engineering, or a related field.
 * 3+ years of experience in data engineering, preferably with time-series or log data processing.
 * Proficiency in Python with experience in Pandas, Polars, or PySpark for large-scale data processing.
 * Strong understanding of database design, indexing, and query optimization (SQL and NoSQL).
 * Experience handling complex data formats such as Parquet, MCAP, or protobuf.
 * Experience building custom web based data visualization tools (JavaScript, React…)
 * Familiarity with data visualization tools like Grafana for real-time analysis and monitoring.
 * Experience with distributed computing frameworks and cloud-based data storage solutions.
 * Strong debugging skills and ability to work with lab teams to interpret robotic system logs.
   
   

Bonus Qualifications


 * Experience with CI/CD pipelines for automated data processing.
 * Knowledge of robotics or embedded system logging frameworks.
 * Familiarity with real-time data streaming and event-driven architectures.
   
   

The US base salary range for this full-time position is between $150,000 - $250,000 annually.

The pay offered for this position may vary based on several individual factors, including job-related knowledge, skills, and experience. The total compensation package may also include additional components/benefits depending on the specific role. This information will be shared if an employment offer is extended.",Full-time
4142617065,16690.0,Data Engineer,"""W2 Only""




Title: Data Engineer

Location: Nashville, TN ( Locals Only )

3 days a week onsite with Fridays remote.







Job Purpose: A Senior Data Engineer within Data Warehouse Systems will work with Lead Data Engineers on building and maintaining data pipelines.

The data ingested through these various pipelines support analytical applications.

The candidate should be well-versed in how data flows and supports the analytical applications. The applicant, to be effective, must have an in-depth knowledge of design of modern programming languages & web technologies, backend infrastructure & databases, and an understanding of AWS cloud services.

",Contract
4125061969,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4124389920,3333121.0,Data Engineer,"Position Title – Data Engineer

CORMAC is seeking a skilled Data Engineer to manage and optimize our database infrastructure. You will play a key role in designing, maintaining, and enhancing our database systems to ensure data integrity, security, and accessibility for business-critical applications.

Responsibilities


 * Design and implement robust, scalable, and efficient database structures to support applications and data analytics.
 * Deploying and managing data infrastructure on cloud platforms like AWS, Azure, or Google Cloud
 * Monitor and optimize database performance, including indexing, query optimization, and load balancing, to ensure high availability and low-latency data access
 * Assist in the migration of data between systems, including database upgrades, platform changes, and ETL processes for data integration.
 * Leveraging cloud-native services for data processing and storage\
 * Optimizing costs while maintaining performance and scalability
 * Choose appropriate technologies for data ingestion and processing
 * Applying various transformations like data cleansing, aggregation, and enrichment
 * Monitor data quality metrics and perform data cleansing as necessary
 * Optimize performance for large-scale data operations.
   
   

Required Skills & Experience


 * Bachelor’s in Computer Science, Computer Engineering, Information Systems, or related field
 * 2+ years of experience as a Database Engineer or similar role
 * Must be a U.S. Citizen
 * Must have the ability to obtain a Public Trust (Tier 1) Security Clearance
 * Experience with cloud platforms such as AWS, Google Cloud, or Azure, utilizing cloud services for data storage, processing, and retrieval.
 * Emphasis on Python and SQL. R and other languages
 * Knowledge of data warehousing, data lakes, and cloud computing
 * Experience in data lakehouse architecture or similar data architecture.
 * Experience using products like Databricks or similar, including Snowflake.
 * Familiarity with machine learning algorithms.
 * Knowledge of ETL processes and data modeling techniques
 * Familiarity with ETL tools, REST APIs, and data integration techniques
 * Understanding of data security and compliance best practices
 * Ability to develop clear, efficient, scalable solutions for complex problems
 * Understanding of data warehousing solutions and database architecture principles.
 * Effective communication and teamwork abilities
 * Strong problem-solving skills and attention to detail
   
   

Why CORMAC?

At CORMAC, we leverage the power of Data Management and Analytics to enable our customers to achieve their strategic goals. With over 20 years of experience in Health Information Technology (HIT), human-centered design principles and Agile development methodologies, CORMAC delivers complex digital solutions to solve some of the most challenging problems facing public healthcare programs today.

As a US Federal Government contractor in the public healthcare sector, our work is impactful and cutting-edge while being performed in a supportive, collaborative, and welcoming environment. We offer flexible work schedules with remote, hybrid, or fully in-person workplace options to empower our employees to decide the workplace most suitable for them. At CORMAC, we have a highly diverse workforce, and believe the work environment is a place where creativity, collaboration, enthusiasm, and innovation happens, regardless of location.

E-Verify Participation/EEO

As an Equal Employment Opportunity employer, CORMAC provides equal employment opportunity to all employees and applicants without regard to an individual's protected status, including race/ethnicity, color, national origin, ancestry, religion, creed, age, gender, gender identity/expression, sexual orientation, marital status, parental status, including pregnancy, childbirth, or related conditions, disability, military service, veteran status, genetic information, or any other protected status.",Full-time
4125067259,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4066466046,102677437.0,Data Engineer,"Job Description:

We are looking for a Data Engineer to assist with the data platform blueprint and design, encompassing the relevant data platform components. We are looking for great, creative engineers who can colloborates with the Integration Architects and Data Architects to ensure cohesive integration between systems and data models.

Responsibilities Include:


 * Develop and support data pipelines to capture and consolidate critical hardware quality telemetry for air-gapped clouds(AGC)
 * Collaborate closely with cross-functional teams, including hardware engineers, firmware developers and data scientists, to understand the sources, ingestion, transformation and utilization of the raw telemetry for key metrics in the public space.
 * Work with Ateam to develop analogous capture and reporting capabilities for air-gapped cloud environments
   
   

Here's What You Need:


 * Bachelor's degree or 4 additional years of professional experience in lieu of degree
 * 3 years of technical expertise in any of the following: SQL, Python, Databricks, Azure Data Factory/Synapse and Apache Spark
   
   

Job Description:

Accenture Federal Services is looking for a Data Engineer to assist with the data platform blueprint and design, encompassing the relevant data platform components. We are looking for great, creative engineers who can colloborates with the Integration Architects and Data Architects to ensure cohesive integration between systems and data models.

Here's What You Need:


 * Bachelor's degree or 4 additional years of professional experience in lieu of degree
 * 3 years of technical expertise in any of the following: SQL, Python, Databricks, Azure Data Factory/Synapse and Apache Spark
   
   

Skills: python,sql,azure,azure data factory/synapse,databricks,apache spark,datasynapse gridserver",Contract
4137192143,1586.0,"Data Engineer II, F3 DASH","Description

Are you interested in being a part of Amazon’s fastest growing business? Are you excited to work on latest Big Data technologies to help shape the future of Grocery data? If the answer to both these questions is Yes, then come be a part of Amazon Fresh’s Central Data Infrastructure team (DASH). Our vision is to build a world class, centralized and secure data infrastructure for Amazon’s Worldwide Omnichannel Grocery Business. Our mission is to make it extremely convenient for Internal stakeholders, 3P partners and the Grocery engineering community to access timely and accurate data for all their reporting and analytics needs. The scale and the complexity of the data we manage requires constant innovation and pushing the boundaries on what’s possible. This role offers you an opportunity to work on VP level visibility initiatives and make a lasting impression on how grocery data is managed and distributed across the globe.

Key job responsibilities

In This Role You Will


 * Help build the infrastructure to answer questions with data, using software engineering best practices, data management fundamentals, data storage principles, and recent advances in distributed systems
 * Manage AWS resources.
 * Collaborate with Business Intelligence Engineers to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation
 * Collaborate with Data Scientists to implement advanced analytics algorithms that exploit our rich data sets for statistical analysis, prediction, clustering and machine learning
 * Drive the architecture and technology choices that enable a world-class user experience
 * Develop expertise in a broad range of Amazon’s data resources and know when, how, and which to use and which not to use
 * Encourage the organization to adopt next-generation data architecture strategies, proposing both data flows and storage solutions
 * be comfortable with a degree of ambiguity and willing to develop quick proof of concepts, iterate and improve
 * Create extensible designs and easy to maintain solutions with the long term vision in mind
 * Have an understanding and empathy for business objectives, and continually align your work with those objectives and seek to deliver business value. You listen effectively.
   
   

A day in the life

Successful candidate would have extensive experience working with big data, building data warehouses and data processing services. They are effective at seeing data patterns and building generic data solutions to improve user experience. Proficiency in SQL and data modelling allows to create data warehouses and tables conforming to wide range of business needs. Previous ETL and MPP experience enables candidate to build extensible and scalable pipelines capable of processing large amounts of data in a short time, ex. >1T rows within few hours. Wide industry experience helps detect inefficiencies in existing designs and address them with minimal effort.

About The Team

F3 DASH is Amazon Fresh central data team responsible for the creation and maintenance of Amazon Grocery’s global data infrastructure. Our mission is to make all of grocery data easily accessible across multiple businesses by all users from a single location without any restrictions for all their reporting and analytics needs. Our long-term vision is to build a best-in-class data infrastructure to support worldwide grocery data to enable timely reporting and automated decision-making with standardized metrics to deliver top-line and bottom-line impact to Amazon’s grocery business.

Basic Qualifications


 * 3+ years of data engineering experience
 * Experience with data modeling, warehousing and building ETL pipelines
   
   

Preferred Qualifications


 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com Services LLC

Job ID: A2872712",Full-time
4150453995,16690.0,Senior Data Engineer,"Title: Senior Data Engineer

Location: Columbus, OH

Duration: 12 Months




Skills:

Key areas of focus:

 * Migrating from SQL/SSIS to Azure/Snowflake
 * Strong Snowflake Skills
 * Sound Microsoft Azure Stack experience
 * Building data pipelines, transformation
 * Handling different problems/challenges that might arise
 * DBT



Key Responsibilities:

 * Design, develop and maintain scalable data pipelines
 * Develop data ingestion and integrations (REST, SOAP, SFTP, MQ, etc.) processes
 * Take ownership of building data pipelines
 * Actively engage in technology discovery and implementation for both on-prem and in Cloud (i.e. Azure or AWS) to build solution for future systems
 * Develop high performance scripts in SQL/Python/etc. to achieve objectives of enterprise data, BI and analytics need.
 * Incorporate standards and best practices into engineering solutions
 * Manage code versions in source control and coordinate changes across team
 * Participate in architecture design and discussions
 * Provide logical and physical data design, and database modeling
 * Be part of the Agile team to collaborate and to help shape requirements
 * Solve complex data issues around data integration, unusable data elements, unstructured data sets, and other data processing incidents
 * Supports the development and design of the internal data integration framework
 * Works with system owners to resolve source data issues and refine transformation rules
 * Partner with enterprise teams, data scientist, architects to define requirements and solution



Key Qualifications :

 * Have a B.A./B.S. and 5-8 years of relevant work experience; or an equivalent in education and experience
 * Must have excellent experience with Snowflake
 * Hands on experience with Microsoft Stack – SSIS, SQL, etc.
 * Possess strong analytical skills with the ability to analyze raw data, draw conclusions, and develop actionable recommendations
 * Experience with the Agile development process preferred
 * Proven track-record of excellence and consistently delivered past project successfully
 * Hands on experience with Azure data factory V2, Azure Databricks, SQLDW or Snowflake, Azure analysis services and Cosmos DB
 * Experience with Python or Scala.
 * Understanding of continuous integration and continuous deployment on Azure
 * Experience with large scale data lake or warehouse implementation on any of the public cloud (AWS, Azure, GCP)
 * Have excellent interpersonal and written/verbal communication skills
 * Manage financial information in a confidential and professional manner
 * Be highly motivated and flexible
 * Effectively handle multiple projects simultaneously and pay close attention to detail
 * Have experience in a multi-dimensional data environment

",Full-time
4125894178,65588154.0,Data Engineer,"Job Title: Hybrid Data Engineer / Business Intelligence Analyst

Pay rate: $71 per hour

Duration: Until 11/2025

W2 contract only (No C2C)

Location- Johnston, IA 50131 (100% remote)




Monday-Friday- 40 hours a week.

Visa sponsorship is not available, now or in the near future, for this position.




 * Experience working in uncertain environments with limited requirements
 * SQL Query experience (1-3 years)
 * Combine raw data into useful summarizations
 * Python (3-5 years)
 * Pyspark (3-5 years)
 * Experience working with large scale data
 * Experience creating automated unit tests
 * Dashboard design experience (3-5 years)
 * Experience translating complex data into business visualizations
 * Experience with Tableau (1-3 years)




*** If this position may be interested to you, please email me back at somp767@kellyservices.com with your most up to date resume in word format) and advise the best time and number at which you can be reached****",Contract
4107287430,66321745.0,Junior Data Engineer,"SYNERGISTICIT is aware that the Job Market is Challenging because of Tech Layoffs due to which The Job market is flooded with hundreds and thousands of laid off Jobseekers who are competing with existing Jobseekers. For entry level Job seekers to get client interviews and jobs they need to differentiate themselves by ensuring they have exceptional skills and technologies to be noticed by clients.

Since 2010 we have helped Jobseekers differentiate themselves by providing the clients with candidates who have the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers. All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few. We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates looking to make their careers in IT Industry We welcome candidates with all visas and citizens to apply. We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

Candidates can benefit from skill enhancement if they fall into the below categories.

Candidates who Lack Experience or are freshers with No actual on Job experience with projects with clients Have had a break in careers Lack Technical Competency or skills being demanded by clients Different visa candidates (Like OPT/H4EAD/L2EAD ) who want to get employed and settle down in the USA please check the below links to see success outcomes of our candidates https://www.synergisticit.com/candidate-outcomes/

Synergisticit Pics /Salaries of Successful Candidates

Synergisticit at Oracle Cloudworld 2023

Synergisticit at Gartner Data & Analytics summit

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

REQUIRED SKILLS For Java /Software Programmers


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Project work on the skills
 * Knowledge of Core Java , javascript , C+
 * or software programming
 * Spring boot, Microservices, Docker, Jenkins and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Project work on the technologies needed
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, PowerBI, Time series analysis

Please understand skills and relevant experience on real world projects are required by clients for selection even if its Junior or entry level position the additional skills and Project work with hands on experience building projects at client site are the only way a candidate can be picked by clients. If not having the skills or hands on project work at client site then candidates can opt for skill enhancement to gain the required skills and project work. No third party candidates or c2c candidates

please only apply to the posting

No phone calls please. Shortlisted candidates would be reached out.",Contract
4133292915,10592585.0,Data Engineer,"Job Title: Data Engineer

Location: Portland, Oregon - Onsite

Position Type: Direct Hire- Full Time

Compensation: $100-110k Annual Salary

Reports to: CIO



C2C & third party vendors not accepted at this time - MUST currently reside within 30 miles of Portland, OR (relocation is not considered at this time)



Ledgent Technology has once again partnered with an amazing client of ours to fill their open Data Engineer position. If you are interested in joining a fast paced and growing organization, this opportunity is for you!



Overview:

We are seeking a skilled and detail-oriented Data Engineer to join our client's dynamic team in Portland, Oregon. This role involves working with hybrid database environments, optimizing in-house databases, and migrating them to Azure-hosted services. You will collaborate closely with application specialists and senior engineers while reporting directly to the CIO. If you are passionate about database optimization, cloud technologies, and modern data engineering practices, we want to hear from you!



Key Responsibilities:

· Design, optimize, and maintain in-house databases, with a focus on MS-SQL.

· Port and optimize existing databases to Azure-hosted services.

· Utilize Azure Data Factory, Azure Fabric, and other tools to enhance data processes.

· Develop and maintain ETL pipelines; experience with Boomi is a plus.

· Write and optimize complex SQL queries; proficiency in Python is a bonus.

· Collaborate with application specialists and senior engineers to meet data infrastructure needs.

· Ensure database performance, security, and scalability in a hybrid cloud environment.

Required Skills and Qualifications:

· Database Platforms: Extensive experience with MS-SQL is required; exposure to Oracle is a plus.

· Cloud Expertise: Proficiency in Azure-hosted database services is a must.

· Programming Languages: Expert-level proficiency in SQL; Python experience would be great to have.

· ETL Tools: Hands-on experience with Boomi or similar tools is beneficial. Familiarity with Azure Fabric and Data Factory is highly desirable.

· Primary Responsibilities: focus on database design, optimization, maintenance, porting, and optimizing in-house databases to Azure is a key part of the position.

· Ability to troubleshoot and resolve complex database performance issues.

· Experience working in a collaborative, cross-functional team environment.



Why Join Us?

· Be part of a growing, innovative team dedicated to leveraging modern cloud technologies.

· Work in a hybrid environment offering flexibility and opportunities for professional growth.

· Collaborate with passionate professionals in an engaging and supportive workplace.



If you are ready to take on this exciting opportunity as a Data Engineer and contribute to our mission of optimizing data systems, we encourage you to apply!

We look forward to learning more about how your expertise can drive success in this role!


All qualified applicants will receive consideration for employment without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, medical condition, genetic information, pregnancy, or military or veteran status. We consider all qualified applicants, including those with criminal histories, in a manner consistent with state and local laws, including the California Fair Chance Act, City of Los Angeles' Fair Chance Initiative for Hiring Ordinance, and Los Angeles County Fair Chance Ordinance. For unincorporated Los Angeles county, to the extent our customers require a background check for certain positions, the Company faces a significant risk to its business operations and business reputation unless a review of criminal history is conducted for those specific job positions.",Full-time
4149902690,1277.0,"Software Engineer - Python, GCP","You Lead the Way. We’ve Got Your Back.

With the right backing, people and businesses have the power to progress in incredible ways. When you join Team Amex, you become part of a global and diverse community of colleagues with an unwavering commitment to back our customers, communities and each other. Here, you’ll learn and grow as we help you create a career journey that’s unique and meaningful to you with benefits, programs, and flexibility that support you personally and professionally.

At American Express, you’ll be recognized for your contributions, leadership, and impact—every colleague has the opportunity to share in the company’s success. Together, we’ll win as a team, striving to uphold our company values and powerful backing promise to provide the world’s best customer experience every day. And we’ll do it with the utmost integrity, and in an environment where everyone is seen, heard and feels like they belong.

Join Team Amex and let's lead the way together.

As part of our diverse tech team, you can architect, code and ship software that makes us an essential part of our customers’ digital lives. Here, you can work alongside talented engineers in an open, supportive, inclusive environment where your voice is valued, and you make your own decisions on what tech to use to solve challenging problems. Amex offers a range of opportunities to work with the latest technologies and encourages you to back the broader engineering community through open source. And because we understand the importance of keeping your skills fresh and relevant, we give you dedicated time to invest in your professional development. Find your place in technology on #TeamAmex.

Job Description

Who we are:

The Finance Data Engineering group at American Express is entering into a new phase of technology transformation driven by opportunities to simplify processes, deepen business intelligence, analytics and reporting, and raise operational efficiency. If you have the talent and desire to deliver innovative products and services at a rapid pace, with hands on experience and strategic thinking, in areas of data management and analytics, cloud computing, and modern software engineering, join our leadership team to be part of our transformation journey.

What we’re looking for:

You’re a talented, creative, and motivated engineer who loves developing powerful, stable, and intuitive apps – and you’re excited to work with a team of individuals with that same passion. You’ve accumulated years of experience, and you’re excited about taking your mastery of Java, Kotlin, Python, or JavaScript to a new level. You enjoy challenging projects involving big data sets and are cool under pressure. You’re no stranger to fast-paced environments and agile development methodologies – in fact, you embrace them. With your strong analytical skills, your unwavering commitment to quality, your excellent technical skills, and your collaborative work ethic, you’ll do great things here at American Express.

Minimum Qualifications


 * Communicates, collaborates, and proactively engages with teammates (and cross-functional teams alike) to ensure requirements are delivered on-time.
 * Accountable to team for delivery of quality work.
   
   

Preferred Qualifications


 * Strong analytical skills and programming skills.
 * Solid Engineering Principles (OOP/Func Paradigms, TDD, DDD, SoC, Microservices, Caching Strategies).
 * Experience with at least one or more languages: Java, Kotlin, Go, Python, JavaScript, C++.
 * Experience with relational database engines (ie: MySQL, Postgres, MemSQL)
 * Experience with container technologies and runtimes (docker, containerd, Kubernetes, EKS, ECS, etc)
 * Experience with CICD pipelines (ie: Jenkins/CircleCI/XLR/Git/GitHub Actions)
 * Experience with different architectures: (ie: mvc, microservices, async/event-based, task-based, workflow-based, ETLs, data pipelines) a plus.
 * Experience with highly available, reliable, and secure APIs, services a plus.
 * Experience with cloud-based infrastructure resources (DevOps, CloudOps, SecOps, or SRE experience a plus)
   
   

Salary Range: $85,000.00 to $150,000.00 annually + bonus + benefits

The above represents the expected salary range for this job requisition. Ultimately, in determining your pay, we’ll consider your location, experience, and other job-related factors.

We back our colleagues and their loved ones with benefits and programs that support their holistic well-being. That means we prioritize their physical, financial, and mental health through each stage of life. Benefits include:


 * Competitive base salaries
 * Bonus incentives
 * 6% Company Match on retirement savings plan
 * Free financial coaching and financial well-being support
 * Comprehensive medical, dental, vision, life insurance, and disability benefits
 * Flexible working model with hybrid, onsite or virtual arrangements depending on role and business need
 * 20+ weeks paid parental leave for all parents, regardless of gender, offered for pregnancy, adoption or surrogacy
 * Free access to global on-site wellness centers staffed with nurses and doctors (depending on location)
 * Free and confidential counseling support through our Healthy Minds program
 * Career development and training opportunities
   
   

For a full list of Team Amex benefits, visit our Colleague Benefits Site.

American Express is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status, disability status, age, or any other status protected by law.

American Express will consider for employment all qualified applicants, including those with arrest or conviction records, in accordance with the requirements of applicable state and local laws, including the California Fair Chance Act, the Los Angeles County Fair Chance Ordinance for Employers, and the City of Los Angeles’ Fair Chance Initiative for Hiring Ordinance. For positions covered by federal and/or state banking regulations, American Express will comply with such regulations as it relates to the consideration of applicants with criminal convictions.

We back our colleagues with the support they need to thrive, professionally and personally. That's why we have Amex Flex, our enterprise working model that provides greater flexibility to colleagues while ensuring we preserve the important aspects of our unique in-person culture. Depending on role and business needs, colleagues will either work onsite, in a hybrid model (combination of in-office and virtual days) or fully virtually.

US Job Seekers/Employees - Click here to view the “Know Your Rights” poster and the Pay Transparency Policy Statement.

If the links do not work, please copy and paste the following URLs in a new browser window: https://www.dol.gov/agencies/ofccp/posters to access the three posters.

Employment eligibility to work with American Express in the U.S. is required as the company will not pursue visa sponsorship for these positions.",Full-time
4143931712,529693.0,Data Engineer,"We believe communication belongs to everyone. We exist to democratize phone service.  TextNow is evolving the way the world connects, and that's because we're made up of people with curious minds who bring an optimistic yet critical lens into the work we do.   We're the largest provider of free phone service in the nation. And we're just getting started.

Join us in our mission to break down barriers to communication and free the flow of conversation for people everywhere.

TextNow is looking for an experienced Data Engineer with hands-on experience designing and developing data platforms. You will own the design, development, and maintenance of TextNow's data platform , enabling us to make effective data-informed decisions. You will be part of cross-functional efforts to build scalable and reliable frameworks that support all of TextNow's business and data products. In this role, you can interact with different functional areas within the business and influence decision-making in a fast-growing mobile communications start-up.  

What You'll Do


 * Own TextNow's data warehouse, pipeline, and integration points between various business systems.  
 * Explore available technologies and develop solutions to build and improve our identity resolution solutions.
 * Design, Develop and support new and existing batch and real-time data pipelines and recommend improvements and modifications.  
 * Manage data to manage our AI/ML data products.  
 * Be a champion of TextNow's data ecosystem by working with engineering and infrastructure to implement data strategy for governance, security, privacy, quality, and retention that will satisfy business policies and requirements.  
 * Communicate strategies and processes around data modeling and architecture to cross-functional groups.  Identify, design, and implement internal process improvements.  
   
   

Who You Are


 * Have 3-8 years of experience working with data warehouse/data lake and ETL architectures, cloud data warehouses (Snowflake), and experience in Python and SQL, preferably at companies with fast-growing and evolving data needs.
 * Have at least 1-2+ years of experience with Airflow, Iceberg, Spark and Flink.
 * Exposure to AWS cloud data/ML services such as EKS, MWAA and Sagemaker.
 * Developed scalable data pipelines using Python/Scala, SQL, and distributed processing frameworks like Spark or Flink.
 * Experience driving technical vision for user identity resolution and data quality in previous roles is preferred.
 * Hands on experience working with building data features using Snowflake, dbt, and Python to power real-time AI/ML inference.
 * Respectfully candid with the ability to initiate and drive projects to completion.
 * Highly organized, structured work approach and dependable.
   
   

More about TextNow...

Our Values


 * Customer Obsessed (We strive to have a deep understanding of our customers)
 * Do Right By Our People (We treat each other with fairness, respect, and integrity)
 * Accept the Challenge (We adopt a ""Yes, We Can"" mindset to achieve ambitious goals)
 * Act Like an Owner (We treat this company like it's our own... because it is!)
 * Give a Damn! (We are deeply commited and passionate about our work and achieving results)
   
   

Benefits, Culture, & More


 * Strong work life blend
 * Flexible work arrangements (wfh, remote, or access to one of our office spaces)
 * Employee Stock Options
 * Unlimited vacation
 * Competitive pay and benefits
 * Parental leave
 * Benefits for both physical and mental well being (wellness credit and L&D credit)
 * We travel a few times a year for various team events, company wide off-sites, and more
   
   

Diversity And Inclusion

At TextNow, our mission is built around inclusion and offering a service for EVERYONE, in an industry that traditionally only caters to the few who have the means to afford it. We believe that diversity of thought and inclusion of others promotes a greater feeling of belonging and higher levels of engagement. We know that if we work together, we can do amazing things, and that our differences are what make our product and company great.

TextNow Candidate Policy

By submitting an application to TextNow, you agree to the collection, use, and disclosure of your personal information in accordance with the TextNow Candidate Policy",Full-time
4113541935,11801243.0,Data Engineer,"Overview

Methods+Mastery is seeking an experienced Data Engineer with a strong background in building scalable data pipelines that process unstructured text data to join our talented team. The ideal candidate will be comfortable taking on leadership roles in ambiguous tasks. This is an excellent opportunity to help shape the future of social media and digital marketing analytics while working with a diverse and passionate team.

Our new Data Engineer will work directly with members of the multi-disciplinary Methods+Mastery team to produce work for top clients in an entrepreneurial and collaborative environment that values team above all. This work will include counseling Methods+Mastery team members on feasible data management solutions for client projects and collaborating with our Data Scientist to build out data pipelines.

Methods+Mastery is an entrepreneurial, collaborative environment that values talented, creative people who like to work with others to create cutting-edge programs for our clients. We’re seeking someone who is passionate about social, data and analytic tools. Someone who has an innate curiosity and the desire to find out ""why?” Our team is growing at an amazing rate, and this is an opportunity to produce work for top clients in an entrepreneurial and collaborative environment that values team above all. We do great work – and hire only great people, too.

Methods+Mastery is actively committed to increasing our team’s diversity, aggressively eliminating systemic barriers to equity, and fostering a culture where different backgrounds and perspectives are respected and celebrated. We firmly believe a team of many diverse perspectives not only makes M+M a better place to work, it is also critically important for producing creative and thoughtful work that represents the world we live in. To that end, we strongly encourage applications from women, people of color, members of the LGBTQ+ community, veterans, individuals with disabilities, and neurodivergent people.

The anticipated salary range for this position is $150,000 - $180,000.

Salary is based on a range of factors that include relevant experience, knowledge, skills, other job-related qualifications, and geography. A range of medical, dental, vision, 401(k) matching, paid time off, and/or other benefits also are available.

Sound like what you’re looking for?

Responsibilities


 * Design, build, and maintain scalable data pipelines, ETL processes, and data integration solutions to support our marketing and business analytics needs.
 * Leverage cloud computing platforms (e.g., GCP, Azure) to develop and deploy data infrastructure and applications.
 * Collaborate with cross-functional teams, including analytics, research, and strategy, to define data requirements, create data models, and implement data solutions.
 * Optimize data storage, processing, and retrieval performance to ensure efficient and reliable access to high-quality data.
 * Develop and maintain data documentation, including data artifacts, data lineage, and data quality metrics
 * Proactively identify and address data-related challenges and opportunities, taking the initiative to lead ambiguous tasks and drive projects to completion
 * Stay up-to-date with the latest industry trends, technologies, and best practices in data engineering and marketing analytics to ensure the company remains competitive
 * Support ad-hoc data requests and analysis from various business units, ensuring timely and accurate delivery of insights
 * Participate in the evaluation and selection of data-related tools and technologies, and contribute to the development of data engineering best practices and standards
   
   

Qualifications

The ideal candidate is keenly strategic, versatile, and insights-driven; someone who thrives in an energetic, fast-paced entrepreneurial environment.

Must-haves


 * Bachelor's degree in Mathematics, Statistics, Economics, Computer Science, Engineering, or a related quantitative discipline
 * 2+ years of professional experience as a Data Engineer utilizing Python, R, Rust, C++, or Scala in cloud computing platforms (AWS, GCP, Azure)
 * Deploying and productionalizing cloud infrastructure as code (e.g. Terraform, Serverless Framework, Pulumi)
 * Proven experience in designing, deploying, and maintaining data pipelines that process and integrate text and image data, ETL processes, and data integration solutions in a production environment, and a proven track record of delivering high-quality, scalable, and reliable data solutions
 * Strong knowledge of SQL and NoSQL databases as well as data warehousing concepts
 * Knowledge of containerization technologies like Docker and Kubernetes and experience with deploying data pipelines in containerized environments
 * Experience with version control systems like Git and familiarity with continuous integration and delivery (CI/CD) processes
 * Familiarity with big data technologies (e.g., Hadoop, Spark) and data visualization tools (e.g., Looker, Tableau, Power BI)
 * Excellent problem-solving skills, with the ability to think critically and adapt to changing requirements
 * Comfortable with ambiguity and taking on leadership roles in ambiguous tasks, demonstrating initiative and resilience in the face of challenges
 * Detail-oriented, with strong organizational and project management skills, and the ability to manage multiple projects and priorities simultaneously
 * Passion for learning and staying up-to-date with the latest data engineering technologies and trends
   
   

Nice To Haves


 * Experience working in a fast-paced consulting environment, with a proven ability to handle multiple projects simultaneously, prioritize tasks, and meet deadlines
 * Experience working with text and image data from social media platforms, such as Twitter, Reddit, or YouTube, and knowledge of social media analytics tools and methodologies
   
   

To be successful, the candidate must have a desire to deliver quality work for clients/brands, be a team player and demonstrate the ability to get the job done. You’ll need a serious interest of trends, best practices, technology and business applications on the Internet and within Methods+Mastery.",Full-time
4128413303,28417.0,Data Engineer,"Candidates should be eligible to work for any employer in the United States without needing Visa sponsorship. W2 eligible candidates only, cannot work with corp-to-corp organizations.




Data Engineer – Databricks/Python

What You’ll Do

 * Design, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals
 * Collaborate with data engineers, data consumers, and other team members to come up with simple, functional, and elegant solutions that balance the data needs across the organization
 * Solve complex data problems to deliver insights that helps the organization achieve its goals
 * Create data products that will be used throughout the organization
 * Advise, consult, mentor and coach other data and analytic professionals on data standards and practices
 * Foster a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytic solutions
 * Develop and deliver documentation on data engineering capabilities, standards, and processes; participate in coaching, mentoring, design reviews and code reviews
 * Partner with business analysts and solutions architects to develop technical architectures for strategic enterprise projects and initiatives.
 * Deliver awesome code




Experience

 * 7+ years relevant and progressive data engineering experience
 * Deep Technical knowledge and experience in Databricks, Python, Scala, Microsoft Azure architecture and platform including Azure Event Hub and ADF (Azure Data Factory) pipelines
 * Hands-on experience working with data pipelines using a variety of source and target locations (e.g., Databricks, SQL Server, Data Lake, file-based, SQL and No-SQL database)
 * Experience in engineering practices such as development, code refactoring, and leveraging design patterns, CI/CD, and building highly scalable data applications and processes
 * Experience developing batch ETL pipelines; real-time pipelines are a plus
 * Knowledge of advanced data engineering concepts such as dimensional modeling, ETL, data governance, data warehousing involving structured and unstructured data
 * Thorough knowledge of SQL Server including T-SQL and stored procedures
 * A successful history of manipulating, processing and extracting value from large disconnected datasets.
 * Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
 * Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.




Other

 * Can be worked 100% remotely from any US time zone, but position will require working PST hours

",Contract
4151495931,164159.0,"Senior Data Engineer-Data Engineering (Austin, San Antonio or Dallas)","Since H-E-B Digital Technology’s inception, we’ve been investing heavily in our customers’ digital experience, reinventing how they find inspiration from food, make food decisions, and ultimately get food into their homes. This is an exciting time to join H-E-B Digital—we’re using the best available technologies to deliver modern, engaging, reliable, and scalable experiences to meet the needs of our growing audience.

As a Senior Data Engineer, you’ll use an advanced analytical, data-driven approach to drive a deep understanding of our fast-changing business and answer real world questions. You’ll work with stakeholders to develop a clear understanding of data and data infrastructure needs, resolve complex data-related technical issues, and ensure optimal data design and efficiency.

Once you’re eligible, you’ll become an Owner in the company, so we’re looking for commitment, hard work, and focus on quality and Customer service. “Partner-owned” means our most important resources—People—drive the innovation, growth, and success that make H-E-B The Greatest Omnichannel Retailing Company.

Do you have a:

HEART FOR PEOPLE… you’re willing to facilitate solutions with multiple engineers, provide upward communication, and mentor others?

HEAD FOR BUSINESS… you consistently demonstrate and uphold the standards of coding, infrastructure, and process?

PASSION FOR RESULTS… you’re capable of high-velocity contributions in multiple technical domains?

We are looking for:


 * 5+ years of experience related to data engineering
   
   

What is the work?

Design & Development:


 * Designs data patterns that support creation of datasets for analytics; implements calculations, cleanses data, ensures standardization of data, maps / links data from more than one source
 * Performs data validation and quality assurance on work of junior peers and write automated tests
 * Maintains / streamlines existing data pipelines end to end
 * Builds / supports more complex data pipelines, application programming interfaces (APIs), data integrations, data streaming solutions, predictive model implementations (quality, velocity, etc.)
 * Identifies more complex data from upstream sources to enable new capabilities.
 * Engages in testing of the technical solutions to ensure data integrity and system functionality of own work and broader system, E2E
 * Builds large-scale batch and real-time data pipelines with big data processing frameworks.
 * Designs / develops data integrations to support application engineering and system integration
 * Designs / develops / maintains large data pipelines; diagnoses / solves production support issues
 * Creates documentation and training related to technology stacks and standards within assigned team
 * Designs / implements monitoring capabilities based on business SLA and data quality
 * Uses / contributes to refinement of Digital Engineering-related tools, standards, and training
 * Engages / collaborates with external technical teams to ensure timely, high-quality solutions
 * Engages with shared services teams and vendors when necessary
 * Works closely with Product, Data Science, Application, and Analytics teams to develop a clear understanding of data and data infrastructure needs; assists with data-related technical issues; ensures optimal data design and efficiency
 * Performs full SDLC process, including planning, design, development, certification, implementation, and support
 * Interacts with Product, Business, Analyst stakeholders to confirm data quality, discuss requirements, and support data testing
 * Peer reviews other team members code; learns / adapts from peer review of own code
 * Contributes to overall design, architecture, security, scalability, reliability, and performance
 * Mentors / provides support to junior Data Engineers
 * Builds more complex data models to deliver insightful analytics; ensures highest standard in data integrity
 * Knowledge in machine learning concepts
   
   

What is your background?


 * A related degree or comparable formal training, certification, or work experience
 * 5+ years of experience related to data engineering
 * Experience in Lean Startup or Agile development methodologies
 * Experience working in large scale infrastructure, large data sets, and mission critical SLAs
   
   

Do you have what it takes to bean H-E-B Senior Data Engineer?


 * Advanced knowledge of Lean Startup / Agile methods
 * Knowledge of business intelligence, analytics and reporting, and application integration
 * Knowledge of data architectures such as data warehouse, data lake, and data mesh and when to apply
 * Strong working understanding of data architecture and data modelling best practices and guidelines for various data and analytic platforms
 * Strong working understanding of coding standards and design principles / patterns
 * Strong prioritization skills
 * Strong verbal / written communication and data presentation skills
 * Ability to deliver on ambiguous projects with incomplete information
 * Ability / willingness to learn new technologies as they emerge
 * Ability to calmly work under pressure
 * Ability to work a flexible schedule as needed
 * Ability to collaborate across multiple work locations
 * Ability to work within a team, and willingness to take feedback from peers and mentors
   
   

Can you...


 * Function in a fast-paced environment with the ability to work from home and / or office
 * Work extended hours; sit for extended periods",Full-time
4118301205,1586.0,"Data Engineer, FinAuto, FinAuto - GREF Tech","Description

Are you interested in building high-performance and globally scalable reporting and analytics infrastructure that support Amazon's Global Real Estate and Facilities (GREF) organization’s current and future growth? Are you seeking an environment where you can drive innovation leveraging the scalability and innovation with Amazon's AWS cloud services? Do you have a passion for ensuring a positive customer experience? This is the opportunity for you.

In Finance Automation, we built technology to simplify and automate the processes Amazon uses to manage its financial relationships with external stakeholders. We are on a journey to create technology that simplifies the processes that Amazon uses to procure, collect and pay. We recently formed a new GREF Technology team which is the software development team for GREF. This team builds products and tools to enable Amazon’s corporate real estate team as they build and operate the company’s facilities worldwide.

The GREF Tech team is looking for a passionate, solution-oriented Data Engineer to lead the implementation of the analytical data infrastructure that will guide the decision making behind initiatives such as space planning, design and construction, corporate security, travel, transportation, lease, facilities, and other key projects within the Global Real Estate and Facilities (GREF) domain.

The team is committed to building the next generation reporting and analytics platform to support Amazon's rapidly growing workforce and improve employee experience. Our projects span multiple organizations and require coordination of data integrity, test design, analysis, validation, and documentation.


 * You will act as the business-facing subject matter expert for data storage and feature instrumentation, with the responsibility of managing end-to-end execution and delivery across various work streams.
 * You will help drive data architecture across many large datasets, perform exploratory data analysis, implement new data pipelines that feed into or from critical data systems at Amazon.
 * You will be responsible for designing and implementing scalable ETL processes in the AWS platform to support the rapidly growing and dynamic business demand for data, and use it to deliver the data as service which will have an immediate influence on day-to-day decision making and strategic initiatives.
 * You will hold a highly visible role that requires interaction with leaders across Finance Automation and GREF.
 * You will provide technical leadership on high-impact cross-functional initiatives
   
   

Basic Qualifications


 * 3+ years of data engineering experience
 * Experience with data modeling, warehousing and building ETL pipelines
 * Experience with SQL
 * Experience in at least one modern scripting or programming language, such as Python, Java, Scala, or NodeJS
 * Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets
 * Experience with big data technologies such as: Hadoop, Hive, Spark, EMR
   
   

Preferred Qualifications


 * Experience as a data engineer or related specialty (e.g., software engineer, business intelligence engineer, data scientist) with a track record of manipulating, processing, and extracting value from large datasets
 * Experience working on and delivering end to end projects independently
 * Experience providing technical leadership and mentoring other engineers for best practices on data engineering
 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com Services LLC

Job ID: A2866575",Full-time
4151635849,52186161.0,"Software Engineer, Path Planning","About this role:

Pickle is on the hunt for a dynamic and driven Software Engineer, Path Planning to revolutionize the future of warehouse automation. You’ll design and develop algorithms that enable our robots to navigate complex environments with precision. If you thrive on solving real-world robotics challenges in a collaborative, fast-paced startup environment, we’d love to hear from you

What You’ll Accomplish:


 * Design, implement, and optimize motion planning and control systems for mobile manipulation robots
 * Collaborate with cross-functional teams including mechanical, electrical, and software engineers to integrate motion planning algorithms with hardware and software systems
 * Participate in the refinement of robotic path planning algorithms to adapt to evolving customer needs and varying operational conditions
 * Test and iterate on solutions to improve reliability, reduce failure rates, and enhance the overall performance of the robot's mobile manipulation capabilities
 * Conduct performance tuning in simulation and on robot to ensure efficient resource usage and minimize latency in robotic operations
 * Contribute to the architecture of scalable software systems that support multiple robot deployments across diverse environments
   
   
   
   
   

Who You Are:


 * A software engineer with 3-7 years of experience working in robotics environments, whether in academia, industry, or research settings
 * Holder of a bachelor's degree in computer science, robotics, electrical engineering, or a related field; a master's degree or higher is strongly preferred
 * An expert in Python, with extensive hands-on experience developing and optimizing robotics software. Experience with additional programming languages, such as Drake, is highly preferred
 * Capable of adapting to new tools and frameworks as needed
 * Experienced in motion/path planning, with a strong understanding of robot kinematics, control systems, and navigation algorithms
 * Mathematically inclined, with a deep understanding of algorithms, data structures, and mathematical optimization
 * Familiar with test-driven development (TDD) and comfortable applying TDD practices to ensure reliability and maintainability in product development
 * Detail-oriented with a systems-level mindset, able to integrate motion planning software into larger robotic architectures
 * Collaborative and communicative, able to work closely with multidisciplinary teams to drive product innovation and troubleshooting
 * Willing to work in-office from our Cambridge, MA location at least three days per week, fostering a strong team dynamic and hands-on testing with our robotics systems
 * Adaptable and eager to learn, staying up to date with the latest advancements in robotics, AI, and motion planning
   
   
   
   
   

About Pickle Robot
Pickle Robot is a pioneer in Physical AI for supply chain applications. Today Pickle robots autonomously unload trucks, trailers, and import containers at human-scale or better performance. The alternative is manual work that is difficult, dirty, sometimes dangerous, and increasingly hard to staff at distribution centers around the globe. Pickle Robot is laser focused on automating truck unloading using generative AI, machine learning, computer vision, advanced sensors, and industrial robotics to deliver engineered products customers rely on. Pickle Robot Unload Systems work alongside people on loading docks to make the work safer, faster, and more efficient. Pickle robots are physical AI that unload trucks.

Pickle provides best-in-class benefits including health, dental, & vision insurance; unlimited vacation, along with all federal and state holidays; 401K contributions of 5% your salary, travel supplies, and other items to make your working life more fun, comfortable, and productive.",Full-time
4045412406,66321745.0,ENTRY LEVEL DATA ENGINEER (REMOTE),"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you need

SynergisticIT understands the complex nature of the job market and how difficult it can be to secure a position, especially for fresh graduates. Therefore, we assist and help tech-savvies to convert their passions into professions. We go above and beyond to keep you working in your niche.

As we focus on long-term success, we provide complete career development solutions. From job search to upskilling portfolio and interview preparation, we can guide you at every step of your career.

SynergisticIT spares no efforts to connect you with a large network of tech giants, including Google, Apple, PayPal, Dell, Cisco, Client, etc. Presently, we are actively looking for ENTRY LEVEL DATA ENGINEER a driven mindset. Get the right opportunity and gain experience in building web-centric solutions on Java.

Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or anyone looking to make their career in IT Industry

We also assist in filing for STEM extension and H1b and Green card filing.

Candidates who are serious about their future in the IT Industry and have set big goals for themselves.

Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill Enhancement Programs if the candidates are missing skills or experience which our clients need with great outcomes

Candidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancement

Candidates Who Lack Experience

Have had a break in careers

Lack Technical Competency

candidates who want to get employed and make a career in the Tech Industry

Please Also Check The Below Links

https://www.synergisticit.com/candidate-outcomes/

https://www.synergisticit.com/java-track/

https://www.synergisticit.com/data-science-track/

https://www.synergisticit.com/which-is-the-best-option-for-tech-job-seekers-staffing-companies-consulting-companies-bootcamps-or-synergisticit/

https://www.synergisticit.com/contact-us/

If the skills are not a match candidates can opt for Skill enhancement. Or their resume can be sent out to clients to see if responses are achievable

REQUIRED SKILLS For Java/Software Programmers


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Core Java , javascript , C&plus;&plus; or software programming
 * Spring boot, Microservices and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, Python, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, Time series analysis

Technical skills are required by clients for selection even if its Junior or entry level position each additional Technical skill helps a candidate's resume to be picked by clients over other job seekers.

Clients hire candidates with the right technical skills which they need and reject candidates who lack the required technical skills.

No third party candidates or c2c candidates

Please apply to the posting

No phone calls please. Shortlisted candidates would be reached out",Full-time
4146764370,29308.0,Data Science Software Engineer,"Candidates applying must have active US Security Clearance with US citizenship only




 * Software development experience with JavaScript and Python
 * Develop and deploy full-stack, AI-based enterprise applications
 * Test, troubleshoot, and enhance software applications
 * Conduct design and development reviews
 * Write application specifications and documentation
 * Bachelors (or equivalent) in Computer Science preferred
 * Experience with Git
 * JavaScript frameworks (React, Redux, Vue, Backbone, or Angular)
 * Deploying software to least one of the leading cloud computing platforms
 * SQL and NoSQL databases
 * Knowledge in data structure and algorithm design and implementation preferred",Full-time
4125063911,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
3875377182,46623.0,Data Engineer,"Description

Your role at GEI.

GEI Consultants has an opening in our Operational Development Team for a qualified Data Engineer to support a variety of systems and data engineering tasks focused on data flow activities. The majority of our systems are based in MS SQL Server, Tableau Server, Azure, and FastField Forms. This person will primarily work closely with members of the Operational Development Team and with members of our IT staff. The ideal candidate will be focused, detail-oriented, and driven to attain and maintain very high standards for efficiency and accuracy in data acquisition and integration into our systems. The ideal candidate will have more than 3 years of data engineering experience in the AEC industry or in similar science and/or engineering environments. GEI seeks a committed, self-motivated, organized and detail-oriented individual who anticipates issues and thrives on creative, independent problem solving within a rapid, deadline-driven environment.

Essential Responsibilities & Duties


 * ETL of data from a wide variety of sources
 * Database and Data Warehouse design/expansion/backup & recovery
 * Index management and optimization
 * Support data sources for Tableau Server, Power BI, and ArcGIS
 * Stored procedure development and maintenance
 * Identify new opportunities within GEI where existing business approaches to data can be replaced with a more efficient/automated data flow and presentation of data for analysis
 * Develop and optimize ETL/SSIS packages to facilitate data transfer between FTP, remote data loggers, Azure, and on-premises databases
 * Troubleshoot SSIS package permission issues related to execute-as/data source read/write access
 * SQL Agent Job development and monitoring
 * Develop data reporting and visualizations as specified by clients using Tableau, SSRS, etc
 * Perform DML and DDL via tsql/stored procedures executed directly within SSMS and remotely via SSIS
 * Develop test plans, implementation plans, and project timelines for various data engineering projects
 * Define, prioritize, communicate, and foster shared understanding of project objectives and scope
 * Coordinate the development of standard operating procedures (SOPs), technical training programs, and QA/QC procedures for staff and work product
 * Team with all staff necessary to complete assignments
 * Collaborate with technical team members to ensure the solution design satisfies project objectives and business requirements
 * Other duties as assigned
   
   

Minimum Qualifications


 * 3+ years of experience in a position performing similar data engineering tasks
 * Proven record of ability to design, manage, and support MS SQL Server and Azure databases
 * Ability to work with the following programming/mark-up/scripting languages preferred: VB.net, python, XML, javascript, and R
 * Bachelor's Degree, from an accredited college or university
 * MS SQL Server/Azure certification preferred
 * Ability to develop project plans and meet deadlines
 * Self-starter with attention to detail and stakeholder needs
 * Able to critically analyze and solve problems of a complex nature
 * Excellent Communication skills
 * Able to work on multiple projects of moderate complexity simultaneously and independently
 * Proficient in organization and time management skills
 * Familiarity with engineering, environmental science, and/or chemistry subject matter preferred.
 * Able to work effectively in GEI’s partnership model, including a team environment, building rapport and relationships.
   
   

We are GEI.

Some of the world’s most pressing problems - from climate change to sustainable development, to critical infrastructure and the future of our energy supply - need our brightest and diverse minds working together to create safer, more resilient communities for tomorrow.

We are technical experts, collaborators, and entrepreneurs who draw from diverse backgrounds to solve our clients’ most complex challenges.

With nearly 60 offices across North America, we offer a range of engineering, science, and technical consulting services. Our range of expertise, project types, and culture make us the choice for top talent in the AEC industry.

Employee-owned. Employee-focused.

As a 100% employee-owned company, our employees support our flat leadership structure, have a say in how our business operates and benefit from our financial success. We are committed to employee growth with career development opportunities, competitive total rewards, a well-being program, flexible work arrangements and more. Our company culture is driven by our 4 Cs - we are Client-Centered, Curious, Collaborative, and Community Minded - which support our focus on sustainability, safety, diversity, equity and inclusion. Get to know us better by visiting GEI’s career site here.

GEI’s Total Rewards Package


 * Market-Competitive Compensation, including Eligibility for an Annual Performance Bonus
 * Pay Range For This Position: $33.65-72.11/hour
 * Comprehensive Benefits Program, including Medical, Dental, Vision, Life, Disability and More
 * Well-Being Program and Paid Parental Leave
 * Commuter Benefits
 * Hybrid Work Schedules and Cell Phone Stipends
 * GEI University (GEIU) with Continuing Education Assistance and Tuition Reimbursement
 * Connecting Conversation Program with a Focus on Professional Development and Opportunities for Advancement
 * Support and Financial Rewards for Publication Awards, Professional Dues, and Professional Licenses
 * Paid Holidays and Generous Paid Time Off Program
 * Rewards and Recognition
 * GEI-Funded Profit Sharing and 401(k)
 * Opportunity to be an Owner and Shareholder (Learn more here)
 * A Vibrant Culture that is Focused on Partnership, Sustainability, Giving Back to Our Communities and Diversity, Equity and Inclusion
 * And More…
   
   

Physical Job Requirements

Sedentary

X

Light

Medium

Other

Activity Level Throughout Workday

Physical Activity Requirements

Occasional

(0-35% of day)

Frequent

(33-66% of day)

Continuous

(67-100% of day)

Not Applicable

Sitting

X

Standing

X

Walking

X

Climbing

X

Lifting (floor to waist level) (in pounds)

X

Lifting (waist level and above) (in pounds)

X

Carrying objects

X

Push/pull

X

Twisting

X

Bending

X

Reaching forward

X

Reaching overhead

X

Squat/kneel/crawl

X

Wrist position deviation

X

Pinching/fine motor skills

X

Keyboard use/repetitive motion

X

Taste or smell (taste=never)

X

Talk or hear

X

Accurate 20/40

Very Accurate 20/20

Not Applicable

Near Vision

X

Far Vision

X

Yes

No

Not Applicable

Color Vision (ability to identify and distinguish colors)

X

Sensory Requirements

Minimal

Moderate

Accurate

Not Applicable

Depth perception

X

Hearing

X

Environmental Requirements

Occupational Exposure Risk Potential

Reasonably Anticipated

Not Anticipated

Blood borne pathogens

X

Chemical

X

Airborne communicable diseases

X

Extreme temperatures

X

Radiation

X

Uneven surfaces or elevations

X

Extreme noise levels

X

Dust/particular matter

X

Other (exposure Risks)

Usual workday hours:

X

8

10

12

Other work hours

GEI is an AA/equal opportunity employer, including disabled and veterans.",Full-time
4146998313,3283052.0,Data Engineer II (Growth),"The Data Engineer position within Grubhub's Growth team plays a pivotal role in enhancing our big data infrastructure and refining existing pipelines that drive Grubhub's growth marketing efforts. Collaborating closely with Customer Engagement and Analytics teams, the Data Engineer will partner to develop automated marketing campaigns and create custom audience segments for email, push, and/or in-app initiatives. Additionally, they will be responsible for developing and maintaining monitoring dashboards to ensure the effectiveness and quality of campaign delivery. As a Data Engineer, you will be expected to develop a well-informed long-term data architecture, lead structured problem-solving efforts, and remain flexible and adaptable to seize new opportunities as they arise. Our team's responsibilities extend to generating automated analytical reports and metrics that are reviewed at senior levels. Candidates should possess expertise in designing, creating, managing, and leveraging large datasets for business purposes.




This position provides a distinct chance to oversee and develop novel solutions for data storage, pipelining, and visualization starting end-to-end. The pipelines and processes developed in this role will be indispensable for accomplishing business needs. As such, we are seeking an individual who can not only excel in engineering tasks but also demonstrate a keen interest in understanding the business intent of their work. The ideal candidate should possess exceptional attention to detail, strong communication skills, resourcefulness, a customer-centric approach, a team-oriented mindset, the ability to work independently in a fast-paced environment, and have an ownership mindset.




The Impact You Will Make

 * Work with high volumes of data and distributed systems using technologies such as Spark, Hive, AWS EMR, AWS S3, Azkaban, Presto
 * Designing and implementing robust data pipelines to efficiently process and analyze large volumes of data
 * Developing scalable and maintainable data storage solutions to accommodate the growing needs of the organization
 * Collaborating with analysts to understand their requirements for metrics and automate them for campaigns launched, so they can scale and evaluate the performance
 * Building monitoring and alerting systems to ensure the integrity and availability of data pipelines
 * Optimizing query performance and data processing workflows to reduce latency and improve efficiency
 * Providing technical expertise and guidance to other team members on best practices for data engineering and architecture
 * Continuously evaluating new technologies and tools to enhance the team's capabilities and improve efficiency.




What You Bring to the Table

 * Bachelor's degree required in Computer Science/Information technology.
 * 3+ years of relevant experience in a data engineering role
 * Excellent knowledge of SQL
 * 2+ years of experience with Python programming language
 * Background in ETL and data processing, familiar with how to transform data to meet our goals i.e. launch automated campaigns, and a monitoring dashboard
 * Ability to take on ownership of projects at both a technical and organizational level
 * Uses business acumen and judgment to drive towards top line business outcomes and impact
 * Sources inputs, perspectives, and risks from multiple partners to arrive at a balanced insight and recommendation
 * Strong written and oral communication skills to effectively partner with various functional groups
 * Willingness to understand the larger business context
 * Strong self-management / prioritization capabilities
 * Enthusiasm for data and the desire to work with a great team!




Got these? Even better

 * Master’s degree in Computer Science/Information technology
 * Experience with AWS or another cloud service provider
 * Understanding of conventional data warehousing principles like 3NF, star schemas, and dimensional modeling
 * Have a strong enthusiasm for learning and sharing knowledge
 * Thorough attention to detail and precision, with a structured and organized approach




As a matter of company policy, Grubhub does not sponsor applicants for employment visa status for this role.




The base salary range for this position is below:



Illinois: $117,000-176,500

New York: $129,000-$194,000




Grubhub uses geographic-specific salary structures, which means the salary offered may vary depending on where the job is located. The final salary offer will take into account various factors, such as the candidate's skills, education, training, credentials, and experience.




And Of Course, Perks!

 * Flexible PTO. Grubhub employees enjoy a generous amount of time to recharge.
 * Health and Wellness. Excellent medical, dental and vision benefits, 401k matching, employee network groups and paid parental leave are just a few of our programs to support your overall well-being.
 * Free Meals. Our employees get a weekly Grubhub credit to enjoy
 * Social Impact. At Grubhub we believe in giving back through programs like the Grubhub Community Fund. Employees are also given paid time off each year to support the causes that are important to them.




Grubhub is an equal opportunity employer. We welcome diversity and encourage a workplace that is just as diverse as the customers we serve. We evaluate qualified applicants without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other legally protected characteristics. If you’re applying for a job in the U.S. and need a reasonable accommodation for any part of the employment process, please send an email to TalentAcquisition@grubhub.com and let us know the nature of your request and contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address.




If you are a resident of the State of California and would like a copy of our CA privacy notice, please email privacy@grubhub.com.",Full-time
4134096666,1058415.0,Data Engineer,"Benzinga is seeking an experienced Data Engineer to join our Data Science team. In this role, you will be responsible for designing, building, and maintaining the systems that collect, store, and process our vast amounts of web traffic, advertising, financial, and product usage data. Your expertise and collaboration with the Data Science team will be crucial in ensuring the integrity, availability, and performance of our data platforms, enabling our team members and partners to make data-driven decisions.

Key Responsibilities


 * Design, develop, and optimize scalable data pipelines to support data collection, transformation, and storage.
 * Build and maintain efficient and reliable ETL processes to ingest data from various sources into our data warehouse.
 * Ensure data integrity, quality, and security across all data systems and processes.
 * Collaborate with stakeholders to understand data needs and deliver solutions that meet business requirements.
 * Monitor and troubleshoot data pipeline performance, addressing any issues that arise promptly.
 * Implement best practices for data governance, including metadata management, data cataloging, and data privacy compliance.
 * Stay current with emerging technologies and trends in data engineering and apply them to improve our data infrastructure.
   
   

Qualifications


 * Bachelor’s degree in Computer Science, Engineering, a related field, or equivalent experience. A master’s degree is a plus.
 * 3+ years of experience in data engineering, software development, or a related role
 * Strong experience with cloud platforms like AWS, Google Cloud Platform, or Azure, and familiarity with data warehousing solutions like Snowflake, Redshift, or BigQuery.
 * Solid understanding of database systems (SQL and NoSQL) and experience with data modeling and schema design.
 * Experience with data pipelines or ETL tools such as DBT, Dataform, or Apache Airflow
 * Advanced SQL skills
 * Proficiency in Python or other programming languages
   
   

Preferred Experience


 * Experience using Segment or a similar CDP tool
 * Exposure to web application, marketing, or advertising data
 * Experience in the financial services or media industry.",Full-time
4152470849,57681755.0,Data Engineer,"Data Engineer

Hybrid to Plano TX, Reston VA




Background in mortgage and financial experience.

• SQL, writing scripts.

• Programming Languages: python, java

• UAT

• Writing & communication skills.

• AWS: RDS from data side will be plus

• Transform the format if needed




Skill set: Apache Spark, Apache Airflow, Scala , Apache Hudi , Apache Griffin .

AWS Tools: S3 and S3 operations (CRUD), EMR & EMR , Glue Data Catalog, MWAA (Managed Workflows Apache Airflow), Lambdas, AWS Batch, AWS Deequ.",Contract
4152481656,69732469.0,Sr. Data Engineer,"Role: Sr. Data Engineer

Location: SFO Bay Area, CA - Hybrid

Duration: Fulltime




Primary responsibilities:

 * Create and maintain optimal data pipeline architecture
 * Build data pipelines that transform raw, unstructured data into formats that data analyst can use to for analysis
 * Assemble large, complex data sets that meet functional / non-functional business requirements

Identify, design, and implement internal process improvements:

 * automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
 * Build the infrastructure required for optimal extraction, transformation, and delivery of data from a wide variety of data sources using SQL and AWS Big Data technologies
 * Work with stakeholders including the Executive, Product, Engineering, and program teams to assist with data-related technical issues and support their data infrastructure needs.
 * Develop and maintain scalable data pipelines and builds out new integrations and processes required for optimal extraction, transformation, and loading of data from a wide variety of data sources using scalable distributed Data technologies
 * Implements processes and systems to validate data, monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it
 * Write unit/integration tests, adopt Test-driven development, contribute to engineering wiki, and document work
 * Performs root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement




Qualifications:

 * 6+ yrs experience and bachelor’s degree in computer science, Informatics, Information Systems or a related field; or equivalent work experience
 * In-depth working experience of distributed systems Hadoop/MapReduce, Spark, Hive, Kafka and Oozie/Airflow
 * At least 5 years of solid production quality coding experience in data pipeline implementation in Java, Scala and Python
 * Experience with AWS cloud services: EC2, EMR, RDS
 * Experience in GIT, JIRA, Jenkins, Shell scripting
 * Familiar with Agile methodology, test-driven development, source control management and test automation




Nice to have skills:

 * Experience building Marketing Data pipelines including Direct Mail will be a big plus
 * Experience with Snowflake and Salesforce Marketing Cloud
 * Working knowledge of open-source ML frameworks and end-to-end model development life cycle
 * Previous working experience with running containers (Docker/LXC) in a production environment using one of the container orchestration services (Kubernetes, AWS ECS, AWS EKS)",Full-time
4115431156,15982140.0,Data Engineer,"

Particle41 is seeking a talented and versatile Data Engineer to join our innovative team. As a Data Engineer, you will play a key role in designing, building, and maintaining robust data pipelines and infrastructure to support our clients' data needs. You will work on end-to-end data solutions, collaborating with cross-functional teams to ensure high-quality, scalable, and efficient data delivery. This is an exciting opportunity to contribute to impactful projects, solve complex data challenges, and grow your skills in a supportive and dynamic environment.

In This Role, You Will:



Software Development


 * Design, develop, and maintain scalable ETL (Extract, Transform, Load) pipelines to process large volumes of data from diverse sources.
 * Build and optimize data storage solutions, such as data lakes and data warehouses, to ensure efficient data retrieval and processing.
 * Integrate structured and unstructured data from various internal and external systems to create a unified view for analysis.
 * Ensure data accuracy, consistency, and completeness through rigorous validation, cleansing, and transformation processes.
 * Maintain comprehensive documentation for data processes, tools, and systems while promoting best practices for efficient workflows.
   
   

Requirements Gathering and Analysis


 * Collaborate with product managers, and other stakeholders to gather requirements and translate them into technical solutions.
 * Participate in requirement analysis sessions to understand business needs and user requirements.
 * Provide technical insights and recommendations during the requirements-gathering process.
   
   

Agile Development


 * Participate in Agile development processes, including sprint planning, daily stand-ups, and sprint reviews.
 * Work closely with Agile teams to deliver software solutions on time and within scope.
 * Adapt to changing priorities and requirements in a fast-paced Agile environment.
   
   

Testing and Debugging


 * Conduct thorough testing and debugging to ensure the reliability, security, and performance of applications.
 * Write unit tests and validate the functionality of developed features and individual elements.
 * Writing integration tests to ensure different elements within a given application function as intended and meet desired requirements.
 * Identify and resolve software defects, code smells, and performance bottlenecks.
   
   

Continuous Learning and Innovation


 * Stay updated with the latest technologies and trends in full-stack development.
 * Propose innovative solutions to improve the performance, security, scalability, and maintainability of applications.
 * Continuously seek opportunities to optimize and refactor existing codebase for better efficiency.
 * Stay up-to-date with cloud platforms such as AWS, Azure, or Google Cloud Platform.
   
   

Collaboration


 * Collaborate effectively with cross-functional teams, including testers, and product managers.
 * Foster a collaborative and inclusive work environment where ideas are shared and valued.
   
   

Skills and Experience We Value:


 * Bachelor's degree in Computer Science, Engineering, or related field.
 * Proven experience as a Data Engineer, with a minimum of 3 years of experience.
 * Proficiency in Python programming language.
 * Experience with database technologies such as SQL (e.g., MySQL, PostgreSQL) and NoSQL (e.g., MongoDB) databases.
 * Strong understanding of Programming Libraries/Frameworks and technologies such as Flask, API frameworks, datawarehousing/lakehouse, principles, database and ORM, data analysis databricks, panda's, Spark, Pyspark, Machine learning, OpenCV, scikit-learn.
 * Utilities & Tools: logging, requests, subprocess, regex, pytest
 * ELK stack, Redis, distributed task queues
 * Strong understanding of data warehousing/lakehousing principles and concurrent/parallel processing concepts.
 * Familiarity with at least one cloud data engineering stack (Azure, AWS, or GCP) and the ability to quickly learn and adapt to new ETL/ELT tools across various cloud providers.
 * Familiarity with version control systems like Git and collaborative development workflows.
 * Competence in working on Linux OS and creating shell scripts.
 * Solid understanding of software engineering principles, design patterns, and best practices.
 * Excellent problem-solving and analytical skills, with a keen attention to detail.
 * Effective communication skills, both written and verbal, and the ability to collaborate in a team environment.
 * Adaptability and willingness to learn new technologies and tools as needed.
   
   

About Particle41

Our core values of Empowering, Leadership, Innovation, Teamwork, and Excellence drive everything we do to achieve the ultimate outcomes for our clients. Empowering Leadership for Innovation in Teamwork with Excellence ( ELITE )


 * E - Empowering: Enabling individuals to reach their full potential.
 * L - Leadership: Taking initiative and guiding each other toward success.
 * I - Innovation: Embracing creativity and new ideas to stay ahead.
 * T - Teamwork: Collaborating with empathy to achieve common goals.
 * E - Excellence: Striving for the highest quality in everything we do.
   
   

We seek team members who embody these values and are committed to contributing to our mission. Particle41 welcomes individuals from all backgrounds who are committed to our mission and values. We provide equal employment opportunities to all employees and applicants, ensuring that hiring and employment decisions are based on merit and qualifications without discrimination based on race, color, religion, caste, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, local, or international laws. This policy applies to all aspects of employment and hiring.

We appreciate your interest and encourage applicants from these regions to apply. If you need any assistance during the application or interview process, please feel free to reach out to us at careers@Particle41.com. This is specifically for USA location only.",Full-time
4151638424,12580762.0,Data Engineer,"About The Role

As a Data Engineer at Veterans United Home Loans, you’ll be creating and maintaining data solutions to enhance the lives of your co-workers and clients. Your primary focus will be on supporting business objectives related to the mortgage and real estate domains, helping veterans and service members buy homes. We're seeking a Data Engineer to join us either in-person or remotely in Columbia, MO.

The compensation for this role ranges from $70,000 to $105,000 depending upon experience and skill level.

Your Responsibilities


 * Innovative Development: Create and deliver functional ETL pipelines and other data solutions using core technologies like SQL, SSIS, Python and Dagster in an agile development environment. Apply sound database design principles and adhere to Clean Code practices.
 * Team Collaboration: Engage in whole team planning, retrospectives, and communication. Interact with Architects and Product Owners to translate requirements into actionable business logic.
 * Standards and Best Practices: Participate in proposing and adopting Engineering standards related to architectural considerations and non-functional requirements such as security, reliability, and stability. Ensure proper management and visibility of borrower data and the life of a loan. Contribute to data governance initiatives.
 * Cultural Contribution: Actively contribute to strengthening the team and culture by taking on various duties as needed, excluding licensed activities.
   
   

About You


 * Driven Developer: You thrive in an environment where your passion for data engineering shines through. You love seeing your hard work lead to meaningful results, helping business needs become reality.
 * Genuine and Transparent: You believe in showing up as your true self every day. Authenticity is key in building strong, trusting relationships. Your honesty is your superpower.
 * Adaptable Engineer: Change is your playground. You excel in dynamic settings, quickly adapting to new challenges and using your skills to achieve your goals in an ever-evolving landscape.
 * Speed Enthusiast: High stakes and fast-paced environments energize you. You recognize the importance of supporting your team and clients efficiently, navigating complex tasks and processes with ease and enthusiasm.
 * Communicative Collaborator: Your ability to connect with others through clear and confident communication sets you apart. You’re a natural at engaging with your team and stakeholders, ensuring everyone is on the same page and moving towards success.
 * Problem-Solving Prodigy: Your analytical mind and strong problem-solving skills allow you to tackle any challenge that comes your way. You’re always looking for innovative solutions to enhance the lives of others.
   
   

Qualifications


 * Relevant experience in data engineering or a related discipline.
 * Demonstrated ability to code effectively and a solid understanding of software engineering principles.
 * Experience using SSIS, Python, and Dagster to build and orchestrate ETL pipelines.
 * Experience using SQL or other query language to manage and process data.
 * Experience working with data from various sources and in various formats, including flat files, REST APIs, Hadoop File System, Excel files, JSON, XML, etc.
 * Experience with SQL Server, MongoDB, or related database technologies.
 * Preference for Agile product delivery.
 * Familiarity with GIT, Change Management, and application lifecycle management tools.
 * Ability to influence others without positional control.
 * Proficiency in basic computer technologies suitable for an internet-based company.
   
   

About Us

At Veterans United Home Loans, we’re passionate about helping veterans and military families achieve their homeownership dreams. We’ve closed over 500,000 VA loans in just two decades and are the #1 VA lender for homebuyers in the nation. But our success isn’t just in numbers. We measure success by living our values every day: Be Passionate and Have Fun, Deliver Results with Integrity, and Enhance Lives Every Day. We’re dedicated to providing friendly service and lifting people and communities across the country.

We value diverse backgrounds and experiences. Our team includes successful individuals from various fields like fitness/sports, sales, hospitality, education, and public service. If you’re driven, adaptable, and passionate about making a difference, we encourage you to apply today!

Learn more about us on Glassdoor and our career site at vu.com/careers

Veterans United Home Loans and its affiliates are proud to be Equal Opportunity Employers committed to creating a diverse and inclusive workforce. We consider all qualified applicants without regard to race, religion, color, sex, national origin, age, sexual orientation, gender identity, disability, veteran status, or other legally protected classifications.",Full-time
4122081026,157344.0,Data Engineer,"Job Summary

The Data Engineer is responsible for SJSU’s Campus Data Warehousing/Business Intelligence. This position will play a key role in the research, design, architecture, creation, development, implementation and maintenance of Campus Data Warehouse. This includes identifying and pulling data from 500+ individual databases across SJSU and curating them into a single data source in order to facilitate data-driven decisions.

The Data Engineer should possess a breadth of knowledge, technical skills, and strategic thinking to build a Data Warehouse to answer important questions across a variety of functional areas and collaborate with business stakeholders and IT management to understand solution requirements and system design for delivering the data model, developing and implementing the solution to deliver the desired business outcomes. Assist in conducting technical reviews, creating definitions of business problems, including the preparation of business/technical requirements to support the mission of the university and administrative departments, provide systems and technical support of vendor and locally developed software, and work with the Data Warehouse Project Manager, SJSU IT Enterprise Solutions resources, external vendors, and IT team members. Duties and system assignments can be temporarily or permanently changed to meet the needs and goals of the department and university.

Key Responsibilities


 * Capture, maintain, and apply data and information in order to support key business processes.
 * Optimize how the organization uses data both internally and externally.
 * Evaluate data that recognizes trends, calling insights, and making recommendations to the executive leadership team to make recommendations to define business strategy.
 * Assist with the development of strategies and coordinates the implementation that support the Organization's development plans and that capture new opportunities.
 * Partner cohesively with the broader Insights leaders across campus concerning the alignment capabilities.
 * Oversee the implementation of analytic methodologies including segmentation, predictive modeling, advanced statistical methods, regression, experimental design, etc.
 * Oversee the sourcing and creation of partnerships with key analytical vendors who can provide specialized expertise to assist with solution development while leading the in-house effort and managing CO interface.
 * Oversee project plans, timelines, and vendor relationships to ensure releases are delivered with the highest quality, on-time and within budget.
 * Partner with University stakeholders and be responsible for data analytics, custodianship, and infrastructure to ensure alignment with departmental data and analytics requirements to avoid conflicting activities, and develop the most efficient data analytics insights across the departments.
 * Identify, interpret, analyze and address critical business issues, questions and to develop use cases.
 * Organize and create an environment that makes data and information accessible with appropriate channels of access controls.
 * Work with internal and external stakeholders to build a relationship of trust and play an advisory role in the use of data to improve performance and University-wide strategy formulation.
 * Develop and document clear understandable plans, roadmaps and communication for business users, technical staff and IT groups.
 * Follow IT policies and standards for maintaining consistency and standards across SJSU campus.
 * Be proactive in making recommendations and ensure users/departments have the most up-to-date technological solutions to perform their jobs and serve the university community effectively.
   
   

Knowledge, Skills & Abilities


 * Advanced skills in analytical and holistic problem-solving, project management, effective communication and coordination of internal and external resources
 * Ability to work effectively with faculty, staff, and senior administrators in areas other than technology to develop and implement appropriate uses of technology
 * Advanced technical knowledge in IT systems and emerging technology trends and issues
 * Ability to synthesize data from multiple sources to address complex business questions
 * Advanced knowledge with analytics tools, “big data” technologies, cloud computing environments, relational database
 * Advanced working knowledge in large ERP scale analytics, optimization, business intelligence, and statistics for IT organizations
 * Ability to identify key insights and built large-scale data products that enhance the customer experience and improve operations processes
 * Strong ability to provide guidance on emerging technologies to innovate and ensure the SJSU is well-positioned in delivering analytic solutions
 * Strong ability to deliver on high-impact analytics projects
 * Advanced working SQL knowledge and skills working with relational databases like Oracle, query authoring (SQL), as well as, working familiarity with a variety of databases
 * Expert knowledge in high level programming languages like: Python, SQL, Java, and JavaScript
 * Advanced knowledge in application architectures on public cloud platform such as Amazon Web Services (AWS), Google Cloud Platform (GCP) or IBM Cloud Pak
 * Advanced knowledge of enterprise data architecture, ETL integration, data warehousing techniques, analytics/end-user reporting tool sets
 * Advanced knowledge in Visualization tools like Google Data Studio, Tableau, Looker etc
 * Knowledge building and optimizing ‘big data’ data pipelines, architectures and data sets
 * Ability to build processes supporting data transformation, data structures, metadata, dependency and workload management
 * Advanced knowledge of Systems development life cycle methodologies (Agile and Waterfall) in order to develop effective systems
 * Advanced knowledge of application development, testing and deployment processes and tools
 * Knowledge performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
 * Strong analytic skills related to working with unstructured datasets
 * Knowledge with big data languages such as R, Python/PySpark and familiarity with cloud architecture
 * Advanced knowledge in data mining, forecasting, simulation, and/or predictive modeling
 * Advanced knowledge building BI environments with significant scale and scope
   
   

Required Qualifications


 * A bachelor’s degree, preferably in computer science or business, or equivalent training and applied experience
 * Five years of experience in business applications analysis, design, and programming for medium or large scale, multi-programmed computers
   
   

Preferred Qualifications


 * Master’s in Business Administration, Computer Science or equivalent degree
 * 3+ years’ experience developing, maintaining and collecting structured and unstructured data sets for analysis and reporting
 * 3+ years advanced analytics experience in support of business strategy
 * 3+ years working experience in implementing public cloud solutions
   
   

Compensation

Classification: Analyst/Programmer - Expert

CSU Salary Range: $7,371/month - $14,274/month

San José State University offers employees a comprehensive benefits package typically worth 30-35% of your base salary. For more information on programs available, please see the Employee Benefits Summary .

Application Procedure

Click Apply Now to complete the SJSU Online Employment Application and attach the following documents:


 * Resume
 * Letter of Interest
   
   

All applicants must apply within the specified application period: January 9, 2025 through January 22, 2025. This position is open until filled; however, applications received after screening has begun will be considered at the discretion of the university.

Contact Information

University Personnel

jobs@sjsu.edu

408-924-2252

CSU Vaccination Policy

The CSU strongly recommends that all individuals who access any in-person program or activity (on- or off-campus) operated or controlled by the University follow COVID-19 vaccine recommendations adopted by the U.S. Centers for Disease Control and Prevention (CDC) and the California Department of Public Health (CDPH) applicable to their age, medical condition, and other relevant indications and comply with other safety measures established by each campus. The system wide policy can be found at https://calstate.policystat.com/policy/9779821/latest/ and questions may be sent to jobs@sjsu.edu .

Additional Information

Satisfactory completion of a background check (including a criminal records check) is required for employment. SJSU will issue a contingent offer of employment to the selected candidate, which may be rescinded if the background check reveals disqualifying information, and/or it is discovered that the candidate knowingly withheld or falsified information. Failure to satisfactorily complete the background check may affect the continued employment of a current CSU employee who was offered the position on a contingent basis.

The standard background check includes: criminal check, employment and education verification. Depending on the position, a motor vehicle and/or credit check may be required. All background checks are conducted through the university's third party vendor, Accurate Background. Some positions may also require fingerprinting. SJSU will pay all costs associated with this procedure. Evidence of required degree(s) or certification(s) will be required at time of hire.

SJSU IS NOT A SPONSORING AGENCY FOR STAFF OR MANAGEMENT POSITIONS. (e.g. H1-B VISAS)

All San José State University employees are considered mandated reporters under the California Child Abuse and Neglect Reporting Act and are required to comply with the requirements set forth in CSU Executive Order 1083 as a condition of employment. Incumbent is also required to promptly report any knowledge of a possible Title IX related incident to the Title IX Office or report any discrimination, harassment, and/or retaliation to the Office of Equal Opportunity.

Jeanne Clery Disclosure of Campus Security Policy and Crime Statistics Act and Campus Housing Fire Safety Notification:

Pursuant to the Jeanne Clery Disclosure of Campus Security Policy and Campus Crime Statistics Act, the Annual Security Report (ASR) is also now available for viewing at https://www.sjsu.edu/clery/docs/SJSU-Annual-Security-Report.pdf. The ASR contains the current security and safety-related policy statements, emergency preparedness and evacuation information, crime prevention and Sexual Assault prevention information, and information about drug and alcohol prevention programming. The ASR also contains statistics of Clery crimes for San José State University locations for the three most recent calendar years. A paper copy of the ASR is available upon request by contacting the Office of the Clery Director by phone at 408-924-1501 or by email at clerycompliance@sjsu.edu .

Pursuant to the Higher Education Opportunity Act, the Annual Fire Safety Report (AFSR) is also available for viewing at https://www.sjsu.edu/clery/docs/SJSU-Annual-Fire-Safety-Report.pdf . The purpose of this report is to disclose statistics for fires that occurred within SJSU on-campus housing facilities for the three most recent calendar years, and to distribute fire safety policies and procedures intended to promote safety on Campus. A paper copy of the AFSR is available upon request by contacting the Housing Office by phone at 408-795-5600 or by email at uhs-frontdesk@sjsu.edu .

Campus Security Authority - In accordance with the Jeanne Clery Disclosure of Campus Security Policy and Campus Crime Statistics Act (Clery Act) and CSU systemwide policy, this position is subject to ongoing review for designation as a Campus Security Authority. Individuals that are designated as Campus Security Authorities are required to immediately report Clery incidents to the institution and complete Clery Act training as determined by the university Clery Director.

Equal Employment Statement

San José State University (SJSU) is an Equal Opportunity/Affirmative Action employer committed to nondiscrimination on the basis of age, ancestry, citizenship status, color, creed, disability, ethnicity, gender, genetic information, marital status, medical condition, national origin, race, religion or lack thereof, sex, sexual orientation, transgender, or protected veteran status consistent with applicable federal and state laws. This policy applies to all SJSU students, faculty and staff programs and activities. Title IX of the Education Amendments of 1972, and certain other federal and state laws, prohibit discrimination on the basis of sex in all education programs and activities operated by the university (both on and off campus).

",Full-time
4132711320,17943955.0,Data Engineer,"Wiliot was founded by the team that invented one of the technologies at the heart of 5G. Their next vision was to develop an IoT sticker, a computing element that can power itself by harvesting radio frequency energy, bringing connectivity and intelligence to everyday products and packaging, things previously disconnect from the IoT. This revolutionary mixture of cloud and semiconductor technology is being used by some of the world’s largest consumer, retail, food and pharmaceutical companies to change the way we make, distribute, sell, use and recycle products.

Our investors include Softbank, Amazon, Alibaba, Verizon, NTT DoCoMo, Qualcomm and PepsiCo.

We are growing fast and need people that want to be part of the journey, commercializing Sensing as a Service and enabling “Intelligence for Everyday Thing”.

Wiliot is seeking an experienced Data Engineer to join our team in one of our key locations: San Francisco, New York, or Dallas. This role will focus on developing and deploying production pipelines in addition to accelerating development of Wiliot’s product for strategic customers by optimizing data tools and infastructure.

Responsibilities:


 * Data Pipeline Development: Design, build, and maintain scalable data pipelines using CI/CD and Git to incorporate best practices. This includes implementing ETL/ELT processes of IoT data to ensure prompt access to business-ready data.
 * Tool Development for Data Scientists: Create and refine tools and frameworks that enable data scientists and analysts to efficiently query, process, and visualize data. This includes custom scripting, development of automated data quality checks, and creation of data models that align with business requirements.
 * Data Architecture: Work on the architecture of our data systems, ensuring they are robust, scalable, and secure. This involves optimizing data flow for real-time analytics and machine learning model training.
 * Integration & Interoperability: Integrate various data sources and ensure interoperability between various cloud services and microservices
 * Performance Optimization: Monitor and enhance the performance of data systems, including tuning SQL queries, optimizing data ingestion rates, and managing data warehouse performance.
 * Collaboration: Work closely with data scientists, analysts, and engineers to understand their needs and provide tailored data solutions. Participate in cross-functional teams to drive projects from conception to deployment.
 * Documentation and Knowledge Sharing: Maintain comprehensive documentation of data pipelines, tools, and processes. Mentor junior team members and share knowledge to foster a culture of continuous learning.
 * Staying Current: Keep abreast of new developments in IoT, big data technologies, and data engineering practices to continuously improve our data infrastructure.
   
   

Requirements:

Education:

Bachelor's or master’s degree in computer science, Machine Learning, or a related field.

Experience:


 * 3-5 years of experience in data engineering roles with at least one role in a technology company.
 * Proven experience in Apache Spark and Python
 * Experience deploying containerized applications via Docker, Kubernetes, and/or Terraform
   
   

Technical Skills:


 * Proficient in programming languages like Python.
 * Experience with big data technologies such as Apache Spark, Kafka, or similar tools.
 * Experience implementing streaming applications with Apache Kafka, Spark Structured Streaming, or Flink
 * Knowledge of cloud platforms (AWS, GCP, Azure) with practical experience in implementing cloud-based data solutions.
 * Familiarity with database systems, both relational (e.g., PostgreSQL) and NoSQL (e.g., MongoDB), as well as data storage formats such as Parquet and Delta.
 * Expertise in version controls systems such as Git
   
   

Additional Skills:


 * Experience with Databricks and workflow management tools such as Databricks Workflows or Apache Airflow
 * Expertise with build pipelines such as Github Actions or Bitbucket Pipelines preferred
 * Proficiency with Java and/or Scala
 * Knowledge of code design frameworks such as microservices, domain driven design, functional programming, and event-based application design
 * Strong analytical and problem-solving skills.
 * Excellent communication skills to liaise between technical and non-technical stakeholders.
 * Ability to independently manage and progress on multiple projects simultaneously.
   
   

What We Offer:


 * Competitive salary and benefits package.
 * Opportunities for professional growth in a dynamic and innovative IoT environment.
 * A collaborative, inclusive work culture with a focus on cutting-edge technology solutions.
   
   ",Full-time
4127761433,66321745.0,Junior/Entry Level Data Engineer,"Since 2010 Synergisticit has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this Job market also, our candidates are able to achieve multiple job offers and $100k + salaries.

please check the below links to see success outcomes, salaries of our candidates .

https://www.synergisticit.com/candidate-outcomes/

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please visit the below videos exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

Required Skills

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, Gen AI, LLM, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full Stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java , javascript , C++ or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Contract
4039904882,1503.0,Data Science Engineer,"Posting Description

DATA SCIENCE ENGINEER, McGovern Institute for Brain Research , to tackle challenging problems at the intersection of brain science and artificial intelligence. Will join world-class neuroscientists and cognitive scientists in applying machine learning, AI, and data science skills to cutting-edge research on the brain and mind; have opportunities for career development, and for a voice in the scientific directions that are explored; help researchers develop large-scale neural network models of perception and cognition; translate computational algorithms into parallelized and GPU-optimized code; stay up-to-date with machine learning developments; aid labs with the integration of machine learning into their research; and help transition users to new computing tools.

Job Requirements

REQUIRED : advanced degree (M.Sc./Ph.D.) in machine learning, computational neuroscience, or computer science; experience implementing efficient large-scale parallelization for data-processing algorithms; experience with GPU optimization in PyTorch and TensorFlow, including ability to write new GPU-based operations in both frameworks; experience training large-scale artificial neural networks across multiple GPUs; experience with large-scale neural network optimization techniques, including hyperparameter optimization; experience with high-performance cluster computing and/or cloud computing at scale; experience with software engineering and publishing, and building user-friendly interfaces; experience analyzing big data and high-speed I/O programming; familiarity with HDF5 or TFRecord; ability to optimize existing scientific computing code; willingness to work with domain scientists; commitment to and experience with open science practices; experience with data management tools that facilitate reproducible science. PREFERRED: background in neuroscience and cognitive science. Job #24490

This is a two year appointment with the potential to renew, pending funding.

Posted 10/3/2024

Revised 10/7/2024",Full-time
4138362875,1028.0,Software/Data Engineer,"Job Description

MUST currently possess and have the ability to hold a TS/SCI with a Poly.

As an acknowledged authority within Oracle, this senior level consulting position is responsible for creating and implementing innovative solutions with industry-wide impact. Leads the solution design and implementation aspects of engagement(s) ensuring high quality, integrated solutions within constraints of time and budget.

Must be proficient in the following skills:


 * Oracle APEX platform with the ability to develop, configure, and deploy APEX applications, forms, pages, and dashboards
 * Oracle Rest Data Services (ORDS)
 * Integration of APEX with Oracle IDM suite for identity and access management
 * Python to develop, configure, and deploy through the use of python language and libraries
 * Oracle Database to create schemas/tables/views, deploy DDLs, and ensure proper database administration
 * SQL developer
 * The use of GIT repository for configuration and change management
 * Designing architecture at various levels of the technical stack to include, infrastructure, security, and data
 * Thorough documentat
   
   
   

Career Level - IC5

Responsibilities

Analyzes business needs to help ensure Oracle solution meets the customer’s objectives by combining industry best practices, product knowledge, and business acumen. As a position of technical/professional influence, this individual frequently operates at the leading edge of technology. Recommends and justifies enhancements to Oracle products to meet very complex customer needs. Exercises creativity and independent judgment in developing methods, techniques, and evaluation criteria to deliver functional and technical expertise on a wide range of business and technology solutions. Leads experienced consulting teams on challenging projects; works on significant and unique issues. As a thought leader and trusted advisor, effectively influences difficult decisions at the leadership-level of customer organizations. Enables business development efforts by providing subject matter expertise. Resolves very complex customer escalations. Drives customer process direction and decisions by providing domain leadership within relevant industries on end-to-end enterprise solutions. Creates new solution sets based on assessment of industry needs, market demands and knowledge of competitive product offerings.

Qualifications

Disclaimer:

Certain US customer or client-facing roles may be required to comply with applicable requirements, such as immunization and occupational health mandates.

Range and benefit information provided in this posting are specific to the stated locations only

US: Hiring Range: from $120,100 - $251,600 per year. May be eligible for bonus, equity, and compensation deferral.

Oracle maintains broad salary ranges for its roles in order to account for variations in knowledge, skills, experience, market conditions and locations, as well as reflect Oracle’s differing products, industries and lines of business.

Candidates are typically placed into the range based on the preceding factors as well as internal peer equity.

Oracle US offers a comprehensive benefits package which includes the following:


 * Medical, dental, and vision insurance, including expert medical opinion
 * Short term disability and long term disability
 * Life insurance and AD&D
 * Supplemental life insurance (Employee/Spouse/Child)
 * Health care and dependent care Flexible Spending Accounts
 * Pre-tax commuter and parking benefits
 * 401(k) Savings and Investment Plan with company match
 * Paid time off: Flexible Vacation is provided to all eligible employees assigned to a salaried (non-overtime eligible) position. Accrued Vacation is provided to all other employees eligible for vacation benefits. For employees working at least 35 hours per week, the vacation accrual rate is 13 days annually for the first three years of employment and 18 days annually for subsequent years of employment. Vacation accrual is prorated for employees working between 20 and 34 hours per week. Employees working fewer than 20 hours per week are not eligible for vacation.
 * 11 paid holidays
 * Paid sick leave: 72 hours of paid sick leave upon date of hire. Refreshes each calendar year. Unused balance will carry over each year up to a maximum cap of 112 hours.
 * Paid parental leave
 * Adoption assistance
 * Employee Stock Purchase Plan
 * Financial planning and group legal
 * Voluntary benefits including auto, homeowner and pet insurance
   
   
   

The role will generally accept applications for at least three calendar days from the posting date or as long as the job remains posted.

About Us

As a world leader in cloud solutions, Oracle uses tomorrow’s technology to tackle today’s problems. True innovation starts with diverse perspectives and various abilities and backgrounds.

When everyone’s voice is heard, we’re inspired to go beyond what’s been done before. It’s why we’re committed to expanding our inclusive workforce that promotes diverse insights and perspectives.

We’ve partnered with industry-leaders in almost every sector—and continue to thrive after 40+ years of change by operating with integrity.

Oracle careers open the door to global opportunities where work-life balance flourishes. We offer a highly competitive suite of employee benefits designed on the principles of parity and consistency. We put our people first with flexible medical, life insurance and retirement options. We also encourage employees to give back to their communities through our volunteer programs.

We’re committed to including people with disabilities at all stages of the employment process. If you require accessibility assistance or accommodation for a disability at any point, let us know by calling +1 888 404 2494, option one.

Disclaimer:

Oracle is an Equal Employment Opportunity Employer*. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans’ status, or any other characteristic protected by law. Oracle will consider for employment qualified applicants with arrest and conviction records pursuant to applicable law.


 * Which includes being a United States Affirmative Action Employer",Full-time
4124858287,2661018.0,Data Engineer,"Position Summary

The Data Engineer designs and supports data systems, maintenance processes and projects by using Azure services such as Data Factory, Databricks, Synapse Analytics, Data Lake, and Blob storage along with proficiency om SQL programming languages like Python or Scala.

Essential Functions


 * Designs and writes code for RTL data solutions.
 * Plans and executes data implementations following system requirements and anticipated usage.
 * Performs data extraction, ensures data accuracy, troubleshoots and resolves bugs during data operations.
 * Analyzes business intelligence data and designs and generates reports.
 * Understands and utilizes ETL tools like Informatica and programming languages like Python.
 * Acts a liaison between IT and business units.
   
   

Qualifications


 * Bachelor’s degree in information technology or related field required.
 * 2 – 4 years of related experience required.
 * Certified in Microsoft Certified: Azure Data Engineer Associate is preferred.
 * Skilled in building and managing ETL pipelines, big data workflows, and scalable data solutions within Azure’s ecosystem.
 * Experience in cloud-native architecture, data security, and compliance in regulated industries.
 * Higher education and/or experience that is directly related to the duties and responsibilities specified may be interchangeable on a year for year basis.
 * Excellent written and oral communication skills
 * Knowledge of a wide range of computer systems software, applications, hardware, networking, and communications.
 * Ability to perform routine preventive maintenance on systems software, applications, hardware, networking, and communications.
 * Ability to determine computer problems and to coordinate hardware, software, and/or network solutions.
 * Ability to analyze and resolve basic computer problems.
 * Ability to communicate technical guidance and instruction to users on using PC, server, and/or network applications and systems.
   
   

Physical Requirements

Duties

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this position. While performing the duties of this position, the employee must be able to:


 * Routinely sit, sometimes for extended periods, and work on a computer;
 * Stand, walk, stoop, kneel, crouch or crawl
 * Occasionally lift up to 15 pounds
 * Occasionally lift up to 50 pounds with assistance
 * At such times, a greater amount of physical exertion, standing and walking would be required.
   
   

Work Environment

The work environment characteristics described are representative of those an employee encounters while performing the essential functions of this position. The noise level in the work environment when in the office is usually quiet, and usually louder in the manufacturing environment.

This job description reflects management’s assignment of essential functions. It does not prescribe or restrict the tasks that may be assigned. Critical features of this job are described under the headings above. They are subject to change at any time in the course of normal business operations.

Tronair is an EEO/AA employer - M/F/Disabled/Veteran",Full-time
4125057966,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4137711075,3486.0,Data Engineer,"Product Team: Transitioning from a legacy stack (Cognos and SSIS) to a modern stack using Power BI and Snowflake. Cognos and SSIS experience are preferred. The modernization journey is critical and offers significant learning opportunities for the candidate. It is required for them to have Snowflake and Reporting expertise.

Key Challenges: Domain knowledge and leadership experience in the product team have diminished due to resignations and other transitions. This creates an opportunity for the new hire to take on a leadership role in the future.

Role Details :

 * Position: Full-time Data Engineer.
 * Location: Hybrid, with reporting to the Raleigh office twice a week.
 * Reporting Structure: The engineer will work in a small, high-visibility BI product team responsible for sourcing, formatting, and ensuring the quality of data before providing insights to stakeholders across the company.



Required:

Data Engineering experience

Snowflake (data warehousing) still required at 3-5 YOE.

SSIS experience (*SSIS being the current state moving to potentially a custom tool in 3+ years)

ETL Experience (3-5 YOE)

Leadership Experience (for the lead oriented role) – Must have led project (requirements gathering, designing, building target state and industry best practices). Has guided junior developers before, making sure set design is followed through, mentoring).

Preferred:

PBI OR Cognos

SQL Server

Modeling skills (DVM, Kimball, etc)

 1. Bonus: Insurance background

 * Responsibilities: Hands-on experience with data extraction, quality checks, and publishing insights for stakeholders, including C-level executives. The candidate should also navigate challenges with street-smart problem-solving.

 1. Potential Growth: The role offers opportunities for promotion, including transitioning into a leadership position.
 2. Immediate Hiring: VERY HIGH VISIBILITY ROLE
 3. Team Visibility: Despite being a small team, it has high visibility and significant exposure to stakeholders, making the role impactful and potentially career-advancing

",Full-time
4079501015,23717227.0,Data & Analytics Engineer,"At Rinsed, we are building software to run the $15bn Car Wash industry.

We're a B2B SaaS company, providing car washes with all the tools they need to transition to a subscription model. Modern car washes are fully-automated tunnels that can wash over 200 cars/hr, and they are moving from selling single washes to all-you-can-wash subscriptions. We are giving this $15bn underserved market the tools to manage and grow their subscription revenue.

We are a small team, who just raised our Series B from VMG Technology in addition to our Series A from Founder's Fund and Bedrock Capital. We are currently installed at over 3,000 car washes nationally helping to manage more than 8 million car wash memberships. What we've built so far is just the beginning. Get to be part of the founding DNA of building a great product, a great culture, and a great company!

A Day in the Life

We are seeking an analytical and intellectually curious candidate who is excited to work at a fast-growing startup.

As a Data & Analytics Engineer, you'll design the architecture, storage, and transformation capabilities of the data pipelines that power our product. You'll also generate external- and internal-facing dashboards that enable our customers to drive value using the millions of data points we gather on their operations.

A typical day for this role at Rinsed includes:

Understanding, modeling, and transforming point-of-sale data into meaningful fact tables using dbt and Snowflake

Identifying gaps in the Rinsed data product and building reports/dashboards that allow our customers to best understand their business

Building data pipelines for third party data to be consumed in our data ecosystem

Working cross-functionally to provide data to Rinsed teams looking to track and optimize their decisions

Creating the tools and models to measure and define internal product goals

Writing scripts to automate and simplify internal data processes

Communicating data-based suggestions, findings, and feedback to customers and Rinsed senior leaders alike

About You

You are a ""end-to-end"" data engineer who believes in owning the whole stack from data cleaning to dashboard to stakeholder communication. You have an entrepreneurial spirit and are adaptable to a fast-growing environment with a high tolerance for ambiguity. You're naturally curious and you have a desire to keep up with advancements in data.

You bring the following experience and expertise:

Proficiency in writing performant SQL to generate business insights and drive better organizational decision making

Strong familiarity with data warehouses (Snowflake, BigQuery, Redshift) and business intelligence tools (Metabase, Tableau, Looker, etc.)

Clear And Direct Communication Skills About Complex Technical Topics

A track record of working autonomously, with strong organizational and time management skills

Comfort with a high degree autonomy and ownership, independently making good decisions for our customers and the business

Exposure to dbt or similar data transformation tools preferred

2 - 3 years experience in a data analytics, data science, or data engineering role preferred

Python Experience a Plus, But Not Required

Our Investment in You

Rinsed has been heavily invested in data since day one. Understanding lifetime value, churn, cost-to-acquire and optimal pricing are huge untapped opportunities in this industry as it moves to a subscription model.

By joining as one of our early team members, there is enormous opportunity ahead for you to have an outsized impact and shape the future of Rinsed in this role.

Competitive salary and benefits including unlimited PTO, health / dental / vision insurance and more.

An incredible team with a great blend of hustle, productivity, and fun

The estimated annual cash salary for this role is $130,000 - $150,000. This position is also eligible for incentive stock options, subject to the terms of applicable Rinsed plans. Rinsed provides an estimate of the compensation for roles that may be hired as required by state regulations. Compensation may vary based on (a) location, as we factor in specific location when benchmarking compensation for most roles, (b) individual candidate skills and qualifications, and (c) individual candidate experience. We leverage current market data to determine compensation, and reserve the right to modify this information at any time, subject to applicable law.

Salary Range

$130,000—$150,000 USD

Rinsed embraces diversity and is proud to be an equal opportunity employer. As part of our commitment to diversifying our workforce, we do not discriminate on the basis of age, race, sex, gender, gender identity, color, religion, national origin, sexual orientation, marital status, citizenship, veteran status, or disability status.

We are also committed to providing reasonable accommodations for qualified individuals with disabilities in our job application process. If you need assistance or an accommodation due to a disability, you may contact people@rinsed.co.",Full-time
4146296190,1441.0,"Software Engineer III, Generative AI, Data Analytics","Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Sunnyvale, CA, USA; Kirkland, WA, USA; New York, NY, USA.Minimum qualifications:


 * Bachelor's degree in Computer Science, similar technical field of study, or equivalent practical experience.
 * 2 years of experience developing ML models and launching AI/ML powered products, with experience in data analytics.
 * 2 years of experience with software development in one or more programming languages (Java, C++, Python, or Go) or 1 year of experience with an advanced degree in an industry setting.
 * Experience in Data analytics and Vertex AI within a cloud based environment
   
   

Preferred qualifications:


 * Master's degree or PhD in Computer Science or a related technical field.
 * 2 years of experience with AI/ML techniques including generative AI, Natural Language Processing (NLP), information retrieval, etc.
 * Experience with Python, Notebooks, ML Frameworks (e.g., TensorFlow).
 * Experience with data systems.
 * Ability to drive process improvements, with excellent problem solving and analytical skills.
   
   

About The Job

Google Cloud's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google Cloud's needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. You will anticipate our customer needs and be empowered to act like an owner, take action and innovate. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward.

You will work with a team of experts to research, explore, and develop innovative solutions that will bring generative AI to the forefront of GCP Data Analytics for customers.

Google Cloud accelerates every organization’s ability to digitally transform its business and industry. We deliver enterprise-grade solutions that leverage Google’s cutting-edge technology, and tools that help developers build more sustainably. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems.

The US base salary range for this full-time position is $136,000-$200,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .

Responsibilities


 * Design and develop next-generation software systems for data analytics.
 * Participate in, or lead design reviews with peers and stakeholders to decide on available technologies.
 * Review code developed by other developers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency).
 * Contribute to existing documentation or educational content and adapt content based on product/program updates and user feedback.
 * Triage product or system issues and debug/track/resolve by analyzing the sources of issues and the impact on hardware, network, or service operations and quality.
   
   
   

Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",Full-time
4152406749,10476.0,Data Engineer,"Required Skills

Databricks administration (70%)

Snowflake administration is a plus (30%)

Optimization experience is very important 

- Engineers with good optimization would work

Deep understanding of cloud platform

Key requirement- Terraform proficency- writing custom modules

Python is a big plus, must have programming language experience 

Strong SQL

Cloud Security and Network Security experience 

Not a manager role- individual contributor who is hands on technically

DevOps - hands on engineers




Prefer CT or Plano, TX- would consider remote for excellent candidate

2 rounds technical interview, 3rd round with Director (possible)

Bachelors required

Long term contract- will consider conversion for the right candidate


",Contract
4048247696,280637.0,Software Data Engineer - LD,"Northstrat is seeking a highly motivated Software Data Engineer who will play a critical role in ensuring the successful acquisition and management of mission-critical and mission support data sets. You will work closely with our team of experts to design and implement data solutions that meet the unique needs of our clients in the military space. Whether you have experience as a developer, analyst, or engineer, we want to hear from you. Your expertise in this area will be invaluable as we work to provide our clients with the highest quality data solutions possible. The successful candidate will have an understanding of data structures, algorithms, and software design principles, as well as experience working with large and complex data sets. They will work closely with our engineers to build and optimize our data pipeline and analytics systems. As a hybrid role, this position will require some on-site work, but you will also have some flexibility to work remotely.

You will be part of a dynamic team of professionals who are passionate about their work and committed to delivering exceptional results. If you are a self-starter who thrives in a fast-paced environment and is eager to take on new challenges, we encourage you to apply for this exciting opportunity.

Essential Job Responsibilities


 * Must have a strong working knowledge and experience developing Java based software capabilities
 * Should have an inquisitive nature, responsiveness, and excellent testing skills
 * Must also possess strong troubleshooting skills and the ability to work under pressure with multiple deadlines
 * Keep up to date with emerging trends and technologies in software development
 * Will work in a fast-paced, small business environment with our talented team
 * Additional duties as assigned
   
   
   

Requirements


 * Security Clearance - Must have a current U.S. Government TS/SCI level security clearance; U.S. Citizenship required
 * At least 5 years of experience in Software Engineering, Modern Java Frameworks and Libraries (e.g. Spring, Guava) and a Bachelors in related field; 3 years relevant experience with Masters in related field; or High School Diploma or equivalent and 9 years relevant experience
 * Experience in designing enterprise APIs
 * Experience in RESTful web services
 * Experience in Microservices architecture
 * Experience in Object Oriented Programming (OOP) paradigms
 * Experience with the agile software lifecycle
 * Has a proven ability to learn quickly and works well both independently as well as in a team setting
 * Experience with the Linux operating system
 * Experience with configuration management tools (e.g. Git, Nexus, Maven)
 * Must have a DoD 8140 / 8570 compliance certifications (i.e. Security+)
 * Must be able to travel up to 10% of the time or more based on customer needs
 * Must be able to work in a hybrid environment, spending an average of 2-3 days per week at our Colorado Springs, CO office. Flexibility is essential to accommodate any changes in the schedule
   
   
   

Preferred Requirements


 * Experience in cloud-based technologies (AWS, Azure)
 * Experience in distributed databases, NoSQL databases, full text-search engines (e.g. Elasticsearch, MongoDB, Solr)
 * Scripting experience is a huge plus
 * Prior experience or familiarity with our Big Data Platform is a plus
 * Understanding of AGILE software development methodologies and use of standard software development tool suites. (e.g., JIRA, Confluence, GitHub Enterprise, etc.)
   
   
   

Benefits

Work/Life Balance

Northstrat values true work life balance. We offer power of choice benefits designed to best meet the needs of you and your lifestyle. Our benefits programs are designed to support and encourage wellness, healthy living, retirement investment, and lifetime learning.

Flex Time

Northstrat does not mandate specific working hours. Although project requirements may dictate schedules, a Northstrat employee is only required to work an average of 8 hours per weekday over the course of a month. For example: John worked 12 hours on June 1st to meet a project deadline. On June 15th, John only worked 4 hours because he left early for a long weekend. John's IBA was not debited for time off because flex time allowed him to carry over those 4 hours from June 1st.

Individual Benefits Account (IBA)

To attract and retain the highest quality staff, Northstrat provides a unique and versatile benefits package, the Individual Benefit Account (IBA), which places the power of choice in the hands of our greatest asset - the employee.

The purpose of the IBA is to provide attractive benefits to all full-time employees of Northstrat on a flexible basis that enables each covered employee to select a package that best suits his or her needs. Whether those needs are paid time off, medical expenses, prescription drug expenses, cash disbursement, or a combination of any of these, the IBA provides flexibility to help you meet your specific goals. The IBA can be used for such things as:


 * Medical and Vision Insurance through United Health Care; Dental insurance through Delta Dental
 * 100% Medical Reimbursement
 * Time Off with Pay
 * Profit Sharing Plan
 * 401k
 * Educational Benefits
 * Additional Income
   
   

IBA Benefits accrue each month in the amount equivalent to 50% of the employee's monthly compensation rate. That is, the effective dollar amount of this accrual is in addition to an employee's salary.

Profit Sharing Plan (PSP)

The PSP is a qualified retirement plan that Northstrat funds semi-annually on the employee's behalf through the IBA in the amount equivalent to 25% (up to the IRS contribution limit) of the employee's compensation. That is, of the 50% accrual in the IBA, half of the amount accrued is applied to the PSP.

Stock Options

Because Northstrat is an employee-owned company, all new employees are offered stock options. Employees have the opportunity to receive additional stock options based on accomplishment of individual performance goals. Stock owners elect the Board of Directors and are directly impacted by the success of the company.

Lifelong Learning

Our culture promotes and nurtures a growth environment. We hire and scale rapidly to meet the needs of our partner customers. Through the use of company provided online learning opportunities, periodic company sponsored training events, and the ability to use IBA funds for reimbursement of work-related education expenses you will have the opportunity to continually grow your skills and abilities.

Bring Your True Self

We embrace diversity and encourage inclusion. We support employee led interest groups and challenge our employees to support others and be their best self. We are so true to our beliefs that we offer employee referral incentives. When you like it here, your friends and family will too!

Northstrat is an Equal Opportunity Employer

We are committed to fostering an inclusive, diverse workplace. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status or other legally protected status.",Full-time
4143091738,5996.0,Data Engineer,"About the Role: We are looking for a talented Data Engineer to join the Enterprise Finance Data & Analytics team who is passionate about solving business problems with trusted data. You will translate raw data into valuable business insights, guide data initiatives to measure financial performance, build end-to-end data pipelines (batch and near real-time) and support managing the cloud data platform. A background in data warehousing, proficiency in Python/SQL, proven data modeling skills, and experience engaging with business partners is necessary. The candidate will be comfortable with ambiguity in a fast-paced environment, displaying big-picturing thinking while paying careful attention to detail.

This position will be located at our facility in Newark, Delaware, with the possibility of a hybrid remote work arrangement, depending upon the responsibilities of the role and business needs. Relocation assistance may be offered for this role.

Responsibilities:


 * Contribute to the enhancements and continuous improvement of performance, reliability, and security of the existing Enterprise Finance Modern Data Estate
 * Contribute to the design, support, and growing scale of finance-related data products where accuracy, completeness, immutability, security, and timeliness
 * Design, build, and optimize data pipelines through the data development lifecycle to support existing and new data models
 * Work with data analysts on our scalable and trusted data infrastructure for analytics
 * Document data workflows and definitions for internal and external stakeholders
 * Ensure the quality, performance, and stability of data platform through robust quality systems and monitoring practices
 * Identify opportunities for automation and implement data management tools and frameworks to enhance efficiency and productivity
 * Participate in code reviews and architecture discussions to exchange actionable feedback with peers
 * Collaborate with Finance to translate business needs into technical requirements, data products and actionable insights
 * Stay up-to-date with emerging technologies and industry best practices in data engineering
 * Ensure data security and compliance with relevant regulations
 * Responsible for maintaining a strong relationship with partners in the Finance team and IT
   
   
   

Required Qualifications:


 * Bachelors/Masters in Computer Science, Information Systems, Business/Data Analytics or a related field
 * Minimum 6 years of experience in data engineering with a focus on cloud-based data platforms
 * Experience with agile development methodologies and Git-based tools such as Azure DevOps or Github
 * Experience with reporting tools such as Microsoft Power BI
 * Expertise in Databricks and Azure Data Factory
 * Expertise in dimensional data modeling, ETL concepts, DevOps/DataOps practices, and patterns for efficient data governance
 * A deep understanding of the modern data stack, with expertise in data ingestion, cleaning, transformation, modeling, orchestration, and data warehouses.
 * Strong knowledge of Python and expertise with modern data processing technologies (Spark, SQL, dbt/sqlmesh or similar)
 * Excellent communication and collaboration skills
 * Proven ability to design, productionize, and optimize batch and real-time data pipelines and systems, ensuring their quality, performance, and stability
 * Ability to travel 5%
   
   
   

Hybrid Working Arrangements are permitted for Associates in the continental United States (US) and Canada, with appropriate approval and compliance with Gore’s hybrid working policies, from the country in which they are employed.

What We Offer: Our success is based on the capability and creativity of our Associates, and we are proud to offer a comprehensive and competitive total rewards program that supports your everyday and helps you build your tomorrow.

We provide benefits that offer choice and flexibility and promote overall well-being. And in keeping with our belief that every Associate should share in the collective success of the enterprise; we provide a distinctive Associate Stock Ownership Plan in each country as well as potential opportunities for “profit-sharing”. Learn more at gore.com/careers/benefits

We believe in the strength of a diverse and inclusive workplace. With diverse perspectives, ideas and experiences, we uncover new possibilities and make a greater impact in the world. We are proud of Associates for building on our rich history of innovation, upholding our values and supporting an inclusive work environment where we treat each other and our external partners with fairness, dignity and respect.

Gore is an equal opportunity employer. We welcome all applications irrespective of race, color, religion, sex, gender, national origin, ancestry, age, status as a qualified individual with a disability, genetic information, pregnancy status, medical condition, marital status, sexual orientation, status as a covered veteran, gender identity and expression, and any other characteristic protected by applicable laws and regulations.

Gore is committed to a drug-free workplace. All employment is contingent upon successful completion of drug and background screening. Gore will consider qualified applicants with criminal histories, e.g., arrest and conviction records, in a manner consistent with the requirements of applicable laws.

Gore requires all applicants to be eligible to work within the U.S. Gore generally will not sponsor visas unless otherwise noted on the position description.

Our Talent Acquisition Team welcomes your questions at gore.com/careers/contact

",Full-time
4096799444,134112.0,Data Engineer,"GARNEY CONSTRUCTION

As the Data Engineer in North Kansas City , you’ll leverage your extensive knowledge of technology in the data infrastructure field. Your expertise will allow you to shape, deploy, and oversee the data warehouse and will position you for success and make you a valuable asset to our team.

THIS IS NOT A REMOTE POSITION AND MUST BE WORKED FROM OUR NORTH KANSAS CITY OFFICE.

What You Will Be Doing


 * Partnering with our external consultant to develop a data warehouse.
 * Advanced SQL scripting.
 * Python development.
 * ETL design and development.
 * API integrations.
 * Matching data design and architecture.
 * Creating, innovating, and automating processes.
 * Build data systems and pipelines.
 * Evaluate business needs and objectives.
 * Prepare data for prescriptive and predictive modeling.
 * Combine raw information from different sources.
 * Explore ways to enhance data quality and reliability.
 * Identify opportunities for leveraging internal data
   
   

What We Are Looking For


 * Excellent judgment, and work accurately and efficiently with minimal guidance
 * Ability to meet deadlines and have an acute attention to detail
 * SQL Skills (e.g. SPs, CTEs, windowed functions)
 * Experience with ETL technology (Informatica, Alteryx, Microsoft, Python, or equivalent)
 * Ability to diagnose, troubleshoot, and solve technical issues.
 * Interpersonal skills and able to collaborate with different departments
   
   

LET'S TALK THE PERKS!


 * Employee Stock Ownership Plan (ESOP)
 * 401K Retirement plan
 * Health, dental, vision and life insurance
 * Flexible Spending Account (FSA) / Health Savings Account (HSA)
 * Long-term disability
 * Holidays, Vacation and PTO
 * Bonus program
   
   

CONTACT US

If you are interested in this Data Engineer position in North Kansas City, MO then please Apply Now. For other opportunities available at Garney Construction go to careers.garney.com . If you have questions about the position or would like more information, please contact Christina by email .",Full-time
4067205797,102677437.0,Data Engineer,"Interview Process: 3 Rounds of Interview

﻿Expertise


 * 5-9+ years of relevant industry experience with a BS/Masters, or 2+ years with a PhD
 * Experience with distributed processing technologies and frameworks, such as Hadoop, Spark, Kafka, and distributed storage systems (e.g., HDFS, S3)
 * Demonstrated ability to analyze large data sets to identify gaps and inconsistencies, provide data insights, and advance effective product solutions
 * Expertise with ETL schedulers such as Apache Airflow, Luigi, Oozie, AWS Glue or similar frameworks
 * Solid understanding of data warehousing concepts and hands-on experience with relational databases (e.g., PostgreSQL, MySQL) and columnar databases (e.g., Redshift, BigQuery, HBase, ClickHouse)
 * Excellent written and verbal communication skills
   
   

A Typical Day


 * Design, build, and maintain robust and efficient data pipelines that collect, process, and store data from various sources, including user interactions, financial details, and external data feeds.
 * Develop data models that enable the efficient analysis and manipulation of data for merchandising optimization. Ensure data quality, consistency, and accuracy.
 * Build scalable data pipelines (SparkSQL & Scala) leveraging Airflow scheduler/executor framework
 * Collaborate with cross-functional teams, including Data Scientists, Product Managers, and Software Engineers, to define data requirements, and deliver data solutions that drive merchandising and sales improvements.
 * Contribute to the broader Data Engineering community at Airbnb to influence tooling and standards to improve culture and productivity
 * Improve code and data quality by leveraging and contributing to internal tools to automatically detect and mitigate issues.
 * Skill Sets - Python, SQL (expert level), Spark and Scala (intermediate).
   
   

Skills: aws,postgresql,spark,hadoop,apache airflow,s3,mysql,luigi,relational databases,oozie,aws glue,columnar databases,hdfs,etl,scala,data warehousing,airflow,kafka,python,sql",Contract
4144919803,2531104.0,Data Engineer,"Connect Search has a client seeking to hire multiple W2 AWS Cloud Data Engineers to join their team for a 2 year contract that can be extended or converted to Full Time.




No Corp to Corp/H1B

Open to W2 and 1099 Professionals ONLY!!




Medical, Dental, Vision, and 401K for eligible employees.

Hourly Range Paid Weekly - $65/hr to $80/hr




We are seeking a Data Engineer with experience in Python development and advanced data pipeline design to join our team. The ideal candidate will have strong SQL skills, expertise in dataframes and Pandas, experience with AWS ecosystems, and a deep understanding of enterprise data environments.

Key Responsibilities:

 * Develop, maintain, and optimize data pipelines for enterprise systems.
 * Utilize dataframes and Pandas for advanced data manipulation, analysis, and transformation tasks.
 * Write and execute complex SQL queries for data modifications and transformations, including joining and updating tables.
 * Load, process, and manage data in Snowflake and establish it as the system of record.
 * Ensure proper data ingestion and create history tracking columns in RDS.
 * Work within an AWS environment, leveraging tools like S3, RDS, DynamoDB, Lambda, and Kinesis for data streaming and storage.
 * Build and tweak CI/CD pipelines to support agile delivery in two-week cycles.
 * Collaborate with the dealer and enterprise data team to ingest and manage subscription data, customer information, and equipment records.
 * Operate autonomously to execute high-priority tasks and troubleshoot complex data scenarios.

Requirements:

 * Bachelors Degree Required
 * At Least 6 years of experience in Data Engineering
 * Proficiency in Python and extensive experience with dataframes and Pandas for data manipulation.
 * Mid to advanced SQL skills for developing and understanding complex queries, with the ability to write and optimize SQL for Snowflake.
 * Familiarity with AWS infrastructure, including data streaming and storage tools like S3, RDS, and Kinesis.
 * Experience with CI/CD pipelines and agile workflows.
 * Enterprise data experience with an understanding of subscription models and data streaming processes.
 * Strong problem-solving skills and the ability to work autonomously.




please apply if interested!!

",Contract
4118737469,71405910.0,Data Engineer,"Job Title: Data Engineer (US Citizens only)

Location: Remote

We are currently seeking candidates who meet the following qualifications:

Responsibilities

Key Responsibilities:


 * Design, develop, and maintain scalable data pipelines and ETL processes.
 * Implement and manage DBT models for data transformation and ensure data quality and consistency.
 * Collaborate with data analysts, data scientists, and business teams to understand data requirements and deliver solutions.
 * Optimize database performance and ensure efficient querying and processing of large datasets.
 * Monitor, troubleshoot, and improve data workflows and systems.
 * Integrate data from various sources into centralized data platforms.
 * Document data workflows, processes, and technical specifications.
 * Stay up-to-date with the latest advancements in data engineering and DBT practices.
   
   

Requirements


 * Bachelor’s or Master’s degree in Computer Science, Data Engineering, or a related field.
 * Proven experience in data engineering, with a strong focus on DBT.
 * Proficiency in SQL and experience with modern data warehouses (e.g., Snowflake, BigQuery, Redshift).
 * Experience with data pipeline orchestration tools (e.g., Airflow, Prefect).
 * Experience with cloud platforms (e.g., AWS, Azure, Google Cloud).
 * Strong programming skills in Python or a similar language.
 * Knowledge of data modeling principles and best practices.
 * Excellent problem-solving skills and attention to detail.
 * Experience with BI tools (e.g., Tableau, Looker, Power BI) is a plus.
 * Federal Experience is a plus.
 * Required Security clearance.
   
   

If you meet these qualifications, please submit your application via link provided in Linkedin.

Kindly do not call the general line to submit your application.",Full-time
3875375341,46623.0,Data Engineer,"Description

Your role at GEI.

GEI Consultants has an opening in our Operational Development Team for a qualified Data Engineer to support a variety of systems and data engineering tasks focused on data flow activities. The majority of our systems are based in MS SQL Server, Tableau Server, Azure, and FastField Forms. This person will primarily work closely with members of the Operational Development Team and with members of our IT staff. The ideal candidate will be focused, detail-oriented, and driven to attain and maintain very high standards for efficiency and accuracy in data acquisition and integration into our systems. The ideal candidate will have more than 3 years of data engineering experience in the AEC industry or in similar science and/or engineering environments. GEI seeks a committed, self-motivated, organized and detail-oriented individual who anticipates issues and thrives on creative, independent problem solving within a rapid, deadline-driven environment.

Essential Responsibilities & Duties


 * ETL of data from a wide variety of sources
 * Database and Data Warehouse design/expansion/backup & recovery
 * Index management and optimization
 * Support data sources for Tableau Server, Power BI, and ArcGIS
 * Stored procedure development and maintenance
 * Identify new opportunities within GEI where existing business approaches to data can be replaced with a more efficient/automated data flow and presentation of data for analysis
 * Develop and optimize ETL/SSIS packages to facilitate data transfer between FTP, remote data loggers, Azure, and on-premises databases
 * Troubleshoot SSIS package permission issues related to execute-as/data source read/write access
 * SQL Agent Job development and monitoring
 * Develop data reporting and visualizations as specified by clients using Tableau, SSRS, etc
 * Perform DML and DDL via tsql/stored procedures executed directly within SSMS and remotely via SSIS
 * Develop test plans, implementation plans, and project timelines for various data engineering projects
 * Define, prioritize, communicate, and foster shared understanding of project objectives and scope
 * Coordinate the development of standard operating procedures (SOPs), technical training programs, and QA/QC procedures for staff and work product
 * Team with all staff necessary to complete assignments
 * Collaborate with technical team members to ensure the solution design satisfies project objectives and business requirements
 * Other duties as assigned
   
   

Minimum Qualifications


 * 3+ years of experience in a position performing similar data engineering tasks
 * Proven record of ability to design, manage, and support MS SQL Server and Azure databases
 * Ability to work with the following programming/mark-up/scripting languages preferred: VB.net, python, XML, javascript, and R
 * Bachelor's Degree, from an accredited college or university
 * MS SQL Server/Azure certification preferred
 * Ability to develop project plans and meet deadlines
 * Self-starter with attention to detail and stakeholder needs
 * Able to critically analyze and solve problems of a complex nature
 * Excellent Communication skills
 * Able to work on multiple projects of moderate complexity simultaneously and independently
 * Proficient in organization and time management skills
 * Familiarity with engineering, environmental science, and/or chemistry subject matter preferred.
 * Able to work effectively in GEI’s partnership model, including a team environment, building rapport and relationships.
   
   

We are GEI.

Some of the world’s most pressing problems - from climate change to sustainable development, to critical infrastructure and the future of our energy supply - need our brightest and diverse minds working together to create safer, more resilient communities for tomorrow.

We are technical experts, collaborators, and entrepreneurs who draw from diverse backgrounds to solve our clients’ most complex challenges.

With nearly 60 offices across North America, we offer a range of engineering, science, and technical consulting services. Our range of expertise, project types, and culture make us the choice for top talent in the AEC industry.

Employee-owned. Employee-focused.

As a 100% employee-owned company, our employees support our flat leadership structure, have a say in how our business operates and benefit from our financial success. We are committed to employee growth with career development opportunities, competitive total rewards, a well-being program, flexible work arrangements and more. Our company culture is driven by our 4 Cs - we are Client-Centered, Curious, Collaborative, and Community Minded - which support our focus on sustainability, safety, diversity, equity and inclusion. Get to know us better by visiting GEI’s career site here.

GEI’s Total Rewards Package


 * Market-Competitive Compensation, including Eligibility for an Annual Performance Bonus
 * Pay Range For This Position: $33.65-72.11/hour
 * Comprehensive Benefits Program, including Medical, Dental, Vision, Life, Disability and More
 * Well-Being Program and Paid Parental Leave
 * Commuter Benefits
 * Hybrid Work Schedules and Cell Phone Stipends
 * GEI University (GEIU) with Continuing Education Assistance and Tuition Reimbursement
 * Connecting Conversation Program with a Focus on Professional Development and Opportunities for Advancement
 * Support and Financial Rewards for Publication Awards, Professional Dues, and Professional Licenses
 * Paid Holidays and Generous Paid Time Off Program
 * Rewards and Recognition
 * GEI-Funded Profit Sharing and 401(k)
 * Opportunity to be an Owner and Shareholder (Learn more here)
 * A Vibrant Culture that is Focused on Partnership, Sustainability, Giving Back to Our Communities and Diversity, Equity and Inclusion
 * And More…
   
   

Physical Job Requirements

Sedentary

X

Light

Medium

Other

Activity Level Throughout Workday

Physical Activity Requirements

Occasional

(0-35% of day)

Frequent

(33-66% of day)

Continuous

(67-100% of day)

Not Applicable

Sitting

X

Standing

X

Walking

X

Climbing

X

Lifting (floor to waist level) (in pounds)

X

Lifting (waist level and above) (in pounds)

X

Carrying objects

X

Push/pull

X

Twisting

X

Bending

X

Reaching forward

X

Reaching overhead

X

Squat/kneel/crawl

X

Wrist position deviation

X

Pinching/fine motor skills

X

Keyboard use/repetitive motion

X

Taste or smell (taste=never)

X

Talk or hear

X

Accurate 20/40

Very Accurate 20/20

Not Applicable

Near Vision

X

Far Vision

X

Yes

No

Not Applicable

Color Vision (ability to identify and distinguish colors)

X

Sensory Requirements

Minimal

Moderate

Accurate

Not Applicable

Depth perception

X

Hearing

X

Environmental Requirements

Occupational Exposure Risk Potential

Reasonably Anticipated

Not Anticipated

Blood borne pathogens

X

Chemical

X

Airborne communicable diseases

X

Extreme temperatures

X

Radiation

X

Uneven surfaces or elevations

X

Extreme noise levels

X

Dust/particular matter

X

Other (exposure Risks)

Usual workday hours:

X

8

10

12

Other work hours

GEI is an AA/equal opportunity employer, including disabled and veterans.",Full-time
4125069340,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
3875378307,46623.0,Jr. Web Application Data Engineer,"Description

Your role at GEI.

The Jr. Web Application Data Engineer position is responsible for the development and support of web applications that are highly data centric. This position goes beyond the typical web programmer and will design and support objects within Microsoft SQL Server. The person hired for this position will work with a team of Web programmers, Data Engineers, Data Architects, GISPs, Power BI designers, and subject-matter experts that are located on the east coast.

Required Qualifications


 * Practical experience with .Net framework for web development, C#, ASP.net, jquery, HTML/ razer, Linq, javaScript, and git or other version control management software.
 * Expertise in SDLC.
 * Ability to provide off-hour deployments and support for bug-fixes.
 * Major in computer-related field (computer science/engineering)
 * Able to work during east coast schedule.
   
   

Preferred Qualifications


 * Experience using Entity Framework Core
 * Experience with Microsoft SQL Server via SSMS - DDL and DML, relationships, indexing, view, and stored procedure development.
 * Knowledge of .Net Core
 * Azure authentication
 * Azure Blob storage integration
 * Power BI cloud service
 * Experience with VB.net for desktop applications, XML, XSD for supporting non-web applications.
   
   

Essential Duties


 * Design, program, test, deploy, and document web applications.
 * Design and build SQL Server schema.
 * Collaborate with data architects and data engineers.
 * Develop a strong understanding of the subject matter for each application to assist with troubleshooting.
 * Provide programming and data engineering assistance for desktop applications.
   
   

Soft Skills


 * Applicant should be self-motivated, detail-oriented, and organized.
 * Must be a quick learner.
 * Work well in a team environment but be self-directed and be able to work independently.
 * Experience in providing high quality deliverables on time.
 * Provide clear concise documentation for developed applications.
 * Ability to research coding solutions and best practices via websites or the resources.
   
   

We are GEI.

Some of the world’s most pressing problems - from climate change to sustainable development, to critical infrastructure and the future of our energy supply - need our brightest and diverse minds working together to create safer, more resilient communities for tomorrow.

We are technical experts, collaborators, and entrepreneurs who draw from diverse backgrounds to solve our clients’ most complex challenges.

With nearly 60 offices across North America, we offer a range of engineering, science, and technical consulting services. Our range of expertise, project types, and culture make us the choice for top talent in the AEC industry.

Employee-owned. Employee-focused.

As a 100% employee-owned company, our employees support our flat leadership structure, have a say in how our business operates and benefit from our financial success. We are committed to employee growth with career development opportunities, competitive total rewards, a well-being program, flexible work arrangements and more. Our company culture is driven by our 4 Cs - we are Client-Centered, Curious, Collaborative, and Community Minded - which support our focus on sustainability, safety, diversity, equity and inclusion. Get to know us better by visiting GEI’s career site here.

GEI’s Total Rewards Package Includes


 * Market-Competitive Compensation, including Eligibility for an Annual Performance Bonus
 * Pay Range For This Position: $25.00-32.00/hour dependent upon experience
 * Comprehensive Benefits Program, including Medical, Dental, Vision, Life, Disability and More
 * Well-Being Program and Paid Parental Leave
 * Commuter Benefits
 * Hybrid Work Schedules and Cell Phone Stipends
 * GEI University (GEIU) with Continuing Education Assistance and Tuition Reimbursement
 * Connecting Conversation Program with a Focus on Professional Development and Opportunities for Advancement
 * Support and Financial Rewards for Publication Awards, Professional Dues, and Professional Licenses
 * Paid Holidays and Generous Paid Time Off Program
 * Rewards and Recognition
 * GEI-Funded Profit Sharing and 401(k)
 * Opportunity to be an Owner and Shareholder (Learn more here)
 * A Vibrant Culture that is Focused on Partnership, Sustainability, Giving Back to Our Communities and Diversity, Equity and Inclusion
 * And More…",Full-time
4125058812,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4125070023,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4126592463,81777085.0,Data Engineer,"MUST HAVES

(60 tech ability/40 soft skills)


 * Snowflake shop
 * Snowflake Certified is a big plus (SnowPro)
 * ETL processes
 * Strong understanding of healthcare Data Standards is a plus (HL7, FHIR)
 * Strong understanding of EMR / EHR system integration (Athena, Mirth, etc)
 * Data migration
 * modern data engineering practices, etc.
 * opentable formats like datalake and iceberg
 * Exposed to databricks pipeline
 * Data mesh exposure
 * Must see the Data frameworks they have worked with in the resume
 * Exposure to delta lake, data mesh approaches, iceberg tables and exposure to databricks pipelines.",Full-time
3787900358,80873376.0,Data Engineer,"HR Professionals is currently seeking candidates to fill various positions for Business Intelligence Developer candidates that are interested in working throughout the State of Louisiana or are interested in Remote opportunities. These positions will require the experiences outlined below.

Job Summary

The Data Engineer will be responsible for operationalizing data and analytics initiatives for the company. They will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection. The Data Engineer is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, data architects, and data analysts on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products.

Minimum Requirements


 * A bachelor's or master's degree in computer science, statistics, applied mathematics, data management, information systems, information science or a related quantitative field or equivalent work experience
 * At least five years or more of work experience in data management disciplines including data integration, modeling, optimization and data quality, and/or other areas directly relevant to data engineering responsibilities and tasks
 * At least three years of experience working in cross-functional teams and collaborating with business stakeholders in support of a departmental and/or multi-departmental data management and analytics initiative
 * Knowledge and/or familiarity of the midstream services industry and data generated in support of business activities related to the gathering, compressing, treating, processing, and selling natural gas, NGLs and NGL products, and crude oil will be strongly preferred
 * Strong experience with advanced analytics tools for Object-oriented/object function scripting using languages such as R, Python, Java, C++, Scala, and others
 * Strong ability to design, build and manage data pipelines for data structures encompassing data transformation, data models, schemas, metadata, and workload management
 * The ability to work with both IT and business in integrating analytics and data science output into business processes and workflows
 * Strong experience with database programming languages including SQL, PL/SQL, and others for relational databases, and knowledge and/or certifications on upcoming NoSQL/Hadoop-oriented databases like MongoDB, Cassandra, and others for nonrelational databases
 * Strong experience in working with large, heterogeneous datasets in building and optimizing data pipelines, pipeline architectures and integrated datasets using traditional data integration technologies
 * Knowledge and/or experience in working with SQL on Hadoop tools and technologies including HIVE, Impala, Presto, others from an open source perspective and Hortonworks Data Flow (HDF), Dremio, Informatica, Talend, others from a commercial vendor perspective
 * Experience in working with both open-source and commercial message queuing technologies such as Kafka, JMS, Azure Service Bus, Amazon Simple Queuing Service, others, stream data integration technologies such as Apache Nifi, Apache Beam, Apache Kafka Streams, Amazon Kinesis, and others
 * Basic experience working with popular data discovery, analytics, and BI software tools like Tableau, Qlik, PowerBI and others for semantic-layer-based data discovery
 * Strong experience in working with data science teams in refining and optimizing data science and machine learning models and algorithms
 * Basic experience in working with data governance/data quality and data security teams and specifically data stewards and security resources in moving data pipelines into production with appropriate data quality, governance and security standards and certification
 * Demonstrated ability to work across multiple deployment environments including cloud, on-premises and hybrid, multiple operating systems and through containerization techniques such as Docker, Kubernetes, AWS Elastic Container Service and others
 * Familiarity with agile methodologies and capable of applying DevOps and increasingly DataOps principles to data pipelines to improve the communication, integration, reuse and automation of data flows between data managers and consumers across an organization
 * Strong written and verbal communication skills with an aptitude for problem-solving
 * Must be able to independently resolve issues and efficiently self-direct work activities based on the ability to capture, organize, and analyze information
 * Experience troubleshooting complicated issues across multiple systems and driving solutions
 * Experience providing technical solutions to non-technical individuals
 * Demonstrated team-building skills
 * Ability to deal with internal employees and external business contacts while conveying a positive, service-oriented attitude
   
   

Summary Of Essential Functions


 * Develop, construct, test, and maintain data architectures or data pipelines
 * Ensure data architecture will support the requirements of the business
 * Discover opportunities for data acquisition
 * Develop data set processes for data modeling, mining, and production
 * Employ a variety of languages and tools to marry systems together
 * Recommend ways to improve data reliability, efficiency, and quality
 * Leverage large volumes of data from internal and external sources to answer business demands
 * Employ sophisticated analytics programs, machine learning, and statistical methods to prepare data for use in predictive and prescriptive modeling while exploring and examining data to find hidden patterns
 * Drive automation through effective metadata management using innovative and modern tools, techniques, and architectures to partially or completely automate the most common, repeatable, and tedious data preparation and integration tasks to minimize manual and error-prone processes and improve productivity
 * Propose appropriate (and innovative) data ingestion, preparation, integration, and operationalization techniques in optimally addressing data requirements
 * Ensure that the data users and consumers use the data provisioned to them responsibly through data governance and compliance initiatives
 * Promote the available data and analytics capabilities and expertise to business unit leaders and educate them in leveraging these capabilities in achieving their business goals
   
   

Powered by JazzHR

V0JPAmSoWn",Full-time
4105709034,99282368.0,Data Engineer II,"Job Title: Data Engineer II

Location: Spring / Houston, TX - 77389

Job Type: 12 Months+ (Long Term Contract)

Data Engineer Responsibilities


 * Perform ETL, ELT operations and administration using modern tools, programming languages and systems securely and in accordance with enterprise data standards
 * Assemble, model, transform large complex sets of data that meet non-functional and functional business requirements into a format that can be analyzed
 * Automate data processing of data from multiple data sources
 * Develop, deploy and version control code for data consumption, reuse for APIs
 * Employ machine learning techniques to create and sustain data structures
 * Perform root cause analysis on external and internal processes and data to identify opportunity for improvement, resolve data quality issues
 * Lead data-related workshops with stakeholders to capture data requirements and acceptance criteria
   
   

Skills And Qualifications

We are looking for someone who has technical depth and broad tool experience related to data engineering and has the following required qualifications:


 * Minimum bachelor’s degree in: Data Science, Business Intelligence, Statistics, Computer Engineering or related field, or the equivalent combination of education, professional training, and work experience
 * 5 or more years performing duties related to data engineering
 * Advance English level
 * Expert proficiency in at least one of these programming languages: Python, NoSQL, SQL, R, and competent in source code management
 * Build processes supporting data transformation, data structures, metadata, dependency, and workload management
 * Create data validation methods and data analysis tools
   
   

Preferred Qualifications / Experience


 * Excellent problem-solving skills and ability to learn through scattered resources
 * Automate routine tasks via scripts, code
 * Capacity to successfully manage a pipeline of duties with minimal supervision
 * Experience supporting and working with cross-functional teams in a dynamic environment
 * Modify existing reports, extracts, dashboards, and cubes as necessary
 * Commitment to operations integrity and ability to hold self and others accountable for results
   
   

Required Proficiency


 * Advanced SQL
 * Snowflake
 * Tamr (Tamr's platform provides an end-to-end workflow so you can collaboratively design, configure, curate, manage, and publish data products.)
 * Python
 * GitHub
 * Databricks
 * Airflow
   
   

If you are interested or have any references please share resume at mukul@brightmindsol.com.",Contract
4151638002,10456809.0,Data Engineer,"Company Introduction

OneSource Regulatory Technology hosts a number of innovative solutions to enhance job performance in the Pharmaceutical space. OSR Technology is looking for an experienced and dedicated data engineer to join our product solutions team!

Job Description

OneSource Regulatory is trying to identify a full-time contractor with at least 4+ years of experience to assist us with ongoing R&D projects.

We are looking for a data engineer to pull data from various sources and do all the necessary steps to clean, normalize, possibly annotate, and finally load the data into databases. The candidate should be able to develop and implement a strategy for testing the data integrity of the collected data. This role requires extreme attention to detail to ensure data quality is top priority.

Responsibilities


 * Well versed in parsing and synthesizing of XML and/or JSON documents.
 * Curating of data that can involve some intermediate to advanced web scraping. (data may need to be fetched via SFTP, FTP, Wget, Curl, REST APIs, GraphQL queries from spots on the Internet)
 * Proficiency with Linux command line and various simple tools, such as grep, wc, sed, awk, find, ls, cat, piped commands and possibly some very light Bash shell scripting, setting up crontab schedules and programs
 * Must have basic knowledge of SQL with the following databases: PostGres, MySQL, Google BigQuery
 * Must have basic knowledge of No-SQL database knowledge such as MongoDB or similar
 * Familiarity with basic Cloud technology such as storage buckets, cloud serverless functions
 * Must have experience extracting text and images from PDF files
 * Knowledge of Puppeteer or other automatable web client technologies
 * Understanding JavaScript, HTML/CSS and HTTP methods (for understanding page structure for web scraping)
   
   

Skills


 * Solid experience with Python and Python Libraries such as Pandas, requests, etc
 * Skill set should match up with required responsibilities listed above
 * Strong English skills (e.g. grammatical analysis and rhetorical structure)
 * Team Player
 * Great communication skills
   
   

Bonus Skills


 * Experience within the Pharmaceutical Space
 * Ability to expose data via C# NETCore and/or GraphQL
 * Google Cloud Platform (Cloud Buckets, Google Cloud Functions (.NET, Python, Node.JS))
 * Ability to parallelize data manipulation and scraping via Python multi-threading, etc.
 * Python BeautifulSoup
 * Scrapy
 * Docker (setting up Kubernetes style processing if warranted for data scraping/data ingestion/normalization)
 * Multithreading concepts",Full-time
4129882615,74475378.0,Software (Data) Engineer,"Software (Data) Engineer - Series A Climate Tech Startup - San Francisco (Onsite)




A Series A funded Climate Tech startup on a mission to stabilize the earth's climate are on the lookout for a Software (Data) Engineer to join their team.




What you'll be doing:




 * Build and scale robust data infrastructure and integrations that power operational workflows and scientific processes, focusing on creating efficient, automated systems that enable data-driven decision making
 * Develop backend solutions using Python/FastAPI while managing technical infrastructure including cloud systems, CI/CD pipelines, and DevOps tools to ensure reliable service delivery
 * Foster a culture of engineering excellence through comprehensive documentation, automated testing, and high-quality code practices that support seamless deployment and system reliability




What we're looking for:




 * At least 3 years' of software development experience in Python
 * Experience with geospatial data
 * Skilled in building ETL pipelines
 * Strong track record of shipping products, especially in a startup environment
 * Passion about addressing climate change




What's in it for you:




 * Join a fast-growing engineering team where you'll have significant autonomy to architect solutions and shape core platform features from the ground up
 * Develop your technical expertise across the full stack while working with modern technologies including Python
 * Make an impact by building meaningful products that directly enhance operational efficiency and enable data-driven decision making at scale
 * Salary of $150,000 - $250,000 dependent on level of experience




Apply now for immediate consideration!",Full-time
4056090620,5094099.0,Data Engineer,"Job Title: Data Engineer

Location: Hybrid / Remote with periodic meetings in Atlanta, GA

Company: Block+Tackle (Block-Tackle.com)




About Us:




Block+Tackle is a boutique marketing automation and customer strategy consultancy that drives innovation and efficiency for our clients through expert data solutions. We’re seeking a Data Engineer to join our growing team and contribute to building scalable, reliable, and efficient data pipelines.




Position Overview:




As a Data Engineer at Block+Tackle, you will be responsible for designing, implementing, and optimizing data pipelines using Azure Data Factory, Databricks, and other cloud-based tools. You will work closely with data architects, analysts, and other stakeholders to deliver robust ETL solutions that enhance data quality, accessibility, and analysis capabilities. This role is critical for transforming raw data into valuable insights that drive client decision-making and success.




Key Responsibilities:




• Design, develop, and maintain scalable ETL processes using Azure Data Factory, Databricks, and other related tools.

• Collaborate with data architects and analysts to understand data requirements, ensuring seamless integration and data flow across systems.

• Optimize and automate data pipelines to ensure high performance, reliability, and scalability.

• Implement data governance and quality controls to ensure accuracy, completeness, and compliance with relevant standards and policies.

• Monitor and troubleshoot data pipeline issues, proactively addressing potential bottlenecks or failures.

• Develop and maintain documentation for ETL processes, data models, and architecture.

• Stay current with new tools, trends, and best practices in data engineering and cloud-based ETL processes, applying them to improve solutions.




Qualifications:




• Bachelor’s degree in Computer Science, Engineering, or a related field (or equivalent work experience).

• 3+ years of hands-on experience as a Data Engineer or similar role, with strong expertise in building ETL pipelines.

• Proficiency in Azure Data Factory and Databricks, with experience in designing data transformation and integration solutions.

• Strong SQL skills, with the ability to write complex queries and manage relational databases.

• Experience with cloud-based data architecture, including data lakes, warehouses, and streaming solutions.

• Knowledge of Python, Scala, or similar programming languages for ETL development and data manipulation.

• Familiarity with data governance, security, and compliance practices.

• Strong problem-solving skills, attention to detail, and the ability to work independently or as part of a team.




Preferred Skills:




• Experience with other cloud data platforms (AWS, GCP).

• Familiarity with DevOps tools for CI/CD pipeline integration.

• Knowledge of marketing data and analytics processes is a plus.




What We Offer:




• Competitive salary and benefits package

• Flexible hybrid work environment

• Opportunities for professional growth and skill development

• A collaborative and inclusive company culture


",Full-time
4135291879,82256378.0,Data Engineer,"Position Overview

We are seeking a Data Engineer to design, build, and maintain the scalable data infrastructure that powers Dorsia's insights and applications. You will work closely with the analytics and data science teams to ensure data availability, reliability, and integrity. The ideal candidate is experienced in building data pipelines, managing data warehouses, and optimizing data systems for performance.

Key Responsibilities


 * Design and implement scalable data pipelines and ETL processes using tools like Fivetran, Airflow, or dbt.
 * Maintain and optimize data storage systems, including data warehouses like Snowflake.
 * Ensure high data quality and integrity across the organization.
 * Collaborate with data analysts and scientists to provide reliable datasets for analysis and modeling.
 * Monitor and troubleshoot data systems to ensure reliability and performance.
 * Implement best practices for data governance and security.
 * Evaluate and integrate new data tools and technologies to enhance our infrastructure.
   
   

Qualifications


 * Bachelor's degree in Computer Science, Engineering, or a related field.
 * 2–4 years of experience in data engineering or a related role.
 * Proficiency in SQL and experience with cloud-based data warehouses like Snowflake or Redshift.
 * Experience with data pipeline tools such as Apache Airflow, Fivetran, or dbt.
 * Strong programming skills in Python or Java.
 * Familiarity with cloud environments (AWS preferred).
 * Knowledge of best practices for data governance and security.
   
   

Preferred Qualifications


 * Experience in a high-growth or start-up environment.
 * Knowledge of big data tools like Apache Spark or Hadoop.
 * Familiarity with observability tools such as DataDog.
   
   

Compensation & Benefits:


 * Salary ranges are based on paying competitively for our size and stage. We determine our pay by considering skills and experience related to the role, location, and ensuring internal equity relative to other Dorsia employees
 * Flexible PTO
 * Medical, dental and vision insurance
 * FSA
 * Commuter benefits
 * Free membership to One Medical
 * Teladoc
 * Talkspace
 * Kindbody
 * 401(k)
 * In-office lunch 3 days a week
 * Employee Dining Credits
   
   

Our Core Values

Lead with hospitality. We respect the craft and precision that are intrinsic to the hospitality industry. We are a team diverse in background and thought, built to be the connective tissue between artists, chefs, diners, and members.

Mise en place. We are persistent in preparation, prioritization, and focus to anticipate our customers' needs to create a powerful platform rooted in simplicity and elegance. And we know that details matter, which is why superior design is crucial to our brand ethos. Thoughtful design is baked into everything we do—our product, brand, creative, culture, and beyond.

Go around the table—then commit. We know creativity takes feedback and iteration, and differing opinions can lead to healthy debate. While we encourage all voices to speak up and be heard, we are geared toward action and unify around the decision once it's made. Sometimes an individual idea or project may not be what's best for the company, so don't be afraid to kill your darlings.

Our product is our signature dish. We are a product and marketing-led organization. Protecting our brand and vision needs to be top-of-mind with every move we make.

Optimize turn times. We are creating beautifully-designed, tech-forward solutions to automate all sides of our business: for members, restaurants, and employees. And we're laying a data-rich foundation to enable all stakeholders to make better decisions and enjoy the finer things in life.

Savor it. We eat slowly and celebrate the wins we share with those around the table. We're in this for the long-haul, so enjoy the ride.

Stay hungry. We can change the world or someone else will. We believe in a sense of urgency to keep pushing toward our goals. And there's always room for dessert, because there's always more to do.",Full-time
4117642601,19283.0,Data Engineer,"Location: Dallas, TX

Position: Full-time

Department: Information Technology

Overview

We are seeking an experienced Data Engineer with a minimum of 4 years of expertise in designing, building, and maintaining data pipelines and architectures. The ideal candidate will have a strong background in data engineering, a passion for working with large datasets, and the ability to collaborate effectively with cross-functional teams.

Responsibilities

 * Design and Development: Build and maintain scalable data pipelines and architectures to support business requirements.
 * Database Management: Manage and optimize databases, ensuring their reliability, scalability, and security to support business needs.
 * ETL Processes: Implement and oversee ETL (Extract, Transform, Load) processes to integrate various data sources into a unified data warehouse.
 * Data Quality Assurance: Establish and enforce data quality standards, including data validation, cleansing, and enrichment techniques.
 * Data Integration: Integrate data from various sources, ensuring data quality and integrity.
 * Optimization: Optimize existing data pipelines and systems for performance and scalability.
 * Collaboration: Work closely with stakeholders to understand data needs and deliver solutions.
 * Data Governance: Implement data governance and security protocols to ensure compliance with organizational standards.
 * Documentation: Create and maintain comprehensive documentation for data pipelines, architectures, and processes.
 * Monitoring: Monitor and troubleshoot overall data architecture components to ensure smooth operation and minimal downtime.

Required Skills

 * Expertise in SQL and experience with relational databases (e.g. SQL Server, MySQL, Azure SQL Database).
 * Experience with big data technologies like Hadoop, Spark, Kafka, and cloud platforms (AWS, Azure, GCP)
 * Proficiency in programming languages such as Python, Java, or Scala.
 * Experience with data integration tools (e.g., Apache Nifi, Talend).
 * Experience in developing data pipelines in Azure Data Factory.
 * Experience with NoSQL database (e.g. Cosmos Db).
 * Experience with data warehousing & data lake concepts and technologies (e.g., Redshift, Snowflake).
 * Experience in building and deploying machine learning models at scale
 * Experience with streaming technologies – Kafka.
 * Perform other duties as assigned.
 * Should have worked on XML, JSON and other custom Complex Data Parsing formats.
 * Ready to learn new technologies and tools




Qualifications

 * Experience: Minimum of 4 years of experience in data engineering or a related field.
 * Education: Bachelor’s degree in computer science, Information Technology, or a related discipline.
 * Strong analytical and problem-solving skills.
 * Excellent communication and interpersonal skills.
 * Ability to work independently and as part of a team.
 * Attention to detail and a commitment to data quality.
 * Excellent analytical and problem-solving skills with a strong ability to derive insights from complex data sets.

",Full-time
4152194549,2678950.0,Data Engineer,"Our client is looking for a Senior Data Engineer to join their team! This position will carry the responsibility of an associate director but will be hands-on and not carry any direct management responsibility but provides an opportunity to solve complex business, data, and technical challenges. The Senior Data Engineer will have delivered solutions which are mixed on-prem / AWS hybrid and have demonstrated a drive toward building cloud-native solutions. The person in this role will be responsible for driving execution through iterative development, software craft and automation wherever possible.

Responsibilities

 * Collaborate with architects, product managers, and designers to understand the requirements, scope, and deliver high-quality solutions.
 * Design, develop, and maintain GraphQL APIs and Data Solutions using RDBMS like Aurora, Postgres, and in-memory data stores like Amazon Memory DB and Redis, ensuring optimal performance, data integrity, availability and scalability.
 * Utilize TypeScript to write clean, maintainable, and efficient code for back-end development.
 * Execute multi-product development strategy in collaboration with cross-functional teams to create, develop and support multiple products, ensuring seamless integration and consistent user experiences.
 * Participate in design, development and review of automated test cases to ensure comprehensive test coverage and high software quality.
 * Extensive experience with cloud platforms, containerization technologies and infrastructure as code (IaC) like AWS, Azure, Docker, Kubernetes and Terraform
 * Strong background in DevOps with extensive experience in CI/CD practices, along with a passion for automating processes to enhance productivity and code quality.
 * Provide technical leadership, guidance and mentorship to junior engineers, promoting best practices and fostering a culture of continuous improvement.
 * Conduct thorough code reviews to ensure code quality, maintainability, and adherence to coding standards.
 * Identify, troubleshoot, and resolve complex technical issues, ensuring the stability and reliability of our software systems.
 * Take a hands-on approach to manage the delivery of innovative projects, collaborating closely with cross-functional teams to meet project timelines and quality standards.
 * Stay up to date with the latest industry trends, technologies, and best practices, and apply this knowledge to improve our software development processes.

Top skills you need to have:

 * Ten years of experience in software development leading large-scale initiatives
 * You must have demonstrable experience developing and designing customer-facing applications and products
 * Strong proficiency in GraphQL, including schema design, query optimization, and performance tuning.
 * Expertise in TypeScript and its application in both front-end and back-end development.
 * Proficiency with data solutions using RDBMS like Aurora and Postgres and in-memory data stores like Redis and memory dB, including data modelling, performance optimization, and data migration.
 * Experience with BPMN workflow solutions such as Camunda, including workflow design, implementation, and management.
 * Familiarity with Node.js, React, or similar frameworks.
 * Experience with CI/CD tools like Jenkins and version control systems, specifically GitHub
 * Previous experience in leadership and mentorship will be an added advantage.

",Contract
4147627929,9215489.0,"Principal Data Engineer - up to $160,000k base salary","Interested in joining a private equity firm involved in the energy ecosystem?




You'd be joining a tight-knit data engineering team, working side-by-side with the head of data engineering, lead architect and some other data engineers on the team. From work cross collaboratively across teams, to creating data roadmaps and pipeline optimization, your main focus will be working on an enterprise data platform that is the backbone of the business.




Recognized as a leading provider of private equity capital to the energy industry, this firm is extremely tech-driven. In the past 5 years, they have seen so much growth which was what engaged this project in the first place.




Upon joining, you'd jump straight into a massive enterpirse data platform project, supported completely by Databricks. You'd be designing data ingestion pipelines from scratch, and using lots of Python and SQL to do so. You'd get to work extensively with ETL frameworks, writing pipelines to load millions of records, and building dashboards with business intelligence tools like Power BI and Tableau.




No up to date resume required, we can work on that together. Apply today.",Full-time
4125059847,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4142274139,52638.0,Data Engineer,"Data Engineer - 2 Year Contract - Remote, PST - W2 ONLY, NO C2C or OPT EAD




Seeking a Data Engineer to join a 6-7 member team for a migration from AWS to Databricks. Must have 3-5 years' experience with Spark, SQL, Airflow, Databricks, and Python. PST hours required.




Requirements:

 * 3-5 years of data engineering experience
 * Strong skills in Spark, SQL, Airflow, Databricks, Python
 * Team player with stakeholder management experience
 * AWS/Databricks certifications a plus




Responsibilities:

 * Migrate data pipelines from AWS to Databricks
 * Develop and optimize Spark and SQL workflows
 * Use Airflow for orchestration
 * Collaborate with team & stakeholders




Mainz Brady Group is a technology staffing firm with offices in California, Oregon and Washington. We specialize in Information Technology and Engineering placements on a Contract, Contract-to-hire and Direct Hire basis. Mainz Brady Group is the recipient of multiple annual Excellence Awards from the Techserve Alliance, the leading association for IT and engineering staffing firms in the U.S.




Mainz Brady Group is an Equal Opportunity Employer. We are committed to Diversity & Inclusion and incorporate non-discrimination best practices in all of our staffing processes. Mainz Brady Group does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, gender expression, age, disability or any other protected class.

",Contract
4001159711,13149.0,"Data Engineer (Python, Spark)","Duties and responsibilities


 * Collaborate with the team to build out features for the data platform and consolidate data
   
   

assets


 * Build, maintain and optimize data pipelines built using Spark
 * Advise, consult, and coach other data professionals on standards and practices
 * Work with the team to define company data assets
 * Migrate CMS' data platform into Chase's environment
 * Partner with business analysts and solutions architects to develop technical
   
   

architectures for strategic enterprise projects and initiatives


 * Build libraries to standardize how we process data
 * Loves to teach and learn, and knows that continuous learning is the cornerstone of every
   
   

successful engineer


 * Has a solid understanding of AWS tools such as EMR or Glue, their pros and cons and
   
   

is able to intelligently convey such knowledge


 * Implement automation on applicable processes
   
   

Mandatory Skills


 * 5
 * years of experience in a data engineering position
 * Proficiency is Python (or similar) and SQL
 * Strong experience building data pipelines with Spark
 * Strong verbal & written communication
 * Strong analytical and problem solving skills
 * Experience with relational datastores, NoSQL datastores and cloud object stores
 * Experience building data processing infrastructure in AWS
 * Bonus: Experience with infrastructure as code solutions, preferably Terraform
 * Bonus: Cloud certification
 * Bonus: Production experience with ACID compliant formats such as Hudi, Iceberg or
   
   

Delta Lake


 * Bonus: Familiar with data observability solutions, data governance frameworks
   
   

Requirements

Bachelor's Degree in Computer Science/Programming or similar is preferred

Right to work

Must have legal right to work in the USA",Contract
4148992528,1304385.0,"Data Engineer, Hybrid","Company Description

AbbVie's mission is to discover and deliver innovative medicines and solutions that solve serious health issues today and address the medical challenges of tomorrow. We strive to have a remarkable impact on people's lives across several key therapeutic areas – immunology, oncology, neuroscience, and eye care – and products and services in our Allergan Aesthetics portfolio. For more information about AbbVie, please visit us at www.abbvie.com. Follow @abbvie on X, Facebook, Instagram, YouTube, LinkedIn and Tik Tok.

Job Description

The US Commercial Business Technology Solutions is looking for Data Engineer who is responsible for working collaboratively with technology and business groups to conceptualize, design, develop, and implement data, software, and technology solutions that address significant scientific or business challenges. The role will involve researching, identifying, and integrating cutting-edge technology platforms to enhance productivity and efficiency within the team and across various business areas. Furthermore, the Data Engineer will play a role in advancing technology for US Commercial Data Services and Operations. The successful candidate will also be responsible for fostering productive collaborations and effective communication with other groups from diverse disciplines. Additionally, they will be responsible in understanding, analyzing and closing out the business enquiries on the data in a timely manner.

Responsibilities:


 * Collaborate with MABI/Field Tools Business clients to gain a deep understanding of their business strategy and tactical priorities, and identify the corresponding data and technology requirements.
 * Assess the existing data and technology capabilities within the business unit and other relevant areas of AbbVie. Recommend suitable applications to align with current business priorities.
 * Stay updated on industry trends and emerging technology solutions relevant to the assigned business area.
 * Utilize knowledge of current and emerging solutions to proactively contribute to the business strategy and identify opportunities for improvement. Conduct comprehensive analysis, identify insights, and develop business cases to communicate strategic opportunities to stakeholders.
 * Advise business stakeholders on the most appropriate and optimal approaches to achieve their objectives, which may involve technology solutions, process changes, or other options.
 * Collaborate with cross-functional teams to develop comprehensive project estimates and timelines by gathering input and feedback from all relevant stakeholders. Engage with IT and business functions to negotiate and secure the necessary resources.
 * Create and maintain system and project documentation, such as change requests, functional requirements, test plans, data migration plans, and cutover plans. Delegate relevant tasks to junior analysts as appropriate.
 * Validate the database design and ensure technical specifications are complete, consistent, concise, and feasible.
 * Provide documentation of technical standards and best practices, incorporating contributions from team members.
 * Collaborate with project development teams on the SDLC (Software Development Life Cycle) and code promotion process.
 * Review effort estimates for all activities including analysis, documentation, development, testing, bug fixing, deployment, and support.
   
   

Qualifications


 * Bachelor's Degree with 5 years of experience; Master's Degree with 3 years of experience; PhD with 2 years of experience.
 * Proven experience in designing and implementing a full-scale Data Warehouse/Data Lake solution based on cloud databases such as Snowflake, Azure SQL Database, RedShift, etc.
 * Proven experience in designing and implementing data ingestion solutions on IICS (Informatica Intelligent Cloud Services), Snowflake, and/or Azure Data Factory.
 * Excellent programming skills in SQL, PL/SQL, and use these skills in day to day Analytics.
 * At least 4 years of experience interpreting data analytic outputs and performing data audits using visualization reports or dashboards such as Qlik, Tableau, Power BI, etc.
 * Experience handling IQVIA (WxDM, DDD), SHA & Specialty Pharmacy healthcare data.
 * Hands on and thorough ability to create ETL mappings, Write SQL queries and be able to deploy the changes through SDLC lifecycle.
 * Ability to work with IT and business teams to coordinate multiple IT projects in the sales planning area.
 * Strong written and verbal communication skills.
   
   

Preferred:


 * Good understanding of the Health care industry and related Commercial Sales and Rep Interaction data.
 * Good Hands on Experience building ETL Mappings, promote the code through standard SDLC.
 * Proven experience in working with multiple business stake holders, convert Functional requirements to Technical requirements, analyze the existing data and solve day to day business enquiries or problems.
 * Experience working with Life Sciences Sales Planning and exposure to the Field/Rep facing Tools.
   
   

Additional Information

Applicable only to applicants applying to a position in any location with pay disclosure requirements under state or local law:


 * The compensation range described below is the range of possible base pay compensation that the Company believes in good faith it will pay for this role at the time of this posting based on the job grade for this position. Individual compensation paid within this range will depend on many factors including geographic location, and we may ultimately pay more or less than the posted range. This range may be modified in the future.
 * We offer a comprehensive package of benefits including paid time off (vacation, holidays, sick), medical/dental/vision insurance and 401(k) to eligible employees.
 * This job is eligible to participate in our short-term incentive programs.
   
   

Note: No amount of pay is considered to be wages or compensation until such amount is earned, vested, and determinable. The amount and availability of any bonus, commission, incentive, benefits, or any other form of compensation and benefits that are allocable to a particular employee remains in the Company's sole and absolute discretion unless and until paid and may be modified at the Company’s sole and absolute discretion, consistent with applicable law.

AbbVie is an equal opportunity employer and is committed to operating with integrity, driving innovation, transforming lives, serving our community and embracing diversity and inclusion. It is AbbVie’s policy to employ qualified persons of the greatest ability without discrimination against any employee or applicant for employment because of race, color, religion, national origin, age, sex (including pregnancy), physical or mental disability, medical condition, genetic information, gender identity or expression, sexual orientation, marital status, status as a protected veteran, or any other legally protected group status.

US & Puerto Rico only - to learn more, visit https://www.abbvie.com/join-us/equal-employment-opportunity-employer.html

US & Puerto Rico applicants seeking a reasonable accommodation, click here to learn more:

https://www.abbvie.com/join-us/reasonable-accommodations.html",Full-time
4149256861,98846464.0,Senior Software Engineer - Data & Machine Learning,"Founded by world renowned data scientists and entrepreneurs, our client is a global venture capital firm with investments in 14 countries and a portfolio representing over 20 technology sectors. They are passionate about leveraging the power of large data sets and machine learning to identify and support exceptional founders building world-changing technologies and businesses.




The ideal candidate is:

 * Seasoned software engineer responsible for the development of new software products and enhancements to existing products
 * Excels in working with big data, machine learning and large-scale applications and frameworks
 * Self-motivated, multi-tasker, and demonstrated team-player
 * Passionate about investing with outstanding communication and leadership skills




Responsibilities:

 * Write clean, high-quality, high-performance, maintainable code
 * Develop and support software including applications, database integration, interfaces, and new functionality enhancements
 * Design, implement, and maintain scalable data infrastructure solutions to efficiently process, store, and analyze large volumes of data, ensuring data availability and reliability for machine learning initiatives
 * Collaborate with data scientists and engineers to integrate machine learning models and algorithms into production systems, enabling data-driven insights and automation of business processes
 * Coordinate cross-functionally to insure project meets business objectives and compliance standards
 * Support test and deployment of new products and features




Qualifications:

 * B.S., M.S. or PhD in Computer Science, Statistics, Information Science or related majors
 * 3+ yrs of relevant work experience
 * Strong working knowledge of Python, data structures, and algorithms
 * Relevant experience with analysis of large data sets
 * Applied experience with Machine Learning software (scikit, tensorflow, etc)
 * Entrepreneurship or experience with the venture ecosystem preferred
 * Outstanding communication and leadership skills

",Full-time
4115711716,2240906.0,Cloud Data Engineer,"ITnova is looking for a Cloud Data Engineer with a minimum of 12 years of experience in architecting, designing, and developing enterprise-scale data warehouse systems using SQL Server on cloud and on-premise platforms. The ideal candidate will have expertise in Azure data platforms, including Azure SQL, Data Factory, Synapse, Data Lake, and Pipelines, along with strong knowledge of data pipelines, API ingestion, and DevOps processes. Experience with Azure Cosmos DB, cloud infrastructure (Azure/AWS), and data warehouse modeling principles is required.

Experience / Qualifications


 * Minimum 12 years of relevant experience in architecting, design, and development of data warehouse systems (SQL Server based on Cloud/on premise and Analytics) at enterprise scale.
 * Experience in building end to end data warehouse and analytical systems using SQL Server family of products, Analysis Services Power BI, etc.
 * Experience in Data platforms development using Azure SQL database, Azure Data Factory, Azure Storage, Azure Pipelines, Azure IaaS/PaaS related to database.
 * Expert level understanding on Azure Data Factory, Azure Synapse, Azure SQL, Azure Data Lake, and Azure App Service is required.
 * Designing and building of data pipelines using API ingestion and Streaming ingestion methods.
 * Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code is essential.
 * Experience in developing NO SQL solutions using Azure Cosmos DB is essential.
 * Thorough understanding of Azure and AWS Cloud Infrastructure offerings.
 * Strong experience in common data warehouse modeling principles, including Kimball and Inmon.
 * Knowledge of Azure Databricks, Azure IoT, Azure HDInsight + Spark, Azure Stream Analytics, and Power BI is desirable.
 * Knowledge of Microsoft BI Stack (SSRS/SSAS (Tabular with DAX & OLAP with MDX) SSIS) is desirable.
 * Knowledge of C# and hands-on experience with PowerShell scripting is desirable.
 * Working knowledge of Python is desirable.
 * Experience developing security models.
   
   

Education


 * Bachelor's degree in computer science/engineering or related fields.
   
   

Work Location


 * Hybrid work at 2 Montgomery Street Jersey City, NJ 07302",Full-time
4149734695,102609.0,Data Engineer,"This is a permanent position. Not open for Corp to Corp or third parties.




Key Responsibilities

 * Lead the design and implementation of Microsoft Fabric-centric data platforms and data warehouses.
 * Develop and optimize ETL/ELT processes within the Microsoft Azure ecosystem, effectively utilizing relevant Fabric solutions.
 * Ensure data integrity, quality, and governance throughout Microsoft Fabric environments.
 * Collaborate with stakeholders, analysts, and architects to translate business needs into actionable data solutions.
 * Troubleshoot and optimize existing Microsoft Fabric implementations for enhanced performance.
 * Test, monitor, and ensure compliance with best practices in data analytics and quality management.




About you:

 * Experience translating business requirements to technical requirements.
 * Proficiency in programming languages commonly used in data engineering (e.g., Python, Java, Scala).
 * Strong knowledge of database systems, data modeling techniques, and SQL proficiency.
 * Proficiency with ETL tools commonly used in data engineering (e.g., SSIS, Databricks, Azure Data Factory).
 * Strong working knowledge and experience with Microsoft Azure services and tools including Microsoft Fabric, Azure Data Factory, Azure Synapse, Azure SQL Database, and Azure Databricks.
 * Experience using a work management tool such as Azure DevOps.




Preferred/Desired Qualifications

 * Microsoft Certified: Fabric Data Engineer Associate.
 * Microsoft Certified: Fabric Analytics Engineer Associate.




Education and Experience

 * Bachelor’s degree in computer science, engineering, information systems, or related field. Master’s degree preferred. A minimum of five years of experience in information technology with at least two years of the following:
 * Experience in business analytics, data science, software development, data modeling, or data engineering work or equivalent experience.
 * Experience manipulating and transforming data in Spark SQL, PySpark, or Spark Scala, or a minimum of two years of experience manipulating and transforming data in T-SQL.




GENESYS Consulting Services, Inc. is proud to be an equal opportunity employer.",Full-time
4143054604,165602.0,Data Engineer.,"Immediate need for a talented Data Modeler. This is a 12+months contract opportunity with long-term potential and is located in McLean, VA (Hybrid). Please review the job description below and contact me ASAP if you are interested.




Job ID:25-58327



Pay Range: $55 - $60/hour. Employee benefits include, but are not limited to, health insurance (medical, dental, vision), 401(k) plan, and paid sick leave (depending on work location).



Key Requirements and Technology Experience:




 * Key Skills: Solid Data Modeling, Strong Collaboration, Visio, SharePoint, Excel, Fixed income knowledge, financial industry background.
 * 5-7 years of experience in data engineering with strong proficiency in Python programing language.
 * Strong proficiency in spark SQL, SQL, gremlin, GraphQL and database management (Client cloud-base warehousing).
 * Strong experience with data processing frameworks, DataFrames, Apache Spark, Graph DBs
 * Experience with cloud platform AWS (EMR, EKS, Lambda).
 * Experience writing statistical and/or optimization programs to develop models and algorithms
 * Experience with RESTful API design and development
 * Familiarity with PySpark for large-scale data processing and analysis




Our client is a leading Banking and Financial Industry, and we are currently interviewing to fill this and other similar contract positions. If you are interested in this position, please apply online for immediate consideration.




Pyramid Consulting, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, colour, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.




By applying to our jobs you agree to receive calls, AI-generated calls, text messages, or emails from Pyramid Consulting, Inc. and its affiliates, and contracted partners. Frequency varies for text messages. Message and data rates may apply. Carriers are not liable for delayed or undelivered messages. You can reply STOP to cancel and HELP for help. You can access our privacy policy here.",Contract
4076506315,33246798.0,Big Data Engineer Intern (Data Platform) - 2025 Summer/Fall (MS),"Responsibilities

TikTok is the leading destination for short-form mobile video. At TikTok, our mission is to inspire creativity and bring joy. TikTok's global headquarters are in Los Angeles and Singapore, and its offices include New York, London, Dublin, Paris, Berlin, Dubai, Jakarta, Seoul, and Tokyo.

Why Join Us

Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible.

Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day.

To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always.

At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.

Join us.

The mission of the Data Platform team is to empower the TikTok Business with data. Our goal is to build a Data Warehouse that can cater to batch and streaming data, Data Products that provide useful information to build efficient data metrics & dashboards which will be used to make smarter business decisions to support business growth. If you're looking for a challenging ground to push your limits, this is the team for you!

We are looking for talented individuals to join us for an internship in 2025. Internships at TikTok aim to offer students industry exposure and hands-on experience. Turn your ambitions into reality as your inspiration brings infinite opportunities at TikTok.

Internships at TikTok aim to provide students with hands-on experience in developing fundamental skills and exploring potential career paths. A vibrant blend of social events and enriching development workshops will be available for you to explore. Here, you will utilize your knowledge in real-world scenarios while laying a strong foundation for personal and professional growth. It runs for 12 weeks beginning in May/June 2025 or August/September 2025 (Select May if Summer or August if Fall

Please state your availability clearly in your resume (Start date, End date).

Summer Start Dates:

Monday, May 12

Monday, May 19

Tuesday May 27 (Memorial Day May 26)

Monday, June 9

Monday, June 23

Fall Start Dates:

Monday, August 11

Monday, August 25

Monday, September 8

Monday, September 22

Applications will be reviewed on a rolling basis. We encourage you to apply early. Candidates can apply to a maximum of TWO positions and will be considered for jobs in the order you apply. The application limit is applicable to ByteDance and its affiliates' jobs globally.

Candidates who pass resume screening will be invited to participate in TikTok's technical online assessment through HackerRank.

Responsibilities:


 * Translate business requirements & end to end designs into technical implementations and responsible for building batch and real-time data warehouse.
 * Manage data modeling design, writing, and optimizing ETL jobs.
 * Collaborate with the business team to building data metrics based on data warehouse.
 * Responsible for building and maintaining data products.
 * Involvement in rollouts, upgrades, implementation, and release of data system changes as required for streamlining of internal practices.
 * Develop and implement techniques and analytics applications to transform raw data into meaningful information using data-oriented programming languages and visualization software.
 * Apply data mining, data modeling, natural language processing, and machine learning to extract and analyze information from large structured and unstructured datasets.
 * Visualize, interpret, and report data findings and may create dynamic data reports as well.
   
   

Qualifications

Minimum Qualifications:


 * Current Master student with a background in Software Development, Computer Science, Computer Engineering, or a related technical discipline.
 * Solid computer basic knowledge (e.g. data structure & algorithms, SQL and networks).
 * Strong coding capabilities and mastering at least one programming language (e.g. C/C++/Java/Python/Golang).
   
   

Preferred Qualifications:


 * Passionate about data warehouse, ETL development, data analysis and eCommerce.
 * Good communication skills and a fast learner of new business and technology knowledge.
 * Strong collaboration skills with the ability to build rapport across teams and stakeholders.
   
   

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at https://shorturl.at/cdpT2.

Job Information

【For Pay Transparency】Compensation Description (Hourly) - Campus Intern

The hourly rate range for this position in the selected city is $57.75- $57.75.

Benefits may vary depending on the nature of employment and the country work location. Interns have day one access to health insurance, life insurance, wellbeing benefits and more. Interns also receive 10 paid holidays per year and paid sick time (56 hours if hired in first half of year, 40 if hired in second half of year).

The Company reserves the right to modify or change these benefits programs at any time, with or without notice.

For Los Angeles County (unincorporated) Candidates:

Qualified applicants with arrest or conviction records will be considered for employment in accordance with all federal, state, and local laws including the Los Angeles County Fair Chance Ordinance for Employers and the California Fair Chance Act. Our company believes that criminal history may have a direct, adverse and negative relationship on the following job duties, potentially resulting in the withdrawal of the conditional offer of employment:


 * Interacting and occasionally having unsupervised contact with internal/external clients and/or colleagues;
 * Appropriately handling and managing confidential information including proprietary and trade secret information and access to information technology systems; and
 * Exercising sound judgment.",Internship
4150537036,36873.0,Data Engineer,"Overview

This is a hybrid role based out of Malvern, PA (3 days in office)

CubeSmart is currently seeking a Data Engineer to join the Information Technology team at our corporate office in Malvern, PA. The Data Engineer will be responsible for the implementation, development, and optimization of database, data objects, and database scripting with the core database platforms utilized by the core CubeSmart business applications.

Who We Are:

At CubeSmart, we’re intentional about culture. You can experience it everywhere from our mission statement of “genuine care” to our “It’s What’s Inside That Counts” tagline to calling each other “teammates” rather than employees. This spirit fosters a fun and collaborative environment that has resulted in our rapid growth and being recognized amongst the top in our industry.

CubeSmart’s award-winning team is made up of people who genuinely care. Teammates care about our customers and the life events and/or business needs they are facing. Teammates are passionate, responsible and understanding. The CubeSmart team is made up of people who have a can-do attitude, are committed to their own success and the success of the company, and lead by example.

If this sounds like a team and culture that matches your personal values and motivations, we want to hear from you.

Responsibilities

This role will also be responsible for the development and maintenance of ETL processes that manage the consumption of data by CubeSmart’s core systems. The role will serve as a technical expert to analyze the needs of CubeSmart’s applications and business data requirements and produce an optimal solution according to their needs and specifications, and in alignment with CubeSmart’s data design standards. This individual will be part of the team building a data and analytics platform in the Microsoft Azure cloud to support the CubeSmart business. This will include designing and building the data ingestion and ETL pipelines to create the cloud Lakehouse environment. In addition, this person will be engaged to develop features in the legacy SQL Server Data Warehouse platform.

Responsibilities


 * Collaborate with program manager(s), application development, and data consumers to develop data ingestion and ETL pipelines required to enable CubeSmart data consumers to onboard processes to the Data Lakehouse platform
 * Create database designs, stored procedures, views and other associated database objects required to implement processes in support of application development efforts
 * Design and development of data pipelines and ETL processes required to support system integration and application development needs in the legacy SQL data warehouse environment
 * Identification and implementation of database performance tuning required to validate that all systems are performing to an optimal level
 * Collaborate with 3rd party vendors to understand externally sourced data and incorporate into CubeSmart’s data environment, in adherence with CubeSmart’s data design standards
 * Bachelor’s degree in Computer Science, Information Technology or a related discipline
 * Strong skills in SQL, Python, and PySpark
 * Experience with Microsoft Azure data services (Azure Data Factory, Azure Databricks, Azure SQL, and Databricks ML Flow) or equivalent is preferred
 * Full understanding of the Software Development Life Cycle (SDLC) and experience with Agile software development processes
 * Solid understanding of cloud DevOps capabilities, preferably Azure DevOps
 * Experience with MongoDB (or similar non-relational database platform) or PostgreSQL is a plus
 * Experience supporting databases and data models for ERP or financial systems in a plus
   
   

Qualifications

Knowledge, Skills, Abilities and Personal Characteristics


 * Service orientation towards business-focused 24×7 support and service mentality
 * Ability to work within a team environment, showing an openness to collaborate with technical and business peer, with the ability to step up and take on new challenges in response to changing business conditions
 * Ability to learn quickly, adapt work processes to adhere with best practices
 * Ability to clearly convey technical information to both technical and non-technical audiences
 * Collaborative individual who creates open channels of communications and encourages technical dialogue across the department.
 * Well-developed analytical and problem-solving abilities
 * Ability to work on multiple tasks and projects at once, with the ability to properly prioritize one’s own work and the work of others
   
   

We are an Equal Opportunity Employer, Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity.

",Full-time
4086795940,81777085.0,Data Engineer,"MUST HAVES

(60 tech ability/40 soft skills)


 * Snowflake shop
 * Snowflake Certified is a big plus (SnowPro)
 * ETL processes
 * Strong understanding of healthcare Data Standards is a plus (HL7, FHIR)
 * Strong understanding of EMR / EHR system integration (Athena, Mirth, etc)
 * Data migration
 * modern data engineering practices, etc.
 * opentable formats like datalake and iceberg
 * Exposed to databricks pipeline
 * Data mesh exposure
 * Must see the Data frameworks they have worked with in the resume
 * Exposure to delta lake, data mesh approaches, iceberg tables and exposure to databricks pipelines.",Full-time
4142857039,96692.0,Data Engineer 4,"Primary Location: Philadelphia, Pennsylvania

V-Soft Consulting is currently hiring for a Data Engineer 4 for our premier client in Philadelphia, Pennsylvania.

Education And Experience »

 * 7-10 years experience.
 * Neo4j Graph database. Neo4j is must.
 * Python - must have.
 * Databricks - must have.
 * AWS components Development.
 * Graph data experience would be preferred.
 * Lambda functions - must have.
 * API’s - must have.
 * Neptune is preferred not mandatory.
 * Machine learning is nice to have.

Knowledge, Skills And Abilities »

 * Top skills: Data bricks, neo4j, Python and Pyspark, big data.

What You’ll Do

Job Responsibilities:

 * Building medallion architecture and bigdata structure approach.
 * Series of ETL consumed in different sources.
 * Optimization of current ETL’s and implementation of ETL’s.

Interested?

Qualified candidates should send their resumes to pgarla@vsoftconsulting.com




V-Soft Consulting Group is recognized among the top 100 fastest growing staffing companies in North America, V-Soft Consulting Group is headquartered in Louisville, KY with strategic locations in India, Canada and the U.S. V-Soft is known as an agile, innovative technology services company holding several awards and distinctions and has a wide variety of partnerships across diverse technology stacks.

As a valued V-Soft Consultant, you’re eligible for full benefits (Medical, Dental, Vision), a 401(k) plan, competitive compensation and more. V-Soft is partnered with numerous Fortune 500 companies, exceptionally positioned to advance your career growth.

V-Soft Consulting provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

For more information or to view all our open jobs, please visit www.vsoftconsulting.com or call (844) 425-8425.

#MonsterPost",Contract
4150497390,8598.0,Data Engineer,"At MAPFRE, our commitment to care is not just our purpose; it’s the driving force behind everything we do. We care about the things that resonate with the needs of our employees, our customers and the community.



 * For Employees: We cultivate an inspiring and dynamic workplace where collaboration and innovation fuel the success of our high-performing teams.
 * For Customers: In addition to being Massachusetts’ #1 home and auto insurer, we provide unmatched peace of mind to our customers across the U.S.
 * For the Community: Our culture of care extends to impactful community engagement and environmental initiatives locally and globally.



This is who we are at MAPFRE, and we invite you to be part of a movement that cares deeply and acts boldly. Together, we make a difference.




Do you think in Python and speak in SQL? Do you appreciate a good data model as much as a good painting in a museum? Are you excited by an opportunity to solve complex problems while also having fun? Are you a team player? Do you strive for simplicity and elegance in your solutions? If so, MAPFRE USA is looking for a data engineer who will be part of the Data Engineering team building data products for our sophisticated data consumers.

As a data Engineer you will be a part of an agile team delivering value. Using modern tools and technologies. You will work closely with the data architect and stakeholders and help MAPFRE USA transform to a data driven organization.




Job Summary

 * Augment and maintain the existing repositories and data structures within AWS (used to process and store large amounts of data from unrelated sources)
 * Experience with several formats and means for data ingestion. Including, data types (structured, semi-structured, and unstructured), and sources (on premise, and in the cloud) using the most appropriate techniques in each case
 * Continue to expand and enhance the model, utilizing best practices, in regards to the organization of data and the various relationships
 * Optimize existing and future models for fast and scalable queries (while maintaining performance and related price thresholds)
 * Work with the team to define, construct, and maintain self-service dashboards for the Business and Advanced Analytics teams within PowerBI
 * Implement scalable and flexible, high performance data pipelines for AWS to support analytics
 * Develop and maintain data maps and their relationships
 * Generate associated technical documentation including follow-up reports
 * Work with Data Governance to implement quality rules and data governance measures (data dictionary, metadata, traceability, ...)
 * Propose improvements and actions based on provided results
 * Communicate results effectively with required teams




Knowledge, Skills and Abilities:

 * Bachelor's Degree with 6+ years of experience.
 * Advanced knowledge and experience using Python, Airflow, Spark, AWS, and Snowflake
 * Database architectures: SQL, NoSQL, graph databases
 * CI/CD and Orchestration: Jira, Jenkins, Bit Bucket, Terraform, and Airflow
 * Past experience with data modeling tools, ETL tools (e.g. Informatica Power Center)
 * Computer languages, data query and transformation tools: AWS Athena, Jupyter notebooks, Spark, Pyspark, Python, and EMR Studio
 * Algorithm analysis (for working with our Data Scientists)
 * Understanding of multidimensional modeling for quantitative and fact related data storage
 * OS: Linux, and MS Windows
 * Code IDE: Microsoft Visual Code, Jupyter notebooks
 * Artificial intelligence, machine learning, and deep learning are a plus




Thank you for considering MAPFRE Insurance as part of your career journey.



We're proud to be rated ""A"" (Excellent) by A.M. Best Company. We offer property and casualty insurance, working with over 3,000 independent agents and brokers in 11 states.",Full-time
3809830050,3657.0,Data Engineer,"APPLICATION INSTRUCTIONS:


 * CURRENT PENN STATE EMPLOYEE (faculty, staff, technical service, or student), please login to Workday to complete the internal application process. Please do not apply here, apply internally through Workday.
 * CURRENT PENN STATE STUDENT (not employed previously at the university) and seeking employment with Penn State, please login to Workday to complete the student application process. Please do not apply here, apply internally through Workday.
 * If you are NOT a current employee or student, please click “Apply” and complete the application process for external applicants.
   
   

JOB DESCRIPTION AND POSITION REQUIREMENTS:

We are seeking a talented, experienced and a highly motivated Data Research Engineer to join the Algorithms, Prototyping and Integration (API) Department of the Applied Research Laboratory (ARL) at Penn State University. You will assist in providing our customers with state-of-the-art visualization and decision support software based solutions. ARL serves as a national center of excellence for advanced capabilities in science and technology research. We provide technical innovations and solutions to real-world problems in national security, economic competitiveness and quality of life. As a designated University-Affiliated Research Center (UARC), ARL Penn State maintains a special long-term strategic relationship with DoD which has allowed us to support the nation for over 75 years with basic and applied research to address challenging problems in support of national security.

The position will be located in either State College, PA or Reston, VA and will report to the API Department head in State College, PA.

ARL is an authorized DoD SkillBridge partner and welcomes all transitioning military members to apply.

You will:


 * Assemble large, complex sets of data that meet research requirements
 * Build required infrastructure for optimal extraction, transformation and loading of data from various data sources using cloud and SQL technologies
 * Integrate analytical tools to utilize the data pipeline, solving research problems posed by the stakeholders and data science team
 * Work with a team of engineers, faculty, students and customers and to assist them with data-related technical and resource issues
 * Execute tasking within an Agile development process
 * Keep current with relevant emerging technologies and trends by attending conferences and workshops relevant to department and project goals
   
   

Additional responsibilities of the higher level include:


 * Coordinate Data Engineering related research and development activities between disciplines involving exploration of subject area, definition of scope and selection of problems for investigation and development of novel concepts and approaches
 * Mentor and train employees in the development of Data Engineering related technical, project, and business development skills
   
   

This job will be filled at the intermediate professional or advanced professional level, depending upon the successful candidate's education, and experience. Minimally requires a Bachelor’s Degree in an Engineering or Science discipline plus 5 years related experience for the advanced professional level. Additional education and/or experience required for higher level positions. A Master’s Degree is preferred.

Requirements include:


 * PostgreSQL
 * Python
 * FastAPI
 * Security+ or similar level of certification
   
   

Preferred:


 * Data flow automation using NiFi
 * PostGIS
 * Active TS/SCI clearance
   
   

Applicants selected will be subject to a government security investigation and standard background checks. You must be a U.S. Citizen to apply. Employment with ARL will require successful completion of a pre-employment drug screen.

ARL at Penn State is an integral part of one of the leading research universities in the nation and serves as a University center of excellence in defense science, systems, and technologies with a focus in naval missions and related areas.

You will be subject to a government security investigation, and you must be a U.S. citizen to apply. Employment with the ARL will require successful completion of a pre-employment drug screen.

The pay range for this position, including all possible grades is:

$86,300.00 - $164,000.00

Salary Structure - additional information on Penn State's job and salary structure.

CAMPUS SECURITY CRIME STATISTICS:

Pursuant to the Jeanne Clery Disclosure of Campus Security Policy and Campus Crime Statistics Act and the Pennsylvania Act of 1988, Penn State publishes a combined Annual Security and Annual Fire Safety Report (ASR). The ASR includes crime statistics and institutional policies concerning campus security, such as those concerning alcohol and drug use, crime prevention, the reporting of crimes, sexual assault, and other matters. The ASR is available for review here.

Employment with the University will require successful completion of background check(s) in accordance with University policies.

EEO IS THE LAW

Penn State is an equal opportunity, affirmative action employer, and is committed to providing employment opportunities to all qualified applicants without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. If you are unable to use our online application process due to an impairment or disability, please contact 814-865-1473.

Federal Contractors Labor Law Poster

PA State Labor Law Poster

Affirmative Action

Penn State Policies

Copyright Information

Hotlines

University Park, PA",Full-time
4040213436,439859.0,Data Engineer,"Qualis LLC is seeking a Data Engineer to provide support and expertise within our National Capital Region or this position can also be performed remotely. Responsibilities include: Data engineer, architect data systems, build ETL pipelines, and perform data ingestion. perform analytical exploration and examination of data to leading the assessment, design, build, and maintenance of Tableau dashboards.

Requirements

Qualifications:


 * Candidate must have a current Secret or TS DoD Security Clearance
 * 5+ years of experience as a Data Engineer or Software Engineer,
 * Candidate must have experience with data architecture and data modeling, knowledge of Data ETL tools, experience in a professional environment using Tableau and Amazon Web Services, knowledge of data ingestion, transformation logic, and querying data, ability to quickly learn technical concepts, ability to communicate with multiple functional groups
 * Candidate must be a US Citizen
   
   
   

Benefits

Qualis Corporation is committed to hiring and retaining a diverse and talented workforce who can contribute to the mission and vision of the Company. Our employees are our greatest asset and we promote a positive work environment, teamwork, professional growth, innovation, community involvement, flexible scheduling and a family-friendly work environment.

Equal Opportunity Employer/M/F/Vet/Disabled and a Participant in E-Verify",Full-time
4045411757,66321745.0,Junior Level Software Engineer (REMOTE),"Since 2010 Synergisticit has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience, and technical competence to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this Job market also, our candidates can achieve multiple job offers and $100k &plus; salaries.

please check the below links to see the success outcomes and salaries of our candidates .

https://www.synergisticit.com/candidate-outcomes/

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

We regularly interact with the Top Tech companies to give our candidates a competitive advantage visit the below videos exhibiting at Oracle Cloud World/Oracle Java One (Las Vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergistic understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like Apple, google, Paypal, Western Union, Client, visa, Walmart lab s etc to name a few.

Currently, We are looking for entry-level software programmers, Java full-stack developers, Python/Java developers, Data analysts/ Data Scientists, and Machine Learning engineers for full-time positions with clients.

Who Should Apply Recent Computer Science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and are looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

Required Skills

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, Gen AI, LLM, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

Required Skills

REQUIRED SKILLS For Java /Full stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java, Javascript, C&plus;&plus;, or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernetes, and REST API experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team and only connect with candidates who match client requirements.

No phone calls, please. Shortlisted candidates would be reached out. No third-party or agency candidates or C2C candidates",Full-time
4083512174,81777085.0,Data Engineer,"MUST HAVES

(60 tech ability/40 soft skills)


 * Snowflake shop
 * Snowflake Certified is a big plus (SnowPro)
 * ETL processes
 * Strong understanding of healthcare Data Standards is a plus (HL7, FHIR)
 * Strong understanding of EMR / EHR system integration (Athena, Mirth, etc)
 * Data migration
 * modern data engineering practices, etc.
 * opentable formats like datalake and iceberg
 * Exposed to databricks pipeline
 * Data mesh exposure
 * Must see the Data frameworks they have worked with in the resume
 * Exposure to delta lake, data mesh approaches, iceberg tables and exposure to databricks pipelines.",Full-time
4136152721,1128772.0,Data Engineer,"The Opportunity

We are seeking a skilled Data Engineer with expertise in ETL, data integration, and big data development to join our team. In this role, you will focus on supporting data ingestion, transformation, and distribution to end consumers. You will work with the Business Intelligence team and operational stakeholders to design, develop, and implement scalable data solutions that meet the organization’s evolving needs.




Key Responsibilities:

 * Collaborate with the Business Intelligence team and stakeholders to design and implement data presentation layers and the technical architecture of the data warehousing environment.
 * Develop reliable, scalable data solutions for real-time and batch data processing across systems from multiple sources.
 * Design and develop database objects, including tables, stored procedures, and views.
 * Create and maintain ETL processes that transform raw data (e.g., flat files, Excel spreadsheets) into structured SQL databases.
 * Analyze, troubleshoot, and resolve data processing issues in real time, delivering end-to-end solutions.
 * Contribute to migration efforts, transforming legacy systems into modern data marts or data lakes.
 * Utilize cloud technologies such as Azure SQL Server, with a strong understanding of cloud services and architecture.
 * Perform requirements analysis, design process flows, develop and conduct unit/integration tests, and maintain comprehensive project documentation.
 * Continuously learn and adapt to new technologies, driving process improvement and innovation.
 * Manage multiple projects, responsibilities, and competing priorities while working in a collaborative team environment.




Qualifications and Experience Needed:

 * Programming Languages: Proficiency in Python, SQL, PLSQL, and VB.
 * Database Platforms: Experience with Oracle, SQL Server, and MySQL.
 * Big Data Technologies: Knowledge of Synapse and Databricks for processing and storage.
 * Cloud Computing: Experience with AWS and Azure, including cloud data solutions and architecture.
 * Data Replication Tools: Familiarity with HVR data replication or similar tools.
 * Strong understanding of data marts, data lakes, and migration processes for legacy systems.
 * Ability to design and develop ETL pipelines and database objects for scalable data integration.
 * Excellent problem-solving and real-time troubleshooting skills.
 * Strong interpersonal and communication skills, with the ability to work effectively in team environments that include end users, customers, contractors, and management.
 * Aptitude for continuous research, learning, and innovation.
 * Experience managing multiple projects and priorities simultaneously.

",Contract
4056938562,81777085.0,Data Engineer,"MUST HAVES

(60 tech ability/40 soft skills)


 * Snowflake shop
 * Snowflake Certified is a big plus (SnowPro)
 * ETL processes
 * Strong understanding of healthcare Data Standards is a plus (HL7, FHIR)
 * Strong understanding of EMR / EHR system integration (Athena, Mirth, etc)
 * Data migration
 * modern data engineering practices, etc.
 * opentable formats like datalake and iceberg
 * Exposed to databricks pipeline
 * Data mesh exposure
 * Must see the Data frameworks they have worked with in the resume
 * Exposure to delta lake, data mesh approaches, iceberg tables and exposure to databricks pipelines.",Full-time
4152471245,18377405.0,Sr Data Platform Engineer,"Lightmatter is leading the revolution in AI data center infrastructure, enabling the next giant leaps in human progress. The company invented the world’s first 3D-stacked photonics engine, Passage™, capable of connecting thousands to millions of processors at the speed of light in extreme-scale data centers for the most advanced AI and HPC workloads.

Lightmatter raised $400 million in its Series D round, reaching a valuation of $4.4 billion. We will continue to accelerate the development of data center photonics and grow every department at Lightmatter!

If you're passionate about tackling complex challenges, making an impact, and being an expert in your craft, join our team of brilliant scientists, engineers, and accomplished industry leaders.

Lightmatter is (re)inventing the future of computing with light!

In this role, as a part of the product engineering, you will be a data systems engineer working on designing, developing, and deploying data systems framework, infrastructure, and processes for Lightmatter product characterizations, test, and validation data. The data system is expected to support from product development to high volume manufacturing. The data system will enable efficient data mining, analysis and commonality to help engineers improve product design, test coverage and overall operational efficiency.

Responsibilities

Design, develop, and deploy the data systems framework and infrastructure, which includes a distributed big data platform and data lake


 * Design and maintain metadata systems, data catalogs, data governance, data search and discovery, and related services
 * Own and extend the data pipeline through the collection, storage, processing, and transmission of datasets
 * Enable seamless data transfer and loading from labs or suppliers in Lighmatter database
 * Customize yield/characterization dashboards per product engineering requirements
   
   

Qualifications


 * BS or higher degree in Electrical Engineering, Data Science, Data Automations (or other related fields)
 * At least 6 years of industry experience with data systems, data platforms and big data.
 * Expert in programming languages including Python, SQL.
 * Hands on data mining and database experience (e.g., Python Pandas, MySQL, HDFS etc.)
 * Must have data visualization experience (e.g., Tableau, Grafana, Matplotlib, JMP, JavaScriptExperience with multiple data architecture paradigms (e.g. SQL, Vertica)
 * Experience in the semiconductor industry working with loading and analyzing electrical/photonics test, assembly and characterization data from integrated circuits (chips), modules and systems.
   
   

Preferred Qualifications


 * MS or PhD with background in integrated photonics/lasers.
 * Experience working with foundry to establish manufacturing in-line monitors SPC, correlations to test yield
   
   

We offer competitive compensation. The base salary range for this role determined based on location, experience, educational background, and market data.

Salary Range: $195,000 USD - $235,000 USD

Benefits


 * Comprehensive Health Care Plan (Medical, Dental & Vision)
 * Retirement Savings Matching Program
 * Life Insurance (Basic, Voluntary & AD&D)
 * Generous Time Off (Vacation, Sick & Public Holidays)
 * Paid Family Leave
 * Short Term & Long Term Disability
 * Training & Development
 * Commuter Benefits
 * Flexible, hybrid workplace model
 * Equity grants
   
   

Lightmatter recruits, employs, trains, compensates, and promotes regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.",Full-time
4105547525,66321745.0,Junior Level Data Engineer,"SYNERGISTICIT is aware that the Job Market is Challenging due to almost 600,000 Tech Layoffs within the past 2 years due to which The Job market is flooded with thousands of laid off Techies who are competing with existing Jobseekers. For entry level Job seekers to get client interviews and jobs they need to differentiate themselves by ensuring they have exceptional skills and technologies to be noticed by clients.

Since 2010 we have helped Jobseekers differentiate themselves by providing the clients with candidates who have the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.

All Positions are open for all visas and US citizens

We are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this economy no client wants or has the resources to take an entry level person and spend resources on upgrading their skills and on top of that pay the jobseeker. That's the specific reason there are so many techies both experience and freshers who are unemployed.

Clients have now the option to hire remote workers from anywhere so for a Jobseeker its important to introspect and see how they can become better and have the skills and technologies to meet client requirements.

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates looking to make their careers in IT Industry

We welcome candidates with all visas and citizens to apply.

If you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.

please check the below links to see success outcomes of our candidates

https://www.synergisticit.com/candidate-outcomes/

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://www.youtube.com/playlist?list=PLJgkOBQ51j5AHT5I6n29glr0q6trzkxYD

https://synergisticit.wistia.com/medias/k6t6a1n4kb

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

If you have relevant skills and industry experience, please apply

For preparing for interviews please visit

https://www.synergisticit.com/interview-questions/

REQUIRED SKILLS For Java /Software Programmers


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Project work on the skills
 * Knowledge of Core Java , javascript , C++ or software programming
 * Spring boot, Microservices, Docker, Jenkins and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Project work on the technologies needed
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, PowerBI, Time series analysis

Please understand skills and relevant experience on real world projects are required by clients for selection even if its Junior or entry level position the additional skills and Project work with hands on experience building projects at client site are the only way a candidate can be picked by clients.

No third party candidates or c2c candidates

please only apply to the posting

If you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.

No phone calls please. Shortlisted candidates would be reached out.",Contract
4129695221,9353551.0,Data Analytics Engineer,"Job Description

JOB DESCRIPTION

Homecare Homebase (HCHB) is the leader in post-acute healthcare EHR systems. This role will be a part of the Data Analytics team at HCHB, which is responsible for the customer facing analytics platform, as well as internal company reporting, both using the industry leading Tableau platform. This is a dynamic, agile team with many opportunities to influence key projects.

We are looking for a motivated and versatile Data Analytics Engineer to join our team. This individual will be responsible for building a modern analytics platform that connects, cleans, and merges data from SQL Server, Snowflake, and other cloud-based data sources, deploying it to our Tableau Server using Python and the REST API. You’ll also manage Tableau Server health and automate deployments, leveraging your technical expertise in Python.

If you’re passionate about data, enjoy wearing multiple hats, and thrive in a small, agile team, we’d love to hear from you.

Qualifications / Skills:


 * 2+ years of experience working with data in Python (required).
 * 2+ years of SQL experience (required).
 * Strong problem-solving skills, with the ability to work independently in a fast-paced environment.
 * High attention to detail and accuracy.
 * A team player with excellent verbal and written communication skills.
 * Excellent time management and prioritization skills.
 * Familiarity with Tableau Server and deploying Tableau solutions, including Tableau REST API (desired).
 * Experience with Tableau Desktop and Tableau Prep (nice to have).
 * Knowledge and experience in health care, specifically post-acute Home Health, Hospice, or Personal Care business is desired, but not required.
 * Bachelor’s degree or higher.
   
   

Responsibilities:


 * Deploy solutions to Tableau Server using Python and Tableau’s REST API.
 * Automate Tableau Server management and deployment processes.
 * Design, develop, and maintain an analytics platform connecting to data on SQL Server.
 * Clean, merge, and transform data for reporting and analysis.
 * Collaborate closely with Product Management, Tableau Developers, and Consulting team to meet customer needs.
 * Monitor and maintain Tableau Server health to ensure continuous availability.
 * As a part of the data analytics development process, adhere to and help test for established quality standards for performance, data accuracy, and presentation.
 * Work closely with management to prioritize stakeholder needs.
   
   

This position does not provide sponsorship. All applicants should either be US Citizens or Permanent Residents eligible to work in the US without immigration restrictions.

",Full-time
4150470918,3076.0,Data Engineer - Strategy,"Responsibilities

Kforce has a client that is seeking a Data Engineer - Strategy in Charlotte, NC. Summary: We are currently seeking a Senior Data Engineer with hands-on coding experience and a strong background in Python, PySpark, and Object-oriented programming. The ideal candidate will be responsible for designing, developing, and implementing new features to our existing framework using PySpark and Python. This position requires a deep understanding of data transformation and the ability to create standalone scripts based on given business logic. Responsibilities:


 * Design, develop and implement new features to our existing framework using PySpark and Python
 * Write efficient and effective standalone scripts in PySpark with transformations as per the defined business logic
 * Use your expertise in Python and Object-oriented concepts to solve complex problems and implement robust solutions
 * Work closely with the team to understand the requirements and develop solutions that align with the company's objectives
 * Test and debug code to ensure it produces the desired results
 * Document all programming tasks and procedures for future reference and troubleshooting
   
   

Requirements


 * Python
 * Pyspark
 * AWS
 * SQL
   
   

The pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.

We offer comprehensive benefits including medical/dental/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.

Note: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.

This job is not eligible for bonuses, incentives or commissions.

Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.

By clicking “Apply Today” you agree to receive calls, AI-generated calls, text messages or emails from Kforce and its affiliates, and service providers. Note that if you choose to communicate with Kforce via text messaging the frequency may vary, and message and data rates may apply. Carriers are not liable for delayed or undelivered messages. You will always have the right to cease communicating via text by using key words such as STOP.",Contract
4147295198,3088.0,"Data Engineer II (AWS, Python)","Who Are We?

Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.

Compensation Overview

The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.

Salary Range

$123,000.00 - $203,000.00

Target Openings

1

What Is the Opportunity?

Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate stories found in data by leveraging a variety of data programming techniques. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.

What Will You Do?


 * Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.
 * Design complex data solutions
 * Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.
 * Incorporate core data management competencies including data governance, data security and data quality.
 * Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.
 * Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.
 * Test data movement, transformation code, and data components.
 * Perform other duties as assigned.
   
   

What Will Our Ideal Candidate Have?


 * Bachelor’s Degree in STEM related field or equivalent
 * Eight years of related experience
 * Strong technical background in AWS stack (Lambda, Step Function, S3, event-driven processing, etc.) and Python.
 * Capability to guide and drive the team to technical solutions.
 * Highly proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and a full understanding of modern software engineering practices.
 * The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.
 * Demonstrated track record of domain expertise including understanding technical concepts necessary and industry trends, and possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems.
 * Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues.
 * Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners.
 * Ability to lead team members and help create a safe environment for others to learn and grow as engineers. and a proven track record of self-motivation in identifying opportunities and tracking team efforts.
   
   

What is a Must Have?


 * Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
 * Four years of data engineering or equivalent experience.
   
   

What Is in It for You?


 * Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.
 * Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
 * Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
 * Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs.
 * Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.
   
   

Employment Practices

Travelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.

In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions.

If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.

Travelers reserves the right to fill this position at a level above or below the level included in this posting.

To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.",Full-time
4076510359,33246798.0,"Data Engineer, Global Live","Responsibilities

TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us

Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible.

Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day.

To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always.

At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.

Join us.

The Data Platform Global Live team is dedicated to empowering the growth of TikTok LIVE business through big data. We support our businesses in achieving their missions by building high quality real-time and offline data warehouses, creating various forms of efficient and data-friendly data assets, and exploring and implementing business oriented data solutions. We provide stable and reliable data capabilities for daily operations, analyses, decision-making of TikTok LIVE features, in addition to robust data support to enhance live performance for streamers.

As a data engineer in the Global Live team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world. You'll have the opportunity to gain hands-on experience on all kinds of systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users.

Responsibilities - What You'll Do


 * Design and build data transformations efficiently and reliably for different purposes (e.g. reporting, growth analysis, multi-dimensional analysis);
 * Design and implement reliable, scalable, robust and extensible big data systems that support core products and business;
 * Establish solid design and best engineering practice for engineers as well as non-technical people.
   
   

Qualifications


 * BS or MS degree in Computer Science or related technical field or equivalent practical experience;
 * Experience in the Big Data technologies(Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc.);
 * Experience with performing data analysis, data ingestion and data integration;
 * Experience with ETL(Extraction, Transformation & Loading) and architecting data systems;
 * Experience with schema design, data modeling and SQL queries;
 * Passionate and self-motivated about technologies in the Big Data area.
   
   

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at dataecommerce.accommodations@tiktok.com.

Job Information

【For Pay Transparency】Compensation Description (Annually)

The base salary range for this position in the selected city is $158080 - $289469 annually.

Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.

Benefits may vary depending on the nature of employment and the country work location. Employees have day one access to medical, dental, and vision insurance, a 401(k) savings plan with company match, paid parental leave, short-term and long-term disability coverage, life insurance, wellbeing benefits, among others. Employees also receive 10 paid holidays per year, 10 paid sick days per year and 17 days of Paid Personal Time (prorated upon hire with increasing accruals by tenure).

The Company reserves the right to modify or change these benefits programs at any time, with or without notice.

For Los Angeles County (unincorporated) Candidates

Qualified applicants with arrest or conviction records will be considered for employment in accordance with all federal, state, and local laws including the Los Angeles County Fair Chance Ordinance for Employers and the California Fair Chance Act. Our company believes that criminal history may have a direct, adverse and negative relationship on the following job duties, potentially resulting in the withdrawal of the conditional offer of employment:


 * Interacting and occasionally having unsupervised contact with internal/external clients and/or colleagues;
 * Appropriately handling and managing confidential information including proprietary and trade secret information and access to information technology systems; and
 * Exercising sound judgment.",Full-time
4126622098,1586.0,"Data Engineer, GSF, Data Platform Team","Description

Over the past 20 years, Amazon has reinvented on behalf of customers and has become the largest internet retailer in the world. Amazon is now reinventing the global supply chain and international e-commerce and is recruiting a senior data engineer to help make this vision a reality. In this role, you will be responsible for the development and improvement of Workforce Planning Analytics platform used for planning, reporting, and forecasting purposes as well as dataset management. You will get the unique opportunity to work closely with a variety of stakeholders, including Business Analysts, Site Leads, and other Program Management teams. The candidate will also be in charge of driving strategic initiatives to improve reporting efficiency, develop new bridging workflow tools and establish new key performance metrics where appropriate.

The ideal candidate will not only raise the bar on Data engineering skills but demonstrates a strong curiosity to understand the business end-to-end and be comfortable working with ambiguity. The candidate will also have an eye for detail, be proficient/advanced in SQL/DWH/Python and invent for solving data and reporting challenges. The role requires good communication skills with other functional teams.

Key job responsibilities


 * Design, implement and support an analytical data infrastructure using AWS technologies
 * Build robust and scalable data integration (ETL) pipelines using SQL, and AWS data storage technologies like Aurora, Red Shift etc.
 * Design and develop Analytics applications using modern scripting languages (Python, R, PHP, etc) supporting critical business functions.
 * Gather business and functional requirements and translate these requirements into robust, scalable, operable solutions with a flexible and adaptable data architecture.
 * Lead architecture design and implementation of next generation BI solution
 * Continually improve ongoing reporting and analysis processes, automating or simplifying self-service modeling and production support for customers.
 * To apply for this role, candidates must initiate an informational meeting with the hiring manager by clicking the “Request Informational” button at the top of the job listing. When you request informational your current manager will not be notified.
 * For more on informational discussions, visit: https://ivy-help-center.talent.a2z.com/article/2gLzMFp5I3TMfchHDv03w2?ref=share-button
 * To understand the internal transfer process and frequently asked questions, refer to: https://ivy-help-center.talent.a2z.com/article/5TdnwN6zJXjHvREhjtTdAJ?ref=share-button
   
   

Basic Qualifications


 * 3+ years of data engineering experience
 * Experience with data modeling, warehousing and building ETL pipelines
   
   

Preferred Qualifications


 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com Services LLC

Job ID: A2872047",Full-time
4119105769,96692.0,Advanced Data Engineer 100% Remote,"Advanced Data Engineer (100% Remote)

Primary Location: 100% Remote

V-Soft Consulting is currently hiring for a Advanced Data Engineer (100% Remote) for our premier client.

Education And Experience »

 * 4+ years in professional data development.
 * 4+ years with SQL and NoSQL technologies.
 * 3+ years building and maintaining data pipelines and workflows.
 * 5+ years developing with Java.
 * 2+ years developing with Python.
 * 3+ years developing Kafka solutions.
 * 2+ years feature engineering for ML pipelines.

Preferred Qualifications

 * Knowledge of Structured Streaming (e.g., Spark, Kafka, EventHub).
 * Experience with GitHub SaaS/GitHub Actions.
 * Familiarity with Databricks, PySpark, and Spark development.

Technical Skills

Knowledge, Skills and Abilities »

 * Expertise with GCP services: BigQuery, Vertex AI Platform, Cloud Storage, AutoMLOps, and Dataflow.
 * Proficiency in CI/CD processes and version control tools (e.g., Git).
 * Strong understanding of ETL, Data Warehousing concepts, and Agile (Scrum) principles.

Soft Skills

 * Excellent communication and agile thinking.
 * Ability to understand and present options effectively.
 * Positive, accomplishment-driven attitude with the ability to adapt to various situations.

What You’ll Do

Job Responsibilities:

 * Technical Leadership: Provide clear technical guidance across ongoing projects, fostering collaboration to solve complex data engineering challenges.
 * Data Pipeline Development: Design, build, and maintain scalable and efficient data pipelines for ingestion, transformation, and integration using tools like Kafka, Databricks, and other technologies.
 * Digital Innovation: Modernize and extend core data assets across SQL, NoSQL, cloud, and real-time streaming platforms.
 * Feature Engineering: Develop and manage feature engineering pipelines for machine learning workflows, utilizing tools such as Vertex AI, BigQuery ML, and custom Python libraries.
 * Automated Testing: Implement automated testing frameworks to ensure data quality, reliability, and compliance with organizational standards.
 * Workflow Optimization: Optimize data workflows for performance, cost efficiency, and scalability across large datasets and complex environments.
 * Team Mentorship: Mentor team members in data principles, patterns, and practices to elevate team capabilities and encourage best practices.
 * Documentation and Communication: Draft and review architectural diagrams, interface specifications, and other technical documentation to ensure clear communication of solutions.
 * Strategic Guidance: Present opportunities with cost/benefit analyses to leadership, guiding architectural decisions for scalable and efficient data solutions.

Interested?

Qualified candidates should send their resumes to sbandi@vsoftconsulting.com




V-Soft Consulting Group is recognized among the top 100 fastest growing staffing companies in North America, V-Soft Consulting Group is headquartered in Louisville, KY with strategic locations in India, Canada and the U.S. V-Soft is known as an agile, innovative technology services company holding several awards and distinctions and has a wide variety of partnerships across diverse technology stacks.

As a valued V-Soft Consultant, you’re eligible for full benefits (Medical, Dental, Vision), a 401(k) plan, competitive compensation and more. V-Soft is partnered with numerous Fortune 500 companies, exceptionally positioned to advance your career growth.

V-Soft Consulting provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

For more information or to view all our open jobs, please visit www.vsoftconsulting.com or call (844) 425-8425.",Contract
4056821856,80427781.0,"Senior, Data Engineer - Data Ventures","Position Summary...

What you'll do...

Job Description

Do you have boundless energy and passion for engineering data used to solve dynamic problems that will shape the future of retail? With the sheer scale of Walmart’s environment comes the biggest of big data sets. As a Walmart Data Engineer, you will dig into our mammoth scale of data to help unleash the power of retail data science by imagining, developing, and maintaining data pipelines that our Data Scientists and Analysts can rely on. You will be responsible for contributing to an orchestration layer of complex data transformations, refining raw data from source into targeted, valuable data assets for consumption in a governed way. You will partner with Data Scientists, Analysts, other engineers, and business stakeholders to solve complex and exciting challenges so that we can build out capabilities that evolve the retail business model while making a positive impact on our customers’ lives.

About Team: Data Ventures

Everyone has data, but the sheer volume of data at Walmart can be limitless. In the Data Engineering team, we help Walmart manage this data by building pipelines and data lakes to prepare big data for analysis and unlocking actionable insights in real-time. We also use cross-departmental data and machine learning to build a holistic view of true profitability, saving millions of dollars across item categories and geographies while assisting our leadership in making better decisions faster. Do you have boundless energy and passion for engineering data used to solve dynamic problems that will shape the future of retail? With the sheer scale of Walmart’s environment comes the biggest of big data sets. As a Walmart Data Engineer, you will dig into our mammoth scale of data to help unleash the power of retail data science by imagining, developing, and maintaining data pipelines that our Data Scientists and Analysts can rely on. You will be responsible for contributing to an orchestration layer of complex data transformations, refining raw data from source into targeted, valuable data assets for consumption in a governed way. You will partner with Data Scientists, Analysts, other engineers, and business stakeholders to solve complex and exciting challenges so that we can build out capabilities that evolve the retail business model while making a positive impact on our customers’ lives.

What You'll Do


 * Data Strategy: Understands, articulates, and applies principles of the defined strategy to routine business problems that involve a single function.
 * Data Transformation and Integration: Extracts data from identified databases. Creates data pipelines and transform data to a structure that is relevant to the problem by selecting appropriate techniques. Develops knowledge of current analytics trends.
 * Data Source Identification: Supports the understanding of the priority order of requirements and service level agreements. Helps identify the most suitable source for data that is fit for purpose. Performs initial data quality checks on extracted data.
 * Data Modeling: Analyses complex data elements, systems, data flows, dependencies, and relationships to contribute to conceptual, physical, and logical data models. Develops the Logical Data Model and Physical Data Models including data warehouse and data mart designs. Defines relational tables, primary and foreign keys, and stored procedures to create a data model structure. Evaluates existing data models and physical databases for variances and discrepancies. Develops efficient data flows. Analyses data-related system integration challenges and proposes appropriate solutions.
 * Code Development and Testing: Writes code to develop the required solution and application features by determining the appropriate programming language and leveraging business, technical and data requirements. Creates test cases to review and validate the proposed solution design. Creates proofs of concept. Tests the code using the appropriate testing approach. Deploys software to production servers. Contributes code documentation, maintains playbook, and provides timely progress updates.
 * Problem Formulation: Translates business problems within one's discipline to data related or mathematical solutions. Identifies what methods (for example, analytics, big data analytics, automation) would provide a solution for the problem. Shares use cases and gives examples to demonstrate how the method would solve the business problem.
 * Applied Business Acumen: Provides recommendations to business stakeholders to solve complex business issues. Develops business cases for projects with a projected return on investment or cost savings. Translates business requirements into projects, activities, and tasks and aligns to overall business strategy. Serves as an interpreter and conduit to connect business needs with tangible solutions and results. Recommends new processes and ways of working.
 * Data Governance: Establishes, modifies, and documents data governance projects and recommendations. Implements data governance practices in partnership with business stakeholders and peers. Interprets company and regulatory policies on data. Educates others on data governance processes, practices, policies, and guidelines. Provides recommendations on needed updates or inputs into data governance policies, practices, or guidelines.
 * Demonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans by providing expert advice and guidance to others. Supporting and aligning efforts to meet customer and business needs and building commitment for perspectives and rationales.
 * Provides and supports the implementation of business solutions by building relationships and partnerships with key stakeholders. Identifying business needs, determining, and carrying out necessary processes and practices.
 * Promotes and supports company policies, procedures, mission, values, and standards of ethics and integrity by training and providing direction to others in their use and application, ensuring compliance with them.
 * Ensures business needs are being met by evaluating the ongoing effectiveness of current plans, programs, and initiatives. Applying suggestions for improving efficiency and cost effectiveness; and participating in and supporting community outreach events.
 * Creates training documentation and trains end-users on data modeling. Oversees the tasks of less experienced programmers and stipulates system troubleshooting supports.
 * Drives the execution of multiple business plans and projects by identifying customer and operational needs. Developing and communicating business plans and priorities, removing barriers and obstacles that impact performance. Providing resources, identifying performance standards, measuring progress, and adjusting performance accordingly. Developing contingency plans and demonstrating adaptability and supporting continuous learning.
   
   

What You'll Bring


 * You have consistently high standards, your passion for quality is inherent in everything.
 * Must have recent strong experience with the following: Spark Scala, SQL, Hadoop, Cloud environments.
 * Preferred: Python/PySpark, Java, Backend, J2EE.
 * You evangelize an extremely high standard of code quality, system reliability, and performance.
 * You have a proven track record coding with at least one programming language (e.g., Scala, Python).
 * You’re experienced in one of cloud computing platforms (e.g., GCP, Azure).
 * You’re skilled in data modeling & data migration protocols.
 * Experience with GCP, Data warehousing.
 * Experience with the integration tools like Automic, Airflow.
   
   

About Walmart Global Tech

Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. That’s what we do at Walmart Global Tech. We’re a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world’s leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.

Flexible, Hybrid Work

We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.

Benefits

Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.

Equal Opportunity Employer

Walmart, Inc. is an Equal Opportunity Employer – By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions – while being inclusive of all people.

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎

You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎

Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For Information About Benefits And Eligibility, See One.Walmart.

‎

Sunnyvale, California US-04396:The annual salary range for this position is $117,000.00-$234,000.00

‎

Bentonville, Arkansas US-09050:The annual salary range for this position is $90,000.00-$180,000.00

‎

‎

‎

‎

‎

‎

‎

‎

‎

‎

Additional Compensation Includes Annual Or Quarterly Performance Bonuses.

‎

Additional Compensation For Certain Positions May Also Include

‎

‎


 * Stock
   
   

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelor’s degree in Computer Science and 3 years' experience in software engineering or related field. Option 2: 5 years’ experience in

software engineering or related field. Option 3: Master's degree in Computer Science and 1 year’s experience in software engineering or related

field.

2 years' experience in data engineering, database engineering, business intelligence, or business analytics.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Master’s degree in Computer Science, Computer Engineering, Computer Information Systems, Software Engineering, or related area and 1 year's experience in software engineering or related area.

Primary Location...

840 W California Ave, Sunnyvale, CA 94086-4828, United States of America",Full-time
4045413592,66321745.0,Junior/Entry Level Data Engineer,"Since 2010 Synergisticit has helped Jobseekers get employed in the tech job market by providing candidates the requisite skills, experience, and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this Job market also, our candidates are able to achieve multiple job offers and $100k &plus; salaries.

please check the below links to see the success outcomes and salaries of our candidates .

https://www.synergisticit.com/candidate-outcomes/

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

We regularly interact with the Top Tech companies to give our candidates a competitive advantage visit the below videos exhibiting at Oracle Cloud World/Oracle Java one (Las Vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like Apple, google, Paypal, Western Union, Client, visa, Walmart lab s etc to name a few.

Currently, We are looking for entry-level software programmers, Java full-stack developers, Python/Java developers, Data analysts/ Data Scientists, and Machine Learning engineers for full-time positions with clients.

Who Should Apply Recent Computer Science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

Required Skills

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, Gen AI, LLM, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

Required Skills

REQUIRED SKILLS For Java /Full stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java, Javascript, C&plus;&plus;, or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates, and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team and only connect with candidates who are matching client requirements.

No phone calls, please. Shortlisted candidates would be reached out. No third-party or agency candidates or c2c candidates",Full-time
3875377500,46623.0,Jr. Web Application Data Engineer,"Description

Your role at GEI.

The Jr. Web Application Data Engineer position is responsible for the development and support of web applications that are highly data centric. This position goes beyond the typical web programmer and will design and support objects within Microsoft SQL Server. The person hired for this position will work with a team of Web programmers, Data Engineers, Data Architects, GISPs, Power BI designers, and subject-matter experts that are located on the east coast.

Required Qualifications


 * Practical experience with .Net framework for web development, C#, ASP.net, jquery, HTML/ razer, Linq, javaScript, and git or other version control management software.
 * Expertise in SDLC.
 * Ability to provide off-hour deployments and support for bug-fixes.
 * Major in computer-related field (computer science/engineering)
 * Able to work during east coast schedule.
   
   

Preferred Qualifications


 * Experience using Entity Framework Core
 * Experience with Microsoft SQL Server via SSMS - DDL and DML, relationships, indexing, view, and stored procedure development.
 * Knowledge of .Net Core
 * Azure authentication
 * Azure Blob storage integration
 * Power BI cloud service
 * Experience with VB.net for desktop applications, XML, XSD for supporting non-web applications.
   
   

Essential Duties


 * Design, program, test, deploy, and document web applications.
 * Design and build SQL Server schema.
 * Collaborate with data architects and data engineers.
 * Develop a strong understanding of the subject matter for each application to assist with troubleshooting.
 * Provide programming and data engineering assistance for desktop applications.
   
   

Soft Skills


 * Applicant should be self-motivated, detail-oriented, and organized.
 * Must be a quick learner.
 * Work well in a team environment but be self-directed and be able to work independently.
 * Experience in providing high quality deliverables on time.
 * Provide clear concise documentation for developed applications.
 * Ability to research coding solutions and best practices via websites or the resources.
   
   

We are GEI.

Some of the world’s most pressing problems - from climate change to sustainable development, to critical infrastructure and the future of our energy supply - need our brightest and diverse minds working together to create safer, more resilient communities for tomorrow.

We are technical experts, collaborators, and entrepreneurs who draw from diverse backgrounds to solve our clients’ most complex challenges.

With nearly 60 offices across North America, we offer a range of engineering, science, and technical consulting services. Our range of expertise, project types, and culture make us the choice for top talent in the AEC industry.

Employee-owned. Employee-focused.

As a 100% employee-owned company, our employees support our flat leadership structure, have a say in how our business operates and benefit from our financial success. We are committed to employee growth with career development opportunities, competitive total rewards, a well-being program, flexible work arrangements and more. Our company culture is driven by our 4 Cs - we are Client-Centered, Curious, Collaborative, and Community Minded - which support our focus on sustainability, safety, diversity, equity and inclusion. Get to know us better by visiting GEI’s career site here.

GEI’s Total Rewards Package Includes


 * Market-Competitive Compensation, including Eligibility for an Annual Performance Bonus
 * Pay Range For This Position: $25.00-32.00/hour dependent upon experience
 * Comprehensive Benefits Program, including Medical, Dental, Vision, Life, Disability and More
 * Well-Being Program and Paid Parental Leave
 * Commuter Benefits
 * Hybrid Work Schedules and Cell Phone Stipends
 * GEI University (GEIU) with Continuing Education Assistance and Tuition Reimbursement
 * Connecting Conversation Program with a Focus on Professional Development and Opportunities for Advancement
 * Support and Financial Rewards for Publication Awards, Professional Dues, and Professional Licenses
 * Paid Holidays and Generous Paid Time Off Program
 * Rewards and Recognition
 * GEI-Funded Profit Sharing and 401(k)
 * Opportunity to be an Owner and Shareholder (Learn more here)
 * A Vibrant Culture that is Focused on Partnership, Sustainability, Giving Back to Our Communities and Diversity, Equity and Inclusion
 * And More…",Full-time
4151644976,10456809.0,Data Engineer,"Company Introduction

OneSource Regulatory Technology hosts a number of innovative solutions to enhance job performance in the Pharmaceutical space. OSR Technology is looking for an experienced and dedicated data engineer to join our product solutions team!

Job Description

OneSource Regulatory is trying to identify a full-time contractor with at least 4+ years of experience to assist us with ongoing R&D projects.

We are looking for a data engineer to pull data from various sources and do all the necessary steps to clean, normalize, possibly annotate, and finally load the data into databases. The candidate should be able to develop and implement a strategy for testing the data integrity of the collected data. This role requires extreme attention to detail to ensure data quality is top priority.

Responsibilities


 * Well versed in parsing and synthesizing of XML and/or JSON documents.
 * Curating of data that can involve some intermediate to advanced web scraping. (data may need to be fetched via SFTP, FTP, Wget, Curl, REST APIs, GraphQL queries from spots on the Internet)
 * Proficiency with Linux command line and various simple tools, such as grep, wc, sed, awk, find, ls, cat, piped commands and possibly some very light Bash shell scripting, setting up crontab schedules and programs
 * Must have basic knowledge of SQL with the following databases: PostGres, MySQL, Google BigQuery
 * Must have basic knowledge of No-SQL database knowledge such as MongoDB or similar
 * Familiarity with basic Cloud technology such as storage buckets, cloud serverless functions
 * Must have experience extracting text and images from PDF files
 * Knowledge of Puppeteer or other automatable web client technologies
 * Understanding JavaScript, HTML/CSS and HTTP methods (for understanding page structure for web scraping)
   
   

Skills


 * Solid experience with Python and Python Libraries such as Pandas, requests, etc
 * Skill set should match up with required responsibilities listed above
 * Strong English skills (e.g. grammatical analysis and rhetorical structure)
 * Team Player
 * Great communication skills
   
   

Bonus Skills


 * Experience within the Pharmaceutical Space
 * Ability to expose data via C# NETCore and/or GraphQL
 * Google Cloud Platform (Cloud Buckets, Google Cloud Functions (.NET, Python, Node.JS))
 * Ability to parallelize data manipulation and scraping via Python multi-threading, etc.
 * Python BeautifulSoup
 * Scrapy
 * Docker (setting up Kubernetes style processing if warranted for data scraping/data ingestion/normalization)
 * Multithreading concepts",Full-time
4126532404,18270648.0,"Staff Data Engineer, Analytics","Afresh is on a mission to eliminate food waste and make fresh food accessible to all. Our first A.I.-powered solution optimizes ordering, forecasting, and store operations for fresh food departments in brick-and-mortar grocers. With our Fresh Operating System, regional and national grocery retailers have placed $1.6 billion in produce orders across the US and we've helped our partners prevent 34 million pounds of food from going to waste. Working at Afresh represents a one-of-a-kind opportunity to have massive social impact at scale by leveraging uncommonly impactful software – we hope you'll join us!

About the Role:

Afresh’s analytics platform allows teams across the company to create reliable metrics from our disparate data sources, and to use those metrics to track internal performance, power new reporting products for our customers, and drive experiment-based decision-making.

Our growing suite of reporting products helps our customers understand what’s happening in their stores and how to use Afresh effectively to reduce food waste. Building these products includes strengthening the analytics platform that powers them.

The Data Science and Analytics team collaborates closely with every team in the company, empowering them to build products and make decisions with data. You will regularly interact with data engineers, applied scientists, data scientists, full stack engineers, and product managers.

As a Staff Data Engineer on the Data Science team, you will own the development of our analytics platform. In this role, you will evolve our data warehouse schema, solidify our transform architecture, and establish data governance patterns to serve our internal and external analytics needs. Some of your responsibilities will include:



 * Improving and extending our data analytics architecture to provide reliable and accessible data for a wide range of use cases
 * Collaborating with engineers, product managers, and data scientists to understand their data needs, and then build extensible dimensional models and semantic layer metrics that allow for consistent and reliable insights
 * Evolving our existing data quality and data governance processes
 * Mentoring and up-skilling other engineers
   
   
   

This is a high-impact role with ownership of highly visible projects and a lot of room to grow in your scope.

Skills and Experience:



 * 6+ years of experience as an data engineer, analytics engineer, data warehouse engineer, or a similar role.
 * Strong understanding of advanced concepts in SQL.
 * Exceptional communication and leadership skills, with a proven ability to facilitate cross-team and cross-functional collaboration and information sharing.
 * 1+ years of experience working with SQL-driven transform libraries that support an ELT paradigm, like dbt or sqlmesh, at scale, including setting up CI/CD pipelines that ensure high quality transformations.
 * Expert knowledge about the differences between OLTP and OLAP database design.
 * Familiarity with the differences between data engineering concepts like Data Mesh, Data Lake, Data Warehouse, Data Fabric, and Data Lakehouse.
 * Experience with setting up a semantic layer defined with code (LookML, Cube.dev, AtScale, dbt semantic layer).
 * Technologies: SQL, Python, Airflow, dbt, Snowflake/Databricks/BigQuery, Spark.
   
   
   

Pay Range in USD:

Pay Range in CAN:

About Afresh

Founded in 2017, Afresh is working on the #1 solution to curb climate change: reducing food waste. By combining human insight and transformative technology, we're helping grocers provide fresher food to customers at more affordable prices.

Afresh sits at an incredible intersection of positive social impact, rocket ship financial growth, and cutting-edge technology. Our best-in-class AI research has been published in top journals including ICML, and we've raised over $148 million in funding from investors including former co-CEO of Whole Foods Market Walter Robb and Eric Schmidt's Innovation Endeavors.

Fresh is the past, present, and future of our food system – the waste we create today will impact our planet for years to come. Join us as we continue to build a vibrant, diverse, and inclusive team that embodies our company’s values of proactivity, kindness, candor, and humility.

Afresh provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity/expression, marital status, pregnancy or related condition, or any other basis protected by law.

Here at Afresh, many of our employees work remotely provided that they reside in one of the following states: AR, CA, CO, FL, GA, IL, KY, MA, MI, MT, MO, NV, NJ, NY, NC, OR, PA, TX, WA, WI. However, there may be key roles that will require a candidate/employee to be local to our San Francisco, CA office. In which case this requirement will be included in the job posting details under ""Skills and experience"" for reference.",Full-time
4045410901,66321745.0,Junior Data Engineer,"Since 2010 and almost 14 years SynergisticIT has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients.

Post Covid the tech Layoffs have been massive—In 2022 there were 165,269 tech layoffs, In 2023 there were 264,220 tech layoffs and so far in 2024 there have been 126,382 tech layoffs. (Source Layoffs.fyi ) -Total layoffs as per this 555,871 tech layoffs.

Client, Dell and Cisco have announced 15,000/12,500 and 4000 tech layoffs respectively in August.

The Job market is Hyper Competitive. For 1 position 500-2000 candidates or more are applying and laid off job seekers are also competing for entry level Job positions.

Acquiring the right technology skillsets which are being demanded by clients and getting yourself in front of clients is the way to get to get Interviews and eventually a Job Offer. Survival of the Fittest is the only way to get a tech Job in this job market.

In this Layoffs fueled market also SynergisticIT's candidates are able to achieve multiple job offers and $100k &plus; salaries once they acquire the required skills.

please check the below links to see success outcomes, salaries of our candidates.

https://www.synergisticit.com/candidate-outcomes/

https://www.synergisticit.com/roi-of-computer-science-degree-colleges-vs-synergisticit/

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please visit the below videos exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, we are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Data Engineers, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

REQUIRED SKILLS For Java /Full Stack/Devops Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Knowledge of Core Java , javascript , C&plus;&plus; or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

For data Science/Data Analyst/AI/Machine learning Positions

Required Skills

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude

Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Full-time
4106963882,81777085.0,Data Engineer,"MUST HAVES

(60 tech ability/40 soft skills)


 * Snowflake shop
 * Snowflake Certified is a big plus (SnowPro)
 * ETL processes
 * Strong understanding of healthcare Data Standards is a plus (HL7, FHIR)
 * Strong understanding of EMR / EHR system integration (Athena, Mirth, etc)
 * Data migration
 * modern data engineering practices, etc.
 * opentable formats like datalake and iceberg
 * Exposed to databricks pipeline
 * Data mesh exposure
 * Must see the Data frameworks they have worked with in the resume
 * Exposure to delta lake, data mesh approaches, iceberg tables and exposure to databricks pipelines.",Full-time
4137192139,1586.0,"Data Engineer II, F3 DASH","Description

Are you interested in being a part of Amazon’s fastest growing business? Are you excited to work on latest Big Data technologies to help shape the future of Grocery data? If the answer to both these questions is Yes, then come be a part of Amazon Fresh’s Central Data Infrastructure team (DASH). Our vision is to build a world class, centralized and secure data infrastructure for Amazon’s Worldwide Omnichannel Grocery Business. Our mission is to make it extremely convenient for Internal stakeholders, 3P partners and the Grocery engineering community to access timely and accurate data for all their reporting and analytics needs. The scale and the complexity of the data we manage requires constant innovation and pushing the boundaries on what’s possible. This role offers you an opportunity to work on VP level visibility initiatives and make a lasting impression on how grocery data is managed and distributed across the globe.

Key job responsibilities

In This Role You Will


 * Help build the infrastructure to answer questions with data, using software engineering best practices, data management fundamentals, data storage principles, and recent advances in distributed systems
 * Manage AWS resources.
 * Collaborate with Business Intelligence Engineers to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation
 * Collaborate with Data Scientists to implement advanced analytics algorithms that exploit our rich data sets for statistical analysis, prediction, clustering and machine learning
 * Drive the architecture and technology choices that enable a world-class user experience
 * Develop expertise in a broad range of Amazon’s data resources and know when, how, and which to use and which not to use
 * Encourage the organization to adopt next-generation data architecture strategies, proposing both data flows and storage solutions
 * be comfortable with a degree of ambiguity and willing to develop quick proof of concepts, iterate and improve
 * Create extensible designs and easy to maintain solutions with the long term vision in mind
 * Have an understanding and empathy for business objectives, and continually align your work with those objectives and seek to deliver business value. You listen effectively.
   
   

A day in the life

Successful candidate would have extensive experience working with big data, building data warehouses and data processing services. They are effective at seeing data patterns and building generic data solutions to improve user experience. Proficiency in SQL and data modelling allows to create data warehouses and tables conforming to wide range of business needs. Previous ETL and MPP experience enables candidate to build extensible and scalable pipelines capable of processing large amounts of data in a short time, ex. >1T rows within few hours. Wide industry experience helps detect inefficiencies in existing designs and address them with minimal effort.

About The Team

F3 DASH is Amazon Fresh central data team responsible for the creation and maintenance of Amazon Grocery’s global data infrastructure. Our mission is to make all of grocery data easily accessible across multiple businesses by all users from a single location without any restrictions for all their reporting and analytics needs. Our long-term vision is to build a best-in-class data infrastructure to support worldwide grocery data to enable timely reporting and automated decision-making with standardized metrics to deliver top-line and bottom-line impact to Amazon’s grocery business.

Basic Qualifications


 * 3+ years of data engineering experience
 * Experience with data modeling, warehousing and building ETL pipelines
   
   

Preferred Qualifications


 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com Services LLC

Job ID: A2872712",Full-time
4084017964,81933911.0,Data Engineer,"



About SumerSports:

SumerSports is a leading football intelligence technology company that specializes in providing an innovative suite of products for football fans and NFL clubs. We are a collection of executives, engineers, data scientists, and visionaries from NFL clubs, technology startups, finance, and academia.

Position Summary:

We are seeking a highly skilled and experienced Data Engineer to join our dynamic and fast-paced team. As a Data Engineer at SumerSports, you will be at the forefront of designing and implementing state-of-the-art data-driven solutions.

Responsibilities:


 * Develop and maintain data pipelines using Databricks, Airflow, or similar orchestration systems.
 * Write robust, maintainable code in Python, following best practices and coding standards.
 * Design and implement solutions using Kubernetes, ensuring high availability and scalability.
 * Gather product data requirements and implement solutions to ingest, process, and serve that data to applications at scale
 * Collaborate closely with Data Science and Engineering teams to build production-ready applications, optimizing for performance and scale.
 * Cultivate data from a wide range of sources for use by our data scientists and maintain documentation for data.
 * Design a modern data stack, with a keen focus on providing a platform for data scientists and ML engineers to develop production ready models and pipelines.
 * Work across Data Science and Engineering teams to ensure effective collaboration and communication.
 * Actively participate in code reviews, coaching, and mentoring within cross-functional teams.
 * Enhance the developer experience through improved tooling and reduced toil.
 * Stay informed of industry advancements and advocate for the adoption of new technologies and best practices.
   
   

Requirements:


 * Proven experience as a data engineer, preferably with at least 3 or more years of relevant experience.
 * Some exposure designing cloud native solutions and implementations with Kubernetes
 * Experience with Airflow or similar pipeline orchestration tools.
 * Strong background in Python programming.
 * Demonstrated experience in collaborating with Data Science and Engineering teams in a production environment.
 * Firm grasp on SQL and knowledge of relational data modeling schemas.
 * Preference for experience with Databricks or Spark
 * Familiarity with modern data stack design and strong opinions on data lifecycle management, testing, and governance.
 * Effective communicator with the ability to advocate best data practices across the organization.
 * Passion for coaching and working in a team-oriented environment.
 * Commitment to improving developer experience and productivity.
 * Experience with distributed systems, microservices architecture, and cloud platforms (e.g., AWS, Azure, Google Cloud).
 * Excellent problem-solving skills and the ability to analyze and debug complex issues.
 * Strong communication and interpersonal skills, with the ability to collaborate effectively with cross-functional teams.
   
   

Benefits:


 * Comprehensive health insurance plan
 * Retirement savings plan (401k) with company match
 * Remote working environment",Full-time
4124174496,16229187.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients' toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government's most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills And Attributes For Success


 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers.
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices.
 * Write code to ensure the performance and reliability of data extraction and processing.
 * Support continuous process automation for data ingest.
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing.
 * Work with program management and engineers to implement and document complex and evolving requirements.
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork.
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists.
   
   

Qualifications


 * Must be a US Citizen.
 * Must be able to obtain a Public Trust Clearance.
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models.
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats.
 * Proficiency in developing ETL processes, and performing test and validation steps.
 * Proficiency to manipulate data (Python, R, SQL, SAS).
 * Strong knowledge of big data analysis and storage tools and technologies.
 * Strong understanding of the agile principles and ability to apply them.
 * Strong understanding of the CI/CD pipelines and ability to apply them.
 * Experience with relational database, such as, PostgreSQL.
 * Work comfortably in version control systems, such as, Git Repositories.
   
   

Ideally, You Will Also Have


 * Experience creating and consuming APIs.
 * Experience with DHS and knowledge of DHS standards a plus.
 * Candidates will be given special consideration for extensive experience with Python.
 * Ability to develop visualizations utilizing Tableau or PowerBI.
 * Experience in developing Shell scripts on Linux.
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions.
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences.
   
   

Our Commitment

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client's specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we've been growing our government-contracting portfolio, and along the way, we've created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:


 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com

$112,597.33 - $152,810.66 a year

PI259869643",Full-time
4142811546,65529778.0,Data Engineer,"Data Engineer Opportunity

We're seeking experienced Data Engineers to join a leading company in the industry. In this role, you'll design and implement scalable cloud-based data architectures using AWS services like Lambda, Kinesis, and SQS. You'll also develop and maintain Snowflake-based data solutions and write Python code with a focus on performance and best practices.

Responsibilities:

 * Build cloud data integration architectures using AWS tools.
 * Develop and maintain Snowflake data solutions.
 * Write scalable Python code.
 * Collaborate with stakeholders to define technical requirements.
 * Enhance automated testing and implement CI/CD pipelines using Jenkins and Terraform.
 * Monitor and troubleshoot systems with AWS tools like CloudWatch and Athena.
 * Support data migration with DMS and Firehose.

Requirements:

 * 4+ years of Python coding experience.
 * 2-5 years of experience with Snowflake.
 * 3-5 years of experience with AWS services (Lambda, Kinesis, SQS, etc.).
 * 2-4 years of experience with CI/CD and IaC (Terraform, Jenkins).
 * Familiarity with DMS and Firehose.



",Contract
4139608302,1586.0,"Data Engineer II, Davengers","Description

Looking for an engineer who can handle and build scalable sustainable data solutions for Amazon's cross border business.

About The Team

We are a Data and Science team of Amazon's cross border business maintaining end to end infrastructure and platforms for Data Engineering, BI and Science solutions.

Basic Qualifications


 * 3+ years of data engineering experience
 * Experience with data modeling, warehousing and building ETL pipelines
   
   

Preferred Qualifications


 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon Development Center U.S., Inc.

Job ID: A2888732",Full-time
4151625059,1120204.0,Data Analytics Engineer III,"At MyFitnessPal, our vision is to be the most trusted brand for improving your health through better food choices. We believe good health starts with what you eat. We provide the tools and resources to reach your weight management goals.

We are looking for a skilled Analytics Engineer to join the MyFitnessPal Data Engineering team. Our users rely on MyFitnessPal to power their health and fitness journeys every day. As a member of our team, you’ll have the opportunity to positively impact those users with your expertise in data modeling, governance, and backend systems. This role bridges the gap between engineering and analytics, with a focus on creating clean, reliable, and scalable data models for business intelligence and data-driven initiatives.

A critical aspect of this role is leading day-to-day efforts to ensure data quality and governance, supporting the long-term data governance strategy, and taking an engineering mindset to ad hoc analysis and investigations. As a self-starter and problem-solver, you will also collaborate with the broader Data Platform team to enhance overall capabilities and efficiency.

In addition to technical expertise, you’ll find that your teammates value collaboration, mentorship, and inclusive environments.

What You’ll Be Doing


 * Lead day-to-day efforts to ensure data quality, governance, and reliability, while driving long-term data governance strategy across the organization
 * Design and implement automated data quality assurance (QA) and quality control (QC) processes to ensure accurate, consistent, and complete data, monitor data workflows and resolve anomalies or inconsistencies in production pipelines
 * Develop and maintain data validation frameworks and testing strategies for pipelines and transformations, identifying and addressing issues proactively
 * Conduct ad hoc analysis and investigations with an engineering mindset, delivering actionable insights to support partner stakeholder teams and cross-functional initiatives
 * Work closely with the Data Platform team, contributing to the continuous improvement and scalability of the organization’s data infrastructure. Evaluate and improve existing pipelines, data models, and processes to provide more scalable and efficient solutions
 * Support business teams by enabling self-service analytics and providing training on data tools and workflows. Integrate with services and systems across MyFitnessPal engineering teams to ensure a seamless flow of data. Collaborate with data scientists, analysts, and business teams to ensure data models meet analytical and operational needs
 * Interact with stakeholders to define and document technical requirements for data pipelines, transformations, and integrations
 * Live our core values in all you do:
 * Be Kind and Care
 * Live Good Health
 * Be Data-Inspired
 * Champion Change
 * Leave it Better than You Found It
 * Make It Happen
   
   

Qualifications To Be Successful In This Role


 * Experience with dbt and modern data modeling practices (e.g., Kimball, Inmon frameworks)
 * Proven expertise in implementing and maintaining QA/QC processes for data pipelines, including automated testing and anomaly detection
 * Proficiency in SQL and development languages like Python
 * Ability to lead both day-to-day efforts and contribute to the long-term data governance strategy
 * Strong problem-solving skills and a self-starter mindset, capable of independently driving projects to completion
 * Ability to perform ad hoc analysis and data investigations with an engineering mindset, ensuring efficiency and reproducibility
 * Experience with data warehouses like Snowflake or relational databases such as MySQL
 * Understanding of data governance principles, including data lineage, access policies, and quality frameworks
 * Experience with Airflow or similar orchestration tools for managing ETL/ELT pipelines
 * Familiarity with API integration and design patterns, including REST
 * Proven ability to develop scalable, high-volume data pipelines for downstream analysis and operational indicators
 * Experience triaging and resolving production data issues
 * Knowledge of data at scale and experience with data validation frameworks
 * Familiarity with AWS or other cloud computing platforms
   
   

Preferred Skills


 * Experience with data visualization tools (e.g., Tableau, Looker, Power BI)
 * Knowledge of Python frameworks for analytics engineering or automation
 * Familiarity with data privacy regulations like GDPR and CCPA
   
   

Please consider applying even if you don’t meet 100% of the qualifications. Research shows you can still be considered for a position if you meet some of the requirements. At MyFitnessPal, we’re building a fitness product for everyone and believe our team should reflect that. We encourage people of different backgrounds, experiences, abilities, and perspectives to apply.

The reasonably estimated salary for this role at MyFitnessPal ranges from $130,000 - $150,000. Actual compensation is based on factors such as the candidate’s skills, qualifications, and experience. In addition, MyFitnessPal offers a wide range of comprehensive and inclusive employee benefits for this role including healthcare, parental planning, mental health benefits, annual performance bonus, a 401(k) plan and match, responsible time off, monthly wellness and technology allowances, and others.

Exciting Full-Time Employee Benefits, Perks and Culture

Face-to-Face Connections: We value personal connections. Enjoy opportunities to meet and connect with your team members in person to help forge meaningful relationships that extend beyond the virtual realm. Teams meet as often as needed and all of MyFitnessPal gathers annually.

Flexibility At Its Best: Achieve the work-life balance you deserve. Enjoy a flexible time-off policy and work on your own terms with our Responsible Time Off benefit.

Give Back: Use your volunteer days off to support what matters most to you. Each full time teammate receives 2 days per calendar year to give back to their community through service.

Mentorship Program: Take control of your career through our mentorship program where, if you’d like, you will be matched with a teammate who can help you scale your skills and propel your growth.

Family-Friendly Support: Embrace the journey with confidence and care. Enjoy our paid maternity and paternity leave, to provide time to balance family responsibilities with your career and take the time needed to strengthen family relationships. We understand the complexities of starting or expanding a family, which is why we provide best-in-class comprehensive assistance for fertility-related matters.

Wellness Comes First: Live Good Health is one of our core values. Receive a monthly Wellness Allowance, empowering you to focus on your physical and mental well-being by choosing from a range of wellness initiatives, including dedicated mental health days.

Celebrate Greatness: Your hard work deserves recognition! Our reward and recognition platform empowers peers to acknowledge and reward each other for the exceptional contributions they make.

Elevate Your Health & Fitness: Get access to MyFitnessPal Premium, allowing you to take your fitness, health and wellness journey to new heights.

Unlock Your Potential: Access our virtual learning and development library, and participate in training opportunities to continuously grow and enhance your skills.

Championing Inclusion: Our dedicated DEI Committee actively fosters a diverse and inclusive workplace by setting actionable goals and evaluating progress across the organization.

Healthcare Matters: Your well-being is our priority. Take advantage of our competitive medical, dental, and vision benefits that cater to your holistic healthcare needs. Feel secure and supported on your wellness journey.

Secure Your Future: Benefit from our retirement savings program, giving you peace of mind for your financial goals. Reach them sooner with MyFitnessPal’s competitive employer match.

At MyFitnessPal, our mission is to enable people to make healthy choices. And it wouldn't be possible without our team. We celebrate the unique POV that each person brings to the table and believe in a collaborative and inclusive environment. As an equal opportunity employer, we prohibit any unlawful discrimination on the basis of race, religion, military or veteran status, sex, gender, marital status, gender identity or expression, sexual orientation, national origin, age, or disability. These are our guiding ideologies and apply across all aspects of employment.

MyFitnessPal participates in E-Verify.",Full-time
4151628081,36095797.0,Software Engineer - Backend (All Levels),"EvenUp is on a mission to support injury law firms across America in providing a consistent and high standard of representation, ensuring that every injury victim who seeks legal assistance can expect a fair resolution. We’ve helped thousands of victims get fair compensation by empowering their representation with best-in-class insights, automation, and document creation.

In the past year, our engineering and data science team grew to 90 team members and we rolled out infrastructure updates, new products, and updates to existing workflows - combining data, ML frontend and backend work. The next 12 months are very exciting for us; we expect the technical team to double as we deliver on a roadmap to handle 10x our current volume. Now is the time to get on the ground floor as we scale!

This is a hybrid role with 2-3 days per week spent collaborating with the team in the office. We are open to applicants located in either the Greater Toronto Area or in the San Francisco Bay Area.

What You’ll Do


 * Build impactful technology: You will build first-of-a-kind technology that will transform an analog industry to improve the lives of millions of injury victims that got their lives turned upside down at no fault of their own
 * Have immediate impact in a small and tightly-knit team: be a key part of building the foundational blocks of their software and the team culture. Start shipping production code in less than two weeks!
 * Be a core part of our engineering team: Be a key part of building the foundational blocks of EvenUp's software and the team culture. Build and deploy and work on our core software product, whereby you’ll tackle hard problems, explore and deliver solutions while working with key people across the organization
 * Work with a world-class team: Our team has deep expertise in technology, machine learning, law, and finance, combining experiences from careers at Google, Uber, Waymo, Quora, Vimeo, Blizzard, and more.
 * Learn new technologies from the best: Our team emphasizes a culture of continual learning and you will have opportunities to work on projects in machine learning, data engineering, back-end, front-end, DevOps
 * Work with our tech-stack: Python, Typescript, React, Postgres, Kubernetes, Elasticsearch…
   
   

What We Look For


 * 5-10+ years of experience with backend engineering, working with relational databases and/or other database technologies
 * Have several years of industry experience building high-quality software, shipping production-ready code and infrastructure
 * Ability to communicate technical ideas or issues in easy-to-understand and actionable terms
 * Learn quickly and are seeking opportunities to work cross-functionally (including data engineering & DevOps) and with a diverse group of people
 * Experience owning a project from start to finish and loves to drive a project across the finish line
 * Demonstrated success in mentoring and upleveling teammates
 * Interest in making the world a fairer place (we don’t get paid unless we’re helping injured victims and/or their attorneys)
 * Kubernetes experience is a plus!
   
   

Benefits & Perks

Our goal is to empower every team member to contribute to our mission of fostering a more just world, regardless of their role, location, or level of experience. To that end, here is a preview of what we offer:


 * Choice of medical, dental, and vision insurance plans for you and your family
 * Flexible paid time off
 * 10 US observed holidays, and Canadian statutory holidays by province
 * A home office stipend
 * 401(k) for US-based employees
 * Paid parental leave
 * Sabbatical program
 * A meet-up program to get together in person with colleagues in your area
 * Offices in San Francisco and Toronto
   
   

Please note the above benefits & perks are for full-time employees

About EvenUp

EvenUp is on a mission to level the playing field in personal injury cases. EvenUp applies machine learning and its AI model known as Piai™ to reduce manual effort and maximize case outcomes across the personal injury value chain. Combining in-house human legal expertise with proprietary AI and software to analyze records. The Claims Intelligence Platform™ provides rich business insights, AI workflow automation, and best-in-class document creation for injury law firms. EvenUp is the trusted partner of personal injury law firms. Backed by top VCs, including Bessemer Venture Partners, Bain Capital Ventures (BCV), SignalFire, NFX, DCM, and more, EvenUp’s customers range from top trial attorneys to America’s largest personal injury firms. EvenUp was founded in late 2019 and is headquartered in San Francisco. Learn more at www.evenuplaw.com.

EvenUp is an equal opportunity employer. We are committed to diversity and inclusion in our company. We do not discriminate based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",Full-time
4142290910,68541971.0,Data Engineer,"About Ensemble VC




At Ensemble VC, we’re not just investors in advanced tech — we’re builders. We’re a data-driven venture capital firm that has been using our proprietary data science platform to identify hidden opportunities and create game-changing partnerships. With half our team made up of engineers and data scientists, we’re constantly pushing the boundaries of how technology can transform venture capital.




In addition to our core fund, we are building an analytical seed fund with two of the world’s premier seed investors. It’s a bold idea with incredible potential, and we’re looking for a Data Engineer to take the lead in building the technical foundation for this partnership.




This role is for someone ready to bet on themselves—a highly entrepreneurial position where success could lead to long-term opportunities and major impact.




The Role: Build the Tech that Builds the Future




As our Data Engineer, you’ll work closely with a team of engineers, data scientists, and Ensemble’s leadership team to enable data-driven investing. You’ll design and build data pipelines on AWS that empower smarter investing, seamless collaboration, and next-level efficiency.




This isn’t just about coding—it’s about solving problems, creating value, and shaping the future of data-driven venture capital. You’ll have the freedom to experiment, innovate, and iterate quickly.




What You’ll Do




 * Collaborate with data scientists, software engineers, and investors to develop data pipelines that deliver actionable insights and data to drive Ensemble VC’s startup investments, while ensuring data accuracy and availability.
 * Maintain data transformation logic while partnering with the data team to evolve, optimize, and integrate critical predictive models and create scalable data solutions.
 * Partner with the investment team to pinpoint opportunities to enhance existing processes for new company identification, reporting, and ad-hoc analysis.
 * Define data engineering standards and best practices, and promote operational excellence.
 * Continuously improve ongoing reporting, data ingestion, and analysis processes.




What We’re Looking For




 * 3+ years of data engineering experience with a solid foundation in data modeling, warehousing and building ETL pipelines
 * Solid track record of manipulating, processing, and extracting values from large datasets to build ML and AI pipelines to assist data science teams.
 * Technical proficiency: Hands-on experience and advanced knowledge of:
 * Relational and document databases
 * Data Modeling and Warehousing
 * Cloud services (AWS, GCP, Azure)
 * Python and data frame libraries (e.g., Pandas)
 * Proven ability to take ownership of customer issues, effectively analyze and troubleshoot problems to deliver results, and communicate solutions clearly while collaborating with colleagues




Why This Role is Different




This isn’t just a job—it’s a unique chance to be a trailblazer. Here’s why:




 * Entrepreneurial opportunity: This role is a trial for a long-term initiative. Success here could lead to a major career step and a lasting impact on the industry.
 * Work with the best: You’ll collaborate with world-class investors, engineers, and data scientists to build something truly innovative.
 * Creative freedom: We value bold ideas and encourage experimentation to find the best solutions.
 * Mission-driven culture: Ensemble VC is all about challenging the status quo and driving progress through technology.




What We Offer




 * Competitive compensation package and benefits, including health and dental insurance
 * Impactful work: Build technology that shapes the future of venture capital.",Full-time
3955779327,15401201.0,Data Engineer,"Venture Global LNG (""Venture Global"") is a long-term, low-cost provider of American-produced liquefied natural gas. The company's Louisiana-based export projects service the global demand for North American natural gas and support the long-term development of clean and reliable North American energy supplies. Using reliable, proven technology in an innovative plant design configuration, Venture Global's modular, mid-scale plant design will replace traditional designs as it allows for the same efficiency and operational reliability at significantly lower capital cost.

The Data Engineer is responsible for developing, designing, and maintaining data platform solutions. The measures of an ideal candidate include communication skills, technical proficiency, collaboration, and willingness to learn new things. This new position will be based in our Arlington, VA headquarters and report to the Director of Business Intelligence. This position is structured within IT under the Vice President of Applications.

The position will be located in Arlington, VA.

Position Responsibilities:

Key Responsibilities and Essential Duties:


 * Build complex data solutions in an Azure Cloud environment.
 * Maintain the Azure components and services.
 * Develop architecture changes using infrastructure as code.
 * Create data architectures diagrams for complex data modeling solutions.
 * Create and maintain data dictionaries for contextualizing data from disparate sources.
 * Enable end-to-end automation for deployment using continuous integration and continuous delivery.
 * Implement data pipelines to ingest data to the platform, standardize the data, and transform the data into business facing datasets.
 * Perform unit and integration testing of data pipelines.
 * Perform data integration at scale with Azure Data Factory.
 * Utilize Databricks to transform, curate, and organize data for use with business intelligence reporting and data analytics.
 * Work with BI developers and business SMEs to translate business requirements into curated datasets suitable for analytics solutions.
 * Document data pipelines for maintainability.
 * Work with source system owners and business owners to incorporate business changes into data pipelines.
 * Design data architecture for future platform growth including data warehousing, machine learning, streaming analytics, and data visualization.
 * Assist in testing, governance, data quality, training, and documentation efforts.
 * Actively engage in business stakeholder requirement workshops to understand, interpret, and translate requirements into effective technical solutions.
   
   

Job Qualifications


 * Bachelor's degree in Computer Science, Data Analytics, Engineering, Mathematics, Business, or related field of study.
 * 2+ years in cloud architecture and data engineering
 * Extensive experience in implementing data storage solutions, managing, and developing data processing, and optimizing data solutions (Azure)
 * Expertise in integrating, transforming, and consolidating data from structured and unstructured data systems suitable for analytics solutions.
 * Understanding of parallel processing and data architecture patterns.
 * Knowledgeable in data processing languages such as SQL, Python, or Spark.
 * Experience in building secure data processing pipelines using Azure data services.
 * Ability to self-manage and make your own decisions.
 * Excellent interpersonal and communications skills, with strong critical thinking and attention to detail.
 * Strong work ethic with ability to effectively prioritize, meet deadlines, adapt to changing priorities and business needs, and succeed in a fast-paced environment.
 * Excellent attention to detail and the ability to efficiently summarize and prioritize information.
   
   

Preferred Qualifications


 * Proficient in Microsoft Azure Storage Explorer, Azure DevOps, Azure Data Factory, Azure Databricks, Azure Data Lake Gen 2, Azure DevOps, Unity Catalog and Git
 * Experience in coding languages primarily Python and Spark.
 * Experience in agile development and sprint planning.
 * Strong technical writing skills.
   
   

Venture Global LNG is an Equal Opportunity Employer. We do not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status, or any other basis covered by appropriate law.

",Full-time
4130677826,874210.0,Data Engineer,"Our family of brands is comprised of Schoolhouse, the lighting, home furnishings, and lifestyle brand based in Portland, Oregon; Food52, the community-driven cooking and home company, based in Brooklyn, New York; and Dansk, the heritage home brand founded in 1954.




Schoolhouse

Schoolhouse is a lighting, home furnishings and lifestyle brand dedicated to thoughtful living and purposeful design. From iconic lighting to one-of-a-kind homewares, our mission is to provide a new generation of heirlooms that inspire people to create unique, meaningful spaces in which to live and work.




Food52

Food52 is a next-generation cooking and home company, named one of the World's Most Innovative Companies by Fast Company, with a monthly reach of more than 25 million people. Food52 challenges the models of traditional media and retailers, combining content, commerce, and community around the belief that the kitchen is the heart of the home and that food is the center of a well-lived life. Food52 inspires, informs, and supports its engaged community with recipes, videos, podcasts, events, and a curated selection of well designed, high-quality products.




Dansk

Dansk is a design company founded in 1954 by Ted and Martha Nierenberg to bring the elegant simplicity and natural materials of Scandinavian design to the American market. The mission of Dansk is to preserve its heritage, to revive many of the exceptional designs from its archives, and to collaborate with leading designers around the world to create new products that will someday be passed down from generation to generation.







ABOUT THE ROLE:

We're seeking an experienced Data Engineer to enhance our data platform and establish robust data engineering practices. You'll work with our existing data stack (DBT and Fivetran) to improve our data warehouse architecture while maintaining high standards for documentation and data quality.




IMPACT YOU’LL MAKE:

 * Improve and optimize our data warehouse design
 * Build expertise in our source systems to ensure optimal data pipeline design
 * Establish clear documentation and data engineering best practices
 * Design data models that serve both analytical and operational use cases efficiently







KEY RESPONSIBILITIES:

Data Warehouse Architecture:

 * Enhance and optimize our data warehouse architecture
 * Design scalable data models for current and future needs
 * Implement dimensional modeling best practices
 * Create efficient storage and partitioning strategies
 * Design data models optimized for both analytical queries and operational workloads
 * Implement appropriate indexing and materialization strategies

Source System Expertise:

 * Build strong technical knowledge of our key systems
 * Document data lineage from source to warehouse
 * Optimize data extraction patterns for each source
 * Understand both analytical and operational access patterns

Data Pipeline Development:

 * Design and implement robust DBT transformations
 * Configure and optimize Fivetran connectors
 * Create reliable testing and validation frameworks
 * Implement incremental processing strategies
 * Establish monitoring and alerting standards

Documentation & Engineering Practices:

 * Maintain comprehensive data dictionary and field-level definitions
 * Document system architecture and data flows
 * Implement automated documentation processes using DBT
 * Establish data quality standards
 * Follow and enhance engineering best practices




REQUIRED TECHNICAL SKILLS:

 * 5+ years of data engineering experience
 * Expert-level DBT knowledge
 * Advanced SQL and data modeling skills
 * Strong Python programming skills for data processing and automation
 * Experience with large-scale data warehouse architecture
 * Track record of clear technical documentation




ADDED DIFFERENTIATORS:

 * Experience with e-commerce systems and data models
 * Knowledge of dimensional modeling patterns
 * Experience with hybrid operational/analytical database design




COMPENSATION

For residents of CT, NJ or NY the compensation for this role is 150k.

This is an exempt role.

This role is eligible for a 10% bonus.




WORKING AT FOOD52

Food52 is committed to providing our team with a competitive benefits package. Some of our benefits include:

 * Health benefits (medical, dental, and vision)
 * Unlimited paid time off
 * Monthly fitness reimbursement
 * Citibike (NYC) or BikeTown (PDX) company-sponsored annual membership
 * Generous employee discount across our brand portfolio
 * 401K
 * FSA / HSA




EEO STATEMENT

Food52 is proud to be an equal opportunity workplace, providing equal employment and advancement opportunities to all team members. We value diversity and recruit, hire, and promote individuals solely based on talent, qualifications, competence, and merit. We evaluate candidates without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, veteran status, or other protected characteristics as required by law and as a matter of our company values.",Full-time
4125069341,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4065665156,92632994.0,Backend/Data Engineer,"As a Backend Engineer at Sweetspot, you will join a team dedicated to pushing the boundaries of LLM usage over disparate and unstructured data sources across United States federal and state governments. You will play a critical role in building and integrating data pipelines that feed directly into a framework built for the aforementioned. More broadly, you will join a team that is highly focused on building a product that bolsters the American economy and provides every business, regardless of size, the tools they need to secure government opportunities.

Please note that this is role is only open to US citizens.

Things You Should Know About Us


 * We work extensively with industry experts to build software that is useful for our clients. This means frequent customer calls and a constant level of iteration.
 * Talent density is far more important than team size. We want to hire the absolute best, and are willing to wait to find the right person.
 * If you’re early in your career and/or don’t come from a “prestigious” background, don’t be afraid to apply - we all went to a state school and don’t place a large emphasis on prestige.
 * Our office is in Newport/Jersey City.
   
   

What You’ll Do


 * Design, develop, and maintain scalable and efficient data pipelines to process and transform large volumes of data from disparate sources across the internet
 * Implement and optimize data pipelines using Python/SQLAlchemy and Dagster, ensuring high performance, reliability, and scalability
 * Work with PostgreSQL databases, including design, optimization, and troubleshooting
 * Collaborate with teammates to build and maintain software that can query hundreds of millions of vectors in a single request
 * Participate in code reviews, testing, and deployment processes to ensure code quality and maintainability
 * Monitor and troubleshoot data infrastructure to identify and resolve issues proactively
 * Stay up-to-date with industry trends and best practices in data engineering and incorporate them into your work
   
   

Requirements


 * Bachelor's degree in Computer Science, Engineering, or a related field
 * Strong proficiency in Python programming language
 * Solid experience with PostgreSQL databases, including writing efficient queries, performance tuning, and database administration
 * Familiarity with data pipeline frameworks such as Dagster, Airflow, Luigi, or similar
 * Knowledge of data processing and transformation techniques, including ETL processes
 * Experience with Git
 * Experience with Docker
 * Excellent problem-solving skills and ability to debug complex systems
 * Strong communication and collaboration skills, with the ability to work effectively in a team environment
 * US citizen
   
   

Preferred Qualifications


 * Experience with cloud platforms such as AWS, GCP, or Azure
 * Experience with data engineering best practices
 * Experience with FastAPI and asynchronous programming
 * Experience with SQLAlchemy
 * Experience with data warehousing and business intelligence tools
   
   

We offer a competitive salary, comprehensive benefits package, and opportunities for growth and development within a fast-paced and innovative company.

If you are passionate data engineering, have a strong foundation in software development, and are interested in contributing to the growth of the American economy, we would love to hear from you. Sweetspot Chat, Inc. is an equal opportunity employer and values diversity in the workplace. We encourage all qualified applicants to apply.",Full-time
4076510190,33246798.0,"Data Engineer, Data Application","Responsibilities

TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us

Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible.

Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day.

To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always.

At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.

Join us.

TikTok's immersive experience, global presence, and high engagement makes it the ideal marketing destination for business, big and small, to showcase their unique brand identity, connect with their consumers, and build strong lasting relationships over time. The Ads Data Team builds and manages the petabyte scale data infrastructure, batch/realtime pipelines and services to support Tiktok's global Ads business. We are committed to building a robust data foundation and scalable data applications, unblocking the full potential of advertising data to optimize advertiser experience, boost business growth, empower strategy execution.

We are looking for passionate Data Engineers that have strong problem solving skills to join forces with talented cross functional partners (business operation, data science, engineering and product management) to solve some of the most interesting data challenges with efficiency and quality. In this role, you will contribute to the company's core business across innovative advertising products, campaign management and measurement solutions. You will see a direct impact from your day-to-day work to customer satisfaction and company growth.

Responsibilities:


 * Work closely with Product Managers, Data Scientists/Analysts, and Software/Machine Learning Engineers and other stakeholders to understand data requirements and deliver data solutions that meet business needs.
 * Evaluate, implement and maintain data infrastructure tools and technologies to support efficient data processing, storage and query.
 * Design, build and optimize scalable data pipelines to ingest, process and transform large volumes of data.
 * Design and implement robust data models and visualization to support complex analytical queries and reporting requirements.
 * Ensure the data integrity, accuracy and consistency of data by implementing data quality checks, validation processes and monitoring mechanisms.
 * Continously optimize data pipelines, queries and processes to improve performance, reduce latency and enhance scalability.
 * Provide rapid response to SLA oncall support to business critical data pipelines.
 * Create and maintain good documentation for data assets and promote best practices for data governance within the data user community.
   
   

Qualifications

Qualifications:


 * Bachelor's degree in Computer Science, Engineering, or a related field.
 * Proven 1~3 years' experience as a Data Engineer or similar role in supporting data-centric business.
 * Strong knowledge of SQL and experience working with relational and non-relational databases.
 * Proficiency in programming languages such as Python, Java, Go etc.
 * Solid understanding of data modeling and data warehousing concepts, data integration and ETL/ELT techniques.
 * Effective communication skills and ability to collaborate effectively with cross-functional teams.
 * Excellent problem-solving skills, attention to detail, and ability to thrive in a fast-paced environment.
   
   

Preferred Qualifications:


 * Experience with big data technologies(e.g. Apache Hadoop, Spark, Kafka, Flink) and working with terabyte to petabyte scale data.
 * Experience with cloud data warehouses(eg. Snowflake, Databricks, BigQuery) and modern business intelligence/data stack.
 * Experience with data governance, data privacy and compliance.
 * Experience in the advertising, e-commerce or gaming industry.
   
   

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at https://shorturl.at/cdpT2

Job Information

【For Pay Transparency】Compensation Description (Annually)

The base salary range for this position in the selected city is $136800 - $205000 annually.

Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.

Benefits may vary depending on the nature of employment and the country work location. Employees have day one access to medical, dental, and vision insurance, a 401(k) savings plan with company match, paid parental leave, short-term and long-term disability coverage, life insurance, wellbeing benefits, among others. Employees also receive 10 paid holidays per year, 10 paid sick days per year and 17 days of Paid Personal Time (prorated upon hire with increasing accruals by tenure).

The Company reserves the right to modify or change these benefits programs at any time, with or without notice.

For Los Angeles County (unincorporated) Candidates:

Qualified applicants with arrest or conviction records will be considered for employment in accordance with all federal, state, and local laws including the Los Angeles County Fair Chance Ordinance for Employers and the California Fair Chance Act. Our company believes that criminal history may have a direct, adverse and negative relationship on the following job duties, potentially resulting in the withdrawal of the conditional offer of employment:


 * Interacting and occasionally having unsupervised contact with internal/external clients and/or colleagues;
 * Appropriately handling and managing confidential information including proprietary and trade secret information and access to information technology systems; and
 * Exercising sound judgment.",Full-time
4129673890,12953980.0,Cloud Data Engineer,"Company Summary:

PuppySpot is the leading puppy adoption service in America.




We combine our passion for puppies with a commitment to excellent service and delivering unconditional love in an empathetic, thoughtful, and expert way. Our team works closely with a national network of carefully vetted breeders to ensure that our customers can find their perfect puppy, and that the puppy arrives at their door ready to love and be loved.




Our culture is fun and focused on constantly improving our ability to serve and support each other, our customers, our breeder partners, and of course, our puppies. While we share a passion, we also embrace differences. In hiring we are an equal opportunity employer that considers all qualified applicants equally, without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status, or disability status.




We remain committed to staying the best in the business. We are the perfect puppy people.




*PuppySpot is a fully remote company. We allow employees to work from anywhere nationwide




We are seeking a skilled Cloud Data Engineer to manage our data pipelines, ensure data quality, and monitor our cloud-based data architecture. This person will be responsible for all components from ingestion through intermediate data modeling and will ensure that all ETL processes run as expected.




Key Responsibilities:

 * Oversee current architecture, including read replica RDS database, AWS Redshift cluster, and other AWS components
 * Monitor usage and storage
 * Troubleshoot and resolve issues
 * Identify scaling and cost savings options
 * Oversee orchestration and execution of data pipelines, including ingestion points
 * Operation and troubleshooting of read replica databases
 * Execution of Hevo ingestion
 * dbt model builds
 * Orchestration and coordination of dependencies
 * Ensure all best practices being followed with dbt
 * Owner of source and intermediate data warehouse models, modifying logic as necessary to accommodate upstream data changes
 * Serve as communication between engineering and data, ensuring that data requirements are submitted, all production data changes are approved of and accompanying data warehouse changes are accommodated
 * Maintain source and intermediate data definitions
 * Accommodate other data ingestion as necessary, leveraging various AWS services
 * Monitor data quality, creating alerts when volumes or distributions of data change; proactively research and resolve any issues




Skills & Experience Required:

 * 3-5 years of experience in data engineering, with a focus on cloud environments
 * Fluency in SQL and proficiency in Python
 * Experience configuring AWS, services including RDS, Redshift, and other related AWS data services
 * Hands-on experience orchestrating transformations using db
 * Strong understanding of data quality frameworks and best practices
 * Excellent problem-solving skills and attention to detail




Benefits/Perks:

 * Full medical, vision, and dental insurance
 * Pet insurance
 * 401(k) retirement savings plan with company match
 * PTO & paid holidays
 * Flexible spending account (FSA)
 * Network of complimentary employee discount programs
 * Financial wellness tools / Education and Health Support
 * Growth opportunities
 * Friends and Family Discount on any PuppySpot puppy




Think you have what it takes to be PuppySpot’s Cloud Data Engineer? Apply today with your resume and start making a difference in families’ lives by helping them find their perfect puppy.",Full-time
4005083923,46623.0,Data Engineer,"Description

Your role at GEI.

GEI Consultants has an opening in our Operational Development Team for a qualified Data Engineer to support a variety of systems and data engineering tasks focused on data flow activities. The majority of our systems are based in MS SQL Server, Tableau Server, Azure, and FastField Forms. This person will primarily work closely with members of the Operational Development Team and with members of our IT staff. The ideal candidate will be focused, detail-oriented, and driven to attain and maintain very high standards for efficiency and accuracy in data acquisition and integration into our systems. The ideal candidate will have more than 3 years of data engineering experience in the AEC industry or in similar science and/or engineering environments. GEI seeks a committed, self-motivated, organized and detail-oriented individual who anticipates issues and thrives on creative, independent problem solving within a rapid, deadline-driven environment.

Essential Responsibilities & Duties


 * ETL of data from a wide variety of sources
 * Database and Data Warehouse design/expansion/backup & recovery
 * Index management and optimization
 * Support data sources for Tableau Server, Power BI, and ArcGIS
 * Stored procedure development and maintenance
 * Identify new opportunities within GEI where existing business approaches to data can be replaced with a more efficient/automated data flow and presentation of data for analysis
 * Develop and optimize ETL/SSIS packages to facilitate data transfer between FTP, remote data loggers, Azure, and on-premises databases
 * Troubleshoot SSIS package permission issues related to execute-as/data source read/write access
 * SQL Agent Job development and monitoring
 * Develop data reporting and visualizations as specified by clients using Tableau, SSRS, etc
 * Perform DML and DDL via tsql/stored procedures executed directly within SSMS and remotely via SSIS
 * Develop test plans, implementation plans, and project timelines for various data engineering projects
 * Define, prioritize, communicate, and foster shared understanding of project objectives and scope
 * Coordinate the development of standard operating procedures (SOPs), technical training programs, and QA/QC procedures for staff and work product
 * Team with all staff necessary to complete assignments
 * Collaborate with technical team members to ensure the solution design satisfies project objectives and business requirements
 * Other duties as assigned
   
   

Minimum Qualifications


 * 3+ years of experience in a position performing similar data engineering tasks
 * Proven record of ability to design, manage, and support MS SQL Server and Azure databases
 * Ability to work with the following programming/mark-up/scripting languages preferred: VB.net, python, XML, javascript, and R
 * Bachelor's Degree, from an accredited college or university
 * MS SQL Server/Azure certification preferred
 * Ability to develop project plans and meet deadlines
 * Self-starter with attention to detail and stakeholder needs
 * Able to critically analyze and solve problems of a complex nature
 * Excellent Communication skills
 * Able to work on multiple projects of moderate complexity simultaneously and independently
 * Proficient in organization and time management skills
 * Familiarity with engineering, environmental science, and/or chemistry subject matter preferred.
 * Able to work effectively in GEI’s partnership model, including a team environment, building rapport and relationships.
   
   

We are GEI.

Some of the world’s most pressing problems - from climate change to sustainable development, to critical infrastructure and the future of our energy supply - need our brightest and diverse minds working together to create safer, more resilient communities for tomorrow.

We are technical experts, collaborators, and entrepreneurs who draw from diverse backgrounds to solve our clients’ most complex challenges.

With nearly 60 offices across North America, we offer a range of engineering, science, and technical consulting services. Our range of expertise, project types, and culture make us the choice for top talent in the AEC industry.

Employee-owned. Employee-focused.

As a 100% employee-owned company, our employees support our flat leadership structure, have a say in how our business operates and benefit from our financial success. We are committed to employee growth with career development opportunities, competitive total rewards, a well-being program, flexible work arrangements and more. Our company culture is driven by our 4 Cs - we are Client-Centered, Curious, Collaborative, and Community Minded - which support our focus on sustainability, safety, diversity, equity and inclusion. Get to know us better by visiting GEI’s career site here.

GEI’s Total Rewards Package


 * Market-Competitive Compensation, including Eligibility for an Annual Performance Bonus
 * Pay Range For This Position: $33.65-72.11/hour
 * Comprehensive Benefits Program, including Medical, Dental, Vision, Life, Disability and More
 * Well-Being Program and Paid Parental Leave
 * Commuter Benefits
 * Hybrid Work Schedules and Cell Phone Stipends
 * GEI University (GEIU) with Continuing Education Assistance and Tuition Reimbursement
 * Connecting Conversation Program with a Focus on Professional Development and Opportunities for Advancement
 * Support and Financial Rewards for Publication Awards, Professional Dues, and Professional Licenses
 * Paid Holidays and Generous Paid Time Off Program
 * Rewards and Recognition
 * GEI-Funded Profit Sharing and 401(k)
 * Opportunity to be an Owner and Shareholder (Learn more here)
 * A Vibrant Culture that is Focused on Partnership, Sustainability, Giving Back to Our Communities and Diversity, Equity and Inclusion
 * And More…
   
   

Physical Job Requirements

Sedentary

X

Light

Medium

Other

Activity Level Throughout Workday

Physical Activity Requirements

Occasional

(0-35% of day)

Frequent

(33-66% of day)

Continuous

(67-100% of day)

Not Applicable

Sitting

X

Standing

X

Walking

X

Climbing

X

Lifting (floor to waist level) (in pounds)

X

Lifting (waist level and above) (in pounds)

X

Carrying objects

X

Push/pull

X

Twisting

X

Bending

X

Reaching forward

X

Reaching overhead

X

Squat/kneel/crawl

X

Wrist position deviation

X

Pinching/fine motor skills

X

Keyboard use/repetitive motion

X

Taste or smell (taste=never)

X

Talk or hear

X

Accurate 20/40

Very Accurate 20/20

Not Applicable

Near Vision

X

Far Vision

X

Yes

No

Not Applicable

Color Vision (ability to identify and distinguish colors)

X

Sensory Requirements

Minimal

Moderate

Accurate

Not Applicable

Depth perception

X

Hearing

X

Environmental Requirements

Occupational Exposure Risk Potential

Reasonably Anticipated

Not Anticipated

Blood borne pathogens

X

Chemical

X

Airborne communicable diseases

X

Extreme temperatures

X

Radiation

X

Uneven surfaces or elevations

X

Extreme noise levels

X

Dust/particular matter

X

Other (exposure Risks)

Usual workday hours:

X

8

10

12

Other work hours

GEI is an AA/equal opportunity employer, including disabled and veterans.",Full-time
4045013672,96668235.0,Data Engineer,"Role: Data Engineer

Location: 3 days per week in Falls Church, Alexandria or Arlington, VA (any location is fine but must be 3 days onsite)

Duration: 1+ year Contract

Citizenship: Active Top Secret Clearance

Top Skills: Bachelors’ Degree and 7 years of experience or Masters Degree and 5 years, AWS Azure or MilCloud, ETL

Position Requirements

Experience with multi-intelligence and multi-domain systems.

Understanding of current object and activity-based models in the community.

Active TS clearance and ability to achieve a TS/SCI clearance with scope.

Required Education

Bachelor’s degree plus 7-10 years of experience, or a Master’s degree plus 5 years of experience.

Required Skills/Experience

Experience with Big Data systems and ETL processes.

Proficiency with AWS, Microsoft Azure, or MilCloud 2.0.

Applying DoD Security Technical Implementation Guides (STIGs) and automating the process.

Experience with multiple coding languages.

Major Duties/Tasks

Support configuration and ingestion of data repositories into capabilities that satisfy mission partner requirements.

Maintain operational aspects of data transfers while ensuring security posture.

Automate configuration management and stay current on ETL technologies and services.

Develop approaches to solutions independently and identify areas for optimization and cost reduction.

Engage with multiple functional groups to comprehend client challenges and prototype new ideas.

Identify and implement scalable and efficient coding solutions.

Thanks

Murali Sharma

Murali@nastechglobal.com

202-828-3494",Contract
4149604390,1586.0,Data Engineer Summer Internship – 2025 (CAN),"Description

Amazon internships are full-time positions, and interns should expect to work Monday-Friday, up to 40 hours per week typically between 8am-5pm. Specific team norms around working hours will be communicated by your manager. Interns should not have conflicts such as classes or other employment during the Amazon work-day. Applicants should have a minimum of one quarter/semester/trimester remaining in their studies after their internship concludes.

By applying to this position, your application will be considered for all Data Engineer roles at all locations we hire for in Canada including, but not limited to: Vancouver, BC; Toronto, ON, Winnipeg, MN, Victoria, BC, Ottawa, ON, Calgary, AB. Locations are subject to change.

You will be able to provide your preference of location and start date during the application process but, we cannot guarantee that we can meet your selection based on several factors including but not limited to the availability and business needs of this role. Finalization on the location and start dates available will be provided to you at the time of job offer.

Start dates for our internships in this posting include the following period:

Summer (Starts May/August 2025)

Do you love building data pipelines? Are you excited by the opportunity to design tools and infrastructure needed to analyze large volumes of data? Do you want to help solve big data warehousing problems, and partner with stakeholders to understand how to best design and implement cutting edge data solutions that provide answers to key business questions? Do you want to be a part of a fast-paced environment and contribute to one of the most visited sites on the Internet?

If this describes you, consider joining us as an as Amazon is looking for a data engineer intern to join one our many lines of business. Amazon interns have the opportunity to work alongside the industry’s brightest engineers who innovate every day on behalf of our customers. You will be matched to a manager and a mentor. You will have the opportunity to impact the evolution of Amazon technology as well as lead mission critical projects early in your career. Your work will contribute to solving some of the most complex technical challenges in the company.

Key job responsibilities

As a Data Engineer Intern, You Will/may


 * Design, implement, and automate deployment of our distributed system for collecting and processing log events from multiple sources.
 * Design data schema and operate internal data warehouses and SQL/NoSQL database systems.
 * Own the design, development, and maintenance of ongoing metrics, reports, analyses, and dashboards that engineers, analysts, and data scientists use to drive key business decisions.
 * Monitor and troubleshoot operational or data issues in the data pipelines.
 * Drive architectural plans and implementation for future data storage, reporting, and analytic solutions.
 * Develop code based automated data pipelines able to process millions of data points.
 * Improve database and data warehouse performance by tuning inefficient queries.
 * Work collaboratively with Business Analysts, Data Scientists, and other internal partners to identify opportunities/problems.
 * Provide assistance with troubleshooting, researching the root cause, and thoroughly resolving defects in the event of a problem.
   
   

A day in the life

In addition to working on an impactful project, you will have the opportunity to engage with Amazonians for both personal and professional development, expand your network, and participate in fun activities with other interns throughout the summer. No matter the location of your internship, we give you the tools to own your summer and learn in a real-world setting.

We’re on the lookout for the curious, those who think big and want to define the world of tomorrow.

At Amazon, you will grow into the high impact, visionary person you know you’re ready to be. Every day will be filled with exciting new challenges, developing new skills, and achieving personal growth.

How often can you say that your work changes the world? At Amazon, you’ll say it often. Join us and define tomorrow.

Basic Qualifications


 * Experience with database, data warehouse or data lake solutions
 * Experience with SQL
 * Experience with one or more scripting language (e.g., Python, KornShell, Scala)
 * Are 18 years of age or older
 * Work 40 hours/week minimum and commit to 12 week internship maximum
 * Experience with data transformation.
 * Currently enrolled in or will receive a Bachelor’s in Computer Science, Computer Engineering, Information Management, Information Systems, or an equivalent technical discipline with a conferral date between October 2025 – December 2028.
   
   

Preferred Qualifications


 * Knowledge of basics of designing and implementing a data schema like normalization, relational model vs dimensional model
 * Experience building data pipelines or automated ETL processes
 * Experience writing and optimizing SQL queries with large-scale, complex datasets
 * Experience with big data processing technology (e.g., Hadoop or ApacheSpark), data warehouse technical architecture, infrastructure components, ETL, and reporting/analytic tools and environments
 * Experience with data visualization software (e.g., AWS QuickSight or Tableau) or open-source project
 * Enrolled in a Master’s Degree or advanced technical degree with a conferral date between October 2025 – December 2028.
 * Previous technical internship(s), if applicable
 * Prior experience with AWS
 * Can articulate the basic differences between datatypes (e.g. JSON/NoSQL, relational)
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $43.85/hr in our lowest geographic market up to $88.94/hr in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com Services LLC - A57

Job ID: A2897395",Full-time
4141447077,60798.0,Software Database Engineer 4,"Job Description

Position Title: Software Database Engineer 4

Position Description: Protingent has an exciting contract opportunity for a Software Database Engineer 4 with our client located in Mountain View, CA. This is a remote role.

Job Responsibilities:


 * The main function of the Engineer is to design, collect, and process data within Azure. This role involves the development of data acquisition tooling and reporting to derive product insights and better align the product to its design specifications.
 * What makes this role interesting? - This role is aligned well: Client infrastructure, using client tool chain and working at the organization (not a lot of third-party tools).
 * The role itself is related to hardware and process capability and data analytics for real products
 * Unique Selling Points: Contributing to making hardware for augmented reality and improving it using a hardware engineering focused view of the program in all of the data that's required to do so.
 * Purpose of the Team: The purpose of this team is working with the Product Analytics team, which develops data collection and processing systems to improve the product capabilities.
 * Key projects: This role will contribute to working with multiple disparate datasets, coming from different teams and locations, and will be standing up secure services to optimize data consumption and analytics.
 * Typical task breakdown and operating rhythm: The role will consist of:
    * 20-30min Daily Team Sync
    * First: Coming up with diagrams for how the system is supposed to work
    * Second: Implementing it within the software tool and environment.
    * Depending on the day: C# or Python coding work that would be done to configure software functions or to set up automated processes.
    * Finally: Customer support issues, outages, new feature requests, more interrupt programming depending on what needs to be done.
    * Attend and contribute to daily team syncs.

 * Takes ownership of data analytics projects and drives adoption and insights to our data consumers.
 * Design, develop, document robust data flow processes.
 * Build and manage data pipelines using Azure Data Factory and Azure Synapse.
 * Monitor and optimize the performance of data systems to ensure they operate efficiently and securely.
 * Provide support for customer issues, outages, and new feature requests.
 * Collaborate with cross-functional teams to integrate disparate datasets into a common data view
 * Responsible for system health and monitoring and ETL development and support.
 * Contribute clear and accurate documentation and user guides to enable data consumers.
   
   

Job Qualifications:


 * Must Have 8-10+ Years of Experience with data pipeline development, ETL, data warehouse design, preference for experience in using Azure Synapse, Azure Data Factory, Azure SQL
 * Must Have 8-10+ Years of experience with a programming language, Python or C#
 * Must Have experience troubleshooting and resolving complex issues
 * Bachelor's degree in engineering is NOT required.
 * Strong ability to use Azure tooling to create data pipelines, security configurations, and automation. C# or Python coding work that would be done to configure Azure functions or to set up automated processes. Azure Synapse understanding would be necessary for ADF pipeline functions.
 * 4-5+ years of experience with Azure data infrastructure, including Azure Synapse, Azure Data Factory, and Azure SQL,
 * 8-10+ years of experience with file formatting (CSV, JSON, HTML) and data transport into SQL databases.
 * Experience with data interpretation layers: Azure Synapse, Azure security settings, Azure blob storage, Azure Function Apps, Azure SQL, Power BI, JMP
 * Experience with Microsoft synapse or Microsoft SQL Azure based tools
 * Strong analytical and problem-solving abilities.
 * Experience understanding and performing azure process optimization
 * Creativity, verbal and written communication skills, analytical and problem-solving ability.
 * Team player and detail oriented.
   
   
   

Job Details:


 * Job Type: Contract
 * Location: Remote (Highly preferred to have a candidate in Mountain View, California for a hybrid schedule (not required)).
 * Pay Range: $75/hr. to $102/hr.
 * An offer of employment is contingent on successfully passing a background check, and applicants who do not successfully pass a background check will not be considered for employment.
   
   
   

Benefits Package: Protingent offers competitive salaries, insurance plan options (HDHP plan or POS plan), education/certification reimbursement, pre-tax commuter benefits, Paid Time Off (PTO) and an administered 401k plan.

About Protingent: Protingent is a niche provider of top Engineering and IT talent to Software, Electronics, Medical Device, Telecom, and Aerospace companies nationwide. Protingent exists to make a positive impact and contribution to the lives of others as well as our community by providing relevant, rewarding, and exciting work opportunities for our candidates.",Contract
4132934747,11829683.0,Data Engineer,"Who are we?

Buyers Edge Platform stands at the forefront of revolutionizing the foodservice industry through technology, purchasing power and partnerships. We are dedicated to empowering stakeholders across the entire foodservice ecosystem (operators, distributors, manufacturers) with efficiency and unprecedented visibility. With a diverse portfolio of over a dozen brands, our mission is clear: to reduce costs, streamline the foodservice supply chain, and propel the industry from manual to automated.

Today, we are one of the largest players in foodservice, with over 200K operator locations across North America and over $50 billion of aggregated spend volume. Our commitment to foodservice excellence is proven in four distinct areas of value: Digital Procurement Network, Fresh Solutions, Supply Chain Management, and Software. Buyers Edge Platform is not just a provider – we are a strategic partner on the journey towards a more efficient, connected, and automated future for the foodservice industry.

This position is remotely based. We are unable to offer work sponsorship for this role.

The data engineering mission within BEP is to make our data quickly and easily accessible with highly performant, scalable, secure and cost-effective solutions. As a data and analytics company, it's important to ensure our clients and analysts can quickly get the information they need to make informed business decisions. Data Engineering allows developers to focus on creating product and features while experienced data engineers focus on the data required for those features.

Your impact:


 * Support and improve our existing data infrastructure
 * Create and modify ETL processes within the AWS Data Ecosystem
 * Collaborate with the DevOps team to create redeployable resources
 * Assist developers and analysts with data performance improvements
 * Responding in a timely manner to service issues and requests
 * Testing and proposing new technology to solve business problems
 * Occasional after-hours work
   
   

About you:


 * Expert with AWS data platforms and integrations, including Data Lakes, pyspark, Glue and Athens
 * Understanding of at least one scripting language such as Python, Golang, NodeJS or TypeScript
 * Basic understanding of an orchestrator tool such as Terraform or Cloud Formation.
 * Git version control
 * Experience with monitoring tools, APM, Logging and Infrastructure.
 * Solid understanding of RDMS schema and performance. MySQL, Amazon Aurora, and Postgres. MSSQL is a plus
 * Familiar with data warehousing technologies like Redshift and Snowflake
 * High level understanding of data storage systems including NoSQL, Time Series, Document and RDMS.
 * High level understanding of messaging queue and data streaming technology
 * Thorough understanding of Apache Hudi or Iceberg
 * Both written and oral effective communication skills
   
   

Don’t meet every requirement mentioned here? Studies have shown that women, communities of color and historically underrepresented talent are less likely to apply to jobs unless they meet every single qualification. At Buyers Edge Platform and our subsidiary brands, we are dedicated to building a diverse, inclusive and authentic workplace. So, if you’re excited about this role but your past experience doesn’t align perfectly with every qualification in the job description, we strongly encourage you to apply. You may be just the right candidate for this position or others with us!

What's in this for you?

Amazing coverages to start. Medical, dental, and vision coverages are just the beginning! We also offer ancillary plans, such as flexible spending accounts for both health and dependent care, critical illness, accident, and voluntary life as well as company paid life and long-term-disability plans! On top of this, we also offer a 401(k) plan with company match.

Invest in your success. We will provide you with a thorough training and development program; and offer competitive compensation.

Live well = Work well. Relax with our Personal Responsibility Paid Time Off policy where you don’t have to accrue time off in order to take it! We also offer half-day Summer Fridays!

We welcome all.

We are committed to creating a diverse environment and are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to actual or perceived race, color, creed, religion, national origin, ancestry, citizenship status, age, sex or gender (including pregnancy, childbirth and pregnancy-related conditions), gender identity or expression (including transgender status), sexual orientation, marital status, military service and veteran status, physical or mental disability, genetic information, or any other characteristic protected by applicable federal, state or local laws and ordinances.",Full-time
4147614611,2904.0,Data Engineer,"The Bronx District Attorney's Office in New York City serves a multicultural, international community of 1.4 million residents. Led by District Attorney Darcel D. Clark, the Bronx District Attorney's Office is one of the country's leading prosecutorial offices. The Office's mission of ""Pursuing Justice With Integrity"" captures its commitment to pursue a safer Bronx through fair justice.

BXDA's Strategic Planning and Analytics Unit serves as the internal management consulting arm of the Office. The unit uses cutting-edge data science and research analytics to support the Office's application of data-driven policies and practices. This unit is responsible for measuring office performance on prosecution indicators, evaluating the effects of policies and initiatives, conducting strategic analysis, and promoting transparency. The unit also manages the Office's grants, which provide critical funding to support prosecutorial practices and victims of crime in the Bronx.

The data engineer will be an integral member of our data analytics team working collaboratively with a diverse team of analysts and alongside information technology and justice system practitioners. This position demands strong SQL and data management skills to assist with the expansion and maintenance of workflows in a Microsoft Azure data analytics and reporting pipeline. This position offers an opportunity to apply strong technical and analytic abilities to inform the implementation of fair and objective public safety policies and procedures.

Job Responsibilities

Helping lead a system of reporting and analytic operations including database queries, updating and expanding stored procedures by leveraging programming languages (e.g., SQL, R, Azure data factory) to support reports and Power BI dashboards;

Develop, implement, and document data management procedures and standards to ensure data quality and accuracy in the Unit’s reporting;

Use advanced data transformation techniques (i.e., ETL) to standardize, check, clean, merge, and integrate disparate datasets from complex criminal justice databases;

Work closely with data analysts conducting quantitative data analysis and research or evaluation projects using a range of criminal justice administrative data sources;

Collaborate with members of the Information Technology Unit in support of the goals of the Strategic Planning & Analytics unit;

Help identify relevant data for measuring office performance and outcomes, and for use in statistical analysis to assess impacts and trends where accuracy is paramount;

Perform all other related duties and projects as assigned.

Qualifications

Minimum of a bachelor’s degree in computer science, Information Systems, Information Technology, Data Science, or a related field.

Minimum of four years of proven experience with SQL databases, ORACLE, XML, JSON or similar data systems a related; master’s degree may substitute for two years .

Experience using SQL, Azure Data Factory, SSIS, or similar database pipeline solutions.

Experience with data analysis programming languages such as R, SAS, PYTHON, Stata or similar.

Excellent interpersonal, organizational, and communication skills

Strong project management skills in a team-oriented environment

Strong analytic ability with knowledge of research and statistical analyses

Prefer knowledge of the criminal justice system and criminal justice databases

Ability to multi-task and meet deadlines.

COMMUNITY COORDINATOR - 56058

Minimum Qualifications


 * A baccalaureate degree from an accredited college and two years of experience in community work or community centered activities in an area related to the duties described above; or
 * High school graduation or equivalent and six years of experience in community work or community centered activities in an area related to the duties as described above; or
 * Education and/or experience which is equivalent to ""1"" or ""2"" above. However, all candidates must have at least one year of experience as described in ""1"" above.
   
   

Public Service Loan Forgiveness

As a prospective employee of the City of New York, you may be eligible for federal loan forgiveness programs and state repayment assistance programs. For more information, please visit the U.S. Department of Education’s website at https://studentaid.gov/pslf/

Residency Requirement

City Residency is not required for this position

Additional Information

The City of New York is an inclusive equal opportunity employer committed to recruiting and retaining a diverse workforce and providing a work environment that is free from discrimination and harassment based upon any legally protected status or protected characteristic, including but not limited to an individual's sex, race, color, ethnicity, national origin, age, religion, disability, sexual orientation, veteran status, gender identity, or pregnancy.

, $70,022.00 – $94,000.00",Full-time
4127832314,2550297.0,Data Engineer,"Job Summary:

We are seeking a highly skilled Data Engineer to join our team and play a critical role in designing, implementing, and maintaining robust ELT (Extract, Load, Transform) data pipelines. The ideal candidate will have a strong background in Snowflake data warehousing, ELT processes, and experience collaborating with stakeholders to optimize data solutions.

Key Responsibilities:

 * Design, implement, and maintain efficient ELT data pipelines to extract, load, and transform data into Snowflake.
 * Collaborate with stakeholders to gather and analyze data requirements, translating them into technical specifications.
 * Optimize and scale Snowflake environments for high performance, reliability, and scalability.
 * Develop and implement best practices for data modeling, performance tuning, and operational efficiency in Snowflake.
 * Ensure data quality and integrity across the pipelines and storage systems.
 * Stay updated with emerging data engineering technologies and suggest innovative solutions to improve existing processes.

Key Requirements:

 * Proven experience as a Data Engineer, preferably with Cisco experience.
 * Strong proficiency in ELT processes and related tools.
 * Extensive experience with Snowflake, including data modeling, query optimization, and performance tuning.
 * Hands-on experience with cloud platforms like Google Cloud (preferred).
 * Familiarity with data visualization tools such as Tableau or Power BI (a plus).
 * Excellent problem-solving and analytical skills.
 * Strong communication and collaboration skills, with the ability to work effectively in a team environment.

Preferred Qualifications:

 * Bachelor’s or Master’s degree in Computer Science, Information Systems, or a related field.
 * Experience with large-scale data systems and big data processing tools.
 * Knowledge of scripting languages like Python or SQL for data automation.

",Contract
4138897478,32150.0,Associate Data Engineer,"Denodo is a leader in data management. The award-winning Denodo Platform is the leading data integration, management, and delivery platform using a logical approach to enable self- service BI, data science, hybrid/multi-cloud data integration, and enterprise data services. Realizing more than 400% ROI and millions of dollars in benefits, Denodo’s large enterprise and mid-market customers across 30+ industries have received payback in less than 6 months. For more information, visit www.denodo.com .

We are a fast-growing, international organization with teams across four continents and we work with a cutting-edge technology, but that's not all we have to offer. At Denodo, we are like a family and it is of the utmost importance to us that we help support your professional growth every step of the way

Job Description

Denodo Technologies, Inc. is seeking an Associate Data Engineer in New York, NY to assist our clients and partners to realize their full potential through accelerated adoption and productive use of Denodo’s Data Virtualization capability to provide modern solutions for agile data delivery to empower people.

Salary Range: $90,000 to $155,000/yr.

Job Responsibilities & Duties


 * Assist our clients and partners to realize their full potential through accelerated adoption and productive use of Denodo’s Data Virtualization capability to provide modern solutions for agile data delivery to empower people.
 * Education, coaching and support during the introduction as well as ongoing projects of the Denodo Platform to achieve high level of client satisfaction.
 * Diagnose and resolve client’s inquiries related to operating Denodo software products in their environment.
 * Participate in problem escalation and call prevention projects to help clients and other technical specialists increase their efficiency when using Denodo products.
 * Contribute to knowledge management activities and promote best practices for project execution.
 * Implement product demos and pilots to showcase Data Virtualization in enterprise scenarios, cloud deployments and Big Data projects.
 * Provide timely, prioritized and complete customer-based feedback to Product Management, Sales, Support and/or Development regarding client’s business cases, requirements and issues.
   
   

Desired Skills & Experience


 * Bachelor’s Degree in Computer Science, Information Systems, or a related field (or foreign equivalent)
 * Demonstrated ability in SQL, relational and analytical database management, Java software development, JDBC, XML, Web Services APIs, and with version control systems.
   
   

Denodo is an equal opportunity employer and prohibits discrimination and harassment of any kind. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by applicable law. Denodo will provide reasonable accommodation to employees who have protected disabilities in accordance with applicable law.

We do not accept resumes from headhunters or suppliers that have not signed a formal fee agreement. Therefore, any resume received from an unapproved supplier will be considered unsolicited, and we will not be obligated to pay a referral fee.",Full-time
4033183105,71405910.0,Data Engineer,"Job Title: Data Engineer (US Citizen Only)

Location: Remote

We are currently seeking candidates who meet the following qualifications

Responsibilities


 * Design, develop, and maintain robust and scalable data pipelines for data ingestion, processing, and storage.
 * Collaborate with data scientists and analysts to understand data needs and implement solutions.
 * Work with structured and unstructured data from various internal and external data sources.
 * Optimize and manage data systems, ensuring data quality, integrity, and security.
 * Create and maintain ETL processes to automate data collection and integration from multiple sources.
 * Implement data solutions using modern technologies like Hadoop, Spark, Kafka, and cloud services (AWS, Azure, GCP).
 * Monitor and troubleshoot performance issues related to data processing and provide solutions for data efficiency.
 * Collaborate with cross-functional teams to implement best practices in data engineering and software development.
 * Document and maintain technical specifications, process flows, and data architectures.
   
   

Qualifications


 * Bachelor’s degree in Computer Science, Information Systems, Data Science, or a related field.
 * Experience in data engineering, software development, or related fields.
 * Proficiency with data processing technologies such as SQL, Python, Scala, or Java.
 * Experience with Big Data tools such as Hadoop, Spark, Kafka, or similar.
 * Strong knowledge of ETL frameworks and data pipeline orchestration tools like Apache Airflow or Luigi.
 * Experience in cloud services (AWS, Azure, Google Cloud) and cloud-based data warehouses (Redshift, BigQuery, Snowflake).
 * Experience with relational and NoSQL databases such as MySQL, PostgreSQL, MongoDB, Cassandra, etc.
 * Experience in data modeling, data warehousing, and OLAP principles.
 * Strong problem-solving skills with a focus on data performance and scalability.
 * Excellent communication skills and the ability to collaborate effectively with technical and non-technical teams.
   
   

Preferred Qualifications


 * Master’s degree in Computer Science, Data Engineering, or a related field.
 * Experience with containerization (Docker, Kubernetes) and CI/CD pipelines.
 * Experience in machine learning workflows and data integration for model training.
 * Certification in cloud platforms like AWS Certified Big Data or Google Professional Data Engineer.
 * Federal Experience is a plus.
 * Required Security clearance.
   
   

If you meet these qualifications, please submit your application via link provided in Linkedin.

Kindly do not call the general line to submit your application.",Full-time
4048255177,71405910.0,Data Engineer,"Job Title: Data Engineer (US Citizen Only)

Location: Remote

We are currently seeking candidates who meet the following qualifications

Responsibilities


 * Design and implement scalable data pipelines to ingest, process, and store data from various sources.
 * Collaborate with data scientists and analysts to understand data requirements and deliver clean, reliable datasets.
 * Optimize data models and architecture for performance and efficiency.
 * Monitor and troubleshoot data processing workflows, ensuring data quality and availability.
 * Implement data governance and security best practices.
 * Stay current with industry trends and emerging technologies in data engineering.
   
   

Qualifications


 * Bachelor’s degree in Computer Science, Engineering, or a related field.
 * Experience in data engineering or a related role.
 * Proficiency in SQL and experience with databases such as PostgreSQL, MySQL, or similar.
 * Experience with big data technologies (e.g., Hadoop, Spark, Kafka) and cloud platforms (e.g., AWS, Azure, GCP).
 * Strong programming skills in languages such as Python, Java, or Scala.
 * Experience with ETL processes and tools (e.g., Apache NiFi, Talend, Informatica).
 * Excellent problem-solving skills and attention to detail.
 * Strong communication skills and the ability to work collaboratively in a team environment.
 * Federal Experience is a plus.
 * Required Security clearance.
   
   

If you meet these qualifications, please submit your application via link provided in Linkedin.

Kindly do not call the general line to submit your application.",Full-time
4139348121,1353.0,Data Engineer,"Job Description

Data Engineer




• Strong experience in python and Java programming with working knowledge of micro-services architecture.

• Good experience Bigdata programming and Hadoop. Good understanding and knowledge of best practices for Hadoop, data modeling, data integration, data pipe-lining and data delivery.

• Good experience in Spark, need to be able to tune the spark jobs.

• Conduct code reviews to ensure adherence to quality standards.

• Experience with design, implementation and optimization of large-scale data and analytics solution

• Experience in building automated data pipelines and data stores including designing, implementing, testing, debugging, and deploying.

• Experience in building metadata driven solutions that are reusable and highly configurable.

• Experience in development of scripts using Unix, Python, etc for loading, extracting and transforming data.

• Experience in developing production-ready data ingestion and processing pipelines using Java, Spark, Scala, Python.

• Implement best practices for data engineering, including data modeling, performance optimization, and monitoring.

• Excellent communication and analytical skills.

• Proven experience as a technical lead or similar role in data engineering.

• Strong understanding of data warehousing and data architecture principles.

• Proficiency in SQL and other data manipulation languages.

• Experience in data visualization tools and data integration platforms.",Full-time
4133378315,72186786.0,Data Engineer,"About Us

Common Room is the customer intelligence platform that captures every buying signal, giving companies superpowers with AI enrichment and automation to reach the right person with the right context at the right time.

Despite an explosion of buyer signals, companies are left struggling with siloed point solution vendors, bloated tech stacks, and unactionable ""intent"" data. Common Room brings together all the buying signals you care about in one place so you can track the entire customer journey, match signals to real people and accounts, take action and automate.

We’ve raised over $50 million from top-tier investors including Greylock, Index, and Madrona to build the world's first customer intelligence platform for modern B2B companies. And we’re backed by 25+ operators from the fastest-growing companies in the world such as Figma, Stripe, Airtable, Slack, Notion, Loom, and more.

You + Common Room? You’d be joining a team that revels in asking hard questions, collaborating gladly, and making decisions quickly—a team that values simplicity, passion, trust, each other, and our customers above all.

So hello! Please, knock on our door. We'd love to meet you.

Why we need you:

Across our broad set of customer, we handle billions of events and user actions each day. You’ll have the enviable task of building efficient data pipelines that allows us to process this data for internal and customer use. You can build system to help transform this data so that customers can get insights about the impact Common Room has on their business, and also help Common Room extract product and business insights from this data. Your experience with ETL pipelines and data warehouses will help scale ours systems to keep up with our growth. You obsess about keeping things simple, efficient, and reliable. You’re a great collaborator and colleague. You strive to ensure that Common Room’s core internal capabilities, infrastructure, and systems continue to serve the needs of our customers and our team, often staying one step ahead of the product.

Outside of this, you also identify and participate in important company-building initiatives that a fast growing startup needs.

You would enjoy being a member of our team if you:


 * Have 5+ years of experience, with 2 years of experience with ETL pipelines and data warehouses.
 * You operate independently, but don’t hesitate to seek help and support from those around you to get your job done.
 * Revel in your craft, are excited by and capable of owning large projects primarily on the backend domain
 * Collaborate effectively with other experienced engineers, including application/front-end engineers
 * You have good judgement on tradeoffs and tools needed to solve the problem, and don’t over index on trendy/fashionable tech. You generally prefer supported, stable technologies
 * Use customer problems as input into designing systems, and find joy in creating simple, elegant solutions
 * Consider observability, SLA and scalability implications, but are able to avoid premature optimization
 * Feel at home with AWS, Postgres, and Node.js
 * Bring your authentic self to work, and engage in candid + respectful feedback
 * Build sustainably, and are capable of managing your time and priorities as best suits your needs
 * Enjoy the journey as much as the destination, but never lose sight of the destination
 * Demonstrate pride, ownership, and accountability for your work, and expect the same from those you work with
   
   

Our current tech stack:

We choose tools that help solve the problem at hand efficiently. For our current set of problems, we prefer to primarily use TypeScript with Node.js. We use TypeGraphQL for our API endpoints, Kafka for event processing, Apollo/Express as our web server, and Postgres (hosted on RDS) + ClickHouse as our database. We use React for front-end, and AWS for our infrastructure needs. We use Snowflake as our data warehouse.

Our values:


 * Be Customer-centric - We work backwards from the needs of our customers. The crisp articulation of customer value guides our decisions.
 * Strive for Simplicity - We choose simplicity over complexity whenever possible. We seek to identify and understand the essential quality of what we are building.
 * Make it Happen - We are quick to take the first step, and prioritize decisiveness over fear of making a mistake. We don’t confuse motion for movement and we measure ourselves on impact over actions.
 * We’re In this Together - We measure personal success by the success of our customers and teammates. Relationships matter, and the strongest ones are built on the foundations of trust, enablement, and transparency.
   
   

Our benefits:

Our investment in caring for our employees and their families is a key part of our values and culture at Common Room:


 * Competitive base compensation with meaningful equity ownership
 * Health insurance including medical, dental, and vision, HSA and FSA
 * We pay 100% of your employee premium and 50% of your premium for any dependents
 * Unlimited Paid Time Off
 * Paid Company Holidays
 * Work from home policy including a laptop and support for your home office needs
 * Monthly Remote Stipend
 * 401(k) self contribution
 * Paid Family Leave
 * Opportunity to join a diverse, passionate, and fun team at a pivotal time in the company’s lifecycle
   
   

Common Room provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

",Full-time
4138895694,32150.0,Data Engineer,"Denodo is a leader in data management. The award-winning Denodo Platform is the leading data integration, management, and delivery platform using a logical approach to enable self- service BI, data science, hybrid/multi-cloud data integration, and enterprise data services. Realizing more than 400% ROI and millions of dollars in benefits, Denodo’s large enterprise and mid-market customers across 30+ industries have received payback in less than 6 months. For more information, visit www.denodo.com .

We are a fast-growing, international organization with teams across four continents and we work with a cutting-edge technology, but that's not all we have to offer. At Denodo, we are like a family and it is of the utmost importance to us that we help support your professional growth every step of the way

Job Description

Denodo Technologies, Inc. is seeking a Data Engineer in New York, NY to obtain and maintain strong knowledge of the Denodo Platform, be able to deliver a superb technical pitch, including overview of our key and advanced features and benefits, services offerings, differentiation, and competitive positioning.

Salary Range: $120,000-170,000/yr.

Job Responsibilities & Duties


 * Obtain and maintain strong knowledge of the Denodo Platform, be able to deliver a superb technical pitch, including overview of our key and advanced features and benefits, services offerings, differentiation, and competitive positioning.
 * Constantly learn new things and maintain an overview of modern technologies.
 * Be able to address a majority of technical questions concerning customization, integration, enterprise architecture and general feature / functionality of our product.
 * Capable of building and/or leading the development of custom deployments based and beyond client’s requirements.
 * Provide timely, prioritized and complete customer-based feedback to Product Management, Sales, Support and/or Development regarding client’s business cases, requirements and issues.
 * Train and engage clients in the product architecture, configuration, and use of the Denodo Platform.
 * Promote knowledge and best practices while managing deliverables and client expectations.
 * Manage client expectations, establish credibility at all levels within the client and build problem-solving partnerships with the client, partners and colleagues.
 * Provide technical consulting, training and support.
 * Develop white papers, presentations, training materials or documentation on related topics.
   
   

Desired Skills & Experience


 * Bachelor’s Degree in Computer Science, Information Systems, or a related field (or foreign equivalent)
 * 2 years of experience as a Data Engineer, Systems Engineer, or similar role
 * Demonstrated ability in SQL, relational and analytical database management, Java software development, JDBC, XML, Web Services APIs, and with version control systems.
   
   

Denodo is an equal opportunity employer and prohibits discrimination and harassment of any kind. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by applicable law. Denodo will provide reasonable accommodation to employees who have protected disabilities in accordance with applicable law.

We do not accept resumes from headhunters or suppliers that have not signed a formal fee agreement. Therefore, any resume received from an unapproved supplier will be considered unsolicited, and we will not be obligated to pay a referral fee.",Full-time
4069931440,71405910.0,Data Engineer,"Job Title: Data Engineer (DBT) (US Citizens Only)

Location: Remote

We are currently seeking candidates who meet the following qualifications

Responsibilities


 * Design, develop, and maintain data models using DBT (Data Build Tool).
 * Create and optimize data pipelines and workflows to facilitate the transformation and loading of data.
 * Collaborate with analytics and BI teams to understand requirements and build solutions that support business objectives.
 * Implement best practices for data governance, quality, and scalability.
 * Ensure data integrity and accuracy through testing, validation, and performance monitoring.
 * Document data architecture, models, and processes to support future development.
 * Stay updated with industry trends and best practices in data engineering and DBT.
   
   

Requirements


 * Bachelor’s degree in Computer Science, Data Engineering, or a related field.
 * Experience in data engineering, with a focus on data modeling and transformation.
 * Strong experience with DBT and SQL-based data modeling.
 * Proficiency in working with cloud data warehouses such as Snowflake, BigQuery, or Redshift.
 * Experience with ETL/ELT pipelines and data integration processes.
 * Strong problem-solving skills and attention to detail.
 * Experience with Git for version control.
 * Federal Experience is a plus.
 * Required Security clearance.
   
   

If you meet these qualifications, please submit your application via link provided in Linkedin.

Kindly do not call the general line to submit your application.",Full-time
4076510269,33246798.0,"Data Engineer, Experimentation & Evaluation-TikTok Data Platform","Responsibilities

TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us

At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.

Team Introduction

Our mission in experimentation and evaluation team is to build the next-gen A/B testing platform, that empowers the company to make data-driven decision for the products. The supported scenarios include recommendation, push, ads, search, mobile app, UI interaction and service upgrades etc. Our platform's capabilities cover the entire experiment life cycle, from experiment design, experiment creation, metrics calculation, statistical analysis to final evaluation and launch. In the process of rapid iteration, we provide reliable services for businesses to make bold hypotheses and cautious verification.

As a data engineer in experimentation and evaluation team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world. You'll have the opportunity to gain hands-on experience on all kinds of systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users.


 * Design and build data transformations efficiently and reliably for different purposes (e.g. reporting, growth analysis, multi-dimensional analysis)
 * Design and implement reliable, scalable, robust and extensible big data systems that support core products and business
 * Establish solid design and best engineering practice for engineers as well as non-technical people
   
   

Qualifications


 * BS or MS degree in Computer Science or related technical field or equivalent practical experience
 * Experience in the Big Data technologies(Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc.)
 * Experience with performing data analysis, data ingestion and data integration
 * Solid communication and collaboration skills
   
   

Preferred Qualifications


 * Working industry experience with Big Data systems and projects
 * Experience in building large scale distributed systems in a product environment
 * Experience with ETL(Extraction, Transformation & Loading), architecting data systems, schema design, and data modeling
 * Experience in writing, analyzing and debugging SQL queries
 * Experience in data privacy and security related projects
   
   

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or an accommodation, please reach out to us at dennis.chau@tiktok.com.

Job Information

【For Pay Transparency】Compensation Description (Annually)

The base salary range for this position in the selected city is $136000 - $280000 annually.

Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.

Benefits may vary depending on the nature of employment and the country work location. Employees have day one access to medical, dental, and vision insurance, a 401(k) savings plan with company match, paid parental leave, short-term and long-term disability coverage, life insurance, wellbeing benefits, among others. Employees also receive 10 paid holidays per year, 10 paid sick days per year and 17 days of Paid Personal Time (prorated upon hire with increasing accruals by tenure).

The Company reserves the right to modify or change these benefits programs at any time, with or without notice.

For Los Angeles County (unincorporated) Candidates

Qualified applicants with arrest or conviction records will be considered for employment in accordance with all federal, state, and local laws including the Los Angeles County Fair Chance Ordinance for Employers and the California Fair Chance Act. Our company believes that criminal history may have a direct, adverse and negative relationship on the following job duties, potentially resulting in the withdrawal of the conditional offer of employment:


 * Interacting and occasionally having unsupervised contact with internal/external clients and/or colleagues;
 * Appropriately handling and managing confidential information including proprietary and trade secret information and access to information technology systems; and
 * Exercising sound judgment.",Full-time
3875372893,46623.0,Data Engineer,"Description

Your role at GEI.

GEI Consultants has an opening in our Operational Development Team for a qualified Data Engineer to support a variety of systems and data engineering tasks focused on data flow activities. The majority of our systems are based in MS SQL Server, Tableau Server, Azure, and FastField Forms. This person will primarily work closely with members of the Operational Development Team and with members of our IT staff. The ideal candidate will be focused, detail-oriented, and driven to attain and maintain very high standards for efficiency and accuracy in data acquisition and integration into our systems. The ideal candidate will have more than 3 years of data engineering experience in the AEC industry or in similar science and/or engineering environments. GEI seeks a committed, self-motivated, organized and detail-oriented individual who anticipates issues and thrives on creative, independent problem solving within a rapid, deadline-driven environment.

Essential Responsibilities & Duties


 * ETL of data from a wide variety of sources
 * Database and Data Warehouse design/expansion/backup & recovery
 * Index management and optimization
 * Support data sources for Tableau Server, Power BI, and ArcGIS
 * Stored procedure development and maintenance
 * Identify new opportunities within GEI where existing business approaches to data can be replaced with a more efficient/automated data flow and presentation of data for analysis
 * Develop and optimize ETL/SSIS packages to facilitate data transfer between FTP, remote data loggers, Azure, and on-premises databases
 * Troubleshoot SSIS package permission issues related to execute-as/data source read/write access
 * SQL Agent Job development and monitoring
 * Develop data reporting and visualizations as specified by clients using Tableau, SSRS, etc
 * Perform DML and DDL via tsql/stored procedures executed directly within SSMS and remotely via SSIS
 * Develop test plans, implementation plans, and project timelines for various data engineering projects
 * Define, prioritize, communicate, and foster shared understanding of project objectives and scope
 * Coordinate the development of standard operating procedures (SOPs), technical training programs, and QA/QC procedures for staff and work product
 * Team with all staff necessary to complete assignments
 * Collaborate with technical team members to ensure the solution design satisfies project objectives and business requirements
 * Other duties as assigned
   
   

Minimum Qualifications


 * 3+ years of experience in a position performing similar data engineering tasks
 * Proven record of ability to design, manage, and support MS SQL Server and Azure databases
 * Ability to work with the following programming/mark-up/scripting languages preferred: VB.net, python, XML, javascript, and R
 * Bachelor's Degree, from an accredited college or university
 * MS SQL Server/Azure certification preferred
 * Ability to develop project plans and meet deadlines
 * Self-starter with attention to detail and stakeholder needs
 * Able to critically analyze and solve problems of a complex nature
 * Excellent Communication skills
 * Able to work on multiple projects of moderate complexity simultaneously and independently
 * Proficient in organization and time management skills
 * Familiarity with engineering, environmental science, and/or chemistry subject matter preferred.
 * Able to work effectively in GEI’s partnership model, including a team environment, building rapport and relationships.
   
   

We are GEI.

Some of the world’s most pressing problems - from climate change to sustainable development, to critical infrastructure and the future of our energy supply - need our brightest and diverse minds working together to create safer, more resilient communities for tomorrow.

We are technical experts, collaborators, and entrepreneurs who draw from diverse backgrounds to solve our clients’ most complex challenges.

With nearly 60 offices across North America, we offer a range of engineering, science, and technical consulting services. Our range of expertise, project types, and culture make us the choice for top talent in the AEC industry.

Employee-owned. Employee-focused.

As a 100% employee-owned company, our employees support our flat leadership structure, have a say in how our business operates and benefit from our financial success. We are committed to employee growth with career development opportunities, competitive total rewards, a well-being program, flexible work arrangements and more. Our company culture is driven by our 4 Cs - we are Client-Centered, Curious, Collaborative, and Community Minded - which support our focus on sustainability, safety, diversity, equity and inclusion. Get to know us better by visiting GEI’s career site here.

GEI’s Total Rewards Package


 * Market-Competitive Compensation, including Eligibility for an Annual Performance Bonus
 * Pay Range For This Position: $33.65-72.11/hour
 * Comprehensive Benefits Program, including Medical, Dental, Vision, Life, Disability and More
 * Well-Being Program and Paid Parental Leave
 * Commuter Benefits
 * Hybrid Work Schedules and Cell Phone Stipends
 * GEI University (GEIU) with Continuing Education Assistance and Tuition Reimbursement
 * Connecting Conversation Program with a Focus on Professional Development and Opportunities for Advancement
 * Support and Financial Rewards for Publication Awards, Professional Dues, and Professional Licenses
 * Paid Holidays and Generous Paid Time Off Program
 * Rewards and Recognition
 * GEI-Funded Profit Sharing and 401(k)
 * Opportunity to be an Owner and Shareholder (Learn more here)
 * A Vibrant Culture that is Focused on Partnership, Sustainability, Giving Back to Our Communities and Diversity, Equity and Inclusion
 * And More…
   
   

Physical Job Requirements

Sedentary

X

Light

Medium

Other

Activity Level Throughout Workday

Physical Activity Requirements

Occasional

(0-35% of day)

Frequent

(33-66% of day)

Continuous

(67-100% of day)

Not Applicable

Sitting

X

Standing

X

Walking

X

Climbing

X

Lifting (floor to waist level) (in pounds)

X

Lifting (waist level and above) (in pounds)

X

Carrying objects

X

Push/pull

X

Twisting

X

Bending

X

Reaching forward

X

Reaching overhead

X

Squat/kneel/crawl

X

Wrist position deviation

X

Pinching/fine motor skills

X

Keyboard use/repetitive motion

X

Taste or smell (taste=never)

X

Talk or hear

X

Accurate 20/40

Very Accurate 20/20

Not Applicable

Near Vision

X

Far Vision

X

Yes

No

Not Applicable

Color Vision (ability to identify and distinguish colors)

X

Sensory Requirements

Minimal

Moderate

Accurate

Not Applicable

Depth perception

X

Hearing

X

Environmental Requirements

Occupational Exposure Risk Potential

Reasonably Anticipated

Not Anticipated

Blood borne pathogens

X

Chemical

X

Airborne communicable diseases

X

Extreme temperatures

X

Radiation

X

Uneven surfaces or elevations

X

Extreme noise levels

X

Dust/particular matter

X

Other (exposure Risks)

Usual workday hours:

X

8

10

12

Other work hours

GEI is an AA/equal opportunity employer, including disabled and veterans.",Full-time
4064935590,80517752.0,Software Engineer - Pretraining Data,"Magic’s mission is to build safe AGI that accelerates humanity’s progress on the world’s most important problems. We believe the most promising path to safe AGI lies in automating research and code generation to improve models and solve alignment more reliably than humans can alone. Our approach combines frontier-scale pre-training, domain-specific RL, ultra-long context, and inference-time compute to achieve this goal.

About the role:

As a Software Engineer working on our pretraining data, you write efficient and robust pipelines for giant, multimodal datasets. You will develop and optimize web scraping techniques to harvest and maintain data at internet-scale.

What you might work on:


 * Design & implement multimodal (video, audio, text etc) web crawlers for scraping and indexing petabytes of data
 * Create large scale data processing pipelines using tools like Ray, Apache Spark, Apache Flink, Google BigQuery etc.
 * Implement and scale deduplication techniques across modalities and apply heuristic and model-based techniques for parsing and filtering crawled data
 * Identify new data sources for inclusion in pre/post-training datasets
   
   

What we’re looking for:


 * Strong proficiency in distributed computing and parallel processing techniques
 * Obsession with details, reliability, and good testing to ensure data quality and integrity
 * Experience with designing and maintaining high-performance, scalable data architectures
 * Ability to design, develop and operate an LLM data pipeline from web scraping to data loading
   
   

Magic strives to be the place where high-potential individuals can do their best work. We value quick learning and grit just as much as skill and experience.

Our culture:


 * Integrity. Words and actions should be aligned
 * Hands-on. At Magic, everyone is building
 * Teamwork. We move as one team, not N individuals
 * Focus. Safely deploy AGI. Everything else is noise
 * Quality. Magic should feel like magic
   
   

Compensation, benefits and perks (US):


 * Annual salary range: $100K - $550K
 * Equity is a significant part of total compensation, in addition to salary
 * 401(k) plan with 6% salary matching
 * Generous health, dental and vision insurance for you and your dependents
 * Unlimited paid time off
 * Visa sponsorship and relocation stipend to bring you to SF, if possible
 * A small, fast-paced, highly focused team
   
   ",Full-time
4131890753,4854165.0,Data Engineer,"PLEASE READ BEFORE APPLYING:

 * Please do NOT apply if you are not already local or within 45 minutes of Cincinnati, OH (NO RELOCATION / NO REMOTE)
 * Due to the nature of the business and confidentiality, this position does require candidates to be US Citizens ONLY (NO Green Card, H1B, OTP, etc..)




Role: Data Engineers

Location: Hybrid- Cincinnati, OH

Duration: Six Months Contract

Eligibility: U.S. Citizen Only




Job Summary: We are seeking three skilled Data Engineer to join our Data Science team. The ideal candidate will be responsible for designing, building, and maintaining scalable data pipelines and infrastructure to support data analytics, machine learning, and Retrieval-Augmented Generation (RAG) type Large Language Model (LLM) workflows. This role requires a strong technical background, excellent problem-solving skills, and the ability to work collaboratively with data scientists, analysts, and other stakeholders.




Key Responsibilities:

Data Pipeline Development:

 * Design, develop, and maintain robust and scalable ETL (Extract, Transform, Load) processes.
 * Ensure data is collected, processed, and stored efficiently and accurately.

Data Integration:

 * Integrate data from various sources, including databases, APIs, and third-party data providers.
 * Ensure data consistency and integrity across different systems.

RAG Type LLM Workflows:

 * Develop and maintain data pipelines specifically tailored for Retrieval-Augmented Generation (RAG) type Large Language Model (LLM) workflows.
 * Ensure efficient data retrieval and augmentation processes to support LLM training and inference.
 * Collaborate with data scientists to optimize data pipelines for LLM performance and accuracy.

Semantic/Ontology Data Layers:

 * Develop and maintain semantic and ontology data layers to enhance data integration and retrieval.
 * Ensure data is semantically enriched to support advanced analytics and machine learning models.

Collaboration:

 * Work closely with data scientists, analysts, and other stakeholders to understand data requirements and deliver solutions.
 * Provide technical support and guidance on data-related issues.

Data Quality and Governance:

 * Implement data quality checks and validation processes to ensure data accuracy and reliability.
 * Adhere to data governance policies and best practices.

Performance Optimization:

 * Monitor and optimize the performance of data pipelines and infrastructure.
 * Troubleshoot and resolve data-related issues in a timely manner.

Support for Analysis:

 * Support short-term ad-hoc analysis by providing quick and reliable data access.
 * Contribute to longer-term goals by developing scalable and maintainable data solutions.

Documentation:

 * Maintain comprehensive documentation of data pipelines, processes, and infrastructure.
 * Ensure knowledge transfer and continuity within the team.




Education and Experience:

 * Bachelor’s or Master’s degree in Computer Science, Engineering, or a related field.
 * 3+ years of experience in data engineering or a related role.




Technical Skills:

 * Proficiency in Python (mandatory).
 * Experience with other programming languages such as Java or Scala is a plus.
 * Experience with SQL and NoSQL databases (e.g., MySQL, PostgreSQL, MongoDB).
 * Familiarity with big data technologies (e.g., Hadoop, Spark, Kafka).
 * Experience with cloud platforms (e.g., AWS, Azure, Google Cloud) and their data services.

RAG Type LLM Skills:

 * Experience with data pipelines for LLM workflows, including data retrieval and augmentation.
 * Familiarity with natural language processing (NLP) techniques and tools.
 * Understanding of LLM architectures and their data requirements.

Semantic/Ontology Data Layers:

 * Familiarity with semantic and ontology data layers and their application in data integration and retrieval.

Tools and Frameworks:

 * Experience with ETL tools and frameworks (e.g., Apache NiFi, Airflow, Talend).
 * Familiarity with data visualization tools (e.g., Tableau, Power BI) is a plus.

Soft Skills:

 * Strong analytical and problem-solving skills.
 * Excellent communication and collaboration abilities.
 * Ability to work in a fast-paced, dynamic environment.




Preferred Qualifications:

 * Experience with machine learning and data science workflows.
 * Knowledge of data governance and compliance standards.
 * Certification in cloud platforms or data engineering.

",Contract
4146501325,7412.0,SAP Data Engineer,"Summary

The AutoZone Data Management group seeks a System Engineer to join our team. This highly collaborative role will help AutoZone enhance its data engineering team and practice to onboard SAP-centric data into the data warehouse.

Working as a strategic business partner to cross-functional teams, this position will leverage your ability to work with a team of data engineers to quickly gain insights from quantitative and qualitative data to understand customers’ needs, and engagement opportunities.

The ideal candidate will possess knowledge of the SAP ecosystem and its integration capabilities, and how these can be leveraged to integrate with GCP.

Job Responsibilities

SAP Analytics professionals with expertise in designing, implementing, and deploying SAP Analytics solutions across Process Areas (Finance, Sales, and Procurement) including SAP S/4 HANA, SAP Datasphere, and SAP Analytics Cloud.

You have data integration experience in Datasphere from multiple SAP and Non-SAP source systems for both Federation as well as Replication scenarios.

Experience in SAP Datasphere implementation projects: architecting, designing, data model, Views, Analytical Models, replication flows and transformation flows.

Data Modeling, Story building, and Data visualization experience in SAP Analytics cloud.

Hands-on experience with building Core Data Services (CDS) views using ABAP development tools in Eclipse.

Experience with database development using Big Data/Cloud technology (AWS, Azure, Google BigQuery)

Position Skills And Requirements

5-7 years of SAP experience minimum

Bachelor’s degree in related IT field.

Experience using tools such as SAS, Google BigQuery, Dataflow, pub/sub, composer etc.

Proficient in Microsoft Office and Advanced skills in MS Excel

Strong communication, interpersonal, and organizational skills.

Strong understanding of data engineering practices.

Benefits At AutoZone

AutoZone cares about people. That’s why AutoZone offers thoughtful benefits programs designed to improve AutoZoners’ physical, mental and financial wellbeing. Some of these benefits include:


 * Competitive pay and time off
 * Unrivaled company culture
 * Medical, dental, vision, life, and short- and long-term disability insurance options
 * 401(k) with Company match and Stock Purchase Plan
 * Mental and physical wellbeing programs
 * Opportunities for career growth and tuition reimbursement
   
   

Eligibility and waiting period requirements may apply. Learn more about all that AutoZone has to offer on careers.autozone.com.

An ONLINE APPLICATION is REQUIRED. Click the Apply button to complete your application. For step-by-step instructions on how to apply visit careers.autozone.com/candidateresources",Full-time
4099248128,1586.0,"Data Engineer, Alexa","Description

This Data Engineering position is responsible for supporting the data pipelines & engineering needs for Alexa analytics and Machine Learning (ML) products. This Data Engineer will build and optimize logical data model and data pipelines for large, complex, datasets across a variety of Alexa analytics product(s), as well as be accountable for ongoing data quality, efficiency, testing, and maintenance. The Data Engineer should thrive and have demonstrated success in an environment which offers ambiguously defined problems, big challenges, and quick changes. They will influence large-size data solutions/access to dataset(s) within our team's architecture, advising product managers, program managers, and other engineers on trade-offs and courses of action.

We are looking for a passionate data engineer to optimize the consumption of these very large data sources we require to generate unique insights. As a data engineering leader within Alexa, we look to you for design, implementation, and successful delivery of large-scale, critical, or difficult data solutions involving a significant amount of work. You will share in the ownership of the technical vision and direction for advanced analytics and insight products. You will be a part of a team of top technical professionals developing complex systems at scale and with a focus on sustained operational excellence. Where needed, you integrate your team’s data solutions with those owned by other teams. You influence your team’s technical and business strategy by making insightful contributions to team priorities and overall data approach. You take the lead in identifying and solving ambiguous problems, architecture deficiencies, or areas where your team bottlenecks the innovations of other teams.

We are looking for people who are motivated by thinking big, moving fast, and changing the way customers use data to drive profitability. If you love to implement solutions to hard problems while working hard, having fun, and making history, this may be the opportunity for you.

The Data Engineer We Are Looking For


 * Has knowledge of recent advances in distributed systems (e.g. MapReduce, MPP architectures, and NoSQL databases). You are proficient in a broad range of data design approaches and know when it is appropriate to use them (and when it is not).
 * Knowledge of engineering and operational excellence best practices. Can make enhancements that improve data processes (e.g., data auditing solutions, management of manually maintained tables, automating, ad-hoc or manual operation steps).
 * Works with engineers to develop efficient data querying and modeling infrastructure.
 * Understands how to make appropriate data trade-offs. Can balance customer requirements with technology requirements. Knows when to re-use code. Is judicious about introducing dependencies.
 * Writing code that a Data Engineer or Software Development Engineer unfamiliar with the system can understand.
 * Can create coherent Logical Data Models that drive physical design.
 * Delivers pragmatic solutions. You do things with the proper level of complexity the first time (or at least minimize incidental complexity).
 * Understands how to be efficient with resource usage (e.g., system hardware, data storage, query optimization, AWS infrastructure etc.)
 * Collaboration with colleagues from multidisciplinary science, engineering and business backgrounds.
 * Communicate proposals and results in a clear manner backed by data and coupled with actionable conclusions to drive business decisions
   
   

About The Team

Our team owns a self-service analytics platform used by Alexa & AGI developers to identify trends in Alexa performance, assess customer impact, and troubleshoot failure patterns. Our customers include: scientists building and debugging ML models, analysts and researchers measuring the customer experience, developers troubleshooting defects and failures, and data teams building business reports and visualizing metrics.

Basic Qualifications


 * 3+ years of data engineering experience
 * Experience with data modeling, warehousing and building ETL pipelines
 * Knowledge of distributed systems as it pertains to data storage and computing
   
   

Preferred Qualifications


 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com Services LLC

Job ID: A2851356",Full-time
4138248188,4787585.0,"Senior Data Engineer, Ring Data Science and Engineering","Description

Come build the future of smart security with us. Are you interested in helping shape the future of devices and services designed to keep people close to what’s important?

About Ring

We started in a garage in 2012 when our founder asked a simple question: what if you could answer the front door from your phone? What if you could be there without needing to actually, you know, be there? After many late nights and endless tinkering, our first Video Doorbell was born.

That invention has grown into over a decade of groundbreaking products and next-level features. And at the core of all that, everything we’ve done and everything we’ve yet to build, is that same inventor's spirit and drive to bridge the distance between people and what they care about. Whatever it is, at Ring we’re committed to helping you be there for it.

(https://www.ring.com)

About The Role

The Senior Data Engineer within Ring Data Science and Engineering plays a pivotal role in shaping how we architect analytics and data science solutions to operate data-driven decision making at scale across all business units, carry the voice of our customers, inform business and product strategy with data, and provide a quality data foundation for AI.

Key job responsibilities

Role

We are seeking an experienced Senior Data Engineer to lead the technical designs of data lakes, data warehouses, and data pipelines within the Ring Data Science and Engineering org. In this role, you will:


 * Own the design, development, and maintenance of scalable solutions for ongoing metrics, reports, analyses, dashboards, etc. to support analytical and business needs
 * Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using AWS services and internal tools
 * Design efficient and scalable data warehouse models.
 * Be responsible for design and code reviews.
 * Build and deliver high quality data sets to support data scientists and customer reporting needs.
 * Identify opportunities to leverage AI for increased productivity.
 * Drive improvements in automation and quality.
 * Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers.
 * Find and create ways to measure the customer experience to drive business outcomes.
 * Recognize and adopt best practices in data engineering: integrity, design, analysis, validation, and documentation.
 * Troubleshoot operational quality issues.
 * Review and audit existing jobs and queries.
 * Recommend improvements to back-end sources for increased accuracy and simplicity.
   
   

A day in the life

You'll collaborate with multiple teams of data, business intelligence, software, and systems development engineers shaping our data strategy through vision setting, data governance, and operational excellence; fostering an inclusive culture that encourages empathy, experimentation, and innovation. You will guide your teams in balancing strategic thinking with company objectives, and collaborate with key cross-functional leaders and teams to work backwards from the customer to ideate, validate, and execute business opportunities at the forefront of the data engineering landscape. This will include overseeing the regular application of techniques involving extracting, transforming, and loading very large datasets, architecting data platforms for feature performance, maintainability, and scale, measuring and improving data quality, and driving measurable business impact.

Basic Qualifications


 * Bachelor's degree in computer science, engineering, analytics, mathematics, statistics, IT or equivalent
 * 5+ years of data engineering experience
 * Experience mentoring team members on best practices
 * Expert-level skills in writing and optimizing SQL
 * 2+ years development experience in python or similar scripting language for automation
 * 3-4+ years of work experience with ETL, Data Modeling, and Data Architecture with terabytes of data
 * 1+ years experience working with distributed computing and associated technologies such as Spark, EMR, etc.
 * 2+ years experience with Redshift. Tangible experience working with Redshift Spectrum, AWS Glue, and S3
   
   

Preferred Qualifications


 * Experience with big data technologies such as: Hadoop, Hive, Spark, EMR
 * Experience operating large data warehouses
 * 5+ years of work experience with ETL, Data Modeling, and Data Architecture.
 * Experience or familiarity with newer AWS data and analytics tools such as AWS Lake Formation, Sagemaker, DynamoDB, Lambda, Kinesis, ElasticSearch
 * 2-3+ years experience working with core AWS data and analytics services. Understand of the applicability, limitations, and tradeoffs between a wide set of AWS database and analytics technologies.
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Los Angeles County applicants: Job duties for this position include: work safely and cooperatively with other employees, supervisors, and staff; adhere to standards of excellence despite stressful conditions; communicate effectively and respectfully with employees, supervisors, and staff to ensure exceptional customer service; and follow all federal, state, and local laws and Company policies. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation. Pursuant to the Los Angeles County Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $139,100/year in our lowest geographic market up to $240,500/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com Services LLC

Job ID: A2869261",Full-time
3988611969,78445528.0,Data Engineer,"Job Title: Data Engineer

Skill Category: Data Engineering

Work Location: Grand Rapids, MI

Onsite/Remote: Hybrid

Hourly C2C Rate: $80/hr

Job Description: We are looking for a Data Engineer with over 6 years of industry experience in business application design, development, implementation, and solution architecture. The ideal candidate should have experience with Databricks and building and designing data and analytics on enterprise solutions such as:


 * Azure Data Factory
 * Azure Function App
 * Log Analytics
 * Databricks
 * Synapse
 * Power BI
 * ADLS Gen2
 * Logic Apps
   
   

Required Skills


 * Data Classification
 * Data Modeling
 * Data Architecture
 * Data Quality
 * Design
 * Network Components
 * Solution Architecture
 * Teamwork
 * Technical Training
 * .Net Core
 * Agile
 * C#
 * Data Warehouse
 * Infrastructure
 * Product Management
 * Functional Requirements
 * Interfaces
 * Research
 * Subsystems
 * Support
 * .Net
 * Python
 * Data Engineering
 * Data Analysis
 * Data Science
   
   

Responsibilities


 * Design, code, test, and implement data movement, dashboarding, and analytical assets.
 * Develop system documentation according to SAFe Agile principles and industry standards.
 * Evaluate architectural options and define the overall architecture of enterprise Data Lake and Data Warehouse.
 * Provide subject matter expertise and technical consulting support on vendor or internal applications and interfaces.
 * Develop Azure Function App using C# and .Net Core.
 * Define functional and non-functional requirements, including performance monitoring, alerting, and code management.
 * Partner with business areas to gather requirements for Data and Analytics and design solutions.
 * Define major elements and subsystems and their interfaces.
 * Mentor and coach team members.
 * Engage with ITS Security and Infrastructure teams to ensure secure development and deployment of solutions.
 * Interface with the Product Manager and IT partners to define and estimate features for agile teams.
 * Conduct industry research, facilitate new product and vendor evaluations, and assist in vendor selection.
   
   

Qualifications


 * 6+ years of industry experience in business application design, development, implementation, and solution architecture.
 * Experience with Azure Data Factory, Azure Function App, Log Analytics, Databricks, Synapse, Power BI, ADLS Gen2, and Logic Apps.
 * Databricks experience is required.
 * Experience designing data pipelines and implementing data quality, governance, and security compliance in Azure architecture.
 * Bachelor's degree in Computer Science, Computer Information Systems, Business Information Systems, Engineering, or related discipline or equivalent work experience and technical training.
 * Excellent written and oral communication skills.
 * Experience in Power BI, Data Modeling, Data Classification, Data Architecture, and reporting.
 * In-depth understanding of computer, storage, and network components, including backup, monitoring, and DR environment requirements.
 * Preferred knowledge and experience in Python and API architecture in Azure.
 * SAFe certification or training is a plus.
 * Experience with diverse technical configurations, technologies, and processing environments.
 * Exceptional interpersonal skills, including teamwork, facilitation, and negotiation.
   
   

Must Be Included With Submittal


 * Full Legal Name
 * Phone
 * Email
 * Current Location
 * Rate
 * Work Authorization
 * Willingness to Relocate
 * Confirmation that the candidate is or will be on your W2
   
   

Skills: technical training,design,functional requirements,data analysis,research,c#,python,.net,data classification,data,data warehouse,agile,interfaces,data quality,data engineering,data modeling,subsystems,data architecture,teamwork,support,.net core,infrastructure,network components,data science,azure,solution architecture,product management,power bi",Contract
4062571557,62869757.0,Data Engineer,"We are actively hiring for Data Engineer

Location: Union Beach, NJ OR Wilmington, DE (Hybrid)


 * Design and implement robust data pipelines using AWS services such as AWS Glue, Amazon Redshift, Amazon S3, and Amazon Kinesis.
 * Collaborate with data scientists, analysts, and business stakeholders to gather requirements and understand data needs.
 * Optimize and maintain existing data systems to ensure high performance, reliability, and scalability.
 * Monitor data quality and implement data validation and cleansing processes.
 * Create and maintain documentation for data architectures, workflows, and processes.
 * Stay updated on AWS technologies and industry best practices to drive continuous improvement in data engineering.
   
   

Qualifications


 * Bachelor’s degree in Computer Science, Information Technology, or a related field.
 * 5-6 years of Proven experience as a Data Engineer, particularly with AWS platforms.
 * Proficiency in AWS services, including AWS Glue, Amazon Redshift, and Amazon S3.
 * Strong programming skills in languages such as Python, SQL, or Java.
 * 2-3 Years of Experience with data modeling, ETL processes, and data warehousing concepts especially Snowflake.
 * Familiarity with cloud computing and data security best practices.
 * Excellent analytical and problem-solving skills with the ability to work effectively in a team environment.
   
   

Nice to have


 * Experience with big data technologies like Apache Spark or Apache Kafka.
 * Knowledge of data visualization tools (e.g., Tableau, Power BI) is a plus.
 * Understanding of DevOps practices and CI/CD pipelines. (edited)",Contract
4144720009,9385135.0,Data Engineer- 2989077,"Job Title: Data Engineer

Division: Manager, Software Development

Location: Washington D.C. (hybrid – 2 days onsite, 3 days WFH)

Salary: $110K - $120K + Bonus, Excellent Benefits!

Type: Full-Time / Permanent (Exempt)

Sponsorship / C2C: No

Referral Fee: $500

Job Description

The Data Engineer is responsible for designing, developing, and maintaining data pipelines for data consumption, analytics, and AI. This includes overseeing the data lifecycle, from ingestion to quality assurance. The Data Engineer is a member of product team and will collaborate with cross functional teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.

The Products and Services department is a data and technology organization responsible for leveraging data, artificial intelligence and cloud technologies to enable the organization to fulfill its mission to protect and strengthen the municipal bond market, enabling access to capital, economic growth, and societal progress in tens of thousands of communities across the country.

Essential Duties And Responsibilities


 * Maintain optimal data pipeline architecture.
 * Assemble structured, semi-structure and unstructured data sets to meet functional / non-functional business requirements.
 * Identify, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. DataOps and/or DevOps.
 * Contribute to the infrastructure required for optimal data extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data' technologies.
 * Utilize analytics tools that utilize the data pipeline to provide actionable insights into market insights and transparency, operational efficiency and other key business performance metrics.
 * Work with stakeholders including the Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
 * Keep data secure across regional boundaries through multiple data centers and AWS regions.
 * Create data tools for analytics and data scientist team members that assist in building and optimizing data products.
 * Support and deploy machine learning models to production.
 * Ensure data quality and consistency across various sources.
 * Other duties as assigned.
   
   

Education/Qualifications


 * 3-4years of experience in a Data Engineer role. Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
 * Experience optimizing ‘big data’ data pipelines, architectures and data sets.
 * Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
 * Experience working with structured datasets.
 * Experience working with unstructured data.
 * Build processes supporting data transformation, data structures, metadata, dependency and workload management.
 * A successful history of manipulating, processing and extracting value from large, disconnected datasets.
 * Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
 * Experience with AWS cloud services: S3, Athena, Aurora/Postgres, RDS, Redshift, Glue, Lambda, SQS, SNS
 * Experience with relational SQL and NoSQL databases, including Postgres and DynamoDB.
 * Experience with scripting languages: Python, R, etc.
 * Experience in debugging and performance tuning of spark jobs.
   
   

#dataengineer

#AWS

#postgres

#sql

",Full-time
4147570045,66321745.0,Junior Software Engineer,"SYNERGISTICIT is aware that the Job Market is Challenging because of Tech Layoffs due to which The Job market is flooded with hundreds and thousands of laid off Jobseekers who are competing with existing Jobseekers. For entry level Job seekers to get client interviews and jobs they need to differentiate themselves by ensuring they have exceptional skills and technologies to be noticed by clients.

Since 2010 we have helped Jobseekers differentiate themselves by providing the clients with candidates who have the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers. All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few. We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates looking to make their careers in IT Industry We welcome candidates with all visas and citizens to apply. We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

Candidates can benefit from skill enhancement if they fall into the below categories.

Candidates who Lack Experience or are freshers with No actual on Job experience with projects with clients Have had a break in careers Lack Technical Competency or skills being demanded by clients Different visa candidates (Like OPT/H4EAD/L2EAD ) who want to get employed and settle down in the USA please check the below links to see success outcomes of our candidates https://www.synergisticit.com/candidate-outcomes/

Synergisticit Pics /Salaries of Successful Candidates

Synergisticit at Oracle Cloudworld 2023

Synergisticit at Gartner Data & Analytics summit

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

REQUIRED SKILLS For Java /Software Programmers


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Project work on the skills
 * Knowledge of Core Java , javascript , C&plus;&plus; or software programming
 * Spring boot, Microservices, Docker, Jenkins and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Project work on the technologies needed
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, PowerBI, Time series analysis

Please understand skills and relevant experience on real world projects are required by clients for selection even if its Junior or entry level position the additional skills and Project work with hands on experience building projects at client site are the only way a candidate can be picked by clients. If not having the skills or hands on project work at client site then candidates can opt for skill enhancement to gain the required skills and project work. No third party candidates or c2c candidates

please only apply to the posting

No phone calls please. Shortlisted candidates would be reached out.",Full-time
4151306827,27179912.0,Senior Data Engineer,"About The Company

Our client is a multi-strategy hedge fund based in Denver, CO with over $3 billion in AUM. They are looking for an experienced Senior Data Engineer to join their growing Engineering team. This person will be leading and owning all things data. This is a unique opportunity to join a dynamic, technology-driven investment firm that provides a challenging and collaborative work environment. This opportunity will provide relocation compensation.

Responsibilities


 * Work closely with investment and technology professionals, designing, developing, and maintaining their data systems, while also building new
 * Develop, manage, and continuously improve technology infrastructure with a focus on database design
 * Contribute to driving the firm’s data platform vision
 * Work directly with research staff to clean, modify, and ensure data correctness
 * Understand current data governance policies and audit existing systems
   
   

Requirements


 * 5+ years of data engineering experience
 * Strong experience in software engineering or equivalent project/coursework
 * Proficient in data Extract-Transform-Load (ETL) processes
 * Proficient in database design, administration, migrations, SQL, RDMS
 * Programming capabilities with Python or other languages
 * Experience with cloud computing services, specifically AWS, AWS Glue, AWS RDS, and AWS Aurora
 * Experience in security best practices/data governance for software and data platforms
   
   

Pluses


 * Experience working in investment/hedge fund or financial services
 * Experience with GraphQL
 * Experience working with financial data sets, managing OneTick and Bloomberg
   
   

Salary Range

$100,000-$140,000

",Full-time
4132360072,16690.0,Data Engineer,"Job Overview:

We are seeking a skilled and motivated GCP Data Engineer to join our team supporting a leading telecom client. The ideal candidate will be responsible for designing, building, and maintaining scalable data pipelines and solutions using Google Cloud Platform (GCP) technologies. You will work closely with cross-functional teams to optimize data workflows, support analytics, and ensure the integrity of large datasets to drive insights and business decisions for our telecom client.




Key Responsibilities:

Design, implement, and manage data pipelines using Google Cloud Platform (GCP) tools such as BigQuery, Dataflow, Pub/Sub, Cloud Storage, and Composer.

Collaborate with data scientists, analysts, and business stakeholders to define data requirements, data models, and ETL processes for various telecom use cases.

Develop and maintain scalable and efficient data architectures to support high-volume, high-performance telecom data processing and analytics.

Integrate data from multiple sources (both on-premise and cloud-based systems) and ensure seamless data flow and synchronization.

Implement best practices for data governance, security, and compliance to protect sensitive telecom customer data.

Monitor data pipeline performance, troubleshoot issues, and optimize performance for cost-effectiveness and scalability.

Design and manage cloud infrastructure using GCP tools to automate deployment and configuration of data solutions.

Provide technical expertise in areas such as data transformation, data storage, and real-time data streaming, enabling data-driven decision-making within the telecom environment.

Assist with data migration from legacy systems to GCP and ensure smooth transition of data workloads.

Continuously evaluate emerging GCP technologies to improve and enhance the data engineering environment for telecom analytics.




Required Skills and Qualifications:

Bachelor's or Master's degree in Computer Science, Information Technology, or a related field.

Proven experience (3+ years) as a Data Engineer, with at least 2 years working with GCP.

Proficiency in Google Cloud Platform services such as BigQuery, Dataflow, Pub/Sub, Cloud Storage, and Composer.

Strong experience with SQL and NoSQL databases (e.g., BigQuery, Cloud SQL, etc.).

Experience with ETL tools and data pipeline orchestration.

Familiarity with programming languages such as Python, Java, or Scala for data processing.

Knowledge of data modeling, data warehousing, and data lakes.

Experience with real-time data processing and streaming (e.g., Apache Kafka, Cloud Pub/Sub).

Strong understanding of data security, privacy, and compliance in a cloud-based environment.

Familiarity with Agile methodologies and working in cross-functional teams.

Excellent communication skills and the ability to collaborate effectively with business stakeholders.




Preferred Skills:

Experience in the telecom industry or with telecom-specific data.

Certifications in Google Cloud Professional Data Engineer or related certifications.

Familiarity with tools like Apache Airflow for orchestration.

Experience with DevOps and automation tools for CI/CD in cloud environments.

Experience with machine learning and AI-based data pipelines is a plus.",Contract
4125206597,3684.0,Data Engineer,"Mastech Digital Inc. is a (certified) minority-owned business certified by NMSDC. Public traded firm under MHH at NYSE, Established in 1986. Headquartered in Pittsburgh, PA, our operations are spread across 11 global recruiting & sales offices across the US.




Role: Data Engineer

Location: Westlake TX

Duration: Full-Time




Job Description

Position Overview

We are seeking a skilled and experienced OBIEE to Power BI Migration Specialist to lead the migration of our business intelligence platform from Oracle Business Intelligence Enterprise Edition (OBIEE) to Microsoft Power BI. The ideal candidate will possess strong expertise in both OBIEE and Power BI, with a proven track record of successful BI platform migrations. This role involves assessing current OBIEE implementations, designing Power BI solutions, and ensuring a seamless transition while maintaining data accuracy and business continuity.

Key Responsibilities

 * Migration Planning and Execution:
 * Analyze existing OBIEE reports, dashboards, and data models to design equivalent or enhanced solutions in Power BI.
 * Create a detailed migration roadmap, outlining tasks, timelines, and dependencies.
 * Migrate and validate OBIEE data sources, metadata, and reports to Power BI while maintaining data integrity.
 * Power BI Development:
 * Design and develop Power BI reports, dashboards, and data models that align with business requirements.
 * Optimize Power BI solutions for performance and scalability.
 * Implement row-level security (RLS) and other security features to ensure appropriate data access.
 * Data Integration and Transformation:
 * Work with ETL tools and scripts to migrate data workflows from OBIEE to Power BI.
 * Ensure data consistency and accuracy across both platforms during the transition.
 * Stakeholder Collaboration:
 * Work closely with business stakeholders to gather requirements and ensure new Power BI solutions meet or exceed their expectations.
 * Provide training and documentation to end-users for the effective utilization of Power BI reports and dashboards.
 * Performance Monitoring and Optimization:
 * Monitor Power BI implementations to identify and resolve performance bottlenecks.
 * Regularly review and optimize reports and dashboards for usability and efficiency.
 * Quality Assurance:
 * Conduct comprehensive testing to validate the accuracy and functionality of migrated solutions.
 * Troubleshoot and resolve issues encountered during the migration process.

Required Skills and Qualifications:

 * Bachelor’s degree in Computer Science, Information Systems, or a related field.
 * 5+ years of experience in business intelligence, with a strong focus on OBIEE and Power BI.
 * Hands-on experience with OBIEE report development, data modeling, and metadata management.
 * Expertise in Power BI, including DAX, Power Query, data modeling, and report development.
 * Proficiency in ETL tools and processes for migrating data between systems.
 * Strong SQL skills and experience with relational databases like Oracle, SQL Server, or similar.
 * Excellent problem-solving and troubleshooting abilities, with attention to detail.
 * Strong communication and collaboration skills for working with technical teams and business stakeholders.

Preferred Qualifications:

 * Experience in migrating large-scale BI platforms from OBIEE to Power BI.
 * Knowledge of Azure Data Services, including Azure Data Factory and Azure Synapse Analytics.
 * Certification in Power BI or other relevant BI tools is a plus.
 * Familiarity with Agile methodologies and project management tools.

",Full-time
4143571018,5140.0,Data Engineer,"Data Engineering: Strong SQL, Apache Spark, Python, Hive, Iceberg, Big Data Ecosystem, Starburst/Trino, Airflow, Kafka

AWS Services related to data and analytics implementing Data Lakehouse solutions in AWS: S3, EC2, EMR, Glue Catalog, SQS, Elastic Kubernetes Service (EKS), Lambda Functions, Cloud Watch, IAM

CI/CD tools: JIRA/Github/Jenkins/Tekton/Harness

Knowledge in Terraform, CyberArk, Hashicorp Vault is a plus.",Full-time
4045409554,66321745.0,Data Engineer(Entry),"SynergisticIT is a full-service staffing and placement firm servicing client in America for the past 10 years. We are dedicated to fulfilling

the IT needs of our clients. From staffing to full implementation of projects we provide the highest quality IT Services. We do provide Java training

to candidates, who we think would fit a job requirement with one of our clients.

Who Should Apply

Candidates who have difficulty finding jobs even after completing their bachelor's and master's.

Candidates who are working on redundant technologies and want to become relevant again to boost their growth.

Candidates who want to enhance their skill portfolio.

Required Qualifications

Bachelors or Masters in Computer Science/MIS/IT.

Skills Required

Basic knowledge of C, C&plus;&plus;.

Benefits Of Working With Our Clients

E-Verified.

On Job Technical Support.

Interested candidates please send a word or PDF copy of your resume.

Regards,

Prakash G

Talent Acquisition Manager

Phone : (510)-989-4911

Email

Website : https://[www.synergisticit.com]www.synergisticit.com

39141 Civic Centre Dr, Fremont, CA

94539, United States",Full-time
4120830018,10667.0,"Data Engineer, Product Analytics","As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a world-class data engineering community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Data Engineer, Product Analytics Responsibilities:


 * Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems
 * Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve
 * Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way
 * Define and manage Service Level Agreements for all data sets in allocated areas of ownership
 * Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership
 * Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains
 * Solve our most challenging data integration problems, utilizing optimal Extract, Transform, Load (ETL) patterns, frameworks, query techniques, sourcing from structured and unstructured data sources
 * Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts
 * Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts
 * Influence product and cross-functional teams to identify data opportunities to drive impact
 * Mentor team members by giving/receiving actionable feedback
   
   

Minimum Qualifications:


 * Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent
 * 4+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions
 * 4+ years of experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.)
   
   

Preferred Qualifications:


 * Master's or Ph.D degree in a STEM field
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$145,000/year to $204,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4144101047,10378230.0,Data Engineer,"Chantilly, VA

TS/SCI with Poly

Bridge Core provides high energy, unified teams; technology integration experience; and innovative approaches, to enable our clients’ mission. We enable our clients’ mission by integrating innovative technologies and implementing adoption processes that modernize the digital workplace. Our trusted, skilled, and diverse team members are making a lasting impact by building tailored, client focused solutions.

Do you want to join a team that is building tailored technical solutions to modernize our government’s mission and our client’s business? Do you have a desire to change how people work? Are you interested in helping to protect our nation’s cyber interests? Join our growing team supporting the government agencies in its mission as a Data Engineer in Chantilly, VA.


 * Support data engineering, exploitation, and management processes.
 * Provide engineering support for data triage and assessment as directed by the Sponsor.
 * Provide direct support to data ingestion in support of requirements.
 * Document CONOPS, data workflows, and processes pertaining to data engineering projects as required by the Sponsor.
 * Identify new technologies and assess their technical and performance characteristics.
 * Identify and provide agile approaches to the automation of manual and inefficient processes.
 * Provide insight into industry trends and make recommendations on future direction for the program.
   
   
   

Required Qualifications


 * Active TS/SCI with required polygraph required to start
 * Bachelors degree or equivalent work experience in Computer Science or a related field
 * Demonstrated experience with large scale Elasticsearch 7.x cluster implementation, index design, and data ingest.
 * Demonstrated experience performing the various aspects of identity resolution at large scale, to include ingest of data, mapping of data, and integration of identity resolution capabilities into data engineer and systems workflows.
 * Demonstrated experience with distributed data pipeline / ETL technologies, including designing data flows and adapting the distributed ETL technology to accommodate new data types.
   
   
   

Desired Qualifications


 * Master’s Degree or equivalent work experience in Computer Science.
 * Demonstrated experience working with technologies in Hadoop ecosystems and integration of Hadoop capabilities into overall ETL flow of data.
 * Demonstrated, Sponsor-specific experience working with Apache Tika to extract metadata and text from various document types.
 * Demonstrated, Sponsor-specific experience as a Data Layer Architect focused on fusion of hybrid data sources into a common model to meet Sponsor needs.
 * Certifications AWS solution developer or AWS solution architect.
   
   
   

Bridge Core is proud to be an equal opportunity workplace and affirmative action employer. We celebrate diversity and are committed to creating an inclusive environment for all team members and applicants. At Bridge Core, we ensure fair treatment for our team members and applicants based on their abilities, achievements and experience without regard to race, national origin, sex, age, disability, veteran status, sexual orientation, gender identity or any other classification protected by law.

Bridge Core does not have a vaccination mandate applicable to team members. Vaccination requirements will depend on the status of the federal contractor mandate and customer site requirements. Regardless of vaccination status , personnel are required to wear masks while indoors when the CDC COVID-19 Community Level is High.",Full-time
4150173276,72055323.0,"AWS Data Engineer- Snowflake, PySpark &KafKa","Who We Are

Artmac Soft is a technology consulting and service-oriented IT company dedicated to providing innovative technology solutions and services to Customers.

Job Description

Job Title : AWS Data Engineer – Snowflake, PySpark & Kafka

Job Type : W2

Experience : 8 to 10 years

Location : Texas,Dallas

Responsibilities


 * 3+ years of experience in Data Engineering, Big Data, or Cloud Data Solutions
 * Experience with Airflow or similar workflow orchestration tools.
 * Knowledge of Terraform, CloudFormation, or other IaC tools.
 * Familiarity with machine learning pipelines and MLOps is a plus.
 * Experience with Apache Kafka for real-time data streaming and event-driven architectures.
 * Strong hands-on experience with AWS services such as AWS Glue, S3, Lambda, and Redshift.
 * Expertise in SQL and working with relational and NoSQL databases.
 * Proficiency in PySpark and Python for data processing and analytics.
 * Experience with Apache Kafka for real-time data streaming and event-driven architectures.
 * Hands-on experience with Snowflake, including data modeling, query optimization, and performance tuning.
 * Understanding of CI/CD pipelines, Infrastructure-as-Code (IaC), and DevOps in cloud environments.
 * Strong problem-solving and communication skills.
 * Design and implement data models and warehouse solutions in Snowflake for optimized analytics and reporting.
 * Integrate streaming and batch data sources using Kafka and other messaging technologies.
 * Work with cross-functional teams to ingest, clean, transform, and store structured and unstructured data.
 * Optimize performance, scalability, and reliability of data workflows on AWS cloud infrastructure.
 * Implement best practices for data security, governance, and compliance.
 * Monitor, debug, and improve data pipelines to ensure high availability and consistency.
   
   

Qualification


 * Bachelor's degree or equivalent combination of education and experience.",Full-time
4125061536,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4120824557,10667.0,"Data Engineer, Product Analytics","As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a world-class data engineering community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Data Engineer, Product Analytics Responsibilities:


 * Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems
 * Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve
 * Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way
 * Define and manage Service Level Agreements for all data sets in allocated areas of ownership
 * Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership
 * Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains
 * Solve our most challenging data integration problems, utilizing optimal Extract, Transform, Load (ETL) patterns, frameworks, query techniques, sourcing from structured and unstructured data sources
 * Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts
 * Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts
 * Influence product and cross-functional teams to identify data opportunities to drive impact
 * Mentor team members by giving/receiving actionable feedback
   
   

Minimum Qualifications:


 * Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent
 * 4+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions
 * 4+ years of experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.)
   
   

Preferred Qualifications:


 * Master's or Ph.D degree in a STEM field
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$145,000/year to $204,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4151649586,89247641.0,Senior Data Engineer,"Full-time Description

About Deep Sync

Deep Sync is the industry leader in deterministic identity. Leveraging our 35-year foundation of compiling direct mail-grade datasets, Deep Sync develops data-first technologies that power marketing, measurement, AI, and business intelligence for agencies and brands with our fully deterministic identity graph, privacy-first audiences, comprehensive data solutions, and integrations with leading platforms and cloud providers.

We are registered and set up to hire people in the following states: CA, CO, FL, GA, MO, NY, OR, SC, TN, TX, WA.

Hiring is remote for those outside of the Greater Seattle, WA and Fort Myers, FL areas.

Position Overview

We are seeking a Senior Data Engineer with a robust background in data engineering to join our team. The ideal candidate will be pivotal in designing, developing, and maintaining our data infrastructure. This role emphasizes not on building machine learning models but on integrating and deploying these models into our data pipelines to enhance our capabilities in advanced analytics and machine learning processes. The successful candidate will contribute expertise to improve and scale our data engineering practices, ensuring the seamless incorporation of machine learning models into our operational workflows.

Key Responsibilities

Data Pipeline Development:


 * Design, implement, and maintain scalable data pipelines to collect, process, and store data from various sources.
 * Ensure data quality, accuracy, and consistency throughout the pipeline.
   
   

Data Modeling Integration


 * Design and implement existing data models for predictive analytics, machine learning, and data exploration.
 * Optimize data structures and storage to support predictive analytics/machine learning processes.
   
   

Data Integration


 * Work closely with cross-functional teams to integrate data from diverse sources, including databases, APIs, and external data providers.
 * Develop and maintain ETL processes to transform and enrich raw data into actionable insights.
   
   

Performance Tuning


 * Monitor and optimize the performance of data pipelines and databases to meet business requirements.
 * Identify and resolve bottlenecks and performance issues.
   
   

Continuous Learning And Mentoring


 * Stay up-to-date with the latest advancements in data engineering and data science technologies.
 * Share knowledge and mentor junior team members.
   
   

Requirements

Experience


 * 5+ years experience in SQL Query Design, SQL Performance Tuning and Query Optimization
 * 5+ years of relevant experience in Data Warehouse Design, Data Warehouse Technical Architectures, Development and Implementation
 * 5+ years of relevant experience in ETL Development, ETL Implementation, Unit Testing, Troubleshooting and Support of ETL Processes
   
   

Knowledge And Skills


 * Proficiency in SQL Query Design and Implementation
 * Strong Experience with Relational Data Warehouse Systems
 * Data Warehouse Management Systems
 * Optimization by Indexing, Partitioning and Denormalization
 * Strong Ability to build and optimize data sets, ‘big data’ data pipelines and architecture
 * Programming skills in languages such as Python or C# required.
 * Strong analytical and problem-solving skills
   
   

Benefits


 * Paid Vacation Time and Paid Holidays
 * Medical/Vision/Dental Insurance, Voluntary Life & AD&D Insurance, Short-Term & Long-Term Disability, Critical Illness & Accident Insurance
 * 401(k) with employer matching
 * Hybrid/remote with flexible work schedule
   
   

Equal Opportunity Employer

Salary Description $130,000-150,000",Full-time
4138814402,162656.0,Data Engineer,"Data Engineer

W2 Contract-to-Hire

Salary Range: $156,000 - $176,800 per year

Location: Dublin, CA - Hybrid Role

Duties and Responsibilities:

 * Perform installation, patching, configuration, and maintenance of StreamSets on-prem runtime instances.
 * Provide L3 escalation support for existing production systems and assist with related enhancement activities.
 * Ensure proper testing and adherence to business change management practices and procedures.




Requirements and Qualifications:

 * Strong technical expertise in cloud applications, data ingestion, and data lake architecture
 * A StreamSets SME knowledgeable on the data landing needs into Snowflake for data analytics and reporting needs.
 * In-depth knowledge of StreamSets cloud and on-prem architecture, including environment configuration and deployment models
 * Hands-on experience and strong technical knowledge with Linux and Windows, authentication systems, networking, clustering, load balancers, Java, SSL, and certificates




Desired Skills and Experience

StreamSets, data ingestion, data lake, Snowflake, data analytics, reporting, cloud, on-prem, Linux, Windows, authentication, networking, clustering, load balancers, Java, SSL, certificates







Bayside Solutions, Inc. is not able to sponsor any candidates at this time. Additionally, candidates for this position must qualify as a W2 candidate.




Bayside Solutions, Inc. may collect your personal information during the position application process. Please reference Bayside Solutions, Inc.'s CCPA Privacy Policy at www.baysidesolutions.com.",Contract
4128397598,74615750.0,Data Engineer,"Who We Are

Imprint is building a next-generation co-branded credit card company to serve America’s great brands. Some of our partners include H-E-B, Turkish Airlines, Brooks Brothers, and Eddie Bauer. Imprint is backed by Khosla Ventures, Kleiner Perkins, and Thrive Capital. We are focused on building a brilliant team who want to change payments and who embody our Operating Principles.

The Team

The Data Analytics team at Imprint is dedicated to building a robust data foundation that drives smarter decision-making across the organization. The team is responsible for developing and maintaining Imprint’s data infrastructure, which includes not only the data warehouse and data pipelines but also comprehensive analytics systems that support both daily operations and strategic initiatives. By efficiently managing data flows, ensuring data quality, and optimizing performance, the Data Analytics team enables accessible, high-quality data that fuels insights into customer behavior, operational efficiency, and market trends. Leveraging these actionable insights, the team plays a crucial role in guiding Imprint's growth and profitability, empowering cross-functional teams to make well-informed, data-driven decisions.

Location

Our offices are located in New York City and San Francisco. This role will be able to work remotely or hybrid from one of our offices

What You'll Do

Build and Manage Data Pipelines


 * Create and maintain data pipelines to bring data from various sources into our systems, ensuring it’s clean, organized, and ready for use
 * Keep data flowing smoothly, making it available when needed by different teams
   
   

Support Data Modeling


 * Work with teams to design and maintain data structures for reporting and analysis
 * Ensure data is structured in a way that answers key business questions
   
   

Ensure Data Quality


 * Maintain data accuracy and integrity, quickly addressing any data issues
 * Monitor data processes and perform routine checks to ensure reliability
   
   

Optimize Data Storage


 * Design and manage cloud-based data storage solutions, optimizing for speed, accuracy, and cost-efficiency
 * Regularly improve the performance of our data systems
   
   

Collaborate Across Teams


 * Partner with data scientists, analysts, and other teams to understand their data needs.
 * Support others in accessing and effectively using data for their projects
   
   

What We Look For


 * 4+ years of experience working in data architecture, data pipeline, data warehouse modeling, master data management
 * Bonus points for Master’s degree in Computer Science, Engineering, Mathematics, Analytics or related field
 * Experience in scaling and optimizing schemas, data warehouse modeling in dbt, performance tuning SQL in Snowflake, data pipeline management in Airflow, working with AWS cloud platforms, manage code changes in Github, manage data infrastructure in Terraform, and understand CI/CD concepts
 * Advanced knowledge and extensive experience in SQL
 * Experience designing, developing, and maintaining large-scale and well-documented data marts to drive data insights
 * Excellent written and verbal communication and interpersonal skills, and ability to effectively collaborate with technical and business teams
   
   

Bonus Points


 * Experience in banking, financial services, credit card, fintech in a start-up environment
   
   

Perks & Benefits


 * Competitive compensation and equity packages
 * Leading configured work computers of your choice
 * Flexible paid time off policy
 * Fully covered, high-quality healthcare including fully covered dependent coverage
 * Additional health coverage includes access to One Medical and option to enroll in an FSA
 * 16 weeks of paid parental leave for the primary caregiver and 8 weeks for all new parents
 * An understanding that successful remote work requires flexibility and an appreciation for asynchronous work
 * Access to industry-leading technology across all of our business units — stemming from our philosophy that we should invest in resources for our team that foster innovation, optimization, and productivity
   
   

Imprint is committed to a diverse and inclusive workplace. Imprint is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. Imprint welcomes talented individuals from all backgrounds who want to build the future of payments and rewards. If you are passionate about FinTech and eager to grow, let’s move the world forward, together.",Full-time
4149011555,860823.0,Data Engineer,"Job Summary

As a Data Engineer, you will manage platforms, applications, and data associated with the job function, performing data migrations, automating data enrichment tasks, and developing system integrations across marketing, finance, sales, and relationship management systems. You will be expected to have expertise in relational databases, data mining and transformation, integration patterns, systems administration, reporting, risk management, and application security. Your role involves collaborating with and coaching team members to create effective, scalable solutions, making strategic decisions, implementing best practices, and ensuring projects are completed on schedule.

Essential Duties And Responsibilities


 * Maintain Windows and Linux servers running integration platforms and assist with compliance procedures.
 * Collaborate with solutions architects, project managers, business analysts, and developers to ensure proper strategy, design, and solutions are created.
 * Create supporting documentation for system integration, administration, and compliance tasks.
 * Assist with incident management and resolution for database and platform settings.
 * Stay up to date with novel integration capabilities and patterns.
 * Create maintainable, elegant code and high-quality data products that are well-documented and user-friendly.
 * Build, maintain, and improve the infrastructure for extracting, transforming, and loading data from various sources using SQL and Oracle technologies.
 * Design analytics tools to utilize the data pipeline to produce actionable insights.
 * Analyze business needs to create scalable solutions.
 * Identify methods to streamline processes and automate repetitive tasks.
 * Work with partners from different functional departments and lead projects.
 * Maintain security data across multiple data centers and regions.
   
   

Education/Experience/Skills

POSITION REQUIREMENTS AND CONDITIONS:

Education


 * Bachelor’s degree in computer science, engineering, information technology, or a related field, or comparable experience.
   
   

Required Skills And Experience


 * 5+ years of experience in creating distributed data pipelines for batch and real-time applications.
 * 4+ years of programming experience in R or Python.
 * 4+ years of experience with SQL; NoSQL experience is a plus.
 * 4+ years of experience in dimensional data modeling and schema design.
 * Expertise in integration development using ETL tools (e.g., Talend, MuleSoft, Informatica, SSIS).
 * Well-versed in a variety of transport and API protocols, including REST, GraphQL, and gRPC.
 * Knowledge of JSON, XML, SQL, and SOAP/REST-based online services.
 * Strong communication skills and ability to work in highly agile environments.
 * Proficiency with API Authentication and Authorization (OAuth, OpenID, Bearer).
 * Strong analytical and problem-solving skills.
 * Ability to work autonomously with little oversight.
 * Knowledge of integration development for sales and CRM technologies.
 * Experience in developing, managing, and designing data processing systems, including MapReduce or MPP systems.
 * Familiarity with constructing microservices using frameworks like Spring Boot.
   
   

Preferred Skills


 * Experience with Oracle Database and Oracle Fusion Cloud.
   
   

Physical Demands and Conditions

Requirements

The physical demands described below are representative of those that must be met by an employee to successfully perform the essential functions of this job. Some requirements may be modified to accommodate individuals with disabilities:


 * While performing the duties of this job, the employee is regularly required to sit; stand; and use the hands to handle, finger, or feel objects, tools or controls;
 * The employee must frequently walk, talk or hear, and reach with the hands and arms; occasionally, the employee must crouch or kneel;
 * The employee must occasionally exert or lift up to 15 pounds carrying boxes of records and forms and frequently exert or lift moderate amounts of weight;
 * Successful performance requires specific vision abilities that include close vision and the ability to adjust focus.
 * The job requires the ability to travel.
 * The work environment is that typical of an office and retail store. The noise level in the work environment is usually quiet.
   
   

IMPORTANT DISCLAIMER NOTICE

The job duties, elements, responsibilities, skills, functions, experience, educational factors, and the requirements and conditions listed in this job description are representative only and not exhaustive of the tasks that an employee may be required to perform. The Employer reserves the right to revise this job description at any time and to require employees to perform other tasks as circumstances or conditions of its business or the work environment change.",Full-time
4150543679,157240.0,Data Engineer,"Choosing Capgemini means choosing a company where you will be empowered to shape your career in the way you’d like, where you’ll be supported and inspired by a collaborative community of colleagues around the world, and where you’ll be able to reimagine what’s possible. Join us and help the world’s leading organizations unlock the value of technology and build a more sustainable, more inclusive world.

Job Description


 * 5-8+ years experience as a Data Engineer.
 * Strong analytical skills with the ability to collect organize analyze and disseminate significant amounts of information with attention to detail and accuracy.
 * Strong knowledge of SQL or other query languages.
 * Experience with SQL Server Oracle and Data Lake platforms.
 * Familiar with information and data modeling practices and standards across conceptual logical and physical levels
 * Familiar with database design and development methodologies.
 * Familiar with Data Definition Language (DDL) and Data Manipulation Language (DML) SQL commands
 * Experience developing and maintaining data dictionaries data catalogs and business glossaries.
 * Familiar with service-oriented and message-based data integration practices.
 * Highly organized with strong communication problem-solving documentation and presentation skills.
   
   

Life at Capgemini

Capgemini supports all aspects of your well-being throughout the changing stages of your life and career. For eligible employees, we offer:


 * Flexible work
 * Healthcare including dental, vision, mental health, and well-being programs
 * Financial well-being programs such as 401(k) and Employee Share Ownership Plan
 * Paid time off and paid holidays
 * Paid parental leave
 * Family building benefits like adoption assistance, surrogacy, and cryopreservation
 * Social well-being benefits like subsidized back-up child/elder care and tutoring
 * Mentoring, coaching and learning programs
 * Employee Resource Groups
 * Disaster Relief
   
   

Disclaimer

Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.

This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.

Capgemini is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to your recruiting contact.

Click the following link for more information on your rights as an Applicant http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law

Capgemini is a global business and technology transformation partner, helping organizations to accelerate their dual transition to a digital and sustainable world, while creating tangible impact for enterprises and society. It is a responsible and diverse group of 340,000 team members in more than 50 countries. With its strong over 55-year heritage, Capgemini is trusted by its clients to unlock the value of technology to address the entire breadth of their business needs. It delivers end-to-end services and solutions leveraging strengths from strategy and design to engineering, all fuelled by its market leading capabilities in AI, cloud and data, combined with its deep industry expertise and partner ecosystem. The Group reported 2023 global revenues of €22.5 billion.",Full-time
4151648318,6825144.0,Data Engineer,"List Of Key Responsibilities For The Position


 * Collaborate with stakeholders to understand business requirements and translate them into scalable data architecture solutions.
 * Design and develop data models, data warehouses, and data lakes to support the storage, integration, and analysis of large volumes of healthcare data.
 * Define data standards, policies, and procedures to ensure data quality, integrity, and security across the organization.
 * Implement data governance processes to manage metadata, data lineage, and data access controls.
 * Evaluate and select appropriate technologies and tools to support data architecture and analytics requirements.
 * Lead the implementation of data migration, transformation, and ETL processes to enable seamless data integration and interoperability.
 * Work closely with data engineers, data scientists, and other stakeholders to ensure alignment with business objectives and technical requirements.
 * Stay current with emerging trends and best practices in data architecture, healthcare analytics, and regulatory requirements in the medical insurance industry.
 * Provide technical leadership, guidance, and mentorship to junior team members.
   
   

Education

Required Qualifications:


 * Bachelor's degree in Computer Science, Information Systems, Data Science, or a related field.
 * A master’s degree or higher in Data Architecture, Data Science, Healthcare Informatics, or a related field is preferred.
   
   

Professional Experience


 * 9+ years of experience in data architecture, data modeling, and database design, including experience with large-scale systems in the healthcare domain.
 * 5+ years of experience working with healthcare data, specifically Medicare, Medicaid, or state healthcare programs.
 * Strong experience with data governance frameworks and healthcare regulatory standards, including HIPAA compliance.
   
   

Certifications (Preferred But Not Mandatory)


 * Certified Data Management Professional (CDMP).
 * AWS Certified Solutions Architect, Azure Data Engineer Associate, or similar cloud certifications.
 * Certified Information Systems Security Professional (CISSP) or other relevant security certifications.
 * Healthcare-related certifications (e.g., Certified Healthcare Data Analyst (CHDA)) are a plus.
   
   

Technical Skills


 * Proficiency with data modeling tools (e.g., Erwin, PowerDesigner).
 * Strong programming skills in SQL, Python, or other relevant languages.
 * Experience with data warehousing solutions (e.g., Snowflake, Redshift, Google BigQuery), ETL tools (e.g., Informatica, Talend), and cloud platforms (AWS, Azure, Google Cloud).
 * Deep knowledge of relational and NoSQL databases (e.g., MySQL, SQL Server, MongoDB).
   
   

Healthcare Expertise


 * Solid understanding of healthcare data structures, medical insurance systems, and regulatory compliance, including experience with claims data and clinical data sets.
 * Experience with healthcare analytics and data integration between different systems and providers.
   
   

Leadership & Communication


 * Proven ability to lead teams, provide technical guidance, and mentor junior staff.
 * Strong collaboration skills with cross-functional teams, including data engineers, scientists, and business stakeholders.
 * Excellent verbal and written communication skills to explain complex technical concepts to non-technical stakeholders.
   
   

Project Management Skills


 * Experience leading data migration, transformation, and integration projects in a healthcare setting.
 * Familiarity with Agile or other project management methodologies is a plus.
   
   

Regulatory Knowledge


 * In-depth understanding of healthcare regulations such as HIPAA, and familiarity with ensuring data privacy and security in compliance with industry standards.",Full-time
4143046926,16690.0,Data Engineer,"Data Engineer

Charlotte, NC- Hybrid




Need Senior Data Engineer with around 10 Years experience.







Mandatory: Python with Object oriented concepts, Spark, Problem-Solving ability, Effective communication

Good to have: AWS.




Detailed Job Description:

We are currently seeking a Senior Data Engineer with hands-on coding experience and a strong background in Python, PySpark, and Object-oriented programming. The ideal candidate will be responsible for designing, developing, and implementing new features to our existing framework using PySpark and Python. This position requires a deep understanding of data transformation and the ability to create standalone scripts based on given business logic.




Responsibilities:

1. Design, develop, and implement new features to our existing framework using PySpark and Python.

2. Write efficient and effective standalone scripts in PySpark with transformations as per the defined business logic.

3. Use your expertise in Python and Object-oriented concepts to solve complex problems and implement robust solutions.

4. Work closely with the team to understand the requirements and develop solutions that align with the company's objectives.

5. Test and debug code to ensure it produces the desired results.

6. Document all programming tasks and procedures for future reference and troubleshooting.




Qualifications:

1. Proficient in Python, PySpark, and Object-oriented programming concepts.

2. Proven experience as a Senior Data Engineer or similar role.

3. Strong problem-solving techniques with an ability to troubleshoot complex software issues.

4. Experience with AWS is preferred, but not mandatory.

5. Excellent communication skills, both written and verbal.

6. Self-motivated and able to work independently with minimal supervision.",Full-time
4151626407,10148384.0,Data Engineer,"Life at Healthy Alliance

At Healthy Alliance, our purpose is to improve health and empower the underserved. Every community has its own needs, affecting the health of those who live, learn, work, and play within them. Our network brings together organizations, big and small, to coordinate and collaborate so that all communities have reliable access to the resources they need. Why? Because every New Yorker deserves the same opportunity to be healthy.

Designated as the Social Care Network (SCN) Lead Entity for the Capital Region, Central NY, and North Country under New York’s 1115 Waiver Amendment’s SCN & Health-Related Social Needs (HRSN) Program, we are responsible for ensuring that there is a seamless, consistent end-to-end process for HRSN screening, navigation, and the delivery of HRSN and other services to thousands of Medicaid Members. Transformative in nature, this novel Program will further sustain our mission of advancing health equity within and across historically marginalized communities.

As a 2019-2024 Albany Business Review’s Best Places to Work and a 2021-2024 Modern Healthcare’s Best Places to Work in Health Care award recipient, we strive to maintain a culture wherein high-performing, mission-driven team members collectively work toward better health for all. Dedicated to promoting a culture built upon autonomy, mastery, and purpose, we believe our differences in strengths and perspectives play an integral role in propelling us forward, while our core values ground us, serving as the common thread that unites our team.

Why You Should Join Healthy Alliance

Benefits

We offer amenities, professional development opportunities, events, and programming that support the interests of our teams while expanding and enriching our culture. Some of the benefits you can expect when you join Healthy Alliance include:


 * Competitive compensation package
 * Comprehensive insurance benefits available the 1st of the month after hire, including but not limited to medical, dental and vision, group short-term disability and life insurance with buy-up options, flexible spending and HSA company-contributed accounts, and more
 * 401K with a company match
 * Unlimited paid time off after 90 days of employment
 * Company-sponsored training and certification opportunities
 * Remote employer with flexible work schedules
 * A workplace that values safety, respect, employee engagement, recognition, and diversity
 * Salary range: $101,000-$116,000 per year, commensurate with experience
   
   

Who You Are

The Data Engineer is responsible for ensuring that Healthy Alliance’s data is reliable, accessible, and effectively utilized by designing, building, and maintaining the infrastructure and data pipelines necessary for efficient data storage, transformation, accessibility, flow, and integration.

Requirements

What You’ll Do


 * Design and implement scalable data pipelines to integrate and process data from diverse sources.
 * Develop and optimize data warehouses and data lakes, ensuring efficient data flow and accessibility across the organization.
 * Implement data quality frameworks and automated data validation processes to ensure data integrity and reliability.
 * Develop and maintain robust error management practices, including error detection, logging, and resolution to ensure data accuracy and minimize data loss.
 * Manage file exchange processes, ensuring secure and efficient transfer of data files between internal and external systems, including handling various file formats and protocols.
 * Contribute to the adoption of modern data engineering practices, including real-time data processing and stream processing.
 * Collaborate with Data Analysts to support the implementation of machine learning models.
 * Implement data governance and security measures, ensuring compliance with HIPAA and other relevant regulations.
 * Optimize query performance and data access patterns for data analytics and reporting systems.
 * Design and implement data APIs and services to facilitate data integration across various applications and platforms.
 * Evaluate and integrate new data technologies to enhance Healthy Alliance's data engineering capabilities.
 * Contribute to the development of best practices and coding standards for the data engineering team and of data engineering initiatives that support Healthy Alliance's strategic goals and operational efficiency.
 * Work with business stakeholders to translate business requirements into effective data solutions.
 * Develop and maintain documentation for data architectures, models, and processes.
   
   

What You’ll Need

Education


 * Bachelor’s degree in computer science, information systems, data science, or a related field. Equivalent work experience in a related field may be considered in lieu of degree requirements.
   
   

Professional Work Experience


 * Minimum of 6+ years of experience in data engineering with a track record of implementing effective data solutions.
 * Experience in the health care or social care services industries is preferred.
   
   

Skills, Knowledge, And Abilities


 * Strong proficiency in SQL and experience with advanced database management systems.
 * Solid experience with big data technologies such as Apache Spark, Kafka, or Hadoop ecosystem tools.
 * Proficiency in Python, Scala, or Java with experience in developing data processing applications.
 * Experience with cloud platforms (preferably Azure) and their data services, including data lakes and data factories.
 * Good understanding of data modeling techniques, including dimensional modeling.
 * Experience in designing and implementing data streaming and processing solutions.
 * Knowledge of data governance principles and data lineage tracking.
 * Familiarity with containerization technologies (e.g., Docker) and orchestration platforms (e.g., Kubernetes).
 * Familiarity with data visualization tools (e.g., Power BI, Tableau) is beneficial.
 * Experience in designing data solutions that support analytics and machine learning workflows.
 * Knowledge of health care data standards (e.g., HL7, FHIR) and health care interoperability challenges.
 * Demonstrated ability to optimize data pipelines for performance and efficiency.
 * Experience in error management, including the detection, logging, and resolution of data errors.
 * Experience in file exchange management, including secure data file transfers and handling of various file formats and protocols.
 * Good communication skills, capable of explaining technical concepts to both technical and non-technical audiences.
 * Embody Healthy Alliance’s vision, mission, and goals.
 * Contribute to a positive work environment by demonstrating cultural expectations, rewarding performance, and valuing accountability, diversity and inclusion, flexibility, continuous improvement, collaboration, and creativity.
   
   

Your next career opportunity is at Healthy Alliance!

Physical Requirements

This position involves sedentary work that primarily involves sitting/standing, use of typical office equipment such as a computer, laptop, and cell phone. The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Equal Opportunity Employer

Healthy Alliance is an Equal Opportunity Employer and does not discriminate against any employee or applicant on the basis of age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We adhere to these principles in all aspects of employment, including recruitment, hiring, training, compensation, promotion, benefits, social and recreational programs, and discipline. If you require reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to hr@healthyalliance.org.

Privacy Requirement

This job function involves potential access / interaction with protected health information. Position will be required to abide by company policies and procedures that support federal, state, and local HIPAA regulations. Any violations will be subject to company policy which includes disciplinary actions up to and including separation of employment.

Healthy Alliance is an At-Will Employer.

Salary Description $101,000-$116,000",Full-time
4063504178,11197463.0,Data Engineer,"Job Description

DATA ENGINEER | $55-$65/HR | DURATION: 6+ MONTHS | REMOTE!

Our client, a developer-led custom software development consulting firm, is seeking an experienced data engineer to work on high value projects across diverse industries. This is an excellent opportunity for an experienced data engineer to contribute to the overall team goals and contribute to innovative, greenfield technology solutions.


 * Pay: $55-$65/hr, depending on level of experience
 * Start Date: ASAP
 * Contract to Hire
 * Location: Remote
   
   

Responsibilities


 * Serve as a subject matter expert, mentoring fellow engineers and leading small teams through complex programming and design challenges.
 * Apply strong analytical abilities, problem-solving skills, and communicate effectively with technical and non-technical stakeholders.
 * Operate effectively in a fast-paced technical environment, building and maintaining relationships with cross-functional teams.
 * Display a proactive, ""self-starter"" approach with the ability to make autonomous decisions.
   
   

Qualifications


 * 5-8 years of building and optimizing cloud-based, enterprise-level data pipelines, architectures, and datasets.
 * Proficiency with big data tools like Spark, Hadoop, and/or Kafka.
 * Experience with object-oriented programming languages such as Python, Java, or Scala.
 * Familiarity with cloud data warehousing technologies (e.g., Snowflake) and cloud platforms (AWS, Azure, and/or Google Cloud).
 * Must be authorized to work in the United States without sponsorship.
 * Bachelor’s or Master’s degree in Computer Science, IT, or a related field is preferred.
   
   

About PeopleCaddie

PeopleCaddie is a digital talent marketplace focused exclusively on contract opportunities for highly skilled business professionals. Our talent cloud utilizes proprietary data and technology to help contractors find attractive job opportunities through PeopleCaddie’s user-friendly mobile app while enjoying unparalleled visibility in pay rates and application status.

With an established array of clients nationwide, including Fortune 500 companies spanning multiple industries, PeopleCaddie has quickly become one of the fastest-growing talent clouds.

#PCIT #FinancialServices

",Contract
4096368429,1562578.0,Data Engineer,"Department: Information Technology

Reporting Structure: Reports to the Director of Data Science

Job Summary

Join our dynamic team at Atlantis University as a Data Engineer and play a key role in transforming data into actionable insights for our Education Management industry. You will be responsible for designing, implementing, and maintaining data pipelines, as well as optimizing data flow and collection for cross-functional teams.

Major Responsibilities


 * Develop and maintain scalable data pipelines
 * Collaborate with data scientists and analysts to understand data requirements
 * Implement data models and structures for efficient storage and retrieval
 * Optimize data flow and collection for improved accessibility and usability
 * Ensure data quality and integrity through data validation and testing
   
   

Qualifications


 * Bachelor's degree in Computer Science, Engineering, or related field
 * Proven experience as a Data Engineer or similar role
 * Strong proficiency in SQL, Python, and data warehousing technologies
 * Experience with ETL processes and tools
 * Knowledge of data modeling and database design principles
 * Excellent problem-solving and analytical skills
   
   

Skills


 * Strong communication and collaboration skills
 * Ability to work in a fast-paced and dynamic environment
 * Attention to detail and accuracy
 * Ability to prioritize and manage multiple tasks simultaneously",Full-time
4127756199,2499560.0,Data Engineer,"Job Title: Data Engineer with Data Analyst Experience

Location: Cleveland OH

Duration: Full-time

Domain: Banking




10+ Years’ experience working in Data Engineering and Data Analysis .

Hands on Experience in Hadoop Stack of Technologies ( Hadoop ,Spark, HBase, Hive , Pig , Sqoop, Scala ,Flume, HDFS , Map Reduce).

Hands on experience with Python & Kafka .

Good understanding of Database concepts , Data Design , Data Modeling and ETL.

Hands on in analyzing, designing, and coding ETL programs which involves Data pre-processing , Data Extraction , Data Ingestion , Data Quality ,Data Normalization & Data Loading.

Working experience in delivering projects in Agile Methodology and hands on in Jira.

Experience in Client Facing Roles with good communication & thought leadership skills to co-ordinate deliverables across the SDLC .

Good understanding of Machine Learning Models and Artificial Intelligence preferred.

Good understanding of Data Components , Data Processing & Data Analytics on AWS is good to have .

Experience with data modeling tools like Erwin is good to have.

Preferred Location : Cleveland or Pittsburgh.

Master's/Bachelor’s in computer science or equivalent fields",Full-time
4074706598,66321745.0,Data Engineer - Remote,"Are you passionate about coding or technology and ready to make your mark in tech? For more than 14 years, SynergisticIT has been helping aspiring developers like you excel in the tech industry. We focus on equipping you with the skills and experience needed to not only secure a job but to thrive in your career!

Why Partner with SynergisticIT?


 * Customized inputs to achieve the desired output : designed with industry needs in mind, ensuring you're equipped with the most sought-after skills.
 * Exclusive Opportunities: Our extensive network allows you to connect with leading tech firms.
 * Outstanding Outcomes: Many of our candidates land multiple job offers, often with starting salaries of $100k or more!
   
   

Synergisticit Pics /Salaries of Successful Candidates

Synergisticit at Oracle Cloudworld 2023

Synergisticit at Gartner Data & Analytics summit

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

Who Should Apply? We're looking for recent grads in Mathematics, Statistics , Computer Science or Engineering or candidates with gaps in their career or people wanting to switch careers into tech. SynergisticIT is committed to supporting your journey!

Preferred SKILLS For Java /Full Stack/Devops Positions

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Knowledge of Core Java , javascript , C++ or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

For data Science/Data Analyst/AI/Machine learning Positions

Preferred SKILLS

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude

Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools

Candidates lacking technical skills or relevant experience can research our Job Placement Programs which can assist in landing a Job

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates

Embrace Your Future! We also assist with F1 OPT to transition into H1B and Green Card byproviding comprehensive support. All positions are open to candidates of all visa types and US citizens.

Are you ready to make an impact?",Contract
4143964604,18476.0,Data Engineer,"Data Engineer

Contract

Remote




Position Purpose: Develops and operationalizes data pipelines to make data available for consumption (data streaming), including data ingestion, data transformation, data validation / quality, data pipeline optimization, and orchestration. Engages with the Lead Engineers and QA to enable continuous integration, testing and deployment of the Migration project.




Responsibilities:

 * Helps guide the design and implementation of complex data management procedures around data staging, data ingestion, data preparation, data provisioning, and data destruction (scripts, programs, automation, assisted by automation, etc.)
 * Provides guidance to engineers and QA in the design, development, implementation, testing, documenting, and operating of large-scale, high-volume, high-performance data structures for data streaming and analytics
 * Designs, develops, and maintains real-time processing applications and real-time data pipelines
 * Ensure quality of technical solutions as data moves across Centene’s environments
 * Provides knowledge and insight into the changing data environment, data processing, data storage, and utilization requirements for the company and drives the team toward viable solutions
 * Develops, constructs, tests, and maintains architectures using advanced programming language and tools
 * Drives ways to improve data reliability, efficiency, and quality and deploys a solution; use data to discover tasks that can be automated
 * Performs other duties as assigned
 * Complies with all policies and standards




Technical Skills:

 * 5+ years of experience in a data engineering
 * Advanced Python skills for data pipeline work
 * Experience with SQL
 * Experience or understanding of Kafka data streaming and Rest APIs
 * Experience with scheduling tools such as Active Batch, Control M, etc.
 * Experience with Big Data; Data Processing
 * Experience with Other: diagnosing system issues, engaging in data validation, and providing quality assurance testing
 * Experience with Data Manipulation; Data Mining
 * Experience working in a production cloud infrastructure",Contract
4024336959,82159342.0,Data Engineer - DeFi,"Career Renew is recruiting for one of its clients a Data Engineer - DeFi - candidates need to be based in PST to EST timezones.

We are the first automated, on-chain economic security system enabling crypto protocols to optimize risk management and capital efficiency while protecting user funds. We use world-class custom EVM simulations to understand protocol mechanics and scenario implications.

Leading protocols, including Aave, GMX, dYdX, Venus, Uniswap, and more, use our platform and tools to help them manage and secure billions of dollars in assets.

We seek candidates interested in delving deep into leading DeFi protocols and crafting data models and pipelines that fuel powerful risk analysis tools. The recommendations derived from these pipelines will be used by industry leaders to make key decisions and ensure the safety and stability of their protocols.

Collaboration is at the heart of our success. You'll work alongside a passionate team of researchers and developers, all dedicated to building a robust and efficient data platform that is already shaping the future of DeFi.

While prior experience with blockchain technology or DeFi protocols is a plus, it's not essential. What truly matters is your dedication to excellence and desire to learn the world of decentralized finance.

Requirements

4+ years of professional development experience (Typescript, Python)..

Experience working with data-oriented products.

Demonstrated experience working in self-managed, fast-paced environments.

Experience In DeFi Or Blockchain Technology Is Strongly Preferred.

Based between PST to EST timezones

Benefits


 * Medical, dental & vision insurance
 * Personalized professional development opportunities
 * Actual compensation is influenced by a wide array of factors including but not limited to skill set, level of experience, and specific office location. The range of pay for this role is $100,000 - $150,000",Full-time
4034573609,77685626.0,Data Engineer,"Job Title: Data Engineer

Location: Virginia (Local Candidates ONLY)

Job Type: Contract

Experience: 4+ years

NOTE: ONLY ON W2 Basis

Job Overview

We are seeking a highly skilled and detail-oriented Data Engineer to join our team in Virginia. The ideal candidate will have a passion for building robust data infrastructure, optimizing data pipelines, and ensuring data quality. As a Data Engineer, you will be responsible for designing, constructing, and maintaining scalable data systems and ensuring the smooth flow of data across the organization.

Key Responsibilities


 * Data Pipeline Development: Design, develop, and maintain efficient data pipelines to extract, transform, and load (ETL/ELT) data from various sources into the data warehouse.
 * Data Warehousing: Develop and optimize data warehouse architecture to support advanced analytics and business intelligence requirements.
 * Data Integration: Integrate structured and unstructured data from different databases, APIs, and data lakes, ensuring smooth and efficient data transfer.
 * Database Management: Work with relational (SQL) and non-relational (NoSQL) databases to manage and query large datasets efficiently.
 * Data Quality: Implement processes for data validation, cleansing, and monitoring to ensure high data quality and consistency.
 * Collaboration: Collaborate with data scientists, analysts, and software engineers to optimize data systems and support machine learning and analytics initiatives.
 * Performance Tuning: Optimize and tune data systems for performance and scalability, ensuring quick and accurate access to large datasets.
 * Automation: Automate routine data engineering tasks, such as database backups, data ingestion, and reporting processes.
 * Security: Ensure data security and compliance with relevant regulations and industry standards, implementing encryption and access control where necessary.
   
   

Required Skills And Experience


 * 4+ years of experience in data engineering, software development, or related fields.
 * Proven experience with SQL and NoSQL databases (e.g., MySQL, PostgreSQL, MongoDB, Cassandra).
 * Experience with data pipeline tools such as Apache Airflow, AWS Glue, Talend, or similar.
 * Proficiency in programming languages such as Python, Java, or Scala.
 * Hands-on experience with cloud platforms such as AWS, Azure, or Google Cloud for data storage and processing.
 * Experience with ETL/ELT processes and tools like Apache Nifi, Apache Spark, or similar.
 * Familiarity with big data technologies (e.g., Hadoop, Hive, Spark) is a plus.
 * Strong problem-solving skills, with an ability to analyze complex data engineering challenges and implement effective solutions.
 * Experience in data modeling and data architecture design.
 * Knowledge of data governance, security, and compliance standards.
 * Strong communication skills and the ability to work in a collaborative team environment.
   
   

Preferred Qualifications


 * Experience with machine learning pipelines and supporting data scientists with feature engineering.
 * Familiarity with streaming data platforms such as Apache Kafka or Kinesis.
 * Certification in cloud platforms (AWS Certified Data Analytics, Google Cloud Data Engineer, etc.) is a plus.
 * Experience with CI/CD pipelines for data engineering workflows.
 * Experience with data visualization tools such as Tableau, Power BI, or Looker.
   
   

Education


 * Bachelor’s or Master’s degree in Computer Science, Engineering, Data Science, or a related field.",Full-time
4125060228,27116538.0,Data Engineer,"Position Description: We are seeking a highly skilled and motivated Data Engineer to join our dynamic team. The ideal candidate will be responsible for performing data mapping, data quality management, metadata management, and master data management, as well as conducting in-depth data analysis to inform and progress our current and future data operating models. The Data Engineer will play a critical role in shaping our data architecture and ensuring the integrity and quality of our data assets.


 * Develop, maintain, optimize, and document SQL queries for data analysis and reporting tasks to ensure, reuse and meet stakeholder needs.
 * Identify and fix data issues (e.g., missing values, outliers, duplicates, inconsistencies) by developing and executing Oracle DML statements, and clean and preprocess raw data for accuracy and consistency.
 * Using Excel and SQL to prepare, analyze, and transform data; conduct statistical analyses; and create visual reports to highlight trends and insights.
 * Communicate findings and insights clearly to both non-technical and technical stakeholders using tools such as Excel, Word, PowerPoint, and Visio.
 * Continuously monitor and implement data validation checks, manage data quality, metadata, and master data, and perform data mapping and analysis. Document findings, provide recommendations, and develop data architecture artifacts to enhance current and future data operating models.
 * Leverage AWS services (e.g., S3, RDS, Lambda) to manage, store, and process large datasets, ensuring data security and compliance with best practices.
 * Monitor and manage data storage costs in AWS, ensuring efficient use of resources and scalability of the database environment.
   
   

Salary Range: 100k-125k - Commensurate with the candidate's skills, experience, location, and qualifications.Required Qualifications:


 * Clearance: Active US DoD Top Secret security clearance or higher.
 * Associate/bachelor's degree with 3+ years of relevant experience
 * Proficiency in Excel, Visio, and Oracle SQL Developer.
 * Experience performing the tasks identified above in AWS and Oracle environments.
 * Strong expertise in data analysis, data architecture, and data services development.
 * Ability to work independently and as part of a team, effectively collaborating with various stakeholders.
 * Advanced analytical and troubleshooting skills with good problem-solving abilities.
 * Experience working with and supporting Agile development teams.
 * Excellent written and verbal communication skills
   
   

Preferred Qualifications:


 * Experience with data visualization tools (e.g., Tableau, Power BI, or Pentaho Report Designer) is a plus.
 * Knowledge of data governance and data management best practices is also a plus.
 * Security+ Certification, preferred
   
   

ThinkTek offers telework and other flexible work arrangements to the greatest extent possible. ThinkTek LLC is proud to be an Equal Opportunity Employer (EOE), making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. ThinkTek offers medical, dental, and vision insurance to all full-time employees; PTO and a variety of other paid leave options are also available. You can read more about ThinkTek benefits at https://www.thinktekllc.com/careers/.",Full-time
4144364300,16167788.0,Data Engineer,"Overview

Job Description

Important: This is a hybrid role working at least 2 days per week in the Atlanta, GA, or Southfield, MI office.

How You’ll Make An Impact

Epsilon is seeking a Data Engineer to join our growing data science team and assist with the telecommunication clients that we serve. Your role is to interpret the business logic required to turn a complex idea into a sustainable value-added process and ensure the data is usable and viable with near real-time reporting, delivering solutions to the problems presented. This role reports to the Senior Director, Analytics.

We didn’t become an industry leader through corporate stagnation. We’re constantly changing, and we love working with people who share our adaptability and thirst for knowledge. With new ideas flying around, we thrive on a collaborative spirit. If you want to work for a company that encourages advancement, then come join us!

What You’ll Achieve

Impact: You will design and deploy the data warehousing system to support day-to-day operations and reporting. You will also conduct preliminary testing of data sources and the data warehouse environment before extracting and loading data into the systems.

Career Growth: If successful, the Data Engineer may gain exposure to other clients where you can make the most impact. Also, you may have an opportunity to level up to a Senior Data Engineer helping to mentor more junior data engineers/ analysts and hone your leadership skills.

Who You Are


 * What you’ll bring with you:
    * Must be able to adopt all necessary steps required to create analysis-ready data tables including data integration, variable preparation, and quality control. Ensures compliance with the production standards
    * Must be familiar with programs and maintain report forms and formats, information dashboards, data generators, canned reports, and other end-user information portals or resources
    * Ability to use of Azure Databricks and/or Data Factory to perform all work.
    * Can detect data anomalies and/or inconsistencies and resolve them promptly
    * Coach junior Data Engineers on tools and processes within the team
    * Initiative – Proactively identifies areas for improvement and automates processes resulting in efficiency gain
    * Problem-Solving – Always follow the best practices and architecture guidelines while building data solutions
    * Collaboration – Collaborate with the internal and external stakeholders to manage data system enhancements including system specifications, data specifications, structures, and rules.
    * Organization – Execute multiple projects concurrently and account for the timeliness and quality.

 * Why you might stand out from other talent:
    * Bachelor’s degree in computer science or equivalent relevant experience required
    * 1-3 years of knowledge of ETL Process, Data Hub/Lakes/Mart/Mesh, and Data Democratization
    * Exposure to Microsoft Azure, Databricks, and Data Factory is a must-have.
    * Working knowledge of Telecom Industry data is an advantage
      

Additional Information

When You Join Us, We’ll Create Something EPIC Together

Epsilon is a global data, technology and services company that powers the marketing and advertising ecosystem. For decades, we’ve provided marketers from the world’s leading brands the data, technology and services they need to engage consumers with 1 View, 1 Vision and 1 Voice. 1 View of their universe of potential buyers. 1 Vision for engaging each individual. And 1 Voice to harmonize engagement across paid, owned and earned channels.

Epsilon’s comprehensive portfolio of capabilities across our suite of digital media, messaging and loyalty solutions bridge the divide between marketing and advertising technology. We process 400+ billion consumer actions each day using advanced AI and hold many patents of proprietary technology, including real-time modeling languages and consumer privacy advancements. Thanks to the work of every employee, Epsilon has been consistently recognized as industry-leading by Forrester, Adweek and the MRC. Epsilon is a global company with more than 9,000 employees around the world.

Epsilon Has a Core Set Of 5 Values That Define Our Culture And Guide Us To Create Value For Our Clients, Our People And Consumers. We Are Seeking Candidates That Align With Our Company Values, Demonstrate Them And Make Them Meaningful In Their Day-to-day Work


 * Act with integrity. We are transparent and have the courage to do the right thing.
 * Work together to win together. We believe collaboration is the catalyst that unlocks our full potential.
 * Innovate with purpose. We shape the market with big ideas that drive big outcomes.
 * Respect all voices. We embrace differences and foster a culture of connection and belonging.
 * Empower with accountability. We trust each other to own and deliver on common goals.
   
   

Because You Matter

Benefits

As an Epsilon employee, you deserve perks and benefits that put you, your family and your finances first. Our benefits encompass a wide range of offerings, including but not limited to the following:


 * Time to Recharge: Flexible time off (FTO), 14 paid holidays
 * Time to Recover: Paid sick time
 * Family Well-Being: Parental/new child leave, childcare & elder care assistance, adoption assistance
 * Extra Perks: Comprehensive health coverage, 401(k), tuition assistance, commuter benefits, professional development, employee recognition, charitable donation matching, health coaching and counseling
   
   

Epsilon benefits are subject to eligibility requirements and other terms.

Epsilon is an Equal Opportunity Employer. Epsilon’s policy is not to discriminate against any applicant or employee based on actual or perceived race, age, sex or gender (including pregnancy), marital status, national origin, ancestry, citizenship status, mental or physical disability, religion, creed, color, sexual orientation, gender identity or expression (including transgender status), veteran status, genetic information, or any other characteristic protected by applicable federal, state or local law. Epsilon also prohibits harassment of applicants and employees based on any of these protected categories. Epsilon will provide accommodations to applicants needing accommodations to complete the application process. Please reach out to LeaveofAbsence@epsilon.com to request an accommodation.

For San Francisco Bay and Los Angeles Areas: Epsilon will consider for employment qualified applicants with criminal histories in a manner consistent with the City of Los Angeles’ Fair Chance Initiative for Hiring Ordinance and San Francisco Police Code Sections 4901-4919, commonly referred to as the San Francisco Fair Chance Ordinance. Applicants with criminal histories are welcome to apply.

",Full-time
4125125313,347778.0,Data Engineer,"Welcome to MFour!

Our Story: Founded in 2011, MFour is a fast-growing data and analytics technology company “democratizing” consumer insights. Named a 2023, “top 25 L.A. tech companies to watch,” by Built In, we’ve created a SaaS ecosystem, giving businesses access to united shopper behavior + opinion data that uncovers the whos, whats, whys, whens and wheres behind consumers in ways never before possible. We help 25% of the Fortune 100 plus organizations of all sizes make product, brand and advertising decisions.

Our Product: Using the nation’s most downloaded, highest-rated, and only Apple-approved app & web data collection and survey app (Surveys On The Go®), MFour is the only consumer market research company that guarantees real, validated responses for every survey, giving businesses the data and insights they need to make impactful decisions.

From validated opinion and behavior trackers to advertising exposure measurement MFour is trusted by hundreds of leading.

Our Goal: To eliminate the unknown (data blind spots) within market research in a way that recognizes a consumer’s right to privacy – so marketers can make better decisions about new and existing products, advertising choices and competitive positioning. MFour is trusted by hundreds of leading brands, including Google, Microsoft, Samsung, Walmart, Disney, Spotify, and Lowe’s.

Our Core Values: Simplicity, Humility, Quality, Consistency, and Innovation.

Your Journey To Success

The Data Engineer will design, implement, and manage scalable data pipelines, databases, and processing systems to support engineering, product, and analytics teams. This includes developing and administering platforms like Databricks and Snowflake, optimizing data architecture, and ensuring performance, scalability, and reliability.

Your Mission


 * Data Infrastructure Development:
    * Design, build, and maintain scalable data pipelines to process large volumes of structured and unstructured data.
    * Optimize data architecture for both real-time and batch processing workflows.
    * Integrate and maintain PostgreSQL, MySQL, Databricks, and Snowflake within our data ecosystem.

 * Databricks Development and Administration:
    * Develop and manage workflows on Databricks to support ETL/ELT processes.
    * Optimize Databricks performance for distributed computing and data processing.
    * Monitor, troubleshoot, and ensure the reliability of Databricks clusters and jobs.

 * Snowflake Development and Administration:
    * Design and optimize Snowflake schemas and data warehouses for efficient querying.
    * Develop and manage data ingestion pipelines for Snowflake using modern tools and frameworks.
    * Administer Snowflake environments, including account management, performance tuning, and resource optimization.

 * Database Management:
    * Administer PostgreSQL and MySQL databases, ensuring high availability and performance.
    * Implement and enforce data governance practices to ensure data security and compliance.

 * Collaboration:
    * Partner with analytics and engineering teams to define data needs and deliver solutions for business insights.
    * Work with product teams to align data solutions with product goals and user requirements.

 * Monitoring and Troubleshooting:
    * Set up monitoring and alerting systems for data platforms and pipelines.
    * Proactively debug and resolve data-related issues to ensure system reliability.

 * Innovation and Best Practices:
    * Stay current with emerging trends and advocate for tools and practices that enhance data engineering efficiency.
    * Document workflows, pipelines, and platform configurations to foster team collaboration and knowledge sharing.
      

What Sets You Apart


 * Bachelor’s degree in Computer Science, Engineering, or a related field (or equivalent experience).
 * 3+ years of professional experience in data engineering or related fields.
 * Proficiency in Databricks development and cluster administration.
 * Hands-on experience with Snowflake development and administration, including performance tuning and security configuration.
 * Strong understanding of relational databases, particularly PostgreSQL and MySQL.
 * Expertise in programming languages like Python, Scala, or SQL for data processing and automation.
 * Familiarity with ETL/ELT tools and frameworks such as Apache Airflow or dbt.
 * Experience with cloud platforms (AWS, Azure, or GCP).
   
   
   

Preferred Skills


 * Knowledge of distributed systems and big data frameworks like Spark.
 * Experience with CI/CD pipelines for deploying data workflows.
 * Familiarity with real-time streaming technologies (Kafka, Kinesis, etc.).
   
   
   

Why Join Us?


 * Work with a passionate, innovative team driving the next wave of industry solutions.
 * Opportunities for professional growth and continuous learning.
 * Competitive compensation, comprehensive benefits, and a flexible work environment.
   
   
   

In Return For Your Dedication, We Offer


 * Salary
    * $125,000

 * Health benefits
    * Top-tier health benefits include; medical, dental, vision, LTD, and life insurance
    * Mental health benefits

 * Work-life balance
    * Unlimited PTO
    * Flexible hybrid schedule

 * Additional benefits
    * In the WeWork office In the heart of the financial district in downtown Kansas City
    * Open space concept & team-focused atmosphere
    * Company-wide celebrations
    * Team bonding events and happy hours
      

CHECK US OUT: https://www.youtube.com/watch?v=cabweOxGias&t=1s

OUR APP : https://surveysonthego.com/",Full-time
4129999535,66321745.0,Junior Data Engineer,"For more than 14 years Synergisticit has helped Jobseekers stand out from other Jobseekers by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this market also our candidates get multiple job offers and $100k + salaries.

Please Check The Below Links

Synergisticit Pics /Salaries of Successful Candidates

Synergisticit at Oracle Cloudworld 2023

Synergisticit at Gartner Data & Analytics summit

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

Required Skills

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full Stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java , javascript , C++ or software programming

Spring boot, Microservices, Docker, Jenkins and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Contract
4030667455,23441.0,Data Analytics Engineer,"Camping World is seeking a Data Analytics Engineer to support the work of the RV Pricing team.

In this role, you will perform a variety of tasks related to data and analysis including developing, testing and deploying ETL processes, performing data manipulation and analysis, creating and maintaining software for analytics and reporting, and other technical tasks.

This is an opportunity for a data scientist, data engineer or software developer with varied technical skills and interests to be part of a high performing team of analysts and data scientists. From day one, you will be working with 10s of millions of rows of data which we expect to grow very quickly. You will report to the Director of RV Pricing Strategy.


 * The position is hybrid in our Lincolnshire, IL offices. You must be able to work in person on-site at least two days per week. No relocation support is available.
   
   

Responsibilities


 * Using Python, SQL, and PowerBI to organize and analyze data.
 * Developing and deploying ETL processes to gather data from enterprise systems and external sources using various data delivery mechanisms and APIs.
 * Identifying data sources and cleaning data for analytics work.
 * Implementing best practice data management, version control and other best practices within the team.
 * Working closely with the pricing team to support their current technical needs and identify new technologies which will be valuable for the team and its mission.
 * Perform daily tasks to monitor technical infrastructure and processes and take corrective action as necessary.
 * Take on special projects as needed including data science tasks such as creating analytics and machine learning projects.
   
   

Technologies We Currently Use


 * Python and related software such as Jupyter, Anaconda, and VS Code
 * Docker
 * Kubernetes
 * Microsoft SQL Server
 * Snowflake
 * Microsoft Power BI
 * Microsoft Excel including Power Query and VBA
   
   

Must Have Qualifications


 * Bachelor's degree in data science, computer science, software development, data engineering, or closely related field.
 * 1 – 2 years’ experience in a business organization including…
    * Data science related projects such as data cleaning, EDA, performing statistical analysis, creating visualizations, and machine learning.
    * Data engineering related projects such as designing new databases and data models, writing SQL queries and CRUD routines, and developing ETL pipelines.
    * Software development experience including creating software for non-technical end-users.

 * Strong programming skills in Python for data manipulation and analysis.
 * Knowledge of data warehouse / data lake solutions.
 * Proficiency with Microsoft Office tools (Word, Excel, PowerPoint, Outlook).
 * Strong analytical and problem-solving skills.
 * Good communication and presentation skills.
 * Ability to maintain professional demeanor and strict confidentiality.
 * Ability to work independently to complete assigned tasks.
 * Must be diligent, organized, and extremely detail oriented.
   

Preferred Qualifications


 * Experience creating front-ends for SQL Server and Snowflake based data.
 * Experience with Microsoft analytical tools, including Power BI, Excel, VBA, and Power Query.
   
   

Camping World is an equal employment opportunity employer. The Company's policy is not to discriminate against any applicant or employee based on race, color, sex, sexual orientation, gender identity, religion, national origin, age (40 and over), disability, veteran or uniformed service-member status, genetic information, or any other basis protected by applicable federal, state, or local laws.

Pay Range

$89,565.00-$134,295.00 Annual

In addition to competitive pay, we offer Paid Time Off, 401(k), an Employee Assistance Program, Good Sam Roadside Assistance, discounts, paid parental leave (if eligibility is met), Tuition Reimbursement (if eligibility is met), and on the job training opportunities. Full-time associates are offered a comprehensive benefit package including medical, dental, vision and more! Part-time associates are offered access to dental & vision coverage! For more information please visit: www.mycampingworldbenefits.com

We are an equal employment opportunity employer. The Company's policy is not to discriminate against any applicant or employee based on race, color, sex, sexual orientation, gender identity, religion, national origin, age (40 and over), disability, veteran or uniformed service-member status, genetic information, or any other basis protected by applicable federal, state, or local laws.",Full-time
4149235974,503474.0,Data Engineer,"Position Summary

The Miami Marlins are seeking a full-time Data Engineer for the Baseball Systems department. The candidate will be responsible for designing, implementing, and optimizing processes that ingest, validate, and organize baseball data from a variety of sources. The Data Engineer will support the data and information requirements of our Baseball Operations department. Strong applicants will have experience with modern database systems, cloud technologies, and database management.

Essential Functions


 * Continuously improve the department’s access to information; design, develop, and optimize processes to ingest data from both new and existing data sources.
 * Improve completeness, cleanliness, and timeliness of existing data processes.
 * Create production-quality software and database scripts to automate ETL processes using scalable, concise, and modern code practices.
 * Maintain high data quality standards. Proactively identify, diagnose, and resolve data issues.
 * Learn, extend, and improve the existing database architecture, ensuring data is well organized for end-users and easy to connect to other data sources.
 * Work with modern code repository systems and maintain version-controlled code.
 * Collaborate with Baseball Operations staff and other stakeholders to understand our organization’s data and information needs.
 * Prioritize workflows effectively and share relevant expertise to best support data users.
   
   

Qualifications & Requirements


 * Strong work ethic, attention to detail, and ability to self-direct.
 * Passion for engineering development, creativity, intellectual curiosity.
 * Excellent interpersonal, verbal, and written communication skills.
 * Demonstrated experience working with SQL, Python, and equivalent technologies.
 * Demonstrated experience with ETL/ELT processes and database management.
 * Experience working with data in various formats including JSON, CSV, etc.
 * Experience with database systems (SQL Server, Snowflake, Google BigQuery, Google CloudSQL, Google BigTable).
 * Experience with cloud computing platforms (GCP, AWS, Azure, etc.) is a plus.
 * Understanding of and passion for baseball and baseball research.
 * Ability to work extended hours including evenings, weekends, and holidays.
   
   

Suggested Education & Experience Guidelines


 * Degree in Computer Science, Information Systems, or equivalent.
   
   

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, age, disability, gender identity, marital or veteran status, or any other protected class.",Full-time
4139521679,72825.0,Data Engineer,"Position Summary:

We are seeking a Data Engineer responsible for developing and implementing the IT technology strategy for the Mortgage Servicing team. This role involves collaborating with business and product teams to design, build, and deliver processes that drives our business and technology objectives within the Mortgage industry. The Data Engineer will focus on executing key initiatives and consolidating research and technologies into a unified technical roadmap to create innovative solutions for both organization and customers.



Responsibilities:

· Drive strategy around solutions, solve complex problems, and successfully execute across the Cloud, end-to-end solution, and more.

· Deep technical experts that help accelerate adoption of the best engineering practices, while maintaining knowledge on industry innovations, trends, and practices.

· Leverage business and domain acumen to interpret and translate business requirements to architecture/technology plans.

· Visionaries, collaborating to deliver on business needs that directly impact the lives of our customers.

· Role models and mentors, helping to coach and strengthen the technical expertise and know-how of our engineering and product community.

· Evangelists, both internally and externally, helping to elevate the Engineering community and establish themselves as a go-to resource on given technologies and technology-enabled capabilities.

· Contribute to developing key framework and components of solutions and provide technical excellence.

· Identifies the balance between the immediate and long-term impact of technical direction and guides the organization to execution in this balance.

· Effectively communicate with and influence key stakeholders across the enterprise, at all levels of the organization.

· Operate as a trusted advisor for a specific technology, platform or capability domain, helping to shape use cases and implementation in unified manner.

· Design and implement benchmarks to measure the performance of software systems and make recommendations on technology selection.



Required Qualifications:

· Bachelor's Degree or equivalent in computer science/Information Technology or related field.

· 4+ years of experience in data engineering.

· Expertise in data warehouse design, data modeling, and ETL processes.

· Proficiency in SQL scripting and tuning.

· Advanced programming skills in Python.

· Experience with API’s, Microservices, Spark and Kafka.

· Familiarity with cloud platforms like Snowflake, Azure and GCP.

· Deep hands-on technical expertise in backend technologies like SQL Server Management Studio, Snowpark, DataStage, Talend, DataBricks, Unix/Linux expertise.

· Understanding of IT concepts and methodologies.

· Experience with enterprise level data governance.



Preferred Qualifications:

· Master’s degree in information technology or related field.

· Experience in the Mortgage or Finance industry.

· Proficiency with SQL & NoSQL databases.

· Certifications in related areas like Snowflake Core & SnowPro, Google Data Eng, Azure Data Eng.",Full-time
4124384456,3493.0,Data Engineer,"Conagra Brands is building an Enterprise Data Platform to deliver best-in-class data solutions. Join our Enterprise Data Engineering team and contribute to shaping and delivering data products that empower our business. Leverage cutting-edge technologies like Databricks, Snowflake, and Palantir to drive data-driven innovation.

As a Data Engineer, reporting to the Director of Information Technology, you will play a vital role in developing, maintaining, and optimizing data pipelines and workflows within our Enterprise Data Platform. Your work will help ensure data accuracy, reliability, and accessibility, enabling teams across the organization to make informed decisions.

This position offers an opportunity to grow your technical skills and collaborate with cross-functional teams to solve data challenges and create impactful solutions.

You Will (Position Responsibilities)


 * Develop and maintain data pipelines to process and integrate data from multiple sources into the Enterprise Data Platform.
 * Collaborate with data scientists, analysts, and business teams to gather and understand data requirements.
 * Build and optimize SQL queries and data transformations to support business use cases.
 * Create and manage data models and validate them with business stakeholders and data architects.
 * Perform data validation and troubleshooting to ensure data accuracy and consistency.
 * Automate workflows to improve data processing efficiency and reduce manual effort.
 * Monitor and optimize the performance of data pipelines and queries.
 * Participate in Agile ceremonies to plan, estimate, and deliver work efficiently.
 * Assist in creating documentation for data workflows, transformations, and standards.
   
   
   

You Have (Position Qualifications)


 * Bachelor’s degree in Computer Science, Information Systems, or a related field (or equivalent experience).
 * 2-4 years of experience in a data engineering or related role.
 * Proficiency in SQL for data transformation and analysis.
 * Familiarity with cloud-based data platforms such as Snowflake, Databricks, or similar tools.
 * Experience with ETL tools and frameworks like Informatica, Talend, or equivalent.
 * Knowledge of Python or PySpark for data processing is preferred.
 * Understanding of data modeling concepts and database design principles.
 * Strong problem-solving and analytical skills with attention to detail.
 * Excellent communication skills and ability to work in a collaborative team environment.
 * This position requires working from our Omaha or Chicago office 3 days a week in a hybrid work model.
   
   
   

Compensation

Pay Range:$71,300-$104,600

The annual salary listed above is the expected offering for this position. An employee’s actual annual salary will be based on but not limited to: location, relevant experience/level and skillset, while balancing internal Conagra employees’ equity. Conagra Brands will comply with applicable law regarding minimum salaries for exempt employees.

Our Benefits

We care about your total well-being and will support you with the following, subject to your location and role:


 * Health: Comprehensive healthcare plans, wellness incentive program, mental wellbeing support and fitness reimbursement
 * Wealth: Great pay, bonus incentive opportunity, matching 401(k) and stock purchase plan
 * Growth: Career development opportunities, employee resource groups, on-demand learning and tuition reimbursement
 * Balance: Paid-time off, parental leave, flexible work-schedules (subject to your location and role) and volunteer opportunities
   
   
   

Our Company

At Conagra Brands, we have a rich heritage of making great food. We aspire to have the most impactful, energized and inclusive culture in food. As a member of our 18,000+ person team across 40+ locations, you are empowered to reach your potential, make an impact and own your career. We're in the business of building champions – within our people and our iconic brands like Birds Eye ®, Slim Jim® and Reddi-Wip®.

Our focus on innovation extends beyond making great food, it also reflects our commitment to embracing new solutions that positively impact our team, the communities we serve and the health of our planet. Foodies Welcome.

Conagra Brands is an equal opportunity employer and considers qualified applicants for employment without regard to sex, race, color, religion, ethnic or national origin, gender, sexual orientation, gender identity or expression, age, pregnancy, leave status, disability, veteran status, genetic information and/or any other characteristic or status protected by national, federal, state or local law. Reasonable accommodation may be made upon request.

",Full-time
4118097928,2190.0,Staff Data Engineer,"Company Description

Visa is a world leader in payments and technology, with over 259 billion payments transactions flowing safely between consumers, merchants, financial institutions, and government entities in more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable, and secure payments network, enabling individuals, businesses, and economies to thrive while driven by a common purpose – to uplift everyone, everywhere by being the best way to pay and be paid.

Make an impact with a purpose-driven industry leader. Join us today and experience Life at Visa.

Job Description

The primary purpose of this role is to serve as a pivotal technical link between the Data Engineering team and the Product organization. Reporting directly to the Data Engineering department, this position will be responsible for executing and aligning data engineering strategies and processes in accordance with Technology Services standards. This person will work closely with the Data Solutions Product Manager to identify and undertake key projects and responsibilities that drive product development and innovation. As a bridge between technical and product realms, this role will ensure seamless integration of data engineering solutions into product initiatives, fostering a data-driven product development culture, and contributing to the overall growth and success of the organization.

Essential Functions:


 * Acts as a key player during meetings with stakeholders (e.g., Product teams, business partners, Cybersecurity) to identify and clarify requirements and determine business needs.
 * Identifies systems, architectures, tools, and storage needs that support the requirements for the application for a product.
 * Proficient in analyzing data for the purpose of intentional database design, discovering new potential data use cases and articulating technical requirements.
 * Implements extensible, maintainable and reusable code, using appropriate coding patterns, guidelines, styles and best practices, informally mentoring others, and adheres to all security requirements.
 * Independently conducts unit testing to confirm functional capability of code. Conducts tests for coding standards and security scans. Conducts user acceptance testing in collaboration with customer.
 * Builds tools and standard automation processes that assist in transforming, managing, accessing, deploying, and monitoring data processes in batches and in real time.
 * Independently writes queries to extract and compile raw data across end-to-end pipelines.
 * Implements and monitors self-healing processes across multiple product features to prevent recurring issues, maintain and improve data quality and pipeline, and optimize performance throughout the data lifecycle.
   
   

This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.

Qualifications

Basic Qualifications

5 or more years of relevant work experience with a Bachelors Degree or at least 2 years of work experience with an Advanced degree (e.g. Masters, MBA, JD, MD) or 0 years of work experience with a PhD

Preferred Qualifications

6 or more years of work experience with a Bachelors Degree or 4 or more years of relevant experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or up to 3 years of relevant experience with a PhD

Four years of experience solving problems using Apache Spark.

Two years of experience with streaming data using Apache Kafka or equivalent technology

Experience of full development lifecycle through both non-production and promotion to production environments

Expert in at least one of the following: Python, Scala, or Java

Experience with web service standards and related patterns (REST, gRPC)

Additional Information

Work Hours: Varies upon the needs of the department.

Travel Requirements: This position requires travel 5-10% of the time.

Mental/Physical Requirements: This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.

Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.

Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.

U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is 124,200.00 to 180,250.00 USD per year, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for bonus and equity. Visa has a comprehensive benefits package for which this position may be eligible that includes Medical, Dental, Vision, 401 (k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness Program.",Full-time
4133254332,3595.0,Sports Data Engineer,"The Sports Data Engineer will assume a role within the team as a developer by setting forth a vision for the modernization of its tech stack, helping guide and mentor more junior members of the team, and serving as a key developer across many of the team’s new and existing metrics. This will include gathering, wrangling, and verifying data, creating advanced statistical models, and writing code to execute those models. Candidates need to have a deep understanding of internal analytics metrics and be able to communicate results both internally and externally. The Data Engineer will help the team tell stories in the most engaging and accurate way, matching the storytelling to the medium. Translating the complex into an understandable language is a key requirement of the job.

The Sports Data Engineer will work collaboratively with other members of the Analytics team as well as engage consistently with outside partners, both inside and outside of Disney, in order to advance the team’s goals. This will include exploring technical solutions with partners to better disseminate, organize, and display the team’s data and metrics and helping develop new products to serve this purpose.

ESPN Analytics is a multidisciplinary group where all members have deep knowledge of sports, statistics, databases, coding across multiple languages, and storytelling. Combining best-in-the-industry data with advanced mathematics and statistical modeling skills, ESPN Analytics has created storytelling tools and metrics that have improved the evaluation of team and player performance, such as Total QBR and power ratings for football, basketball, and more. These products make fans better informed and help keep ESPN at the cutting edge of sports statistical analysis.

Responsibilities:



 * Develop data requirements for new metrics and help establish a technical methodology for production execution
 * Write optimized, production-quality code to transform data into automated metrics across ESPN platforms and internal research tools
 * Help identify the key components in these complex formulas and turn them into language that allows them to be readily used in storytelling across ESPN platforms
 * Engage consistently and thoroughly with external partners around dissemination of the team’s metrics
 * Identify trends and help the team react to news stories using the tools developed by the team
 * Be engaged in the larger sports analytics community and be aware of the latest sports statistical analysis research
   
   
   

Qualifications:



 * A minimum of 3 years’ experience with sports analytics or a bachelors’ degree in a related field of study
 * Some experience with predictive modeling, machine learning, Bayesian statistics, trend analysis, and other data analysis techniques
 * Demonstrated experience coding with programming languages such as R, Python, and SQL
 * Experience in AWS Cloud management
 * Full availability for this position, which could include nights, weekends and holidays
 * Demonstrated ability to ensure accuracy of content
 * A knowledge of sports statistical analysis in the marketplace
 * Strong sports knowledge, both historical and current
   
   
   

Preferred Qualifications:



 * Statistics, engineering, advanced mathematics degree
 * Experience in the R Programming language
 * Experience in general data wrangling, database development, and SQL coding
 * Experience with sports betting
 * Experience writing production-quality code and collaborating via SCM
 * Experience developing cloud computing environments
 * Experience turning sports analytics into storylines
 * Experience in digital and/or television sports production
 * Strong understanding of sports betting and how betting markets work
   
   
   

Required Education:



 * Bachelor's Degree in a related field
   
   
   

Preferred Education:



 * Statistics, engineering, advanced mathematics or economics degree strongly preferred
   
   
   

#ESPNMedia",Full-time
4115784862,2947777.0,Data Engineer (Remote),"Title: Data Engineer (Multiple Positions)

Location: Remote

About IWorks

iWorks Corporation, founded in 2005, is a leading provider of information technology and professional services to the federal government. We are a recognized leader in personnel security and vetting solutions, Agile, DevOps, DevSecOps, data analytics, and cloud solutions. Our continuous process improvement approach, combined with our business and technology expertise, results in innovative solutions.

About This Position

We are seeking a highly skilled and motivated Data Engineer to join our dynamic team. The ideal candidate will be responsible for performing data mapping, data quality management, metadata management, and master data management, as well as conducting in-depth data analysis to inform and progress our current and future data operating models. The Data Engineer will play a critical role in shaping our data architecture and ensuring the integrity and quality of our data assets.

Salary Range: 115k-135k - commensurate with the candidate's skills, experience, location, and qualifications.

On a Day-to-day Basis You Will


 * Using Excel and SQL to prepare, analyze, and transform data; conduct statistical analyses; and create visual reports to highlight trends and insights.
 * Develop, maintain, optimize, and document SQL queries for data analysis and reporting tasks to ensure, reuse and meet stakeholder needs.
 * Identify and fix data issues (e.g., missing values, outliers, duplicates, inconsistencies) by developing and executing Oracle DML statements, and clean and preprocess raw data for accuracy and consistency.
 * Communicate findings and insights clearly to both non-technical and technical stakeholders using tools such as Excel, Word, PowerPoint, and Visio.
 * Continuously monitor and implement data validation checks, manage data quality, metadata, and master data, and perform data mapping and analysis. Document findings, provide recommendations, and develop data architecture artifacts to enhance current and future data operating models.
 * Monitor and manage data storage costs in AWS, ensuring efficient use of resources and scalability of the database environment.
   
   

Required Education/Qualifications


 * Clearance: MUST be fully adjudicated & maintain a Top Secret security clearance or higher.
 * Associate/bachelor's degree with 3+ years of relevant experience
 * Security+ Certification required
 * Proficiency in Excel, Visio, and Oracle SQL Developer.
 * Experience performing the tasks identified above in AWS and Oracle environments.
 * Strong expertise in data analysis, data architecture, and data services development.
 * Ability to work independently and as part of a team, effectively collaborating with various stakeholders.
 * Advanced analytical and troubleshooting skills with good problem-solving abilities.
 * Experience working with and supporting Agile development teams.
 * Excellent written and verbal communication skills
   
   

Preferred Qualifications


 * Experience with data visualization tools (e.g., Tableau, Power BI, or Pentaho Report Designer) is a plus.
 * Knowledge of data governance and data management best practices is also a plus.
   
   

Potential Career Growth Opportunities

Depending on your drive and aspirations, this role provides a foundation for various career paths over the next 3 to 5 years, including:


 * Data Architect: Progress into designing and managing high-level data frameworks and architectures for enterprise-wide data systems.
 * Data Scientist: Transition to building predictive models, performing advanced analytics, and deriving insights from complex datasets.
 * ETL Developer/Manager: Specialize in extracting, transforming, and loading data, ensuring seamless data flow across systems.
   
   

FLSA & EMPLOYMENT STATUS: FLSA EXEMPT AND FULL-TIME POSITION

iWorks Corporation is an Equal Employment Opportunity/Affirmative Action Employer. We evaluate qualified applicants without regard to race, color, religion, sex, national origin, disability, Veteran status, sexual orientation, or other protected characteristic.

iWorks is committed to maintaining a safe and productive work environment for all employees and ensuring the security and well-being of our clients. As part of our standard hiring process, we may conduct background checks and drug screenings on potential candidates to assess their suitability for employment.",Full-time
4069874946,79693228.0,Data Engineer,"Company Overview:

For over twenty years, Atmospheric G2 has provided our customers market-leading weather intelligence software that enables them to confidently assess the impacts of weather on their markets. Our flagship product is up on monitors throughout the trading day across most trade floors in North America and Europe. AG2 forecasts have been proven, via various third-party studies, to have the best accuracy in the world, exceeding the US National Weather Service and other weather vendors. At AG2, we understand that the strength of our offerings depends on the talent of our team, and we are seeking skilled Data Engineers to help us maintain our position as an industry leader.




Job Description:




We are looking for an experienced Data Engineer to join our team and contribute to the development of data processing and transformation pipelines. The ideal candidate will have expertise in building Python ETL processes, leveraging AWS Step Functions and Lambda, and working with relational databases such as MySQL (or equivalents). Familiarity with weather data formats, including GRIB, NetCDF, and Zarr, is a bonus and will help in supporting AG2’s core mission of providing high-quality, accurate weather intelligence.




Key Responsibilities:




 * Develop, maintain, and optimize ETL pipelines for processing and transforming data, primarily using Python with AWS Step Functions and Lambda.
 * Manage, monitor, and scale data workflows to ensure reliability, accuracy, and timeliness.
 * Design and implement data models and database structures, primarily in MySQL or equivalent systems.
 * Collaborate closely with cross-functional teams to understand data requirements and deliver solutions that support business goals.
 * Enhance data pipelines to integrate with weather-specific formats (GRIB, NetCDF, Zarr) as applicable.
 * Participate in code reviews and provide constructive feedback to peers, promoting a high-quality codebase.
 * Contribute to best practices in data engineering, including data quality and observability.
 * Stay informed on emerging data engineering technologies, particularly those in AWS and weather data handling.




Requirements:




 * 5+ years of experience in data engineering, with a strong focus on Python-based ETL processes.
 * Proficiency with AWS services, including Step Functions, Lambda, and other data-related services.
 * Strong experience with MySQL or equivalent relational database systems.
 * Experience working with weather data formats (GRIB, NetCDF, Zarr) is a plus.
 * Strong problem-solving skills with attention to data accuracy and quality.
 * Familiarity with version control systems, particularly Git.
 * Excellent communication and collaboration skills to work effectively within cross-functional teams.




What We Offer:




 * A competitive salary and comprehensive benefits package.
 * A well-established company with a start-up mindset, fostering innovation and agility.
 * A collaborative work environment that values professional growth and contribution.
 * Flexibility with a hybrid work model to support work-life balance.




Join our team to make an impact in the world of weather intelligence, leveraging your data engineering expertise to drive informed decisions across global markets.

",Full-time
3915650409,11130470.0,"Analytics Data Engineer, Applied Engineering","About The Team

The Applied team works across research, engineering, product, and design to bring OpenAI’s technology to consumers and businesses.

We seek to learn from deployment and distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely. Safety is more important to us than unfettered growth.

About The Role

We're seeking a Data Engineer to take the lead in building our data pipelines and core tables for OpenAI. These pipelines are crucial for powering analyses, safety systems that guide business decisions, product growth, and prevent bad actors. If you're passionate about working with data and are eager to create solutions with significant impact, we'd love to hear from you. This role also provides the opportunity to collaborate closely with the researchers behind ChatGPT and help them train new models to deliver to users. As we continue our rapid growth, we value data-driven insights, and your contributions will play a pivotal role in our trajectory. Join us in shaping the future of OpenAI!

In This Role, You Will


 * Design, build and manage our data pipelines, ensuring all user event data is seamlessly integrated into our data warehouse.
 * Develop canonical datasets to track key product metrics including user growth, engagement, and revenue.
 * Work collaboratively with various teams, including, Infrastructure, Data Science, Product, Marketing, Finance, and Research to understand their data needs and provide solutions.
 * Implement robust and fault-tolerant systems for data ingestion and processing.
 * Participate in data architecture and engineering decisions, bringing your strong experience and knowledge to bear.
 * Ensure the security, integrity, and compliance of data according to industry and company standards.
   
   

You Might Thrive In This Role If You


 * Have 3+ years of experience as a data engineer and 8+ years of any software engineering experience(including data engineering).
 * Proficiency in at least one programming language commonly used within Data Engineering, such as Python, Scala, or Java.
 * Experience with distributed processing technologies and frameworks, such as Hadoop, Flink and distributed storage systems (e.g., HDFS, S3).
 * Expertise with any of ETL schedulers such as Airflow, Dagster, Prefect or similar frameworks.
 * Solid understanding of Spark and ability to write, debug and optimize Spark code.
   
   

This role is exclusively based in our San Francisco HQ. We offer relocation assistance to new employees.

About OpenAI

OpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.

We are an equal opportunity employer and do not discriminate on the basis of race, religion, national origin, gender, sexual orientation, age, veteran status, disability or any other legally protected status.

OpenAI Affirmative Action and Equal Employment Opportunity Policy Statement

For US Based Candidates: Pursuant to the San Francisco Fair Chance Ordinance, we will consider qualified applicants with arrest and conviction records.

We are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.

OpenAI Global Applicant Privacy Policy

At OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.",Full-time
4149833129,1128772.0,Data Engineer,"We are seeking a software engineer/developer or ETL/data integration/big data developer with experience in projects emphasizing data processing and storage. This person will be responsible for supporting the data ingestion, transformation, and distribution to end consumers. Candidate will perform requirements analysis, design/develop process flow, unit and integration tests, and create/update process documentation.




· Work with the Business Intelligence team and operational stakeholders to design and implement both the data presentation layer available to the user community, as well as the underlying technical architecture of the data warehousing environment.

· Develop scalable and reliable data solutions to move data across systems from multiple sources in real time as well as batch modes.

· Design and develop database objects, tables, stored procedures, views, etc.

· Independently analyze, solve, and correct issues in real time, providing problem resolution end-to-end

· Design and develop ETL Processes that will transform a variety of raw data, flat files, xl spreadsheets into SQL Databases

· Understands the concept of Data marts and Data lakes and experience with migrating legacy systems to data marts/lake

· Uses additional cloud technologies (e.g., understands concept of Cloud services like Azure SQL server)

· Maintain comprehensive project documentation

· Aptitude to learn new technologies and the ability to perform continuous research, analysis, and process improvement.

· Strong interpersonal and communication skills to be able to work in a team environment to include customer and contractor technical, end users, and management team members.

· Manage multiple projects, responsibilities and competing priorities.




Experience Needed:

· Programming languages, frameworks, and file formats such as: Python, SQL, PLSQL, and VB

· Database platforms such as: Oracle, SQL Server, MySQL

· Big data concepts and technologies such as Synapse & Databricks

· AWS and Azure cloud computing

· HVR data replication",Full-time
4045411776,66321745.0,Remote Software Engineer (Junior/Entry),"Since 2010 Synergisticit has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this Job market also, our candidates are able to achieve multiple job offers and $100k &plus; salaries.

please check the below links to see success outcomes, salaries of our candidates .

https://www.synergisticit.com/candidate-outcomes/

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please visit the below videos exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

Required Skills

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, Gen AI, LLM, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full Stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java , javascript , C&plus;&plus; or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Full-time
4125067256,11300833.0,Data Engineer,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:



 * Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
 * Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
 * Write code to ensure the performance and reliability of data extraction and processing
 * Support continuous process automation for data ingest
 * Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
 * Work with program management and engineers to implement and document complex and evolving requirements
 * Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
 * Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
   
   
   
   
   

Qualifications:



 * Must be a US Citizen
 * Must be able to obtain a Public Trust Clearance
 * 7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
 * Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
 * Proficiency in developing ETL processes, and performing test and validation steps
 * Proficiency to manipulate data (Python, R, SQL, SAS)
 * Strong knowledge of big data analysis and storage tools and technologies
 * Strong understanding of the agile principles and ability to apply them
 * Strong understanding of the CI/CD pipelines and ability to apply them
 * Experience with relational database, such as, PostgreSQL
 * Work comfortably in version control systems, such as, Git Repositories
   
   
   
   
   

Ideally, you will also have:



 * Experience creating and consuming APIs
 * Experience with DHS and knowledge of DHS standards a plus
 * Candidates will be given special consideration for extensive experience with Python
 * Ability to develop visualizations utilizing Tableau or PowerBI
 * Experience in developing Shell scripts on Linux
 * Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
 * Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences
   
   
   
   
   

Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:



 * Health, Dental, and Vision
 * Life Insurance
 * 401k
 * Flexible Spending Account (Health, Dependent Care, and Commuter)
 * Paid Time Off and Observance of State/Federal Holidays
   
   
   
   
   

Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com",Full-time
4045410885,66321745.0,Remote Software Engineer (Junior/Entry),"Since 2010 and almost 14 years SynergisticIT has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients.

Post Covid the tech Layoffs have been massive—In 2022 there were 165,269 tech layoffs, In 2023 there were 264,220 tech layoffs and so far in 2024 there have been 126,382 tech layoffs. (Source Layoffs.fyi ) -Total layoffs as per this 555,871 tech layoffs.

Client, Dell and Cisco have announced 15,000/12,500 and 4000 tech layoffs respectively in August.

The Job market is hyper-competitive. For 1 position 500-2000 candidates or more are applying and laid off job seekers are also competing for entry level Job positions.

Acquiring the right technology skillsets which are being demanded by clients and getting yourself in front of clients is the way to get to get Interviews and eventually a Job Offer. Survival of the Fittest is the only way to get a tech Job in this job market.

In this Layoffs fueled market also SynergisticIT's candidates are able to achieve multiple job offers and $100k &plus; salaries once they acquire the required skills.

please check the below links to see success outcomes, salaries of our candidates .

https://www.synergisticit.com/candidate-outcomes/

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please visit the below videos exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, we are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Data Engineers, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

Required Skills

REQUIRED SKILLS For Java /Full stack/Devops Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Knowledge of Core Java , javascript , C&plus;&plus; or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

For data Science/Data Analyst/AI/Machine learning Positions

Required Skills

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude

Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Full-time
4124797602,64515483.0,Staff Data Engineer,"About Nayya


Founded in 2019, Nayya is on a mission to connect people’s most important information, so they can thrive in their health and wealth. Powered by AI and advanced analytics, Nayya’s platform transforms complex benefits experiences into intuitive, seamless, and ongoing interactions—meeting people meeting people's real world needs. As a trusted platform and partner to leading employers, benefits solutions, and HR tech providers, Nayya unlocks long-term value through helping employees live more resilient lives. Backed by strategic investors like ICONIQ, Felicis Ventures, SemperVirens, Workday Ventures, MetLife Nextgen Ventures, and ADP Ventures, Nayya is ushering in the future of health and wealth for all.


 

About the RoleWe are seeking a highly skilled and motivated Staff Data Engineer to join our growing team at Nayya. In this role, you will lead the design and implementation of scalable data systems and pipelines that power our data extraction and integration services, while also developing a centralized data strategy. You will work on building batch, event processing, and stream processing infrastructure, enhancing our data enrichment services, developing a robust, de-identified analytics platform for our Data Science, BI, and Analytics teams to consume, and enabling our entire organization with data by developing easy access patterns. We are looking for a data expert who thrives in an environment that values impatience, excellence, resilience, and courage—a leader ready to make an immediate impact on our data infrastructure in a fast-paced, high-growth environment.


As a Staff Data Engineer, you will play a key role in shaping our data systems' architecture, reliability, and performance while fostering innovation and collaboration across teams. This position provides an exciting opportunity to drive technical strategy and lead efforts to solidify and scale our data infrastructure.


Objectives and Responsibilities


Technical Leadership & Data Infrastructure


   
   
 * Centralized Data Strategy: Develop a single source of truth for organizational data, driving data validation, governance, and improved access for analytical and operational use.
   
   
 * Build, Improve, and Maintain Data Systems: Lead the development of scalable data pipelines that handle high-volume batch and streaming data.
   
   
 * Data API and Eventing Development: Enhance and maintain APIs and event driven architecture to provide efficient and reliable access to internal and external data consumers.
   
   


Anonymization and Tokenization Development


   
   
 * Build utilities and workflows to de-identify data, link disparate sources, and build a holistic view of entities across data sources.
   
   
 * Data Enrichment & Integration: Implement data enrichment solutions at scale that interface with third-party data sources to enhance product capabilities.
   
   
 * Analytics & Reporting Platform: Improve our reporting and analytics platform while treating security and compliance as a top priority.
   
   


Collaboration & Mentorship


   
   
 * Cross-Functional Collaboration: Work closely with product, engineering, business, and infrastructure teams to design solutions that meet evolving business and technical needs. Advocate for data-driven decision making.
   
   
 * Mentor and Develop: Provide guidance and mentorship to engineers, fostering a culture of continuous learning and growth.
   
   
 * Lead by Example: Identify and evaluate our current processes, documentation, workflows and governance and make recommendations and plans for improvements. Lead with documentation.
   
   


Continuous Improvement


   
   
 * Optimize Performance: Focus on tuning, performance testing, and optimization of the data platform.
   
   
 * Innovate with Agility: Embrace a growth mindset, iterating on data infrastructure and processes to ensure scalability and reliability.
   
   
 * Ensure Security and Scalability: Identify gaps and risk in current infrastructure to solidify the data platform.
   
   


Skills and Qualifications


   
   
 * 7+ years of experience in data engineering, data infrastructure, or related roles.
   
   
 * Strong experience with Python and PySpark.
   
   
 * Strong experience with RDBMS.
   
   
 * Proficiency with workflow orchestration tools (Airflow, Dagster, etc.).
   
   
 * Experience implementing data pipelines using Apache Spark, AWS Glue, or EMR.
   
   
 * Hands-on experience building data intensive applications using common API frameworks (FastAPI, NestJS, etc.).
   
   
 * Expertise in SQL optimization, query performance tuning, and data warehousing.
   
   
 * Experience with infrastructure as code tools such as Terraform.
   
   
 * Experience with AWS suite of data engineering managed services and OSS tools.
   
   
 * Familiar with Domain Driven Design.
   
   
 * Experience with monitoring and observability frameworks and tools.
   
   
 * Familiarity with data quality measures, tools, and frameworks.
   
   
 * Ability to identify tradeoffs for warehousing vs data lake infrastructure and applying solutions to the appropriate use case.
   
   
 * Ability to communicate highly technical topics to non-technical stakeholders.
   
   
 * Familiar with common pitfalls in high volume, partitioned data ingestion pipelines such as orphaned records and table locks.
   
   


Preferred Qualifications


   
   
 * Experience with Apache Hudi or similar data lake platforms.
   
   
 * Experience with provisioning and managing Redshift.
   
   
 * Experience with federated query engines.
   
   
 * Experience with data catalogues.
   
   
 * Experience with claims data.
   
   
 * Experience with MLOps engineering and best practices.
   
   
 * Experience with data governance over PHI and other sensitive information.
   
   
 * Experience in fast-paced startup environments or high-growth companies.
   
   


The salary range for New York based candidates for this role is $185,000 - $225,000. We use a location factor to adjust this range for candidates that are located outside of geographic region of our New York office. Placement within the salary band is determined based on experience. 





 

Nayya is proud to be an Equal Employment Opportunity employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics",Full-time
4151632924,2825305.0,Data Engineer,"Data Engineer III (Large Language Models)

About Catalytic Data Science (CDS)

Catalytic Data Science is a groundbreaking cloud R&D platform designed to integrate volumes of scientific resources, data, and analytic tools while providing the ability to network with colleagues in one secure and scalable environment. By enabling R&D teams to work more collaboratively and improving productivity company-wide, the Catalytic platform helps teams achieve key R&D milestones faster and with greater accuracy. Our customers are passionate about making the world a better place, and we are inspired by the opportunity to help them.

The Role

You are a Data Engineer with experience in processing terabytes of data and working with large language models (LLMs). You have experience in creating and automating scalable, fault-tolerant, and reproducible data pipelines for natural language processing (NLP) using Amazon AWS technologies. You will design and implement data ingestion, processing, and storage solutions that can handle massive amounts of text data from various sources. You are interested in helping to create a platform completely built on top of AWS. You are eager to join a team of Life Scientists and Software Engineers that believe the brightest minds in research should have the best tools to drive innovation.

What You’ll Do


 * Build, test, and operate automated Extract, Transform, and Load (ETL) pipelines that process terabytes of text data nightly
 * Develop service frontends around our various backend data stores (AWS Aurora, MySQL, Elasticsearch, S3)
 * Rapidly protype, test, and deploy data pipelines for LLMs using AWS.
 * Collaborate with data scientists and NLP engineers to understand the data requirements and specifications for LLMs and related tasks such as text summarization, translation, and question answering.
 * Optimize the performance, reliability, and scalability of the data pipelines and LLMs by applying best practices and techniques such as data partitioning, caching, compression, and monitoring.
 * Ensure the quality, integrity, and security of the data by implementing data validation, cleaning, and governance policies and procedures.
 * Research and evaluate new technologies and methods for data engineering and LLMs and stay updated with the latest trends and developments in the field.
 * Participate in data architecture and engineering decisions, bringing your strong experience and knowledge to bear.
   
   

Qualifications


 * Bachelor's degree or higher in computer science, engineering, or a related field.
 * 3+ years of experience in data engineering, preferably with large-scale text data and LLMs and 6+ years of any software engineering experience (including data engineering).
 * Proficient in Python 3 or Java, preferably both.
 * Experience with data modeling, ETL, and data warehouse design and implementation.
 * Expertise with ETL schedulers such as Airflow, Prefect or similar frameworks.
 * Familiar with LLMs and NLP concepts and frameworks such as Transformers, BERT, GPT, PaLM, and LLaMA.
 * Day-to-day experience using AWS technologies such as Lambda, ECS Fargate, SQS, & SNS
 * Experience extracting, processing, storing, and querying of petabyte-scale datasets
 * Familiarity with building and using containers
 * Familiarity with event-based microservices
 * Strong communication, collaboration, and problem-solving skills.
   
   

Core Skills


 * ETL Processes
 * Data Modeling and Database Design
 * Proficiency in Large Language Models
 * Data Pipeline Optimization
 * Cross-functional Collaboration
 * Problem-solving and Analytical Skills
   
   

Nice-to-Haves


 * Prior experience with Elasticsearch (custom development and/or administration) is a huge plus
 * Knowledge of Graph databases
   
   

What Do We Love in Team Members?

Your Specialization Is Less Important Than Your Ability To Learn Fast And Adapt To Shifting Technologies. We’re Especially Fond Of People Who


 * Focus on customer’s needs and our company’s goals, not just writing code
 * Iterate until customers love what you’ve built
 * Self-start and initiate
 * Self-organize
 * Strive to grow personally and professionally, beyond just expanding technical abilities
 * Love to experiment with new technology and share knowledge with the team
   
   

In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",Full-time
4120822730,10667.0,"Data Engineer, Product Analytics","As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a world-class data engineering community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Data Engineer, Product Analytics Responsibilities:


 * Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems
 * Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve
 * Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way
 * Define and manage Service Level Agreements for all data sets in allocated areas of ownership
 * Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership
 * Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains
 * Solve our most challenging data integration problems, utilizing optimal Extract, Transform, Load (ETL) patterns, frameworks, query techniques, sourcing from structured and unstructured data sources
 * Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts
 * Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts
 * Influence product and cross-functional teams to identify data opportunities to drive impact
 * Mentor team members by giving/receiving actionable feedback
   
   

Minimum Qualifications:


 * Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent
 * 4+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions
 * 4+ years of experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.)
   
   

Preferred Qualifications:


 * Master's or Ph.D degree in a STEM field
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$145,000/year to $204,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4134403760,56445.0,"Data Engineer, Hospital","We are looking for an experienced data engineer to join our team. You will use various methods to transform raw data into useful data systems. For example, you’ll create algorithms and conduct statistical analysis. Overall, you’ll strive for efficiency by aligning data systems with business goals.




To succeed in this data engineering position, you should have strong analytical skills and the ability to combine data from different sources. Data engineer skills also include familiarity with several programming languages and knowledge of learning machine methods.




Responsibilities

 * Analyze and organize raw data
 * Build data systems and pipelines
 * Evaluate business needs and objectives
 * Interpret trends and patterns
 * Conduct complex data analysis and report on results
 * Prepare data for prescriptive and predictive modeling
 * Build algorithms and prototypes
 * Combine raw information from different sources
 * Explore ways to enhance data quality and reliability
 * Identify opportunities for data acquisition
 * Develop analytical tools and programs
 * Collaborate with data scientists and architects on several projects

Requirements and skills

 * Previous experience as a data engineer or in a similar role
 * Technical expertise with data models, data mining, and segmentation techniques
 * Knowledge of programming languages (e.g. Java and Python)
 * Hands-on experience with SQL database design
 * Azure Data Factory
 * Great numerical and analytical skills
 * Degree in Computer Science, IT, or similar field; a Master’s is a plus
 * Data engineering certification (e.g IBM Certified Data Engineer) is a plus
 * MS Fabric preferred",Full-time
4151634897,90415924.0,"Software Engineer, ML Platform (All levels)","About Overland AI

Founded in 2022 and headquartered in Seattle, Washington, Overland AI is transforming land operations for modern defense. The company leverages over a decade of advanced research in robotics and machine learning, as well as a field-test forward ethos, to deliver combined capabilities for unit commanders. Our OverDrive autonomy stack enables ground vehicles to navigate and operate off-road in any terrain without GPS or direct operator control. Our intuitive OverWatch C2 interface provides commanders with precise coordination capabilities essential for mission success.

Overland AI has secured $42M in funding, including a Series A led by 8VC, and built trusted partnerships with DARPA, the U.S. Army, Marine Corps, and Special Operations Command. Backed by eight-figure contracts across the Department of Defense, we are strengthening national security by iterating closely with end users engaged in tactical operations.

We are looking for software engineers to join our team to improve the quality of our AI models and development process.

Experienced, well-qualified remote candidates able to work during Pacific Time Zone business hours will be considered.

In This Role, You Will


 * Design and implement Overland AI’s infrastructure to enable training, evaluating, and deploying machine learning/deep learning models for autonomous vehicles, including:
    * Writing software to enable the fast curation and creation of high-quality labels for various robotics tasks using state-of-the-art AI and human feedback.
    * Design and implement data processing pipelines, dashboards, and visualization tools for model evaluation and dataset insights.
    * Design and implement distributed workflows, including data processing, training, and evaluation (on-prem and cloud).

 * Be responsible for on-prem and cloud infrastructure including data storage, compute resources and access.
 * Leverage CI/CD practices to make the machine learning lifecycle efficient and reproducible.
 * Collaborate closely with experts in Perception and Behavior Planning.

Qualifications


 * Strong programming skills in Python and/or C++
    * Including experience with any matrix library, such as numpy, Eigen, etc.

 * Strong understanding of data processing pipelines for training ML models
 * Experience with batch processing tools, such as Spark, Beam, Ray, etc.
 * Experience with data stores and databases, such as MinIO, Postgres, Redshift/BigQuery, etc.
 * You excel in a small-team atmosphere, taking ownership of problems and working with your colleagues to solve problems across disciplines.
 * Ability to obtain and maintain a DOD Security Clearance.
   

Preferred


 * Prior industry experience in a similar software infrastructure or MLOps team
 * Prior experience with ROS or other robotics middleware
 * Contributions to any related open source software project
   
   

Benefits Overland AI believes in creating a work environment that you look forward to embracing every day.


 * The salary range for this position is $120K to $300K annually
 * Equity compensation
 * Best-in-class healthcare, dental and vision plans.
 * Unlimited PTO
 * 401k with company match
 * Parental leave",Full-time
4123905444,66321745.0,Data Engineer - Remote,"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you need

Position open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, IT enthusiasts, Python/Java developers, Data analysts/ Data Scientists.

We welcome candidates with all visas and citizens to apply.

Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates looking to make their careers in IT Industry

Candidates who are serious about their future in the IT Industry and have set big goals for themselves.

Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience which our clients need with great outcomes

Candidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancement

Candidates Who Lack Experience

Have had a break in careers

Lack Technical Competency

Different visa candidates who want to get employed and settle down in the USA

Please Also Check The Below Links

Synergisticit Pics /Salaries of Successful Candidates

Synergisticit at Oracle Cloudworld 2023

Synergisticit at Gartner Data & Analytics summit

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

If not a match candidates can opt for Skill enhancement.

REQUIRED SKILLS For Java/Software Programmers


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Core Java , javascript , C&plus;&plus; or software programming
 * Spring boot, Microservices and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, Python, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, Time series analysis

Please understand skills are required by clients for selection even if its Junior or entry level position the additional skills are the only way a candidate can be picked by clients.

No third party candidates or c2c candidates

Please understand skills are required by clients for selection even if its Junior or entry level position the additional skills are the only way a candidate can be picked by clients.

Please apply to the posting

No phone calls please. Shortlisted candidates would be reached out",Full-time
4141499375,45680.0,Data Engineer,"Key Responsibilities

Data Engineering & Automation


 * Develop, optimize, and maintain ETL/ELT pipelines to process large datasets from various sources.
 * Automate repetitive data processing tasks, including Excel workbook updates, reporting workflows, and data cleaning.
 * Ensure data quality, accuracy, and security across pipelines, implementing best practices for data integrity and governance.
   
   

Data Analysis & Insights


 * Query, analyze, and generate reports from large datasets to drive business decision-making.
 * Develop data models, dashboards, and reports using SQL, Python, or BI tools.
 * Collaborate with cross-functional teams to understand business data needs and provide scalable solutions.
   
   

Qualifications

Required Education & Experience:


 * Bachelor’s degree in Computer Science, Information Systems, Data Science, or a related field.
 * Minimum 4 years of experience in data engineering, data analytics, or a related field.
   
   

Required Skills


 * Strong SQL skills, including complex queries, performance tuning, and handling large datasets efficiently.
 * In-depth knowledge of indexing strategies (e.g., B-tree, composite indexes) and when to use them.
 * Experience with partitioning, materialized views, and caching mechanisms for database optimization.
 * Proven ability to assess schema design and diagnose bottlenecks (e.g., full table scans, inefficient joins).
 * Proficiency in scripting with Python, Ruby, or a similar language for automation and data processing.
 * Hands-on experience designing and maintaining ETL/ELT processes and data pipeline automation.
 * Experience with Excel automation using Python, VBA, or Power Query.
 * Strong understanding of data warehousing principles, schema design, and best practices for scalability and performance.
   
   

Preferred Skills


 * Experience with BI tools such as Tableau, Power BI, or Looker.
 * Knowledge of data governance, security, and compliance best practices in a corporate environment.
   
   

Soft Skills


 * Ability to translate complex business needs into efficient technical data solutions.
 * Strong problem-solving skills with the ability to work independently and in a team.
   
   

Excellent written and verbal communication skills, with the ability to convey technical concepts to non-technical stakeholders.

The total compensation package for this position will also include incentive compensation and benefits such as health insurance, unlimited paid time off, parental leave, a 401k matching program, and other benefits to its employees.

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, gender identity, sexual orientation, protected veteran status, or any other characteristic protected by law.",Full-time
4126028458,3152304.0,Data Analytics Engineer," * Please note that we are only considering candidates who are legally authorized to work in the United States without the need for employer sponsorship, now or in the future.***
   
   

About Us

Trolley Hospitality Companies is comprised of catering, restaurant, vending, and corporate dining divisions spanning from Charlottesville to the Hampton Roads area. We were awarded one of the Top Workplaces by the Richmond Times-Dispatch three years running and have consistently been voted one of Richmond's top caterers by Style Weekly and Virginia Living Magazine as well as named 'Operator of the Year' by the National Automatic Merchandising Association.

We understand that our success is driven by the dedication and passion of our employees and together we are committed to fulfilling our purpose of delivering happiness to our customers, our community, and our employees. We hope you will join us!

Our Values - The Trolley Way


 * No excuses
 * Do the right thing
 * Can-do attitude
 * Always growing
 * Help first--be part of the solution
 * Transparency and honesty--no BS
   
   

Please visit our website at www.trolleyhouseva.com to learn more!

About You


 * You can visualize how to organize processes for best efficiency
 * Taming data overload is your superpower
 * You have a passion for understanding needs and using technology to deliver value
 * You have a strong knowledge of best practices
 * You understand the importance of meeting deadlines and commitments
 * You take pride in consistent and timely communication with your team
 * You like being exceptionally good at what you do
 * You are willing to own your mistakes and learn from them
   
   

How You Will Make An Impact

Trolley is committed to utilizing data and technology to make good business decisions. As we continue to grow, we are looking for a Data Analytics Engineer with a strong focus on automation to streamline our data processes and enhance efficiency. Here are some of the things you will be doing:


 * Data Lakehouse Management: Lead the development and maintenance of our data lakehouse, leveraging your expertise in Microsoft Fabric.
 * SQL Proficiency: Write custom SQL queries, focusing on T-SQL and Spark SQL to create views in the lakehouse.
 * API Integration: Evaluate and integrate various web APIs to enhance lakehouse capabilities and ensure seamless data flow.
 * Advanced Automation: Develop automated systems for data retrieval, processing, and integration from diverse sources, including APIs and ERP systems.
 * Data Translation and Parsing: Use Python or PySpark for data translation and parsing, ensuring data integrity.
 * SaaS Platform Support: Provide user support across various SaaS platforms, optimizing the user experience.
 * Data Governance: Assist in developing and enforcing data governance policies to ensure compliance and data quality.
 * Report Creation and Data Analytics: Utilize Power BI to create insightful reports, supporting informed decision-making.
 * Team Collaboration: Work effectively within a team, showcasing strong communication skills and a collaborative spirit. Act as a backup for data and IT issues when team members are unavailable, liaising with our outsourced IT provider as needed.
   
   

What You Bring To The Table


 * Bachelor's or Master's degree in Computer Science, Data Science, Engineering, or a related field
 * Proven experience in data engineering, with a focus on data warehouses and Microsoft Fabric
 * Proficiency in SQL and T-SQL for writing custom queries and creating views
 * Experience with Python or PySpark for data translation and parsing
 * Experience in supporting SaaS platforms like HubSpot, Total Party Planner, VendSys, Quickbooks, and iSolved
 * Knowledge of data governance principles
 * Competency in Power BI for reporting and data analysis
 * Excellent communication skills for effective teamwork
 * Familiarity with online ordering platforms and supplier data management preferred
 * Basic IT knowledge, particularly in troubleshooting and understanding IT-related challenges, a plus (resolution is managed through an outsourced IT provider)
   
   

The Good Stuff


 * Starting salary of $85k-$92k a year
 * Paid holidays and PTO
 * Medical, Dental, and Vision insurance plans available
 * 401(k) retirement plan and company match after 1 year of employment
 * Company paid Life and Short Term Disability insurance
 * Free lunch provided daily in the breakroom
 * Discounts at all Trolley House Hospitality companies including catering services and vending items in our warehouse
   
   

Salary: $85000 - $92000 per year",Full-time
4045412560,66321745.0,Software Engineer - Junior Level(Remote),"The Job Market is Challenging due to more than 150,000 Tech Layoffs in 2022 and in 2023 more than 240,000 layoffs so almost 3,90,00 tech employees have been laid off since 2022 and its still going on . The effect of this has led hundreds of thousands of laid off Tech employees competing with existing Jobseekers. Entry level Job seekers struggle to get responses to their applications, are getting ghosted after interviews. In such a scenario the Job seekers need to differentiate themselves by ensuring to obtain exceptional skills and technologies to be hired by clients as its an employer's market presently and they have a lot of hiring choices.

For more than 12&plus; years Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.

All Positions are open for all visas and US citizens

We are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this challenging economy every client wants to save $$$'s and they want the best value for their money. Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs as Clients now post covid can also hire remote workers which increases even more competition for jobseekers.

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in IT Industry

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We also offer optionally Skill and technology enhancement programs for candidates who are either missing skills or are lacking Industry/Client experience with Projects and skills. Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. If they are qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients. Shortlisting and selection is totally based on clients discretion not ours.

please check the below links to see success outcomes of our candidates and our participation at different Tech industry events and how we are different from other organizations in helping Jobseekers secure Tech careers

https://www.synergisticit.com/candidate-outcomes/

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

Oracle CloudWorld Event (OCW) Las Vegas 2023/ 2022 | SynergisticIT - YouTube

https://youtu.be/Rfn8Y0gnfL8?si=p2V4KFv5HukJXTrn

https://youtu.be/-HkNN1ag6Zk?si=1NRfgsvL_HJMVb6Q

https://www.youtube.com/watch?v=NVBU9RYZ6UI

https://www.youtube.com/watch?v=EmO7NrWHkLM

https://www.youtube.com/watch?v=NVBU9RYZ6UI

https://www.youtube.com/watch?v=OAFOhcGy9Z8

https://www.youtube.com/watch?v=Yy74yvjatVg

For preparing for interviews please visit https://www.synergisticit.com/interview-questions/

We are looking for the right matching candidates for our clients

Please apply via the job posting

REQUIRED SKILLS For Java /Full Stack/Software Programmer


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Project work on the skills
 * Knowledge of Core Java , javascript , C&plus;&plus; or software programming
 * Spring boot, Microservices, Docker, Jenkins and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning Positions

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Project work on the technologies needed
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, PowerBI, SAS, Tensorflow

If you get emails from our skill enhancement team please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates

At SynergisticIT, we're all about making connections. Whatever IT goals you have, our software programmers can help achieve those. Our Software development teams can take up turnkey projects and execute them in an effective and efficient manner. If you are looking to source talent our recruiters will find the ideal IT talent for your company. What's the secret to our success? Well, it all starts with taking quality time to listen to each client's specific needs. After we have a thorough grasp of your IT goals, we can better customize our Developments as per your specific needs. We can also tailor make recruiting programs to exceed your expectations. Since our founding in 2010, SynergisticIT's strategies have earned the company an enviable position in the software development, IT staffing and IT skill enhancement fields. SynergisticIT continues to work with hundreds of satisfied American clients with our software programmers working on our projects and after gaining hands on experience on cutting edge technologies moving to contribute their skills to great clients like Apple, Google, Client, Ebay, Paypal, Kroger, the Walt Disney Company and hundreds more. If you are tired of working with inefficient programmers who take a lot of time to ramp up we want you to try us. Our software programmers can hit the ground running and get you the maximum return on your investment. You have already tried the rest its time you tried the best. SynergisticIT - Home of the Best Data Scientists and Software Programmers in the Bay Area.

Why Us ?

SynergisticIT has a proven track record of successfully skill enhancement and staffing IT employees for some of the world's most iconic brands. Our team takes the time to fully understand every client's needs so we could best meet your IT staffing requirements. The knowledgeable staff at SynergisticIT is always more than happy to work with clients to ensure they reach their software development goals. Besides staffing, SynergisticIT is also committed to helping young IT professionals advance their career with a robust upskill program . Everyone who goes through SynergisticIT's program learns all the skills necessary to succeed in many IT fields ranging from Java to Machine Learning. Additionally, everyone trained at SynergisticIT has been through extensive mock and technical interview screenings to bolster their career prospects. Last, but certainly not least, SynergisticIT takes great care to respect the privacy considerations for every client. All companies who work with SynergisticIT can rest assured their confidential data is protected using the most up-to-date encryption technologies. SynergisticIT also complies with all the latest NDA agreements.

REQUIRED SKILLS For Java /Software Programmers


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Project work on the skills
 * Knowledge of Core Java , javascript , C&plus;&plus; or software programming
 * Spring boot, Microservices, Docker, Jenkins and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Project work on the technologies needed
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, PowerBI, Time series analysis

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2022 and at Gartner Data Analytics Summit (Florida)-2023

Oracle CloudWorld Event (OCW) Las Vegas 2022 | SynergisticIT - YouTube

https://www.youtube.com/watch?v=OAFOhcGy9Z8

https://www.youtube.com/watch?v=EmO7NrWHkLM

https://www.youtube.com/watch?v=NVBU9RYZ6UI

https://www.youtube.com/watch?v=Yy74yvjatVg

SynergisticIT at Gartner Data and Analytics Summit 2023 - YouTube

For preparing for interviews please visit https://www.synergisticit.com/interview-questions/

We are looking for the right matching candidates for our clients

Please apply via the job posting

REQUIRED SKILLS For Java /Full Stack/Software Programmer


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Project work on the skills
 * Knowledge of Core Java , javascript , C&plus;&plus; or software programming
 * Spring boot, Microservices, Docker, Jenkins and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning Positions

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Project work on the technologies needed
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, PowerBI, Tensorflow

If you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Full-time
4118544073,18503560.0,Software Engineer (AI System),"About Pangaea Data

Pangaea Data (Pangaea) is a South San Francisco and London based business founded by Dr Vibhor Gupta and Prof Yike Guo (Director Data Science Institute at Imperial College London; Provost, Hong Kong University of Science and Technology). They have worked in medicine and computing for over 20 years and have raised over $300 million through their academic research, including a $110 million grant focused on development work on large language models in medicine. Pangaea’s AI platform, PALLUX, is configured on clinical guidelines to find more untreated (undiagnosed, miscoded, at-risk) and under-treated patients with hard-to-diagnose conditions for screening and treatment at the point of care. Pangaea’s advisors include industry veterans from healthcare and the life sciences, including Lord David Prior (former chairman, NHS England) and Mr. Andy Palmer (former CIO, Novartis).

The Role

Pangaea Data is looking for talented engineers to join its technical team and focus on the development, deployment, and maintenance of AI systems and services in the healthcare domain. The ideal candidate is a strong team player with a software engineering background and experience in deploying AI-based solutions.

Key Responsibilities

Technical Responsibilities


 * Design and develop backend systems that integrate healthcare AI/LLM modules for tasks such as data extraction, summarization or decision support.
 * Design and implement systems that integrate with the client side such as Web UI or EHR system.
 * Implement and maintain CI/CD pipelines for automating deployment, testing, and monitoring processes.
 * Work on deploying AI models as scalable microservices using containers and orchestration tools like Docker and Kubernetes.
 * Manage cloud-based AI deployments on Azure platform or other cloud platform or on-prem.
 * Write clean, maintainable, and well-documented code using languages such as Python, JavaScript, or other relevant technologies.
   
   

This role will also work closely with internal teams to:


 * Work closely with AI engineers, clinicians, scientific, and product teams to ensure that deployed tools meet functional and non-functional requirements.
 * Understand the users they engage with and the problems, pain points and requests they are seeing.
 * Clearly communicate our roadmap and product changes in advance of their launch.
 * Run early rounds of internal feedback gathering, before we launch to users.
 * Understand how our internal tooling can be improved for internal users.
 * Understand the high-level company vision and goals, and make sure these are reflected in ongoing product development.
   
   

Requirements

Technical Skills:


 * With university qualification (Bachelors, Masters, Doctorate) who have completed at least two years of university study in Computer Science, Informatics, Data Science, Engineering, or related.
 * 3+ years of large-scale commercial software engineering experience with a focus on backend development.
 * Strong programming skills in Python or Javascript (Node.js).
 * Hands-on experience with CI/CD tools (e.g. GitHub Actions, Azure Pipelines).
 * Familiarity with containerization (Docker)
 * Understanding of RESTful APIs and microservices architecture.
 * Experience with AI/ML-related tools and libraries (e.g., Hugging Face, LangChain, PyTorch) preferred
   
   

Personal Traits


 * A strong intuition for what makes products a joy to use.
 * Empathy for how different users will need different things out of a product at different stages, and how to effectively serve these different needs in one product.
 * Strong communication and mediation skills.
 * Strong people skills and the ability to engage all levels of the organization (especially the front line).
 * Ability to work collaboratively in a team environment.
 * Ability to communicate complex ideas effectively, both verbally and in writing, in English.
 * A strong software engineering background with machine learning expertise to understand how the user facing product will tie into backend and architectural decisions.
   
   

Nice To Have


 * Experience in software engineering in healthcare and pharmaceutical domains.
 * Experience in data pipelines and engineering in healthcare and pharmaceutical domains.
 * Strong knowledge and experience in AI/LLM.
   
   

Perks and Benefits


 * Flexible working hours.
 * Salary depending on experience.
 * Benefits include private medical insurance, life insurance and travel cards.
 * You would join a small, dedicated and fast-growing team.
 * You will have the opportunity to learn about building a startup business from experienced professionals and serial entrepreneurs.
 * We are currently supported by serial entrepreneurs and angel investors. You will have the opportunity to experience an investment life cycle for a startup and meet leading venture capitalists.
   
   

Application Contact Information

Please send your latest resume along with a cover letter to careers@pangaeadata.ai

General Information

Pangaea Data’s headquarters is in London (UK) with teams in San Francisco (US) and Hong Kong. For more information please visit www.pangaeadata.ai.

Pangaea Data is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, colour, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances.",Full-time
4084557055,66321745.0,Entry Level Data Engineer,"Since 2010 SynergisticIT has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients.

The Tech Job market has been affected by massive layoffs and since 2021 there have been more than 600,000.00 tech layoffs.

The Job market is Hyper Competitive. For 1 position 500-1000 candidates or more are applying and laid off job seekers are also competing for entry level Job positions.

Please see the below links to know more about Synergisticit and some useful tips

Synergisticit Pics /Salaries of Successful Candidates

Synergisticit at Oracle Cloudworld 2023

Synergisticit at Gartner Data & Analytics summit

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

We regularly interact with the Top Tech companies to give our candidates a competitive advantage.

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

We are continuously looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Data Engineers, Machine Learning engineers for full time positions with clients.

Who Should Apply? Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We need Data Science/Machine learning/Data Analyst and Java Full stack candidates

Preferred SKILLS For Java /Full Stack/Devops Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Knowledge of Core Java , javascript , C&plus;&plus; or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

For data Science/Data Analyst/AI/Machine learning Positions

Preferred SKILLS

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude

Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools

Candidates lacking technical skills can research our other programs which can assist in landing a Job

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Full-time
4063772757,801292.0,Data Engineer III,"ABSC is a technology and services company that combines the agility of a small business with proven processes refined over more than two decades in business. We specialize in supporting public sector clients in the Intelligence, Defense, Health, and Safety areas. As we continue to grow at a rapid pace, we need some amazing new recruits to join our team. We are seeking an experienced Data Engineer III to primarily support our contingent, based on award, upcoming program. If you are a strategic thinker with a passion for innovation, we would love to hear from you.

Seniority of this role: III is SENIOR

Clearance Required for this role: Secret

Requirements:


 * Bachelors Degree
 * 10 years of experience
   
   

Responsibilities:


 * Assembling large, complex sets of data that meet non-functional and functional business requirements.
 * Identifying, designing and implementing internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes.
 * Building required infrastructure for optimal extraction, transformation and loading of data from various data sources using Azure, AWS and Google technologies
 * Building analytical tools to utilize the data pipeline, providing actionable insight into key business performance metrics including operational efficiency and customer acquisition.
 * Working with stakeholders including data, design, product and executive teams and assisting them with data-related technical issues.
 * Working with stakeholders including the Executive, Product, Data and Design teams to support their data infrastructure needs while assisting with data-related technical issues.
   
   

Who we are:

ABSC is a technology and services company that combines the agility of a small business with proven processes refined over more than two decades in business. We specialize in supporting public sector clients in the Intelligence, Defense, Health, and Safety areas. Our team stands ready to deliver the next generation of programs, personnel, and solutions to help advance our federal government customers’ driving innovation, agility, and security across all mission areas.

Some of our benefits include:

4 weeks of PTO plus 11 Federal Holidays

Retirement Planning – 401k Fully Vested with Match

Tuition Assistance Program – Annual contributions to help you pay down your loans

Annual Health and Wellness Allowance – buy an Apple Watch, a treadmill, or hit the gym on us

Career Development – 5,250 Annual Funds to spend on Education and Training

Volunteer Time Off – Annually, all employees can spend 8 hours directly supporting a charity of choice

Charitable Match – ABSC matches up to 250 USD of an employee’s donation to a qualifying charity

Paid Parental Leave –Employees receive 3 weeks of paid parental leave at 100% pay

Referral Program – We pay for internal and external referrals!

LOV Awards – Earn bonus awards throughout the year from our Living Our Values awards program

Apply to join our team today! We are always looking to grow our team - if you know someone who is seeking a new career opportunity, please share this job opening with them! ABSC offers generous external referral bonuses. You don’t need to be an employee to benefit from our Referral Program!


 * ABSC is a proud V3, Virginia Values Vets, member which recognizes our commitment to hiring Veterans. If you are a veteran, please be sure to include that in your application. Thank you! *
   
   

Absolute Business Solutions Corp. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. Equal Employment Opportunity Posters https://www.dol.gov/agencies/ofccp/posters; If you’d like to view a copy of the company’s affirmative action plan or policy statement, please email HR@absc-us.com.

If you are an individual with a disability and would like to request a reasonable accommodation as part of the employment selection process, please contact ABSC Human Resources at 703-437-3000 or HR@absc-us.com. Please do not call about the status of your job application if you do not require accessibility assistance or an accommodation. Messages left for other purposes, such as following up on an application or non-disability related technical issues, will not receive a response.",Full-time
4151647150,8194.0,Data Engineer,"Job Description

We are looking for a Data Engineer with outstanding technical skills. This position is essential for designing, building, and maintaining our Data Platform. It requires a strong grasp of data platforms, cloud data architecture, and practical experience with Azure Data services. This role specializes in the conceptual design, capacity planning, interface specifications, data loading and maintenance, data integration and processing, building data pipelines, centralized data stores and databases and data security associated with data collection along with Big Data platform development and deployment.


 * Collaborate with our infrastructure, database management teams and the broader IT organization to design, build, and manage scalable, efficient data processing systems both on-premises and in the cloud.
 * Develop and maintain high-performance ETL/ELT pipelines to transfer large datasets across systems, ensuring data integrity and reliability.
 * Architect and optimize data solutions on Azure, leveraging services such as Azure Data Lake, Synapse Analytics, SQL Data Warehouse, and Blob Storage.
 * Integrate data from various sources, including on-prem systems, third-party platforms, and external sources, using tools like Azure Data Factory and Databricks.
 * Work closely with our Database management team to Manage Azure-based databases, ensuring data consistency, security, and seamless accessibility.
 * Implement and enforce data governance policies, encryption protocols, and access controls to meet security and compliance standards.
 * Proactively monitor data pipelines, resolve issues, and apply data validation to ensure high data quality and accuracy.
 * Work closely with data scientists, analysts, DBA’s and business teams to understand data requirements and deliver tailored solutions.
 * Optimize data storage and query performance in cloud environments, ensuring scalability, cost-efficiency, and high availability.
 * Onboarding, consolidating, cleansing, and structuring data for efficient use in reports, analytical applications, and machine learning models.
 * Collaborate with AI/ML teams to train and fine-tune ML models, enabling rapid experimentation and deployment with large datasets.
 * Document architecture, data pipelines, and models, producing detailed reports on data flow and system performance.
 * Implement DevOps practices for the Data Function, including CI/CD pipelines using tools like GitLab, Jenkins, Puppet, or Chef.
 * Leverage Infrastructure as Code (IaC), test-driven development, and agile methodologies to scale data solutions.
   
   

Traits we believe make a strong candidate.


 * Proven experience in designing and implementing data architectures on Azure or similar platforms.
 * Expertise in data integration tools and techniques, with a strong focus on performance optimization and security.
 * Hands-on experience with Azure Synapse Analytics, Azure Data Factory, and other Azure data services, Azure DevOps, CI/CD data pipelines, and cloud-based development practices.
 * Proficient in SQL and data modeling, expertise in programing languages like Python or Scala
 * A Team player with strong collaboration and problem-solving skills to translate complex data needs into actionable solutions.
   
   

Preferred Education & Experience


 * At least 6 years of experience as Data Engineer
 * Bachelor’s degree in computer science, Data Science, or a related field
 * Azure certifications, such as Azure Solutions Architect
   
   

EQUAL OPPORTUNITY STATEMENT

It is the policy of Axcelis to provide equal opportunity in all areas of employment for all persons free from discrimination based on race, sex, religion, age, color, national origin, disability status, medical condition (including pregnancy), veteran status, sexual orientation, marital status, or any other characteristic protected by federal, state or local law. Axcelis will provide reasonable accommodation necessary to enable a disabled candidate or employee to perform the essential functions of the position, unless the accommodation would create an undue hardship for the Company.",Full-time
4138569748,106170142.0,Data Engineer,"About Us

Luxe Vision Consulting is a Wisconsin-based consulting firm dedicated to connecting top global talent with leading U.S. companies. We specialize in sourcing skilled professionals, conducting rigorous screening and technical assessments, and preparing candidates for opportunities in the U.S. job market.

Our mission is to bridge the gap between exceptional talent and top-tier businesses, ensuring the right fit for both candidates and clients. With a focus on quality, efficiency, and innovation, we help professionals unlock their potential and secure rewarding careers with prestigious U.S. organizations.

At Luxe Vision Consulting, we believe in integrity, excellence, and results-driven recruitment. Whether you're a company looking for the best talent or a professional seeking your next big opportunity, we are committed to making the connection that drives success.

The Role

Job Description

We are looking for a skilled Data Engineer to join our team. The ideal candidate will have strong experience in designing, building, and maintaining scalable data pipelines and architectures. You will play a critical role in managing data workflows, ensuring data integrity, and optimizing data processing.

Responsibilities


 * Data Pipeline Development: Design, build, and maintain scalable and efficient data pipelines to process and transform large datasets.
 * ETL & Data Integration: Develop and optimize ETL (Extract, Transform, Load) workflows for structured and unstructured data sources.
 * Big Data Processing: Work with PySpark and Pandas to handle large-scale data processing tasks.
 * Database Management: Design, implement, and manage relational (SQL) and non-relational databases for data storage and retrieval.
 * Cloud Technologies: Leverage cloud platforms such as AWS, GCP, or Azure to deploy and manage data infrastructure.
 * Collaboration: Work closely with data scientists, analysts, and software engineers to support analytical and machine learning projects.
 * Data Quality & Performance Optimization: Ensure data accuracy, consistency, and security while optimizing performance.
 * Monitoring & Troubleshooting: Identify and resolve data pipeline performance bottlenecks and failures.
   
   

Ideal Profile

Required Work Experience


 * 2+ years of experience in data engineering or a related field.
 * Proven experience developing ETL pipelines and data processing workflows.
 * Hands-on experience with PySpark, Pandas, and SQL.
 * Experience working with big data technologies such as Apache Spark, Hadoop, or Kafka (preferred).
 * Familiarity with cloud data solutions (AWS, GCP, or Azure).
   
   

Required Skills


 * Programming: Strong proficiency in Python (PySpark, Pandas) or Scala.
 * Data Modeling & Storage: Experience with relational databases (PostgreSQL, MySQL, SQL Server) and NoSQL databases (MongoDB, Cassandra).
 * Big Data & Distributed Computing: Knowledge of Apache Spark, Hadoop, or Kafka.
 * ETL & Data Integration: Ability to develop efficient ETL processes and manage data pipelines.
 * Cloud Computing: Experience with AWS (S3, Redshift, Glue), GCP (BigQuery), or Azure (Data Factory, Synapse).
 * Data Warehousing: Understanding of data warehousing concepts and best practices.
 * Problem-Solving: Strong analytical skills to troubleshoot and optimize data pipelines.
 * Communication: Must be proficient in spoken English to collaborate with US-based teams.
   
   

Education Requirements


 * Bachelor’s degree in Computer Science, Data Engineering, Information Technology, or a related field (preferred).
 * Equivalent work experience in data engineering will also be considered.
   
   

Fill out the application form here: https://forms.gle/nefgwYRFYE7mffdA7

Alternatively, feel free to message us directly here on the page or email your resume to hiring@ luxevisionconsulting com

📑Subject: Position - First and Last Name

Only shortlisted candidates will be contacted. We look forward to hearing from you!

What's on Offer?


 * Work within a company with a solid track record of success
 * Attractive salary & benefits
 * Excellent career development opportunities",Full-time
4150457380,2302613.0,Data Engineer,"Reports To: Director, Customer Data and Analytics




Direct Reports: 0




FLSA Status: Exempt (Not eligible for OT)




Employment Type: Full time




Location: Candidates must reside in the U.S. and have U.S. work authorization to be considered.




Position Overview: The Data Engineer will play a critical role in designing, implementing, and maintaining National Safety Apparel’s Snowflake Data Warehouse. This position requires strong technical expertise in Snowflake and ETL processes, with a preference for familiarity with Matillion. The ideal candidate will collaborate closely with cross-functional teams to optimize data infrastructure and ensure that high-quality, secure, and compliant data is available to drive informed decision-making.




Essential Job Functions:

 * Data Warehouse Development: Design, build, and maintain a robust Snowflake Data Warehouse tailored to the organization’s needs.
 * ETL Development: Create and manage ETL pipelines using Matillion to integrate data from multiple sources into Snowflake.
 * Performance Optimization: Optimize Snowflake queries and data models to enhance scalability and efficiency.
 * Collaboration: Partner with business stakeholders, analysts, and data scientists to understand data requirements and deliver solutions aligned with strategic goals.
 * Data Integration: Ensure seamless integration of diverse data sources into the Snowflake platform.
 * Documentation: Develop and maintain clear and comprehensive documentation of data processes, system architecture, and data models.
 * Data Quality Assurance: Implement monitoring and validation processes to maintain data integrity and address inconsistencies.




Non-Essential Job Functions: Other duties as assigned




Training: On the job




Qualifications:

Education & Certifications:

 * Bachelor’s Degree in Computer Science, Information Systems, or a related field.
 * Preferred: Master’s Degree in Data Engineering, Business Analytics, or a related discipline.
 * Certifications: SnowPro Certification or similar is a plus.




Experience: 3 years of experience in data warehousing, ETL development, and data modeling. They should possess strong proficiency in Snowflake, including querying, performance tuning, and data modeling. Familiarity with Matillion or similar ETL tools is preferred, along with hands-on experience in SQL and cloud platforms.




Key Competencies: Advanced Excel and PowerPoint Skills, Team-Oriented, Problem-Solving, Time Management, Flexible, Highly Organized, Detail-Oriented, Professional Communication (written & verbal), Data-Driven, Process-Oriented, Analytical, Strong Business / Financial Acumen




Physical Requirements: Long periods of sitting or standing at an individual workstation, heavy computer work.




Working Conditions: Daily work in a temperature-controlled office environment, heavy computer work, must be able to stand/sit for duration of workday.




EEO Statement: National Safety Apparel provides equal employment opportunities for all persons regardless of race, color, religion, sex, national origin, handicap, disability, ancestry, age, veteran status, marital status, sexual orientation or any other protected group status as defined by law.",Full-time
4148901841,92893317.0,Founding Software Engineer – Data Infrastructure,"At Windfall Bio, we are pioneers in biotech innovation, tackling some of the world’s most critical environmental challenges. Our breakthrough solutions focus on capturing and transforming climate-harming methane emissions into beneficial products. Utilizing cutting-edge technology and methane-eating microbes, we convert methane from various sources into valuable outputs, such as organic fertilizers. This nature-based approach provides a sustainable method for industries like agriculture, oil and gas, and waste management to significantly reduce their carbon footprint and environmental impact. Join us in our mission to create a cleaner, greener future.

About the Role

Data is a critical asset at Windfall Bio. Our products depend on collecting and processing data throughout the ""Methane Capture to Value"" pipeline to generate accurate, verifiable insights. Given our global enterprise customers, the data platform must be enterprise-grade and highly scalable.

As a founding engineer of the Software and AI team, you will:


 * Design, build, and operate scalable data infrastructure
 * Develop data pipelines and orchestrate ETL workflows
 * Create integration services for Carbon Credit Markets and ESG platforms
 * Manage sensor data collection and aggregation at the edge and in the cloud
 * Collaborate closely with scientists and bioengineers across the company
   
   

Your work will have a direct impact on saving the planet. For real. :)

About you

First and foremost, you're a senior software engineer who knows how to ship production-quality software. You love data and excel at building data pipelines and orchestrating ETL workflows. You're comfortable with both stream and batch processing. With prior startup experience, you balance tech debt, time-to-market, and infrastructure robustness. You've successfully built scalable, enterprise-grade software in high growth environments.


 * 5+ years of programming experience, preferably in Python
 * Strong knowledge of databases and ORMs
 * Experience in two or more of the following:
 * Data warehouses (e.g., Snowflake, BigQuery, Iceberg)
 * Data job orchestration (e.g., Dagster, Airflow)
 * Batch and stream processing (e.g., Kafka, Kinesis)
 * Data cataloging and life-cycle management
 * Experience with at least one public cloud provider (AWS, GCP, Azure)
 * Low ego, high empathy, and the capacity to collaborate effectively with scientists and bioengineers.
 * Thrive in a fast paced, ambiguous, high-growth environment
   
   

Nice to have


 * Experience with Kubernetes, Kubeflow
 * Are familiar working with Terraform or other IaC tools
   
   

Additional Information

Location

Hybrid, minimum 3 days in week in office San Mateo, Bay Area, California.

Benefits


 * Medical, Dental, and Vision Health Coverage
 * Maternity/Paternity Leave Policies
 * Flexible Spending Account
 * Employee Assistance Program
 * Flexible Vacation Policy
   
   

The base salary range for this full-time position is $150-$210k plus equity and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all locations. Within the range, individual pay is determined by factors including job-related skills, experience, relevant education or training, and location.

Windfall Bio prohibits unlawful discrimination based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin or ancestry, age, disability, marital status and veteran status.",Full-time
4127753445,165602.0,Python Data Engineer,"Immediate need for a talented Python Data Engineer. This is a 12+ Months Contract opportunity with long-term potential and is located in Jersey City, NJ (Hybrid). Please review the job description below and contact me ASAP if you are interested.




Job ID:25-56210




Pay Range: $68 - $70/hour. Employee benefits include, but are not limited to, health insurance (medical, dental, vision), 401(k) plan, and paid sick leave (depending on work location).



Key Responsibilities:




 * This role will be responsible for hands-on application development to support the current and target process, as well as partnering with the multiple Technology teams to implement the target architecture and migration to strategic platform.




Key Requirements and Technology Experience:




 * Skills-Python, Spark, Hadoop.
 * 8+ years of experience in Python development experience is a must.
 * 4+ years of experience in big data technologies like Spark, Hadoop.
 * 2+ years of SQL programming experience preferably with databases such as Oracle Exadata.
 * Knowledge of performance tuning data intensive applications.
 * Expertise in performance profiling, ability to identify performance improvements and memory optimizations.
 * Strong coding, debugging, and analytical skills.
 * Experience in large scale enterprise application design and implementation.
 * Creative individual with a track record of working on and implementing innovative tech based solutions.
 * Excellent communication skills.
 * Degree from outstanding university.
 * Background in Client calculations.
 * BS/MS in Computer Science, Engineering, or any quantitative discipline.
 * Knowledge and/or experience working within the Hadoop or other big data distributed ecosystem.
 * Knowledge of cloud computing or distributed computing.
 * 2+ years of Java development is preferred.
 * Experience working with agile methodologies and SDLC processes would be preferred.
 * 1+ years of UNIX scripting experience and unit test mock frameworks would be preferred.
 * Experience in Quartz (Internal bank platform) would be preferred but optional.




Our client is a leading Banking and Financial Industry and we are currently interviewing to fill this and other similar contract positions. If you are interested in this position, please apply online for immediate consideration.




Pyramid Consulting, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.




By applying to our jobs you agree to receive calls, AI-generated calls, text messages, or emails from Pyramid Consulting, Inc. and its affiliates, and contracted partners. Frequency varies for text messages. Message and data rates may apply. Carriers are not liable for delayed or undelivered messages. You can reply STOP to cancel and HELP for help. You can access our privacy policy here.

",Contract
4138895693,32150.0,Data Engineer,"Denodo is a leader in data management. The award-winning Denodo Platform is the leading data integration, management, and delivery platform using a logical approach to enable self- service BI, data science, hybrid/multi-cloud data integration, and enterprise data services. Realizing more than 400% ROI and millions of dollars in benefits, Denodo’s large enterprise and mid-market customers across 30+ industries have received payback in less than 6 months. For more information, visit www.denodo.com .

We are a fast-growing, international organization with teams across four continents and we work with a cutting-edge technology, but that's not all we have to offer. At Denodo, we are like a family and it is of the utmost importance to us that we help support your professional growth every step of the way

Job Description

Denodo Technologies, Inc. is seeking a Data Engineer in Chicago, IL to obtain and maintain strong knowledge of the Denodo Platform, be able to deliver a superb technical pitch, including overview of our key and advanced features and benefits, services offerings, differentiation, and competitive positioning.

Salary Range: $120,000-145,000/yr.

Job Responsibilities & Duties


 * Obtain and maintain strong knowledge of the Denodo Platform, be able to deliver a superb technical pitch, including overview of our key and advanced features and benefits, services offerings, differentiation, and competitive positioning.
 * Constantly learn new things and maintain an overview of modern technologies.
 * Be able to address a majority of technical questions concerning customization, integration, enterprise architecture and general feature / functionality of our product.
 * Capable of building and/or leading the development of custom deployments based and beyond client’s requirements.
 * Provide timely, prioritized and complete customer-based feedback to Product Management, Sales, Support and/or Development regarding client’s business cases, requirements and issues.
 * Train and engage clients in the product architecture, configuration, and use of the Denodo Platform.
 * Promote knowledge and best practices while managing deliverables and client expectations.
 * Manage client expectations, establish credibility at all levels within the client and build problem-solving partnerships with the client, partners and colleagues.
 * Provide technical consulting, training and support.
 * Develop white papers, presentations, training materials or documentation on related topics.
   
   

Required Skills

Desired Skills & Experience


 * Bachelor’s Degree in Computer Science, Information Systems, or a related field (or foreign equivalent)
 * 2 years of experience as a Data Engineer, Systems Engineer, or similar role
 * Demonstrated ability in SQL, relational and analytical database management, Java software development, JDBC, XML, Web Services APIs, and with version control systems.
   
   

Denodo is an equal opportunity employer and prohibits discrimination and harassment of any kind. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by applicable law. Denodo will provide reasonable accommodation to employees who have protected disabilities in accordance with applicable law.

We do not accept resumes from headhunters or suppliers that have not signed a formal fee agreement. Therefore, any resume received from an unapproved supplier will be considered unsolicited, and we will not be obligated to pay a referral fee.",Full-time
4051841829,11137552.0,Data Engineer - Active TS/SCI,"Data Engineer

San Antonio, Texas

The Data Engineer supports missions and functions for 16 AF Service needs and Air Forces Cyber (AFCYBER).

RESPONSIBILITIES AND DUTIES:


 * Supports/integrates enterprise database systems, using sound database management practices to organize and store data.
 * Interacts with development and end-user personnel to determine application data access requirements, transaction rates, volume analysis, and other pertinent data required to develop and maintain integrated databases.
 * Provides support and reviews web-based applications including on-line and internal applications to support client operations. The Web Provides support in developing the site concept, interface design, and architecture of the website.
 * Supports the implementation of interfaces to applications, reviews both client side and server-side code to allow web-based applications to deliver the correct content.
   
   

QUALIFICATIONS:

Be able to translate applications requirements into the design of complex web sites, including integrating web pages and applications.

Must be able to apply new and emerging technologies to the site development process.

EDUCATION REQUIREMENTS:


 * Bachelor's Degree in Computer Science, Information Technology, Database Management or related fields
 * Proficiency in programming languages such as Python, Scala, and SQL preferred
 * Additional certifications such as CCP, ABDE, or AWS Certified Data Analytics preferred
   
   

Skills And Certifications

Active TS/SCI",Full-time
4150916918,5279801.0,"Software Engineer Co-op, Firmware","Company Overview:

Bose Professional is a leader in the professional audio industry, specializing in the design and manufacturing of cutting-edge audio solutions including loudspeakers, amplifiers, signal processing devices, controls, software, and accessories. As we continue to expand our team, we are seeking a Software Engineer Co-op, Firmware to join us on our journey.

We have organized ourselves culturally around a set of shared values. We are a team first, which means we are collaborative and support each other toward our common goals. We start everything from the outside in, starting with the customer and solving from there. We value trust, so we are a company of people who are open and direct, avoid politics, and who do what it takes to deliver on our commitments. And as we work together, we are empathetic, courteous, and fair, because we respect each other. Finally, we believe that creativity and innovation belong in all parts of the company to drive excellence in everything we do.

Position Overview:

Do you love great sounding music with quality that brings joy to people’s lives? Would you love to work with a team that helps develop the best sounding Digital Signal processors, amplifiers, subwoofers, and loudspeakers in the world? Bose Professional is looking for an intern with a working knowledge of software development and an interest in gaining real-world software engineering experience at an innovative and thriving high-technology company.

You will work in a tight-knit team of Software Engineers to develop best-in-class professional audio software applications used to design, configure, and control Bose Professional audio amplifiers and signal processors that are used to drive our award-winning loudspeakers.   

Using your programming skills, you will be creating software for our next generation software middleware that would drive best-in-class digital signal processors, amplifiers and controls. 

Key Responsibilities:


 * Develop C/C++ software for embedded systems for our next-gen AV system.
 * Develop embedded software in one or more of the following areas:
 * communication protocols (e.g., UART, I2C, CAN, Bluetooth, Wi-Fi).
 * linux device-drivers for audio devices.
 * embedded software services for cloud connectivity and telemetry
 * networking & connectivity
   
   

Qualifications:


 * The ideal candidate will be either in a Master’s program or in their Junior or Senior year of study in the 2025 calendar year with emphasis in Computer Engineering, Electrical Engineering or a related STEM field such as math or physics.
 * Demonstrate an understanding of basic algorithms, data structures, and design principles.
 * Code—and debug code—in C/C++
 * Use test-driven development and automated testing frameworks.
 * Have clear verbal and written communication skills.
 * Experience with real-time processing on embedded systems (e.g., ARM, Raspberry Pi) is desirable
   
   

Bose Professional is an equal opportunity employer and values diversity in the workplace. We encourage all qualified individuals to apply.

Position/Title: Software Engineer Co-op, Firmware

Location: Hopkinton, MA - Hybrid

Reports to: Director of Software Engineering

Department: Engineering

Powered by JazzHR

2kMeeohetA",Internship
4092494925,3559341.0,"Senior Software Engineer, Brand","Everyone is welcome at Handshake. We know diverse teams build better products and we are committed to creating an inclusive culture built on a foundation of respect for all individuals. We strongly encourage candidates from non-traditional backgrounds, historically marginalized or underrepresented groups to apply.

Your impact

Handshake is hiring a Senior Software Engineer to join our Brand Team. In this role, you'll play a pivotal part in our mission to build a robust Branding platform that enables nearly 1 million employers to amplify their reach to over 15 million students and 1,500+ educational partners.

Although we’ve already launched a promising MVP, this initiative is just beginning to reveal its potential. As we scale and expand, we’re looking for talented engineers to help elevate our systems and build features that drive significant business revenue.

The platform and features you develop will directly contribute to Handshake’s revenue streams while positively impacting key performance indicators such as engagement and adoption. You’ll lead large-scale projects through every stage of development—from brainstorming and refining requirements to architectural design, scoping, execution, and final release.

Your role

As a Senior Software Engineer, your day-to-day will involve collaboration and impact across multiple domains:


 * Cross-functional teamwork: Work closely with designers, product managers, and fellow engineers to develop exceptional solutions. Engage with teams across the organization, including data analytics, support, and marketing.
 * Build impactful features: Architect and deliver scalable, high-quality features that SMB employers use daily.
 * Lead projects: Own and deliver sizable projects, including those requiring collaboration across multiple engineers and teams.
 * Maintain high standards: Lead by example in producing quality code and providing thoughtful feedback in reviews and architecture discussions. Contribute to organization level technical enhancements.
 * Shape the roadmap: Use your expertise to influence team priorities, balancing innovation with operational health initiatives like quality control, on-call reliability and technical excellence.
 * Mentor and guide: Provide mentorship to junior engineers, unblocking challenges, and fostering growth within the team.
   
   

Your Experience

We’re seeking candidates who bring:


 * Extensive experience: 6+ years as a full-stack engineer with confidence driving architectural decisions on both backend and frontend systems.
 * Proven collaboration: Success in partnering with product, design, and analytics teams to define, build, and launch impactful systems and experiences.
 * Scalable solutions: A track record of implementing complex, scalable, and highly available services that power high-traffic platforms across web and mobile.
 * Leadership in execution: Experience leading significant user-focused projects from strategy to delivery with high quality.
 * Empathy and mentorship: Strong interpersonal skills to provide guidance and support to your team, fostering a culture of growth and excellence.
 * Commitment to growth: A proactive approach to feedback and continuous improvement in code, processes, and team dynamics.
 * Effective communication: The ability to articulate technical concepts to both technical and non-technical audiences.
   
   

Bonus areas of expertise


 * Experience with Ruby on Rails, GraphQL, PostgreSQL, ReactJS, Google Cloud Platform (GCP) or similar technologies.
 * Familiarity with SMB SaaS products or Ed-Tech at scale.
 * Demonstrated ownership mentality and accountability in delivering impactful work.
   
   

Compensation Range

$180,000 - $260,000

For cash compensation, we set standard ranges for all U.S.-based roles based on function, level, and geographic location, benchmarked against similar stage growth companies. In order to be compliant with local legislation, as well as to provide greater transparency to candidates, we share salary ranges on all job postings regardless of desired hiring location. Final offer amounts are determined by multiple factors, including geographic location as well as candidate experience and expertise, and may vary from the amounts listed above.

About Us

Handshake is the career platform for Gen Z. With a community of over 17 million students, alumni, employers, and career educators, Handshake’s network is where career advice and discovery turn into first, second, and third jobs. Nearly 1 million companies use Handshake to build their future workforce—from Fortune 500 to federal agencies, school districts to startups, healthcare systems to small businesses. Handshake is built for where you’re going, not where you’ve been.

When it comes to our workforce strategy, we’ve thought deeply about how work-life should look at Handshake. With our hybrid-work model, employees benefit from collaboration and shared team experiences three days per week in our vibrant offices, and enjoy the flexibility of remote work two days per week. Handshake is headquartered in San Francisco, with offices in New York, London, and Berlin.

What we offer

At Handshake, we'll give you the tools to feel healthy, happy and secure.

Benefits Below Apply To Employees In Full-time Positions.


 * 💰 Equity and ownership in a fast-growing company.
 * 🍼 16 Weeks of paid parental leave for birth giving parents & 10 weeks of paid parental leave for non-birth giving parents.
 * 💝 Comprehensive medical, dental, and vision policies including LGTBQ+ Coverage. We also provide resources for Mental Health Assistance, Employee Assistance Programs and counseling support.
 * 💻 Handshake offers $500/£360 home office stipend for you to spend during your first 3 months to create a productive and comfortable workspace at home.
 * 📚 Generous learning & development opportunities and an annual $2,000/£1,500/€1,850 stipend for you to grow your skills and career.
 * 💰 Financial coaching through Origin to help you through your financial journey.
 * 🛜 Monthly internet stipend and a brand new MacBook to allow you to do your best work.
 * 🚃 Monthly commuter stipend for you to expense your travel to the office (for office-based employees).
 * 🥗 Free lunch provided twice a week across all offices.
 * 🤝 Referral bonus to reward you when you bring great talent to Handshake.
   
   

(US-specific Benefits, In Addition To The First Section)


 * 🏦 401k Match: Handshake offers a dollar-for-dollar match on 1% of deferred salary, up to a maximum of $1,200 per year.
 * 🏝 All full-time US-based Handshakers are eligible for our flexible time off policy to get out and see the world. In addition, we offer 8 standardized holidays, and 2 additional days of flexible holiday time off. Lastly, we have a Winter #ShakeBreak, a one-week period of Collective Time Off.
 * 🍼 Family support: We partner with Milk Stork to provide comprehensive 100% employer-sponsored lactation support to traveling parents and guardians. Parental leave coaching and support provided by Parentaly.
   
   

(UK-specific Benefits, In Addition To The First Section)


 * 🏦 Pension Scheme: Handshake will provide you with a workplace pension, where you will make contributions based on 5% of your salary. Handshake will pay the equivalent of 3% towards your pension plan, subject to qualifying earnings limits.
 * 🏝 Up to 25 days of vacation to encourage people to reset, recharge, and refresh, in addition to 8 bank holidays throughout the year.
 * 🤝 Regular offsites each year to bring the team together + opportunity to travel to our HQ in San Francisco.
 * 🛍️ Discounts across various high street retailers, cinemas and other social activities exclusively for Handshake UK employees.
   
   

(Germany-specific Benefits, In Addition To The First Section)


 * 🏝 25 days of annual leave + 5 days of a winter #ShakeBreak, a one-week period of Collective Time Off across the company.
 * 🤝 Regular offsites each year to bring the team together + opportunity to travel to our HQ in San Francisco once a year.
 * 🧘 Urban sports club membership offering access to a diverse network of fitness and wellness facilities.
 * 🛍️ Discounts across various high street retailers, cinemas and other social activities exclusively for Handshake Germany employees.
   
   

Looking for more? Explore our mission, values and comprehensive US benefits at joinhandshake.com/careers.

Handshake is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or reasonable accommodation, please let your recruiter know during initial communications.",Full-time
4067600259,5827.0,Data Engineer 2,"Department: Information Services

Classification: Analyst Programmer 2

Appointment Type and Duration: Regular, Ongoing

Salary: $62,028 - $115,128 per year

FTE: 1.0

Hybrid eligible

Review of Applications Begins

December 2, 2024; position open until filled

Special Instructions to Applicants

To be considered for this position, applicants must submit a complete application. Complete applications must include an online application and resume that address how you meet the minimum and preferred qualifications.

We are interested in finding the best candidate for this position. We encourage you to apply, even if you don't think you meet every one of our preferred qualifications - use your application to let us know what is meaningful to you about the role and what transferable skills or other qualities you would bring.

Department Summary

Information Services (IS) is the central information technology unit at the University of Oregon and provides wide ranging services to campus. Information Services consists of four major functional areas: Customer Experience, which serves as the key contact point for interactions with campus clients and customers; Enterprise Solutions, which manages and supports applications, integration services, identity management and data management; Information Security, which helps protect virtual or physical information; and Technology Infrastructure, which provides administration and support for the software, hardware, and services needed to support the campus IT environment. Information Services also includes the Advanced Network Technology Center. IS works closely with the Network for Education and Research in Oregon.

Established in 1876, the University of Oregon offers a breadth and depth of curricula with more than 270 academic programs and provides the opportunity to work at a respected research university with a strong holistic, liberal arts foundation. The UO also has a history of political and social involvement that embraces diverse beliefs, cultures, and values, and it is committed to environmental responsibility.

The University is also proud of the newly-announced Phil and Penny Knight Campus for Accelerating Scientific Impact, an initiative specifically designed to fast-track scientific discoveries and the process of turning those discoveries into innovations that improve the quality of life for people in Oregon, the nation and beyond. Information Services collaborates with Research and Innovation and our schools and colleges to support the research, teaching, and learning mission of the University.

Eugene is the home of the University of Oregon. Located in the lush Willamette Valley, Eugene is well-known for outdoor pursuits like running, cycling, rafting, and fishing, as well as arts, music, crafts, brewing, wine-making, and community-supported agriculture. With branches in Portland and on the Oregon coast, the UO is deeply connected to Oregon's natural and cultural treasures.

Position Summary

The Data Engineer 2 position is responsible for data pipeline, transformation, and model planning, design, development, and support for enterprise data warehouses and data lakes. This position works alongside other data professionals like Architects, ETL Developers and Data Analysts, both internal and external to the department, to meet critical data and analytical needs of the institution. Additional collaboration happens with ERP Developers or other technical staff to respond to changes in source systems, to maintain high quality and timely data pipelines.

This position develops and maintains high quality and up-to-date critical system documentation. This position provides expertise and consultation to other Information Services teams with regards to data structures and pipelines. This position functions within a team to initiate, promote and coordinate activities to foster growth within the university business intelligence community. This position has no budget authority and no supervisory authority.

Minimum Requirements

This classification requires a basic foundation of knowledge and skills in systems analysis and related programming support functions generally obtained by a bachelor's degree in computer science or an equivalent amount of training and applied experience.

Professional Competencies


 * Ability to work effectively with faculty, staff, and students from a variety of diverse backgrounds.
 * Demonstrated advanced problem-solving skills.
 * Excellent verbal and written communication skills, including the ability to explain technical concepts to audiences with a wide range of technical skills.
 * Ability to adapt within a rapidly changing technical environment.
 * Ability to work independently as well as in a team-oriented, collaborative environment.
 * Keen attention to detail in analysis and validation and strong organizational skills.
   
   

Preferred Qualifications


 * Experience with Ellucian Banner, ODS and/or EDW.
 * Experience with Oracle Databases and/or Oracle Data Integrator (ODI).
 * Experience with IBM Cognos or Microsoft Power B.l
 * Experience with Microsoft Azure or AWS data warehouse and data lake technologies.
 * Experience developing complex SQL.
 * Experience developing with python.
 * Experience with DataOps or DevOps tools and processes, such as git, Jenkins, DBT or Azure DevOps.
 * Experience with Agile development methodology.
 * Experience with ITIL version 4 or ITSM (Information Technology Service Methodology).
   
   

FLSA Exempt: Yes

All offers of employment are contingent upon successful completion of a background check.

This is a classified position represented by the SEIU Local 503, Oregon Public Employees Union.

The University of Oregon is proud to offer a robust benefits package to eligible employees, including health insurance, retirement plans, and paid time off. For more information about benefits, visit https://hr.uoregon.edu/about-benefits .

The University of Oregon is an equal opportunity, affirmative action institution committed to cultural diversity and compliance with the ADA. The University encourages all qualified individuals to apply and does not discriminate on the basis of any protected status, including veteran and disability status. The University is committed to providing reasonable accommodations to applicants and employees with disabilities. To request an accommodation in connection with the application process, please contact us at uocareers@uoregon.edu or 541-346-5112.

UO prohibits discrimination on the basis of race, color, religion, national origin, sex, sexual orientation, gender identity, gender expression, pregnancy (including pregnancy-related conditions), age, physical or mental disability, genetic information (including family medical history), ancestry, familial status, citizenship, service in the uniformed services (as defined in federal and state law), veteran status, expunged juvenile record, and/or the use of leave protected by state or federal law in all programs, activities and employment practices as required by Title IX, other applicable laws, and policies. Retaliation is prohibited by UO policy. Questions may be referred to the Office of Investigations and Civil Rights Compliance. Contact information, related policies, and complaint procedures are listed here .

In compliance with federal law, the University of Oregon prepares an annual report on campus security and fire safety programs and services. The Annual Campus Security and Fire Safety Report is available online at https://clery.uoregon.edu/annual-campus-security-and-fire-safety-report .",Full-time
4127926785,94207.0,Junior Software Engineer,"Pango Technology is seeking a Junior Software Engineer to join our team of IT professionals dedicated to delivering exceptional technology solutions tailored to our clients' needs.

About The Role

As a Junior Software Engineer at Pango, you will:


 * Work as part of the telecommunications service provisioning team to support and enhance software systems
 * Develop and maintain databases to track customer provisioning information
 * Collaborate using agile methodologies to ensure effective team processes and communication
 * Respond to Jira tickets, addressing tasks and resolving issues in a timely manner
 * Work across multiple applications and leverage a diverse set of technologies to meet project requirements
   
   

Qualifications

We are looking for candidates who meet the following criteria:


 * A relevant degree in Computer Science, Information Technology, or a related discipline
 * 1-2 years of professional experience in software development, systems integration, or a related field
 * Proficiency or familiarity with back-end technologies such as .NET/C# and scripting tools such as Perl and PHP
 * Experience with configuration management tools like Ansible is a plus
 * Basic experience in database design, SQL programming, and reporting tools (e.g., SQL Server)
 * Familiarity with front-end frameworks such as Angular or React is helpful but not required
   
   

Key Skills


 * Strong analytical and problem-solving abilities
 * Excellent written and verbal communication skills
 * Ability to document processes and requirements clearly and concisely
 * Flexibility and adaptability in a diverse technical environment
 * Strong collaboration and teamwork skills within client and project team dynamics
   
   

Why Join Pango?

At Pango, we work hard, think creatively, and relish the challenge of solving complex problems. In return, we offer:


 * A dynamic work environment rooted in teamwork and innovation
 * Exceptional benefits and competitive compensation
 * A vibrant company culture that embraces Alaska’s incredible outdoor lifestyle—because Pangos work to live!
   
   

This position is based out of our office in Anchorage, Alaska. Relocation assistance is not available for this role.

Compensation is based on experience. Pango Technology is proud to be an equal opportunity employer, committed to fostering a diverse and inclusive workplace.

Powered by JazzHR

9vJ9rrbv6l",Full-time
4137003016,25074192.0,Data Engineer,"Datavant is a data platform company for healthcare whose products and solutions enable organizations to move and connect data securely. Datavant has a network of networks consisting of thousands of organizations, more than 70,000 hospitals and clinics, 70% of the 100 largest health systems, and an ecosystem of 500+ real-world data partners.

By joining Datavant today, you’re stepping onto a highly collaborative, remote-friendly team that is passionate about creating transformative change in healthcare. We invest in our people and believe in hiring for high-potential and humble individuals who can rapidly grow their responsibilities as the com

Join our Data Platforms organization on the Data Engineering team. We’re a horizontal team whose mission is to use our data to drive maximum value across the business we are today and the business we’ll be in the future. You’ll operate across a diverse range of technologies in every layer of our “data stack” to make that mission a reality.

You will:


 * Deliver a world-class data platform from the ground up
 * Plan and delegate complex projects with broad scope
 * Mentor and grow early career developers or engineers transitioning into Data Infrastructure from other domains
 * Facilitate technical discussions, guiding the team toward the most effective approaches to problem solving
 * Engage with stakeholders across the business to ensure their needs are being met
 * Build, upgrade, and maintain Data-related infrastructure & monitoring across multiple clouds and other systems & services
 * Write performant, readable, and reusable code and Infrastructure-as-Code
 * Review code for your team to ensure a high standard of technical quality across our codebases
   
   
   

What you will bring to the table:


 * 3+ years of experience as a data engineer, analytics engineer, or data scientist
 * 1+ year of experience building and maintaining an enterprise-scale data lake and/or data warehouse
 * Strong collaborative and communication skills to work with our variety of stakeholders
 * Mastery of ANSI SQL and data modelling best practices
 * Deep experience with data warehouse technologies like Snowflake, BigQuery, or Redshift
 * Expertise in Python
   
   
   

Bonus points for:


 * Direct experience with Snowflake, dbt, Apache Airflow, AWS, or Azure
 * Prior experience in Healthcare or another highly regulated industry like Finance
 * Background as a Database Administrator, Data Analyst, or similar role
   
   
   

We are committed to building a diverse team of Datavanters who are all responsible for stewarding a high-performance culture in which all Datavanters belong and thrive. We are proud to be an Equal Employment Opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity, religion, national origin, disability, veteran status, or other legally protected status.

Our compensation philosophy is to be externally competitive, internally fair, and not win or lose on compensation. Salary ranges for this position are developed with the support of benchmarks and industry best practices.

We’re building a high-growth, high-autonomy culture. We rely less on job titles and more on cultivating an environment where anyone can contribute, the best ideas win, and personal growth is driven by expanding impact. The range posted is for a given job title, which can include multiple levels. Individual rates for the same job title may differ based on their level, responsibilities, skills, and experience for a specific job. The estimated salary range for this role is $130,000 - $200,000.

At the end of this application, you will find a set of voluntary demographic questions. If you choose to respond, your responses will be anonymous and used to help us identify areas of improvement in our recruitment process. (We can only see aggregate responses, not individual responses. In fact, we aren’t even able to see if you’ve responded or not.) Responding is your choice and it will not be used in any way in our hiring process.

This job is not eligible for employment sponsorship.",Full-time
4147106379,5322.0,Data Engineer,"Job Description:

Role Synopsis

As part of the Data Platforms team, the Data Engineer position contributes to the overall BPX Data Platform Strategy.


 * Define data workflow, pipelines, security, and ELT/ETL guidelines, policies, and procedures
 * Provide oversight to ensure that project teams are following the approved data workflow, pipelines, security, and ETL/ELT processing guidelines
 * Evaluate, compare, and recommend new Data Platform vendor products and/or tools
 * Partner with project teams to provide technical direction and new integration patterns, where needed, for complex and/or large data sets
 * Present modifications to Data Platforms to the Architecture Review Board for approval
   
   

Key Accountabilities


 * Responsible for the development, guidance, and oversight for data ingestions and integrations for BPX cloud data platforms.
 * Work with project teams to provide direction on approved patterns to meet the project data requirements for our Data Platforms.
 * Strong SQL development knowledge required to provide support to project developers/users for database design, data flow and analysis activities.
 * Development and deployment of innovative big data platforms for advanced analytics and data processing.
 * Define and build the data rules and pipelines that will enable faster, better, data-informed decision-making within the business.
 * Ensure stable solutions, stable infrastructure, and participate in the design and build out of data solutions.
 * The database and data support roles are outsourced to a managed services partner that resides within the Data Platform team, and this role will require the ability to work and partner with those resources.
 * Create data storage solutions optimized for performance and maintain data architecture standards across BPX Data Platforms.
 * Partner with the Data Quality Lead to incorporate testing and validation scripts to support the accuracy of data transformations.
 * Implement Master Data Management solutions, processes, and governance to support the Data Management team.
 * Partner with the DataOps support team to troubleshoot data issues and provide guidance for solving these issues.
 * Drive excellent, consistent customer service.
   
   

Essential Education


 * BS in Computer Science, MIS, Mathematics, or equivalent degree preferred but not required.
   
   

Requirements

Essential Experience and Job Requirements


 * 5+ years of Data Engineering experience
 * 5+ years of relevant work experience in IT/Data and/or Analytics space
 * Experience in any cloud data warehouse, Snowflake Cloud preferred
 * Experience with replication tools, Fivetran preferred
 * Experience with transformation tools, dbt preferred
 * Experience with programming tools, python preferred
 * Experience with REST APIs for data ingestion
 * Strong understanding of ETL/ELT processing with large data stores
 * Experience designing and delivering large scale, 24-7, mission-critical data pipelines and features using modern big data architectures
 * Stream processing services such as Kafka, AWS Kinesis, Apache Storm, Spark Streaming, Azure Event Grid etc
 * Demonstrated experience working in large-scale data environments which includes real-time and batch processing
 * Strong data modeling skills (relational, dimensional, and flattened)
 * Strong analytical and SQL skills, with attention to detail
 * Ability to aid in tuning and performance recommendations for poor performing SQL queries and/or python scripts
 * Knowledge of Database Administration tasks Indexing, SQL Tuning/Performance, Backup/Recovery, DR
 * Ability to work with multiple external teams and accomplish shared goals by building consensus
 * Strong communication (written/verbal) and collaboration skills
 * Consulting, negotiation, and relationship skills
 * Problem solving skills",Full-time
4063198386,66321745.0,Data Engineer (Entry Level) - Remote,"Are you passionate about coding or technology and ready to make your mark in tech? For more than 14 years, SynergisticIT has been helping aspiring developers like you excel in the tech industry. We focus on equipping you with the skills and experience needed to not only secure a job but to thrive in your career!

Why Partner with SynergisticIT?


 * Customized inputs to achieve the desired output : designed with industry needs in mind, ensuring you're equipped with the most sought-after skills.
 * Exclusive Opportunities: Our extensive network allows you to connect with leading tech firms.
 * Outstanding Outcomes: Many of our candidates land multiple job offers, often with starting salaries of $100k or more!
   
   

https://www.synergisticit.com/candidate-outcomes/

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

How Can Recently Laid Off Tech People Get Employed Again? | SynergisticIT

Who Should Apply? We're looking for recent grads in Mathematics, Statistics , Computer Science or Engineering or candidates with gaps in their career or people wanting to switch careers into tech. SynergisticIT is committed to supporting your journey!

Preferred SKILLS For Java /Full Stack/Devops Positions

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Knowledge of Core Java , javascript , C++ or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

For data Science/Data Analyst/AI/Machine learning Positions

Preferred SKILLS

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude

Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools

Candidates lacking technical skills can research our Job Placement Programs which can assist in landing a Job

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates

Embrace Your Future! We also assist with F1 OPT to transition into H1B and Green Card byproviding comprehensive support. All positions are open to candidates of all visa types and US citizens.

Are you ready to make an impact?",Contract
4126276782,2748.0,Data Visualization Engineer,"No Relocation Assistance Offered

Job Number #164586 - Piscataway, New Jersey, United States

Who We Are

Colgate-Palmolive Company is a global consumer products company operating in over 200 countries specializing in Oral Care, Personal Care, Home Care, Skin Care, and Pet Nutrition. Our products are trusted in more households than any other brand in the world, making us a household name!

Join Colgate-Palmolive, a caring, innovative growth company reimagining a healthier future for people, their pets, and our planet. Guided by our core values—Caring, Inclusive, and Courageous—we foster a culture that inspires our people to achieve common goals. Together, let's build a brighter, healthier future for all.

Join our dynamic Digital Data & Analytics team as a Data Visualization Engineer and take your career to the next level! We’re on the hunt for a talented individual with a unique blend of technical expertise and business savvy. In this exciting role, you will:


 * Collaborate with stakeholders to address strategic challenges and drive company growth.
 * Develop compelling visualizations that clearly convey strategic objectives.
 * Translate data requests into actionable solutions using cutting-edge visualization and analytics tools.
 * Champion innovative visualization tools and techniques throughout the company to democratize data access.
 * Stay updated with the latest trends to continuously introduce fresh and innovative ideas.
   
   

Hybrid role. Work visa sponsorship not available for this position

As a Data Visualization Engineer, you'll be at the forefront of converting data into powerful insights, influencing strategic decisions, and nurturing a culture of data-driven excellence across our organization. Your expertise in data visualization and analytics tools will play a vital role in shaping our business strategy and optimizing operational performance. If you're ready to make a real impact, we want to hear from you!

Required Qualifications:


 * Bachelor’s degree in Computer Science, Management Information Systems, or a related field.
 * 4+ years of experience utilizing data visualization tools like Domo, Tableau, Sigma, Google Data Studio, or Smartsheet.
 * Skilled in crafting complex SQL queries to integrate data into visualization tools.
   
   

Preferred Qualifications:


 * Proficiency in programming languages and frameworks like Python, JavaScript, Node.js, React.js, and experience with modern data warehousing technologies such as Snowflake, DBT, and BigQuery.
 * Familiarity with DevOps tools and practices, including Airflow, GitHub, and Terraform, and strong analytical and problem-solving skills.
 * Demonstrated ability to work independently, creatively solve problems, and take accountability.
 * Skilled in harmonizing, processing, and extracting value from large, disconnected datasets, and collaborating with cross-functional teams.
 * Excellent communication skills and the ability to present data-driven insights that drive strategic decisions.
   
   

Compensation And Benefits

Salary Range $91,200.00 - $130,000.00 USD

Pay is determined based on experience, qualifications, and location. Salaried employees may also be eligible for discretionary bonuses, profit-sharing, and long-term incentives for Executive-level roles.

Benefits: Salaried employees enjoy a comprehensive benefits package, including medical, dental, vision, basic life insurance, paid parental leave, disability coverage, and participation in the 401(k) retirement plan with company matching contributions subject to eligibility requirements. Additional benefits include a minimum of 15 vacation/PTO days (hourly employees receive a minimum of 120 hours) and 13 paid holidays (vacation days are prorated based on the employee's hire date within the calendar year). Paid sick leave is adjusted based on role and location in accordance with local laws. Detailed information regarding paid sick leave entitlements will be provided to employees upon hiring and may be subject to adjustments based on changes in legislation or company policies.

Our Commitment to Diversity, Equity & Inclusion

Achieving our purpose starts with our people — ensuring our workforce represents the people and communities we serve —and creating an environment where our people feel they belong; where we can be our authentic selves, feel treated with respect and have the support of leadership to impact the business in a meaningful way.

Equal Opportunity Employer

Colgate is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, ethnicity, age, disability, marital status, veteran status (United States positions), or any other characteristic protected by law.

Reasonable accommodation during the application process is available for persons with disabilities. Please complete this request form should you require accommodation.

For additional Colgate terms and conditions, please click here.

",Full-time
4151623332,3833190.0,Data Engineer,"Twenty Ideas (20i) is the home of passionate people who work together to elevate the web and create meaningful digital experiences for clients across a variety of sectors. Our team values innovative, cooperative design and development in an environment full of mutual respect, hard work, and fun. In other words, we work together closely to build really awesome things. We’re looking for a Data Engineer to join our remote-first team with our headquarters in beautiful Eugene, Oregon. At this time, we can only accept applicants who reside in Oregon, Washington, Idaho, Pennsylvania, and Washington, D.C.

About Us


 * We are a remote first company with an office option located in Eugene, Oregon.
 * Great company culture & tight-knit collaborative team.
 * Diverse and exciting technologies & digital products.
 * Opportunities for professional development - online seminars, internal learning, company paid resource materials.
 * Six weeks (i.e. 30+ days) of PTO & 20i holidays along with flexible work hours.
 * 100% company paid medical, dental, vision, life and disability Insurance.
 * We offer a 401K plan & 4% company match, remote perks, and optional FSA/Dependent care.
 * Company-sponsored happy hours & social events – we have fun too.
   
   

Here’s What You’ll Do


 * Work with cutting-edge technologies in the management and migration of data.
 * Ability to learn new systems and tools to manipulate, transform, and work with data.
 * Design, Construct, Install, Test, and Maintain Data Management Systems. Ensure that all systems meet company and performance requirements.
 * Data Acquisition and Processing: Develop data processes for data modeling, mining, and production.
 * Improve Data Foundational Procedures, Guidelines, and Standards: Optimize data retrieval, develop dashboards, reports, and other visualizations for stakeholders.
 * Collaborate Across Functional Teams: Work with engineering and business teams to understand data needs and implement solutions accordingly.
 * Work closely with teammates and clients to collaborate on concepts, and put ideas into practice.
 * Help define the tools and practices used across all Twenty Ideas engineering team.
   
   

Here's What You'll Need


 * 8+ years of experience as an engineer with a large amount of experience working with data.
 * Expertise in programming languages, especially languages that are built for working with data (e.g. Python).
 * Extensive Database Knowledge: SQL (e.g. PostgreSQL), NoSQL (e.g. DynamoDB), data warehousing solutions.
 * Strong Analytic Skills: Experience with database management and data processing.
 * Excellent Problem-solving and Teamwork Skills: Ability to work in a dynamic, cross-disciplinary environment.
 * High attention to details in terms of complex data migrations and an awareness of risk and assurance of correctness.
 * You know how to test your work by writing your code in a testable way.
 * You’re an expert working through the terminal (tailing logs, piping, checking file permissions, etc).
 * You’re an expert with at least one popular Cloud Provider’s technology (e.g. AWS, GCP, Azure).
 * Preferred, a degree in Computer Science, Engineering, or Relevant Field (e.g. Bachelor’s or Master’s).
   
   

Bonus Points Awarded For


 * Experience leading groups of developers towards a common goal.
 * Familiarity with best practices and regulations in the Health Care industry (HIPAA, PII protections, etc).
 * Advanced Degrees in Data Science or a Related Field.
 * Certifications: Such as Certified Data Management Professional.
 * Experience with Machine Learning and Artificial Intelligence.
 * Experience in a Startup Environment: Adaptability to rapid changes in project conditions and objectives.
 * Experience with Big Data Tools: Such as Hadoop, Spark, Kafka, etc.
 * A passion project or two that you’ve created or collaborated with someone on.
   
   

Twenty Ideas values diversity. We are an equal opportunity employer and we do not discriminate on the basis of race, creed, color, ethnicity, national origin, religion, gender, sexual orientation, gender expression, age, veteran status, marital status or disability status.",Full-time
4123368924,84838512.0,Data Engineer,"Company Description


ShanuDT IT Solutions INC in Farmington, MI is dedicated to providing performance-based solutions for our customers. We work with startups and large businesses across various industries to deliver top-notch IT solutions. Our business consulting professionals offer strategic advisory services and consultation to international financial services and insurance companies.


Role Description


This is a contract Data Engineer role based in Farmington, MI. The Data Engineer will be responsible for tasks such as data engineering, data modeling, ETL (Extract Transform Load), data warehousing, and data analytics. The role will involve working on-site to support the company's data needs.


Qualifications

 * Data Engineering, Data Modeling, and ETL (Extract Transform Load) skills
 * Data Warehousing and Data Analytics expertise
 * Experience in designing and implementing data solutions
 * Proficiency in data manipulation and analysis tools
 * Strong problem-solving and analytical skills
 * Ability to work effectively in a team environment
 * Bachelor's degree in Computer Science, Engineering, or related field
 * Relevant certifications in data engineering or data analytics",Contract
4080102053,1956.0,Healthcare Data Engineer,"Sogeti is a leading provider of professional technology services, specializing in Application Management, Infrastructure Management and High-Tech Engineering. Sogeti offers cutting-edge solutions around Testing, Business Intelligence, Mobility, Cloud and Security, combining world class methodologies and the global delivery model, Rightshore®. Sogeti brings together more than 20,000 professionals in 15 countries and is present in over 100 locations in Europe, the US and India. Sogeti is a division of Capgemini S.A., listed on the Paris Stock Exchange.




At Sogeti USA, we are committed to building a long and enduring relationship with our employees and to creating an environment that rewards and empowers. Our mission is to constantly exceed our employees' expectations in the same way that we strive to exceed our clients' expectations. We offer an environment that celebrates innovation and helps you to achieve a good balance between your professional and personal life. We strive to be an employer of choice!




NOTE: This is a FULL-TIME position with Sogeti. Candidates looking for contract work need not apply.




Requirements:

 * Minimum 6 years experience in Data Warehouse projects
 * Strong hands-on experience with SQL Server development
 * Good understanding of design and implementation of large scale data and analytics solutions
 * Writing SQL queries against Snowflake developing scripts Unix, Python, etc. to do Extract, Load and Transform data.
 * Good experience in data warehousing - OLTP, OLAP, Dimensions, Facts, and Data modeling
 * Hands-on experience in writing Stored procedures preferred
 * Nice to have experience in Healthcare insurance domain




The benefits our employees enjoy:

 * 401(k) Savings Plan- Matched 150% up to 6%. (Our 401k is in the top 1% of 401(k) plans offered in the US!)
 * Medical/Prescription/Dental/Vision Coverage!
 * $12,000 in Tuition Reimbursement
 * 100% Company-paid mobile phone plan
 * Personal Time Off (PTO)- Ensuring a balance of work and home life




Life at Sogeti

We support all aspects of your well-being throughout the changing stages of your life and career. For eligible employees, we offer:

 * Flexible work
 * Healthcare including dental, vision, mental health, and well-being programs
 * Financial well-being programs such as 401(k) (matched 150% up to 6%) and Employee Share Ownership Plan
 * 100% Company-paid mobile phone plan
 * 3 weeks Personal Time Off (PTO) and 7 Paid Holidays
 * Paid parental leave
 * Family building benefits like adoption assistance, surrogacy, and cryopreservation
 * Social well-being benefits like subsidized back-up child/elder care and tutoring
 * Mentoring, coaching and learning programs
 * Continuing Education: $12,000 Annual Tuition Reimbursement plus access to over 20,000 online courses and certifications through Capgemini University, as well as Coursera and Degreed.
 * Programs for Counseling, Support, Health and Fitness perks, Auto discounts and much, much more!
 * Employee Resource Groups
 * Disaster Relief




Disclaimer

Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.

Please be aware that Capgemini may capture your image (video or screenshot) during the interview process and that image may be used for verification, including during the hiring and onboarding process.

This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.

Capgemini is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to your recruiting contact.

Click the following link for more information on your rights as an Applicant http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law

Please be aware that Capgemini may capture your image (video or screenshot) during the interview process and that image may be used for verification, including during the hiring and onboarding process.

Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.




If this position is in Colorado, Nevada, New York, California, or Washington:

Capgemini discloses salary range information in compliance with state and local pay transparency obligations. The disclosed range represents the lowest to highest salary we, in good faith, believe we would pay for this role at the time of this posting, although we may ultimately pay more or less than the disclosed range, and the range may be modified in the future. The disclosed range takes into account the wide range of factors that are considered in making compensation decisions including, but not limited to, geographic location, relevant education, qualifications, certifications, experience, skills, seniority, performance, sales or revenue-based metrics, and business or organizational needs. At Capgemini, it is not typical for an individual to be hired at or near the top of the range for their role. The base salary range for the tagged location is [recruiter to insert salary range].

This role may be eligible for other compensation including variable compensation, bonus, or commission. Full time regular employees are eligible for paid time off, medical/dental/vision insurance, 401(k), and any other benefits to eligible employees.

Note: No amount of pay is considered to be wages or compensation until such amount is earned, vested, and determinable. The amount and availability of any bonus, commission, or any other form of compensation that are allocable to a particular employee remains in the Company's sole discretion unless and until paid and may be modified at the Company’s sole discretion, consistent with the law.

",Full-time
4143934303,529693.0,Data Engineer,"We believe communication belongs to everyone. We exist to democratize phone service.  TextNow is evolving the way the world connects, and that's because we're made up of people with curious minds who bring an optimistic yet critical lens into the work we do.   We're the largest provider of free phone service in the nation. And we're just getting started.

Join us in our mission to break down barriers to communication and free the flow of conversation for people everywhere.

TextNow is looking for an experienced Data Engineer with hands-on experience designing and developing data platforms. You will own the design, development, and maintenance of TextNow's data platform , enabling us to make effective data-informed decisions. You will be part of cross-functional efforts to build scalable and reliable frameworks that support all of TextNow's business and data products. In this role, you can interact with different functional areas within the business and influence decision-making in a fast-growing mobile communications start-up.  

What You'll Do


 * Own TextNow's data warehouse, pipeline, and integration points between various business systems.  
 * Explore available technologies and develop solutions to build and improve our identity resolution solutions.
 * Design, Develop and support new and existing batch and real-time data pipelines and recommend improvements and modifications.  
 * Manage data to manage our AI/ML data products.  
 * Be a champion of TextNow's data ecosystem by working with engineering and infrastructure to implement data strategy for governance, security, privacy, quality, and retention that will satisfy business policies and requirements.  
 * Communicate strategies and processes around data modeling and architecture to cross-functional groups.  Identify, design, and implement internal process improvements.  
   
   

Who You Are


 * Have 3-8 years of experience working with data warehouse/data lake and ETL architectures, cloud data warehouses (Snowflake), and experience in Python and SQL, preferably at companies with fast-growing and evolving data needs.
 * Have at least 1-2+ years of experience with Airflow, Iceberg, Spark and Flink.
 * Exposure to AWS cloud data/ML services such as EKS, MWAA and Sagemaker.
 * Developed scalable data pipelines using Python/Scala, SQL, and distributed processing frameworks like Spark or Flink.
 * Experience driving technical vision for user identity resolution and data quality in previous roles is preferred.
 * Hands on experience working with building data features using Snowflake, dbt, and Python to power real-time AI/ML inference.
 * Respectfully candid with the ability to initiate and drive projects to completion.
 * Highly organized, structured work approach and dependable.
   
   

More about TextNow...

Our Values


 * Customer Obsessed (We strive to have a deep understanding of our customers)
 * Do Right By Our People (We treat each other with fairness, respect, and integrity)
 * Accept the Challenge (We adopt a ""Yes, We Can"" mindset to achieve ambitious goals)
 * Act Like an Owner (We treat this company like it's our own... because it is!)
 * Give a Damn! (We are deeply commited and passionate about our work and achieving results)
   
   

Benefits, Culture, & More


 * Strong work life blend
 * Flexible work arrangements (wfh, remote, or access to one of our office spaces)
 * Employee Stock Options
 * Unlimited vacation
 * Competitive pay and benefits
 * Parental leave
 * Benefits for both physical and mental well being (wellness credit and L&D credit)
 * We travel a few times a year for various team events, company wide off-sites, and more
   
   

Diversity And Inclusion

At TextNow, our mission is built around inclusion and offering a service for EVERYONE, in an industry that traditionally only caters to the few who have the means to afford it. We believe that diversity of thought and inclusion of others promotes a greater feeling of belonging and higher levels of engagement. We know that if we work together, we can do amazing things, and that our differences are what make our product and company great.

TextNow Candidate Policy

By submitting an application to TextNow, you agree to the collection, use, and disclosure of your personal information in accordance with the TextNow Candidate Policy",Full-time
4045412628,66321745.0,Junior Level Software Engineer (REMOTE),"For more than 12 years Synergisticit has helped Jobseekers stand out from other Jobseekers by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this market also our candidates get multiple job offers and $100k &plus; salaries.

please check the below links to see success outcomes of our candidates .

https://www.synergisticit.com/candidate-outcomes/

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

https://www.youtube.com/watch?v=OFoqPTNORew

https://www.youtube.com/watch?v=-HkNN1ag6Zk

https://www.youtube.com/watch?v=OAFOhcGy9Z8

https://youtu.be/bJJl27D8bh0

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

Required Skills

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full Stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java , javascript , C&plus;&plus; or software programming

Spring boot, Microservices, Docker, Jenkins and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Full-time
4120828067,10667.0,"Data Engineer, Product Analytics","As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a world-class data engineering community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Data Engineer, Product Analytics Responsibilities:


 * Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems
 * Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve
 * Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights visually in a meaningful way
 * Define and manage Service Level Agreements for all data sets in allocated areas of ownership
 * Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership
 * Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains
 * Solve our most challenging data integration problems, utilizing optimal Extract, Transform, Load (ETL) patterns, frameworks, query techniques, sourcing from structured and unstructured data sources
 * Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts
 * Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts
 * Influence product and cross-functional teams to identify data opportunities to drive impact
 * Mentor team members by giving/receiving actionable feedback
   
   

Minimum Qualifications:


 * Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent
 * 7+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions
 * 7+ years of experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala or others.)
   
   

Preferred Qualifications:


 * Master's or Ph.D degree in a STEM field
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$173,000/year to $242,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4138835331,3537.0,Data Engineer,"The Data Analytics team within our Technology group is building a leading data and analytics platform. We partner and build batch and real-time analytics solutions for traders, quants, desk analysts and central data teams across the Commodities and Global Markets business.

At Macquarie, our advantage is bringing together diverse people and empowering them to shape all kinds of possibilities. We are a global financial services group operating in 34 markets and with 55 years of unbroken profitability. You’ll be part of a friendly and supportive team where everyone - no matter what role - contributes ideas and drives outcomes.

What role will you play?

You will work directly with our business, developing data analytics capabilities and solutions, such as the data catalog, data science workbench, visualisation tools, and real-time analytics. You’ll be working with our public-cloud based data lake, data pipelines for internal operational and external fundamental and alternative market data. You will join us on our journey to continually improve the robustness of our solutions and the speed with which we can respond to our business’s needs.

What You Offer


 * Interest in Data and Automation
 * Ability to code and debug in Python
 * Knowledge of GIT and CI/CD
 * Awareness of Cloud (eg. AWS)
   
   

We love hearing from anyone inspired to build a better future with us, if you're excited about the role or working at Macquarie we encourage you to apply.

About Technology

Technology enables every aspect of Macquarie, for our people, our customers and our communities. We’re a global team that is passionate about accelerating the digital enterprise, connecting people and data, building platforms and applications and designing tomorrow’s technology solutions.

Benefits

Macquarie employees can access a wide range of benefits which, depending on eligibility criteria, include:


 * Hybrid and flexible working arrangements
 * One wellbeing leave day per year and minimum 25 days of annual leave
 * Primary caregivers are eligible for 20 weeks paid leave along with 12 days of transition leave upon return to work and 6 weeks paid leave for secondary caregivers
 * Paid volunteer leave and donation matching
 * Range of benefits to support your physical, psychological and financial wellbeing
 * Employee Assistance Program, a robust behavioural health network with counselling and coaching services
 * Recognition and service awards
   
   

Our commitment to diversity, equity and inclusion

We are committed to providing a working environment that embraces diversity, equity and inclusion. As an inclusive employer, Macquarie provides equal opportunities to all individuals regardless of race, color, religion, sex, sexual orientation, national origin, age, disability, protected veteran status, genetic information, marital status, gender identity or any other impermissible criterion or circumstance.

Our aim is to provide reasonable accommodations to individuals who may need support during the recruitment process and through working arrangements. If you require additional assistance, please let us know during the application process.",Full-time
4149111541,90439523.0,Software Engineer - Streamlit Open Source,"Build the future of the AI Data Cloud. Join the Snowflake team.

We’re at the forefront of the data revolution, committed to building the world’s greatest data and applications platform. Our ‘get it done’ culture allows everyone at Snowflake to have an equal opportunity to innovate on new ideas, create work with a lasting impact, and excel in a culture of collaboration.

Snowflake, in collaboration with Streamlit, is on a mission to become an integral part of the Python community, alongside renowned libraries like NumPy, Pandas, TensorFlow, and PyTorch. We are searching for a dynamic engineer with a strong background in both Python and frontend development to help us propel our open-source project forward.

As a Software Engineer with the Open Source team, you will have the opportunity to work with our best-of-breed tech stack, including React/Hooks, TypeScript, Emotion, and Python. Join us in creating the future of the Data Cloud and delighting our customers with exceptional experiences.

Our Ideal Software Engineer Will Have


 * Software development experience, including 3+ years of experience in product web UI application development.
 * Deep Python knowledge Strong command of Python, including experience in building backend systems and integrating frontend and backend components.
 * Proficiency in frontend technologies Expertise in React/Hooks, TypeScript, and Emotion, with a keen eye for crafting intuitive and visually appealing user interfaces.
 * Strong problem-solving skills Ability to tackle complex technical challenges and provide innovative solutions in a fast-paced environment.
 * Strong communication and empathy skills Effective communication skills to collaborate with cross-functional teams, mentor engineers, and engage with the developer community.
 * Passion for innovation A drive to stay up-to-date with the latest industry trends, technologies, and best practices, and a passion for driving innovation within the team.
 * Promote strong collaboration within a cross functional team, including design, product management.
 * Be a strong contributor to the product vision and drive team planning.
 * A strategic mindset and eagerness to learn. You thrive under ambiguity and are motivated to drive impact.
 * Build for scale and high performance.
 * Familiarity or interest with data science, AI, machine learning is a plus.
   
   

Every Snowflake employee is expected to follow the company’s confidentiality and security standards for handling sensitive data. Snowflake employees must abide by the company’s data security plan as an essential part of their duties. It is every employee's duty to keep customer information secure and confidential.

Snowflake is growing fast, and we’re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.

How do you want to make your impact?

The following represents the expected range of compensation for this role:


 * The estimated base salary range for this role is $157,000 - $230,000.
 * Additionally, this role is eligible to participate in Snowflake’s bonus and equity plan.
   
   

The successful candidate’s starting salary will be determined based on permissible, non-discriminatory factors such as skills, experience, and geographic location. This role is also eligible for a competitive benefits package that includes: medical, dental, vision, life, and disability insurance; 401(k) retirement plan; flexible spending & health savings account; at least 12 paid holidays; paid time off; parental leave; employee assistance program; and other company benefits.

Snowflake is growing fast, and we’re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.

How do you want to make your impact?",Full-time
4143829072,50820.0,"Senior Data Engineer | DWH ETL (PL/SQL, Data-marts, Snowflake, SOQL/NetSuite)","Role: Sr. Data Engineer (DWH ETL) (PL/SQL, Data-marts, Snowflake, SFDC/SOQL/NetSuite)

Job Location - San Jose, California (Hybrid - 3 days onsite, 2 day's WFH)

Duration: 6 months initial contract W2 only + possible extension




Job Description:

• The candidate should be result-oriented, self-starter and self-motivated who can manage multiple time-sensitive assignments.

• Evaluate business requirements, conduct a POC and proactively call out data anomalies within the source system.

• Looking for someone in PL/SQL experience, back end working on designing data-warehousing projects.

• Develop/performance tune complex SQL designing (PL/SQL and/or T-SQL queries and stored procedures.

• Knowledge with Creating Data Solutions, Data marts, Data Layer, DWH/ETL/ Informatica reporting solutions, Some Dash-boarding / Reporting solution(Tableau/PowerBI/ data source)

• Knowledge of Commercial Organisations Data (Finance, CRM, Sales, Sales Operations, Marketing

• Scripting is a plus like airflow, Crontab but to understand how these scripts work, or Able to batch processes using any bash scripting language like pearl, Unix or python.

• Perform end to end data validation for a solution ensuring quality data delivery.

• Should be well versed with project tracking tools like Jira and Github.

• Candidate should be able to create strategic design and mapping of business requirements to system/technical requirements.

• Candidate should be able to communicate, translate, and simplify business requirements to ensure buy-in from all stakeholders.




Requirements

• Candidate should have experience working with NetSuite objects or Snowflake, SFDC/SOQL or CRM.

• 7-10 years of experience with Database Development using Packages/Stored Procedures/Triggers in SQL and PLSQL

• 7-10 years of experience in Dimensional Modeling, Star and Snowflake Schemas design and maintaining dimensions using Slowly Changing Dimensions(SCD)

• 7+ years of experience in SQL performance tuning and optimization techniques

• Ability to work on on ad-hoc requests and should be able to work on simultaneous projects or tasks

• Effective and positive communication and Team working skills.",Contract
4137003406,18977.0,Data Engineer (Python/PySpark/AWS)," * Candidates must be local to the Washington D.C. metro area.
   
   

About Infinitive

Infinitive is a data and AI consultancy that enables its clients to modernize, monetize and operationalize their data to create lasting and substantial value. . We possess deep industry and technology expertise to drive and sustain adoption of new capabilities. We match our people and personalities to our clients' culture while bringing the right mix of talent and skills to enable high return on investment.

Infinitive has been named “Best Small Firms to Work For” by Consulting Magazine 6 times most recently in 2023. Infinitive has also been named a Washington Post “Top Workplace”, Washington Business Journal “Best Places to Work”, and Virginia Business “Best Places to Work.”

We are seeking a highly skilled and motivated Data Engineer to join our dynamic team. As a Data Engineer, you will play a crucial role in designing, developing, and maintaining our clients data infrastructure. Your expertise in Python, PySpark, ETL processes, CI/CD (Jenkins or GitHub), and experience with both streaming and batch workflows will be essential in ensuring the efficient flow and processing of data to support our clients.

Responsibilities

Data Architecture and Design:


 * Collaborate with cross-functional teams to understand data requirements and design robust data architecture solutions.
 * Develop data models and schema designs to optimize data storage and retrieval.
   
   

ETL Development


 * Implement ETL processes to extract, transform, and load data from various sources.
 * Ensure data quality, integrity, and consistency throughout the ETL pipeline.
   
   

Python And PySpark Development


 * Utilize your expertise in Python and PySpark to develop efficient data processing and analysis scripts.
 * Optimize code for performance and scalability, keeping up-to-date with the latest industry best practices.
   
   

Data Integration


 * Integrate data from different systems and sources to provide a unified view for analytical purposes.
 * Collaborate with data scientists and analysts to implement solutions that meet their data integration needs.
   
   

Streaming And Batch Workflows


 * Design and implement streaming workflows using PySpark Streaming or other relevant technologies.
 * Develop batch processing workflows for large-scale data processing and analysis.
   
   

CI/CD Implementation


 * Implement and maintain continuous integration and continuous deployment (CI/CD) pipelines using Jenkins or GitHub Actions.
 * Automate testing, code deployment, and monitoring processes to ensure the reliability of data pipelines.
   
   

Qualifications


 * Bachelor's or Master's degree in Computer Science, Information Technology, or a related field.
 * Proven experience as a Data Engineer or similar role.
 * Strong programming skills in Python and expertise in PySpark for both batch and streaming data processing.
 * Hands-on experience with ETL tools and processes.
 * Familiarity with CI/CD tools such as Jenkins or GitHub Actions.
 * Solid understanding of data modeling, database design, and data warehousing concepts.
 * Excellent problem-solving and analytical skills.
 * Strong communication and collaboration skills.
   
   

Preferred Skills


 * Knowledge of cloud platforms such as AWS, Azure, or Google Cloud.
 * Experience with version control systems (e.g., Git).
 * Familiarity with containerization and orchestration tools (e.g., Docker, Kubernetes).
 * Understanding of data security and privacy best practices.
   
   

Applicants for employment in the U.S. must possess work authorization which does not require sponsorship by the employer for a visa. Infinitive is an Equal Opportunity Employer.",Full-time
4131023581,29170.0,"Intern, Data Engineer (Spring 2025)","Wiss is seeking a Data Engineer who will be responsible for building and maintaining data pipelines and data warehouse that support business intelligence and analytics solutions to drive operational efficiency and effectiveness by enabling data-driven decisions across the organization. This role, reporting to the Director of Data Analytics & Business Intelligence will design, develop, and maintain a scalable and efficient data architecture that serves as the central source for all data-related needs, ensuring data integrity, security, and accessibility.




This position will reside in our Florham Park, NJ office. ONLY NEW JERSEY CANDIDATES WILL BE CONSIDERED.







Responsibilities:

 * Collaborate with Digital Technology team members to develop enterprise data warehouse, data marts and other business intelligence projects.
 * Design, develop data integration solutions using Microsoft Fabric (Data Factory/Fabric Data Warehouse etc.) and other tools as appropriate to facilitate efficient data extraction, transformation, and loading (ETL) processes.
 * Implement and maintain data quality checks and validations to ensure data is accurate and consistent across systems.
 * Monitor and optimize the performance of SQL queries, ETL processes to ensure efficient data processing and data warehouse reliability.
 * Troubleshoot and resolve data-related issues, including data integration failures, data quality problems, and performance bottlenecks.




Essential Qualifications:

 * Bachelor's degree in Computer Science, Information Systems, or a related field, master’s degree highly preferred.
 * 1+ years of experience building scalable data and analytics solutions, with a focus on designing and implementing complex ETL processes.
 * 1+ years of data engineering including ETL and pipeline building experience using data integration engines such as SQL Server Integration Services (SSIS) or Azure Data Factory or Synapse
 * Propose and implement ETL/ELT strategies, leveraging Azure Data Factory, Microsoft Fabric, and other tools to ensure efficient data movement and transformation.
 * Working knowledge of business intelligence tools such as PowerBI and Tableau.
 * Proficiency in programming language Python, for data engineering and scripting tasks.
 * Familiarity with common system integration methods and technologies including SOAP/REST APIs, flat files (JSON, XML, CSV, Parquet, etc.) and transforming data for ingestion into the data warehouse.
 * Strong interpersonal and communication skills with Agile/Scrum experience.
 * Strong problem solving and critical thinking skills with a proven record for identifying and diagnosing problems, and solving complex problems with simple, logical solutions.




Preferred Qualifications:

 * Microsoft Certified: Azure Data Engineer Associate




Wiss, LLP Highlights

 * Accounting Today's 2024 Regional Leaders
 * Accounting Today's 2024 Top 100 Firms
 * Accounting Today's 2024 top firms by AUM







Wiss is an Equal Opportunity-Affirmative Action Employer - Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation / Age ""




""Wiss is committed to diversity and inclusion. We seek candidates from all backgrounds to join our team and encourage our employees to bring their authentic and best selves to work. ""




To all staffing agencies: Wiss does not utilize 3rd party firms for any internal or client positions. Please be advised, Wiss is not responsible for any fees related to unsolicited resumes. All unsolicited resumes will become the property of Wiss.",Internship
4045414137,66321745.0,Junior Level Software Engineer (REMOTE),"Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart lab s etc to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

If you applied for a job and got emails from our Job Placement Program team please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.

please check the below links to see success outcomes of our candidates and our participation at different Tech industry events and how we are different from other organizations in helping Jobseekers secure Tech careers

https://www.synergisticit.com/candidate-outcomes/

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

https://www.youtube.com/watch?v=OFoqPTNORew

https://www.youtube.com/watch?v=-HkNN1ag6Zk

https://www.youtube.com/watch?v=OAFOhcGy9Z8

https://youtu.be/bJJl27D8bh0

For preparing for interviews please visit https://www.synergisticit.com/interview-questions/

We are looking for the right matching candidates for our clients

Please apply via the job posting

Required Skills

REQUIRED SKILLS For Java /Full stack/Software Programmer


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Project work on the skills
 * Knowledge of Core Java , javascript , C&plus;&plus; or software programming
 * Spring boot, Microservices, Docker, Jenkins and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning Positions

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Project work on the technologies needed
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, PowerBI, SAS, Tensorflow

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Full-time
4116424990,66321745.0,Data Engineer - Remote,"Since 2010 Synergisticit has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this Job market also, our candidates are able to achieve multiple job offers and $100k + salaries.

Please Check The Below Links

https://www.synergisticit.com/candidate-outcomes/

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://www.youtube.com/playlist?list=PLJgkOBQ51j5AHT5I6n29glr0q6trzkxYD

https://synergisticit.wistia.com/medias/k6t6a1n4kb

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

Required Skills

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, Gen AI, LLM, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full Stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java , javascript , C++ or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Contract
4143462443,3088.0,"Data Engineer II (Python, AWS, Databricks)","Who Are We?

Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.

Compensation Overview

The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.

Salary Range

$123,000.00 - $203,000.00

Target Openings

1

What Is the Opportunity?

Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate stories found in data by leveraging a variety of data programming techniques. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.

What Will You Do?


 * Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.
 * Design complex data solutions
 * Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.
 * Incorporate core data management competencies including data governance, data security and data quality.
 * Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.
 * Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.
 * Test data movement, transformation code, and data components.
 * Perform other duties as assigned.
   
   

What Will Our Ideal Candidate Have?


 * Bachelor’s Degree in STEM related field or equivalent
 * Eight years of related experience
 * Highly proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and a full understanding of modern software engineering practices.
 * The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.
 * Demonstrated track record of domain expertise including understanding technical concepts necessary and industry trends, and possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems.
 * Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues.
 * Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners.
 * Ability to lead team members and help create a safe environment for others to learn and grow as engineers. and a proven track record of self-motivation in identifying opportunities and tracking team efforts.
 * This role will focus on Data and AI product implementation for underwriting and operations models. We will be building and supporting new products to support our day to day risk management and operations.
 * Python, AWS, Databricks, Snowflake, SQL, Docker, Terraform, Git Actions
   
   

What is a Must Have?


 * Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
 * Four years of data engineering or equivalent experience.
   
   

What Is in It for You?


 * Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.
 * Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
 * Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
 * Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs.
 * Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.
   
   

Employment Practices

Travelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.

In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions.

If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.

Travelers reserves the right to fill this position at a level above or below the level included in this posting.

To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.",Full-time
4143935147,529693.0,Data Engineer,"We believe communication belongs to everyone. We exist to democratize phone service.  TextNow is evolving the way the world connects, and that's because we're made up of people with curious minds who bring an optimistic yet critical lens into the work we do.   We're the largest provider of free phone service in the nation. And we're just getting started.

Join us in our mission to break down barriers to communication and free the flow of conversation for people everywhere.

TextNow is looking for an experienced Data Engineer with hands-on experience designing and developing data platforms. You will own the design, development, and maintenance of TextNow's data platform , enabling us to make effective data-informed decisions. You will be part of cross-functional efforts to build scalable and reliable frameworks that support all of TextNow's business and data products. In this role, you can interact with different functional areas within the business and influence decision-making in a fast-growing mobile communications start-up.  

What You'll Do


 * Own TextNow's data warehouse, pipeline, and integration points between various business systems.  
 * Explore available technologies and develop solutions to build and improve our identity resolution solutions.
 * Design, Develop and support new and existing batch and real-time data pipelines and recommend improvements and modifications.  
 * Manage data to manage our AI/ML data products.  
 * Be a champion of TextNow's data ecosystem by working with engineering and infrastructure to implement data strategy for governance, security, privacy, quality, and retention that will satisfy business policies and requirements.  
 * Communicate strategies and processes around data modeling and architecture to cross-functional groups.  Identify, design, and implement internal process improvements.  
   
   

Who You Are


 * Have 3-8 years of experience working with data warehouse/data lake and ETL architectures, cloud data warehouses (Snowflake), and experience in Python and SQL, preferably at companies with fast-growing and evolving data needs.
 * Have at least 1-2+ years of experience with Airflow, Iceberg, Spark and Flink.
 * Exposure to AWS cloud data/ML services such as EKS, MWAA and Sagemaker.
 * Developed scalable data pipelines using Python/Scala, SQL, and distributed processing frameworks like Spark or Flink.
 * Experience driving technical vision for user identity resolution and data quality in previous roles is preferred.
 * Hands on experience working with building data features using Snowflake, dbt, and Python to power real-time AI/ML inference.
 * Respectfully candid with the ability to initiate and drive projects to completion.
 * Highly organized, structured work approach and dependable.
   
   

More about TextNow...

Our Values


 * Customer Obsessed (We strive to have a deep understanding of our customers)
 * Do Right By Our People (We treat each other with fairness, respect, and integrity)
 * Accept the Challenge (We adopt a ""Yes, We Can"" mindset to achieve ambitious goals)
 * Act Like an Owner (We treat this company like it's our own... because it is!)
 * Give a Damn! (We are deeply commited and passionate about our work and achieving results)
   
   

Benefits, Culture, & More


 * Strong work life blend
 * Flexible work arrangements (wfh, remote, or access to one of our office spaces)
 * Employee Stock Options
 * Unlimited vacation
 * Competitive pay and benefits
 * Parental leave
 * Benefits for both physical and mental well being (wellness credit and L&D credit)
 * We travel a few times a year for various team events, company wide off-sites, and more
   
   

Diversity And Inclusion

At TextNow, our mission is built around inclusion and offering a service for EVERYONE, in an industry that traditionally only caters to the few who have the means to afford it. We believe that diversity of thought and inclusion of others promotes a greater feeling of belonging and higher levels of engagement. We know that if we work together, we can do amazing things, and that our differences are what make our product and company great.

TextNow Candidate Policy

By submitting an application to TextNow, you agree to the collection, use, and disclosure of your personal information in accordance with the TextNow Candidate Policy",Full-time
4116431023,66321745.0,Data Engineer - Remote,"SYNERGISTICIT is aware that the Job Market is Challenging due to almost 600,000 Tech Layoffs within the past 2 years due to which The Job market is flooded with thousands of laid off Techies who are competing with existing Jobseekers. For entry level Job seekers to get client interviews and jobs they need to differentiate themselves by ensuring they have exceptional skills and technologies to be noticed by clients.

Since 2010 we have helped Jobseekers differentiate themselves by providing the clients with candidates who have the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.

All Positions are open for all visas and US citizens

We are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this economy no client wants or has the resources to take an entry level person and spend resources on upgrading their skills and on top of that pay the jobseeker. That's the specific reason there are so many techies both experience and freshers who are unemployed.

Clients have now the option to hire remote workers from anywhere so for a Jobseeker its important to introspect and see how they can become better and have the skills and technologies to meet client requirements.

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates looking to make their careers in IT Industry

We welcome candidates with all visas and citizens to apply.

If you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.

please check the below links to see success outcomes of our candidates

Synergisticit Pics /Salaries of Successful Candidates

Synergisticit at Oracle Cloudworld 2023

Synergisticit at Gartner Data & Analytics summit

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

If you have relevant skills and industry experience, please apply

For preparing for interviews please visit

https://www.synergisticit.com/interview-questions/

REQUIRED SKILLS For Java /Software Programmers


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Project work on the skills
 * Knowledge of Core Java , javascript , C++ or software programming
 * Spring boot, Microservices, Docker, Jenkins and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Project work on the technologies needed
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, PowerBI, Time series analysis

Please understand skills and relevant experience on real world projects are required by clients for selection even if its Junior or entry level position the additional skills and Project work with hands on experience building projects at client site are the only way a candidate can be picked by clients.

No third party candidates or c2c candidates

please only apply to the posting

If you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.",Contract
4151352416,1315115.0,Data Engineer,"Data Engineer - Full Remote Working from anywhere in the US

SQL+Python+ETL+Airflow




Our client is a global leading high tech company:

-Over 6,500 employees across 20+ offices;

-Fast growing;

-Cutting edge AR and VR technologies, 3D printing, etc.




They are looking for a Data Engineer to join their FinTech team!




You will develop scalable data pipelines, ensure data quality, and support business decision-making with high-quality datasets.




-Technologies: SQL, Python, ETL, Big Query, Spark, Hadoop, vision control systems such as Git, workflow management tools such as Airflow, Data Architecture, Data Warehousing

-Design and develop scalable ETL pipelines to automate data processes, optimize delivery, and comply with privacy and governance standards.

-Implement and manage data warehousing solutions, ensuring data integrity through rigorous testing and validation.

-Develop tools and systems to address limitations in data consumption portals.

-Implement and maintain robust data security practices




Requirements:

-5+ years of experience in SQL

-5+ years of development in Python

-MUST have experience in Apache Airflow

-Experience in Google BigQuery, Spark, and Hadoop is a big plus

-Experience with ETL tools, data architecture, and data warehousing solutions

-Strong communication skills




W2 employer full time contract, initially till the end of 2025 with the option to extend yearly. Offer up to $70 an hour (40 hours per week, Mon-Fri) plus 50% contribution to medical plan, sick leave and federal public holidays as PTOs. Full remote working from anywhere in the US.",Contract
4146058231,2385278.0,Data Engineer,"Hiring Now: Senior Data Engineer (8+ Years’ Experience) | Healthcare & Cloud Data Solutions

We are looking for a Senior Data Engineer with 8+ years of experience to join our team and drive data integration, cloud transformation, and analytics solutions. This role will involve working with large-scale healthcare datasets, building ETL pipelines, and optimizing data storage and processing in cloud environments.




Key Responsibilities:

 * Design, develop, and maintain scalable ETL pipelines for structured and unstructured healthcare data.
 * Work with EHR, claims data, and patient records, ensuring data security and compliance (HIPAA, GDPR).Optimize data pipelines using Apache Spark, AWS Glue, and Snowflake for real-time analytics.
 * Collaborate with Data Scientists, Analysts, and Product Managers to improve data accessibility.
 * Implement data governance best practices for metadata management, lineage tracking, and data quality.Develop and maintain cloud-based data solutions on AWS (S3, Redshift, Lambda), Azure, or GCP.
 * Perform data modeling and schema design to support analytical workloads.
 * Leverage SQL, Python, and Spark to enhance data processing efficiency.




Required Skills & Qualifications:

 * 8+ years of experience in data engineering, big data processing, or ETL development.
 * Strong expertise in Python, SQL, and Apache Spark for large-scale data processing.
 * Experience with AWS (S3, Glue, Redshift, Lambda), Azure Synapse, or GCP BigQuery.
 * Deep understanding of healthcare data (EHR, HL7, FHIR, Claims Processing).
 * Hands-on experience with Snowflake, Databricks, or Kafka for real-time streaming.Knowledge of data governance, security, and compliance (HIPAA, SOC2, GDPR).
 * Experience in building data pipelines, automation, and CI/CD for data workflows.
 * Familiarity with data visualization tools (Tableau, Power BI) is a plus.Why Join Us?
 * Work on cutting-edge healthcare data solutions impacting millions of lives.
 * Flexible hybrid/remote work options.
 * Opportunity to work with modern data stacks and cloud technologies.




Collaborative and growth-oriented engineering culture.If you are passionate about building scalable, high-performance data platforms, apply now or DM me for more details!




#Hiring #DataEngineer #BigData #AWS #HealthcareData #CloudComputing #ETL #Snowflake #Spark #Python #SQL #MachineLearning",Full-time
4151634663,81884531.0,Data Engineer,"Job Summary

The Data Engineer is responsible for SJSU’s Campus Data Warehousing/Business Intelligence. This position will play a key role in the research, design, architecture, creation, development, implementation and maintenance of Campus Data Warehouse. This includes identifying and pulling data from 500+ individual databases across SJSU and curating them into a single data source in order to facilitate data-driven decisions.

The Data Engineer should possess a breadth of knowledge, technical skills, and strategic thinking to build a Data Warehouse to answer important questions across a variety of functional areas and collaborate with business stakeholders and IT management to understand solution requirements and system design for delivering the data model, developing and implementing the solution to deliver the desired business outcomes. Assist in conducting technical reviews, creating definitions of business problems, including the preparation of business/technical requirements to support the mission of the university and administrative departments, provide systems and technical support of vendor and locally developed software, and work with the Data Warehouse Project Manager, SJSU IT Enterprise Solutions resources, external vendors, and IT team members. Duties and system assignments can be temporarily or permanently changed to meet the needs and goals of the department and university.

Key Responsibilities


 * Capture, maintain, and apply data and information in order to support key business processes.
 * Optimize how the organization uses data both internally and externally.
 * Evaluate data that recognizes trends, calling insights, and making recommendations to the executive leadership team to make recommendations to define business strategy.
 * Assist with the development of strategies and coordinates the implementation that support the Organization's development plans and that capture new opportunities.
 * Partner cohesively with the broader Insights leaders across campus concerning the alignment capabilities.
 * Oversee the implementation of analytic methodologies including segmentation, predictive modeling, advanced statistical methods, regression, experimental design, etc.
 * Oversee the sourcing and creation of partnerships with key analytical vendors who can provide specialized expertise to assist with solution development while leading the in-house effort and managing CO interface.
 * Oversee project plans, timelines, and vendor relationships to ensure releases are delivered with the highest quality, on-time and within budget.
 * Partner with University stakeholders and be responsible for data analytics, custodianship, and infrastructure to ensure alignment with departmental data and analytics requirements to avoid conflicting activities, and develop the most efficient data analytics insights across the departments.
 * Identify, interpret, analyze and address critical business issues, questions and to develop use cases.
 * Organize and create an environment that makes data and information accessible with appropriate channels of access controls.
 * Work with internal and external stakeholders to build a relationship of trust and play an advisory role in the use of data to improve performance and University-wide strategy formulation.
 * Develop and document clear understandable plans, roadmaps and communication for business users, technical staff and IT groups.
 * Follow IT policies and standards for maintaining consistency and standards across SJSU campus.
 * Be proactive in making recommendations and ensure users/departments have the most up-to-date technological solutions to perform their jobs and serve the university community effectively.
   
   

Knowledge, Skills & Abilities


 * Advanced skills in analytical and holistic problem-solving, project management, effective communication and coordination of internal and external resources
 * Ability to work effectively with faculty, staff, and senior administrators in areas other than technology to develop and implement appropriate uses of technology
 * Advanced technical knowledge in IT systems and emerging technology trends and issues
 * Ability to synthesize data from multiple sources to address complex business questions
 * Advanced knowledge with analytics tools, “big data” technologies, cloud computing environments, relational database
 * Advanced working knowledge in large ERP scale analytics, optimization, business intelligence, and statistics for IT organizations
 * Ability to identify key insights and built large-scale data products that enhance the customer experience and improve operations processes
 * Strong ability to provide guidance on emerging technologies to innovate and ensure the SJSU is well-positioned in delivering analytic solutions
 * Strong ability to deliver on high-impact analytics projects
 * Advanced working SQL knowledge and skills working with relational databases like Oracle, query authoring (SQL), as well as, working familiarity with a variety of databases
 * Expert knowledge in high level programming languages like: Python, SQL, Java, and JavaScript
 * Advanced knowledge in application architectures on public cloud platform such as Amazon Web Services (AWS), Google Cloud Platform (GCP) or IBM Cloud Pak
 * Advanced knowledge of enterprise data architecture, ETL integration, data warehousing techniques, analytics/end-user reporting tool sets
 * Advanced knowledge in Visualization tools like Google Data Studio, Tableau, Looker etc
 * Knowledge building and optimizing ‘big data’ data pipelines, architectures and data sets
 * Ability to build processes supporting data transformation, data structures, metadata, dependency and workload management
 * Advanced knowledge of Systems development life cycle methodologies (Agile and Waterfall) in order to develop effective systems
 * Advanced knowledge of application development, testing and deployment processes and tools
 * Knowledge performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
 * Strong analytic skills related to working with unstructured datasets
 * Knowledge with big data languages such as R, Python/PySpark and familiarity with cloud architecture
 * Advanced knowledge in data mining, forecasting, simulation, and/or predictive modeling
 * Advanced knowledge building BI environments with significant scale and scope
   
   

Required Qualifications


 * A bachelor’s degree, preferably in computer science or business, or equivalent training and applied experience
 * Five years of experience in business applications analysis, design, and programming for medium or large scale, multi-programmed computers
   
   

Preferred Qualifications


 * Master’s in Business Administration, Computer Science or equivalent degree
 * 3+ years’ experience developing, maintaining and collecting structured and unstructured data sets for analysis and reporting
 * 3+ years advanced analytics experience in support of business strategy
 * 3+ years working experience in implementing public cloud solutions
   
   

Compensation

Classification: Analyst/Programmer - Expert

CSU Salary Range: $7,371/month - $14,274/month

San José State University offers employees a comprehensive benefits package typically worth 30-35% of your base salary. For more information on programs available, please see the Employee Benefits Summary.

Application Procedure

Click Apply Now to complete the SJSU Online Employment Application and attach the following documents:


 * Resume
 * Letter of Interest
   
   

All applicants must apply within the specified application period: January 9, 2025 through January 22, 2025. This position is open until filled; however, applications received after screening has begun will be considered at the discretion of the university.

Contact Information

University Personnel

jobs@sjsu.edu

408-924-2252

CSU Vaccination Policy

The CSU strongly recommends that all individuals who access any in-person program or activity (on- or off-campus) operated or controlled by the University follow COVID-19 vaccine recommendations adopted by the U.S. Centers for Disease Control and Prevention (CDC) and the California Department of Public Health (CDPH) applicable to their age, medical condition, and other relevant indications and comply with other safety measures established by each campus. The system wide policy can be found at https://calstate.policystat.com/policy/9779821/latest/ and questions may be sent to jobs@sjsu.edu.

Additional Information

Satisfactory completion of a background check (including a criminal records check) is required for employment. SJSU will issue a contingent offer of employment to the selected candidate, which may be rescinded if the background check reveals disqualifying information, and/or it is discovered that the candidate knowingly withheld or falsified information. Failure to satisfactorily complete the background check may affect the continued employment of a current CSU employee who was offered the position on a contingent basis.

The standard background check includes: criminal check, employment and education verification. Depending on the position, a motor vehicle and/or credit check may be required. All background checks are conducted through the university's third party vendor, Accurate Background. Some positions may also require fingerprinting. SJSU will pay all costs associated with this procedure. Evidence of required degree(s) or certification(s) will be required at time of hire.

SJSU IS NOT A SPONSORING AGENCY FOR STAFF OR MANAGEMENT POSITIONS. (e.g. H1-B VISAS)

All San José State University employees are considered mandated reporters under the California Child Abuse and Neglect Reporting Act and are required to comply with the requirements set forth in CSU Executive Order 1083 as a condition of employment. Incumbent is also required to promptly report any knowledge of a possible Title IX related incident to the Title IX Office or report any discrimination, harassment, and/or retaliation to the Office of Equal Opportunity.

Jeanne Clery Disclosure of Campus Security Policy and Crime Statistics Act and Campus Housing Fire Safety Notification:

Pursuant to the Jeanne Clery Disclosure of Campus Security Policy and Campus Crime Statistics Act, the Annual Security Report (ASR) is also now available for viewing at https://www.sjsu.edu/clery/docs/SJSU-Annual-Security-Report.pdf. The ASR contains the current security and safety-related policy statements, emergency preparedness and evacuation information, crime prevention and Sexual Assault prevention information, and information about drug and alcohol prevention programming. The ASR also contains statistics of Clery crimes for San José State University locations for the three most recent calendar years. A paper copy of the ASR is available upon request by contacting the Office of the Clery Director by phone at 408-924-1501 or by email at clerycompliance@sjsu.edu.

Pursuant to the Higher Education Opportunity Act, the Annual Fire Safety Report (AFSR) is also available for viewing at https://www.sjsu.edu/clery/docs/SJSU-Annual-Fire-Safety-Report.pdf. The purpose of this report is to disclose statistics for fires that occurred within SJSU on-campus housing facilities for the three most recent calendar years, and to distribute fire safety policies and procedures intended to promote safety on Campus. A paper copy of the AFSR is available upon request by contacting the Housing Office by phone at 408-795-5600 or by email at uhs-frontdesk@sjsu.edu.

Campus Security Authority - In accordance with the Jeanne Clery Disclosure of Campus Security Policy and Campus Crime Statistics Act (Clery Act) and CSU systemwide policy, this position is subject to ongoing review for designation as a Campus Security Authority. Individuals that are designated as Campus Security Authorities are required to immediately report Clery incidents to the institution and complete Clery Act training as determined by the university Clery Director.

Equal Employment Statement

San José State University (SJSU) is an Equal Opportunity/Affirmative Action employer committed to nondiscrimination on the basis of age, ancestry, citizenship status, color, creed, disability, ethnicity, gender, genetic information, marital status, medical condition, national origin, race, religion or lack thereof, sex, sexual orientation, transgender, or protected veteran status consistent with applicable federal and state laws. This policy applies to all SJSU students, faculty and staff programs and activities. Title IX of the Education Amendments of 1972, and certain other federal and state laws, prohibit discrimination on the basis of sex in all education programs and activities operated by the university (both on and off campus).

",Full-time
4152004185,104411273.0,"Software Engineer, Backend","About Arcade:

Arcade is the world’s first AI product marketplace, where everything that can be dreamed of can be made. Our mission is to create magical and social shopping experiences for people everywhere, using unparalleled design-to-manufacturing AI technologies. Arcade enables anyone to design, purchase, and sell custom, manufacturable products with a simple text prompt. We match consumers with a marketplace of independent makers which we have built and vetted to bring their dreams to life.

Arcade aims to redefine commerce by offering unprecedented personal choice, expression, and meaning in product creation. We’re using AI to empower anyone to design a product, and feel the profound experience of wearing or using a product that is an expression of their unique vision.

Arcade is led by Mariam Naficy, who has 25+ years of entrepreneurial experience in e-commerce, creator communities, and make-on-demand manufacturing (Eve.com, Minted). Mariam's co-founders include Will Zhuk, most recently of OpenAI.

Arcade is based in San Francisco and has raised $17M in funding from Reid Hoffman, Offline Ventures, Sound Ventures, and CRV. Angel investors include Christy Turlington Burns, Elad Gil, Colin Kaepernick, Karlie Kloss, David Luan, Gwyneth Paltrow, Kelly Wearstler, Jeff Wilke, and Sharon Zhou.

Arcade is an Equal Opportunity Employer committed to inclusion and diversity.

Overview of Role

Arcade is seeking a highly skilled Software Engineer with expertise in Python and Django. The ideal candidate is entrepreneurial who has delivered impactful backend software solutions in collaboration with a small team of frontend and AI engineers. This entrepreneurial person has experimented with and knows about a variety of AI technologies and their APIs, and can use that experience to tackle big challenges such as orchestrating inference flows across large number of models.

What you will do

Backend Development. We are a small highly focused team, building a uniquely robust backend platform. Youʼll own design and development of critical server- side components and REST APIs in Python. Work with Django, Postgres, Redis and cloud infrastructure products on GCP including Pub/Sub, Kubernetes Engine, Cloud Storage and SQL.

Collaboration. Teamwork is key in our environment. Youʼll bring diverse perspectives and collaborate with Frontend and AI engineers, Product managers and other stakeholders in a hands-on environment with new technologies and architectures in a flexible, small but exceptional, forward-thinking organization thatʼs always pushing boundaries.

Craftsmanship. Youʼll own projects end-to-end with strong drive to execute, and continuously improve through small, frequent changes. sweat the important details and strive for excellence.

Qualifications


 * BS/MS in Computer Science, Engineering or a related technical field
 * Extensive experience within our tech stack including Python, Django, Postgres, Redis, Pub/Sub
 * Experience with CI/CD pipelines and infrastructure stack including Docker, Kubernetes and GCP
 * Proficiency writing unit and integration tests
 * Experience owning technically challenging cross-functional projects
 * Proven ability to work in a fast-paced startup environment and execute autonomously
 * User-first mindset to make sure what weʼre building meets their needs
 * Basic understanding of front-end technologies like Typescript
 * Sense of urgency and ability to ship quality code in tight timelines
   
   
   

Preferred Qualifications


 * Experience with Frontend development in Typescript
 * Experience with deployments and operations on GCP
 * Experience providing high quality code reviews
 * Experience contributing to open source projects
 * Experience developing e-commerce or marketplace platforms
   
   
   

Applicants must be authorized to work for ANY employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time.

Arcade is an Equal Opportunity Employer committed to inclusion and diversity. We welcome people of different backgrounds, experiences, abilities and perspectives and will consider all qualified applicants for employment in accordance with all state, local, and federal laws.",Full-time
4045410859,66321745.0,Remote Software Engineer (Junior/Entry),"Since 2010 Synergisticit has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this Job market also, our candidates are able to achieve multiple job offers and $100k &plus; salaries.

please check the below links to see success outcomes, salaries of our candidates .

https://www.synergisticit.com/candidate-outcomes/

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please visit the below videos exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

Required Skills

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, Gen AI, LLM, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full Stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java , javascript , C&plus;&plus; or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Full-time
4132707409,79383535.0,Data Engineer,"Akkodis is seeking a Data Engineer for a Direct Hire (FTE) position, and this is a 100% On-Site role that must sit in Omaha, Nebraska. This candidate will heavily focus on ETL processes and moving data into operational data stores using SQL and Python. Find out more about this Direct Hire position below.




Salary Range: $110K-$130K per annum. The salary may be negotiable based on experience, education, geographic location, and other factors.




Responsibilities

 * Demonstrate experience in data engineering with 8 years' experience using ETL tools (e.g., Informatica, DataStage).
 * Strong relational database knowledge, including a broad understanding of current and prospective data architecture and database performance tuning.
 * 6+ years of SQL experience.
 * 4+ years' experience using Python.
 * 8+ years of IT experience, to include at least 6 years’ progressive experience in relational database management systems.




If you are interested in this position, then please click APPLY NOW. For other opportunities available at Akkodis go to www.akkodis.com.




Equal Opportunity Employer/Veterans/Disabled




Benefit offerings include medical, dental, vision, term life insurance, short-term disability insurance, additional voluntary benefits, commuter benefits, and a 401K plan. Our program provides employees the flexibility to choose the type of coverage that meets their individual needs. Available paid leave may include Paid Sick Leave, where required by law; any other paid leave required by Federal, State, or local law; and Holiday pay upon meeting eligibility criteria. Disclaimer: These benefit offerings do not apply to client-recruited jobs and jobs that are direct hires to a client.




To read our Candidate Privacy Information Statement, which explains how we will use your information, please visit https://www.akkodis.com/en/privacy-policy




The Company will consider qualified applicants with arrest and conviction records.",Full-time
3990955818,35516092.0,Data Engineer,"Translate technical complexities, develop appropriate solutions, and contribute to the agency of transformation our agency into a data-driven culture.

Essential Duties/Responsibilities


 * Work closely with the solution leads, project managers, data architects, data scientists, and data analysts on solution design, architecture, and implementation
 * Performing extraction, transformation, and loading of data from a wide variety of data sources using various data engineering tools and methods.
 * Designing and implementing data solutions for operational and secure integration across systems.
 * Assist, with guidance and oversight from data architects, in creating database models and architecture design and documentation
 * Conduct research and development as well as contribute to the long-term positioning of and emerging technologies related to data sourcing, cleansing, and integration
 * Documenting and demonstrating solutions by developing documentation, flowcharts, layouts, diagrams, charts, code comments and clear code.
 * Improving operations by conducting systems analysis; recommending changes in policies and procedures.
 * Involvement requirements gathering, solution reviews, and explaining technical complexities and business benefits in layperson terms.
   
   

Job Requirements


 * Bachelor's degree in Computer Science, Engineering or a similar field is required
 * 3+ years of data engineering, software engineer, or similar experience
 * 2+ hands-on industry experience working with SQL on various relational database platforms (Microsoft, Oracle, Hana, Postgres, etc.)
 * 2+ hands-on industry experience working with enterprise ETL/DW tools like Azure Data Factory, Redshift, Informatica, etc.
 * Hands-on experience with aspects of data engineering design and implementation including data sourcing, data modeling of warehouses/marts/repositories, data integration/transformation/ETL, APIs, reporting, business intelligence and analytics
 * Hands-on experience with modern programing languages like Python, C#, JavaScript, etc.
 * Hands-on experience with cloud platforms like AWS, Azure, GCP, etc.
 * Experience with Docker for containerization and Kubernetes for orchestration a plus
 * Collaborative team player who is detailed oriented, focused on solution quality and execution
 * Progressive mindset particularly around deployment models and emerging technologies
   
   

Supervisory Responsibilities/Direct Reports

No direct supervision responsibilities. Some oversight/guidance of staff on projects

Difficulty Of Work

Work assignments involve contributing to a wide variety of general and complex modeling and data engineering projects. The broad range of project goals requires excellent time management, analytical prowess, database querying, and data engineering design and implementation skills. Good judgement and ability to apply specialized knowledge are required to perform duties successfully. Work assignments also require critical thinking and decision-making abilities.

Responsibility

Expected to complete project tasks independently with minimal guidance from senior staff. Work products are periodically reviewed for quality, accuracy, efficiency, and achievement of project goals by senior staff. Incumbent keeps supervisor and coworkers apprised of work.

Regularly responsible for execution of tasks that impact priorities, as well as tasks impacting specific program areas. May also contribute to projects with broader agency impact, under supervision of senior staff.

Expected to work collaboratively with other staff to make progress toward agency priorities and advancing the mission.

Personal Work Relationships

This staff member works independently, with some support from other team members and management, to complete various modeling and data engineering projects. Maintains relationships with project teams and program area staff.

Physical Effort

Requires sitting for long periods in front of a computer.

Working Conditions

Work is performed indoors in a routine office environment or from an approved remote location.",Contract
4077297411,1636943.0,"Databricks Data Engineer / Data Engineer, Databricks, 24-13040","Databricks Data Engineer / Data Engineer, Databricks, 24-13040

The Short Scoop

Looking for an exciting opportunity to build transformative data solutions? My client seeks a Databricks Data Engineer to play a pivotal role in advancing data integration and analytics capabilities. This on-site position offers the chance to work on cutting-edge projects that drive business growth, optimize operations, and redefine industry standards for data utilization.




Location: Addison, IL Or Warren, MI

Status: 100% on-site, with 1 day a week work from home!




**** THIS IS NOT A REMOTE CAREER OPPORTUNITY

**** RELOCATION COMPENSATION IS NOT A CONSIDERATION

**** MUST HAVE EXPERIENCE CREATING DATA PIPELINES IN DATABRICKS




Why You Should Apply

 * Lead Innovation: Shape advanced analytics and data integration solutions that directly impact company strategy.
 * Dynamic Tech Stack: Work with Databricks, Python, and Spark to design scalable pipelines and ETL workflows.
 * Impactful Role: Enable real-time decision-making by providing accurate and integrated data to internal and external stakeholders.
 * Professional Growth: Collaborate with senior IT and business leaders to solve complex challenges.




The outstanding benefits package includes the following

 * Benefits
 * Medical has 2 options HRA, FSA
 * Dental Plan
 * Vision Plan
 * Basic Life/AD&D/Additional Voluntary Benefits
 * Supplemental Life: Option to purchase
 * Short-Term Disability / Long-Term Disability
 * Wellness Program
 * Tuition Reimbursement
 * Employee Assistance Plan
 * 401 (k) Plan - Two options for contributions.
 * Sales Bonus
 * Vacation based on experience accrued throughout the year
 * Holidays 8 company paid, 2 floating holidays
 * Benefits may have been updated – Details confirmed upon offer.




Compensation range: 110-120K annually




What You’ll Be Doing

 * Developing backend data models and scalable ETL workflows on Databricks.
 * Building and automating processes for data transformation, synchronization, and integration.
 * Collaborating with business experts to analyze source data and ensure data aligns with business needs.
 * Defining data architecture strategies, including data governance, management, and advanced analytics.
 * Debugging and optimizing complex code for maintainability and efficiency.




About You

 * Be able to do the job as described.
 * 3+ years of experience with Databricks, including the ability to build end-to-end pipelines in Databricks.
 * Skilled in Python, Spark, and SQL for data engineering tasks.
 * Experience with conceptual and logical data modeling and ETL design.
 * Ability to collaborate with cross-functional teams and translate business needs into data solutions.
 * Preferred technologies – SQL Server, Power BI, SSIS




How To Apply




We’d love to see your resume, but we don’t need it to have a conversation. It is as easy as one, two, three! Send an email to directly to me, teambradley123 (at) gmail (dot) com and tell me why you’re interested. Or, if you do have a resume ready, apply on this site.




Setting Expectations

We’d love to help every single person who is interested and applies to this role. Unfortunately, too many people apply who don’t appear capable of doing the job. We apologize in advance, but we will not be able to respond directly to all submissions.




Sponsorship is not an option for this role.

This client is an Equal Opportunity Employer

This is NOT A REMOTE ROLE!




TBI Id No: 24-13040, Data Engineer, Databricks / Databricks Data Engineer",Full-time
4119679711,29619.0,Data Engineer - Python/Airflow Developer,"Job Type

Full-time

Description

We are HALO! We connect people and brands to create unforgettable, meaningful, and lasting experiences that build brand engagement and loyalty for our over 60,000 clients globally, including over 100 of the Fortune 500. Our nearly 2,000 employees and 1,000 Account Executives located in 40+ sales offices across the United States are the reason HALO is #1 in our $25B industry.

Halo Branded Solutions is seeking a highly skilled and experienced Data Engineer to join our team. The successful candidate will be responsible for designing, developing, and maintaining data integrations to expand our enterprise data warehouse and integrate data in other platforms. This role requires a strong background in data/software engineering, DevOps, and Agile methodologies.


 * Note: Must be able to work Eastern or Central time hours*******Must be able to the go to the Oakbrook, IL office once a Qtr.****
   
   

Key Responsibilities:


 * Design and implement data integration solutions using tools such as Apache Airflow, Informatica, Python, and Snowflake.
 * Develop and maintain ETL processes to ensure data is accurately and efficiently loaded into the data warehouse.
 * Develop error handling, alerting, monitoring, and testing processes into data pipelines.
 * Collaborate with cross-functional teams to understand data requirements and deliver solutions that meet business needs.
 * Manage and optimize data pipelines for performance and scalability.
 * Implement and manage DevOps practices in the Data Engineering environment, including version control with BitBucket and continuous integration/continuous deployment (CI/CD) with Jenkins.
 * Develop and manage branching strategies to support multiple development streams.
 * Ensure data quality and integrity through rigorous testing and validation.
 * Work with databases and SQL to extract, transform, and load data.
 * Integrate data from various APIs into the data warehouse and other data platforms.
 * Participate in Agile development processes, including sprint planning, daily stand-ups, and retrospectives.
 * Use Jira for task management and tracking progress.
 * Be available for occasional on-call night/weekend support.
   
   

Requirements


 * Bachelor’s degree in Computer Science, Information Technology, or a related field.
 * Proven experience as a Data Engineer or in a similar role.
 * Strong understanding of data warehousing concepts and best practices, especially with Snowflake.
 * Experience with ETL tools and processes.
 * Proficiency in Python and SQL.
 * Hands-on experience with DevOps tools and practices.
 * Familiarity with Agile methodologies and tools like Jira.
 * Excellent problem-solving skills and attention to detail.
 * Strong communication and collaboration skills.
 * Experience with AWS.
   
   

Preferred Qualifications:


 * Experience with data modeling of data warehouses
 * Experience with Apache Airflow is a plus.
   
   

Key Skills and Technologies:


 * Apache Airflow
 * Informatica
 * Python
 * Snowflake
 * BitBucket
 * Jenkins
 * AWS
 * Databases and SQL
 * API Integrations
 * Agile Methodologies
 * Jira
 * ServiceNow
   
   

Why Join Us:


 * Opportunity to work with cutting-edge technologies and shape the future of data architecture in our organization.
 * Collaborative and innovative work environment.
 * Competitive salary and benefits package.
 * Professional development and growth opportunities.
   
   

If you are a visionary data engineer with a passion for building scalable and efficient data solutions, we would love to hear from you. Apply now to join our team and make a significant impact on our data-driven journey.

Compensation: The estimated base salary range for this position is between $90,000 and $130,000 annually. Please note that this pay range serves as a general guideline and reflects a broad spectrum of labor markets across the US. While it is uncommon for candidates to be hired at or near the top of the range, compensation decisions are influenced by various factors. At HALO, these include, but are not limited to, the scope and responsibilities of the role, the candidate's work experience, location, education and training, key skills, internal equity, external market data, and broader market and business considerations.

Benefits: At HALO, we offer benefits that support all aspects of your life, helping you find a work-life balance that’s right for you. Our comprehensive benefits include nationwide coverage for Medical, Dental, Vision, Life, and Disability insurance, along with additional Voluntary Benefits. Prepare for your financial future with our 401(k) Retirement Savings Plan, Health Savings Accounts (HSA), and Flexible Spending Accounts (FSA).

More About HALO:

At HALO, we energize our clients' brands and amplify their stories to capture the attention of those who matter most. That’s why over 60,000 small- and mid-sized businesses partner with us, making us the global leader in the branded merchandise industry.


 * Career Advancement: At HALO, we’re passionate about promoting from within. Internal promotions have been key to our exponential growth over the past few years. With so many industry leaders at HALO, you’ll have the opportunity to accelerate your career by learning from their experience, insights, and skills. Plus, you'll gain access to HALO’s influential global network, leadership opportunities, and diverse perspectives.
 * Culture: We love working here, and we’re confident you will too. At HALO, you’ll experience a culture of ingenuity, inclusion, and relentless determination. We push the limits of possibility and imagination by staying curious, humble, and bold breaking through yesterday’s limits. Diversity fuels our creativity, and we thrive when each of us contributes to an inclusive environment based on respect, dignity, and equity. We hold ourselves to a high standard of excellence with a commitment to results and supporting one another with accountability, transparency, and dependability.
 * Recognition: At HALO, your success is our success. You can count on us to celebrate your wins. Colleagues across the company will join in recognizing your milestones and nominating you for awards. Over time, you’ll accumulate recognition that can be converted into gift cards, trips, concert tickets, and merchandise from your favorite brands.
 * Flexibility: Many of our roles offer hybrid work options, and we pride ourselves on flexible schedules that help you balance professional and personal demands. We believe that supporting our customers is a top priority and trust that you and your manager will collaborate to create a schedule that achieves this goal.
   
   

HALO is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We insist on an environment of mutual respect where equal employment opportunities are available to all applicants without regard to race, color, religion, sex, pregnancy (including childbirth, lactation and related medical conditions), national origin, age, physical and mental disability, marital status, sexual orientation, gender identity, gender expression, genetic information (including characteristics and testing), military and veteran status, and any other characteristic protected by applicable law. Inclusion is a core value at HALO and we seek to recruit, develop and retain the most talented people.

HALO participates in E-Verify. Please see the following notices in English and Spanish for important information: E-Verify Participation and Right to Work.

HALO is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need reasonable accommodation because of a disability for any part of the employment process – including the online application and/or overall selection process – you may email us at hr@halo.com. Please do not use this as an alternative method for general inquiries or status on applications as you will not receive a response. Reasonable requests will be reviewed and responded to on a case-by-case basis.",Full-time
4091949778,3631.0,Data Engineer,"The Opportunity

At MassMutual, we are dedicated to empowering millions of individuals to achieve financial independence, a commitment that fuels our journey to create highly interactive digital experiences for our customers. As part of our Data Platform Data Engineering team, we are seeking Data Engineers who are enthusiastic about utilizing data to drive impactful business outcomes.

As a Data Engineer - you are proficient in design, development, and review of data pipelines towards Analytical and Operational data.

The Team

The Data Engineering team in Enterprise IT Product and Operations Technology organization, is comprised of highly skilled, collaborative, problem solvers who are motivated to create innovative solutions that exceed the changing needs of our customers and move MassMutual forward. As a Data Engineer you will be transforming complex data into actionable insights and are committed to a culture of growth and evolving capabilities in the dynamic field of data engineering.

The Impact


 * Define and establish a Data Integration Strategy which will enable the systems integrations moving from point-to-point to passthrough model.
 * Design, develop and implementation of data integration solutions supporting batch/ETL and API-led integrations that deliver tangible business value.
 * Proactively assess the current state of the technology and identify gaps and overlaps. Capture future state technology vision in actionable, context-specific roadmaps.
 * Develop policies around data quality, data security, data retention, data stewardship, and proactively identify and support project impacts.
 * Serves as an expert level technical resource across multiple initiatives.
 * Work in a team-based environment including a global workforce, vendors, and third-party contractors.
 * Translate high-level business requirements into detailed technical specifications.
 * Collaborate closely with peers, offering mentorship and fostering a knowledge-sharing environment.
 * Continuously evaluate and advocate for advanced tools, technologies, and processes that drive industry best practices.
 * Actively participate in our Agile development processes, contributing to team meetings and delivering incremental improvements.
 * Collaborate with cross-functional teams to understand data requirements and deliver reliable data solutions.
 * Monitor data pipeline performance, troubleshoot issues, and implement optimizations to improve efficiency.
 * Assist in the design and development of APIs for seamless data integration across platforms.
   
   

The Minimum Qualifications


 * Bachelor’s degree in computer science, Engineering, or a related field.
 * 5+ years of Data engineering experience in designing/ building complex data pipelines supporting data analytics and data warehousing.
 * 4+ years working with Data and relevant computation frameworks and system.
 * 4+ years using Python programming language.
 * 5+ years’ experience in writing SQL and query optimization.
 * 3+ years of experience with Cloud Technologies preferably AWS.
 * 3+ years of experience working with columnar databases such as AWS Redshift, Snowflake, Databricks, Vertica etc.
   
   

The Ideal Qualifications

Beyond the minimum qualifications, the ideal candidate will also possess the following additional qualifications


 * Master’s degree in computer science or engineering.
 * Cloud Technologies: Proven experience in a cloud computing environment, preferably AWS (S3, EC2, Kubernetes, Terraform, etc.).
 * Python: Practical development and data analysis experience using Python.
 * Advanced Data Processing: Knowledge in using data processing technologies such as Apache Spark or Kafka.
 * Workflow Management: Familiarity with orchestration and scheduling tools like Apache Airflow.
 * Experience with data reporting and visualization tools (e.g., MicroStrategy, Tableau) and data cataloging tools (e.g., Alation).
 * Experience with Agile data engineering principles and methodologies
 * Exceptional problem-solving skills and willingness to learn new concepts, methods, and technologies.
 * Strong understanding of ELT methodologies and tools.
 * Experience in data warehousing and familiarity with data warehousing concepts and terminologies.
 * Capable of troubleshooting and conducting root cause analysis to address and resolve data issues effectively.
 * Analyze and develop physical database designs, data models and metadata
 * Communication: Outstanding communication skills, coupled with strong problem-solving, organizational, and analytical abilities.
   
   

What to Expect as Part of MassMutual and the Team


 * Regular collaboration with the Data Platform Data Engineering team.
 * Focused one-on-one time with your manager to support your development.
 * Access to mentorship opportunities within and outside the team.
 * Networking opportunities including access to diverse Business Resource Groups.
 * Engage with learning content on Degreed and other platforms to enhance your skills.
 * Your ethical values will be appreciated in a company known for its strong ethical standards, offering industry-leading pay and benefits.
   
   

MassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran. We welcome all persons to apply. Note: Veterans are welcome to apply, regardless of their discharge status.

If you need an accommodation to complete the application process, please contact us and share the specifics of the assistance you need.

",Full-time
4094015693,14858.0,Data Engineer,"The Data Engineer will be responsible for building and maintaining enterprise data management infrastructure both on-premises and in the cloud. The Data Engineer will be responsible for orchestrating pipelines using modern data tools/architectures as well as design and engineering of existing transactional and RDBMS processing systems.

Work Schedule This position currently follows a hybrid work model. Employees are required to work from the office at least four days per week (Monday - Thursday), with Friday available for remote work, offering a blend of in-person collaboration and flexibility.


 * Develop and maintain data pipelines that extract, transform, and load data into an information and analytics environment
 * Develop and maintain datasets in a conventional data warehouse (operational data store, dimensional models)
 * Develop and maintain datasets in a modern, cloud-based data warehouse (Redshift, Snowflake, Azure)
 * Implement and configure data sets on column oriented (column-store) database management systems
 * Assist application development teams during application design and development for highly complex and critical data projects.
 * Create and enhance analytic and data platforms using tools that enable state of the art, next generation capabilities and applications.
 * Utilize programming languages like SQL, Java, Spark, Python, with an emphasis in tuning, optimization, and best practices for application developers.
 * Function as team member in an Agile development environment
 * Leverage DevOps techniques and practices like Continuous Integration, Continuous Deployment, Test Automation, Build Automation and Test-Driven Development to enable the rapid delivery of end user capabilities’
 * Develop data solutions on cloud deployments such as AWS and Azure.
 * Understand concepts of data ingestion from event driven architectures
 * Remain on the cusp of new technologies in Data Engineering, Big Data and Analytics, and Cloud space.
 * Bachelor’s degree from an accredited institution or equivalent experience.
 * 4+ years experience connecting to various data sources and structures APIs, NoSQL, RDBMS, Blob Storage, Data Lake, etc. Knowledge of cloud providers such as AWS, Azure, and Snowflake
 * Database systems (SQL and NoSQL)
 * ETL tools including SSIS, Glue, and Kinesis Firehose
 * Data APIs
 * Python, PowerShell
 * Experience with multiplatform integration and distributed systems (Kafka)
 * Experience with Dev Ops tools such as Azure DevOps and Visual Studio
 * Master Data Management (MDM)
 * Understanding of data-warehousing and data-modeling techniques
 * Advanced level SQL for data transformations, queries & data modeling
 * Data Quality tools and processes.
 * Graph Database Systems including Neo4J
 * Cypher Query Language
 * Data warehousing solutions
 * T-SQL, MDX, and Spark programming languages
 * Prior knowledge of modern Cloud based ETL tools such as Matillion or Fivetran
   
   
   

Established in 2002, Isagenix International has created simple, proven products that optimize what your body is capable of—helping you protect your greatest asset, your health. For more than twenty years, Isagenix has made holistic science an art with transparency and integrity—creating products and systems that address nutrition, stress, fitness, energy, natural beauty, focus, and financial wellbeing. The global wellbeing company, based in Gilbert, Arizona, markets its products through a network of independent distributors in 22 key markets the United States, Canada, Puerto Rico, Australia, New Zealand, Mexico, the United Kingdom, Ireland, the Netherlands, Belgium, Spain, Austria, Denmark, Finland, France, Germany, Italy, Norway, Poland, Portugal, Sweden, and Switzerland. For more information, visit Isagenix.com.

Isagenix International, LLC is an equal opportunity employer and affords equal opportunity to all applicants for all positions without regard to race, color, religion, sex, national origin, age, disability, veteran status or any other status protected by law.",Full-time
4115777013,101021.0,Data Engineer (Hybrid),"Job Title: Data Engineer

Location: Falls Church, Pentagon, Alexandria, or Arlington

Workplace: Hybrid (must be able to commute to one of the above offices 2-3 times per week)

Clearance Required: must have an active Top-Secret (TS) clearance (must be able to achieve a TS/SCI clearance with scope)

Position Overview

Supports the Department of Defense's (DoD) Chief Digital and Artificial Intelligence Officer's (CDAO) Mission Analytics / Core Analytics Products, Search Products Portfolio, and Unstructured Data Search Enhanced by AI/ML (UD/SEAM).

Major Duties/Tasks


 * Support the configuration and ingestion of designated structured, unstructured, and
   
   

semi-structured data repositories into capabilities that satisfy mission partner

requirements and support a data analytics and DevOps pipeline to drive rapid delivery

of functionality to the client;


 * Maintain all operational aspects of data transfers while accounting for the security
   
   

posture of the underlying infrastructure and the systems and applications that are

supported and monitoring the health of the environment through a variety of health

tracking capabilities;


 * Automate configuration management, leverage tools, and stay current on data extract,
   
   

transfer, and load (ETL) technologies and services;


 * Work under general guidance, demonstrate an initiative to develop approaches to
   
   

solutions independently, review architecture, and identify areas for automation,

optimization, right-sizing, and cost reduction to support the overall health of the

environment;


 * Apply comprehension of data engineering-specific technologies and services, leverage
   
   

expertise in databases and a variety of approaches to structuring and retrieving of data,

comprehend Cloud architectural constructs, and support the establishment and

maintenance of Cloud environments programmatically using vendor consoles;


 * Engage with multiple functional groups to comprehend client challenges, prototype new
   
   

ideas and new technologies, help to create solutions to drive the next wave of

innovation, and design, implement, schedule, test, and deploy full features and

components of solutions


 * Identify and implement scalable and efficient coding solutions
 * Maintain an existing collection of web scraping tools used as the initial step of the ETL
   
   

process

Requirements

Required Education:


 * Bachelor’s degree plus 5-10 years experience, or a Masters Degree plus 3-5 years of
   
   

experience.

Required Skills/Experience


 * Experience with Big Data systems, including Apache Spark / Databricks
 * Experience with ETL processes;
 * Experience with Amazon Web Services (AWS), Microsoft Azure, or MilCloud 2.0;
 * Applying DoD Security Technical Implementation Guides (STIGs) and automating that
   
   

process


 * Experience with multiple coding languages
 * Experience engineering data pipelines across multiple security domains / classified
   
   

networks

Preferred Skills And Qualifications


 * An active TS/SCI clearance
   
   

Experience With


 * the DoD’s CDAO, Advana, or other CDAO products
 * Agile methodology
 * AI-enhanced search
 * AI/ML for information retrieval and insight extraction
   
   

About Elder Research, Inc

People Centered. Data Driven

Elder Research is a fast growing consulting firm specializing in predictive analytics. Being in the data mining business almost 30 years, we pride ourselves in our ability to find creative, cutting edge solutions to real-world problems. We work hard to provide the best value to our clients and allow each person to contribute their ideas and put their skills to use immediately.

Our team members are passionate, curious, life-long learners. We value humility, servant-leadership, teamwork, and integrity. We seek to serve our clients and our teammates to the best of our abilities. In keeping with our entrepreneurial spirit, we want candidates who are self-motivated with an innate curiosity and strong team work.

Elder Research believes in continuous learning and community - each week the entire company attends a “Tech Talk” and each office location provides lunch. Elder Research provides a supportive work environment with established parental, bereavement, and PTO policies. By prioritizing a healthy work-life balance - with reasonable hours, solid pay, low travel, and extremely flexible time off - Elder Research enables and encourages its employees to serve others and enjoy their lives.

Elder Research, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

Elder Research is a Government contractor and many of our positions require US Citizenship.",Full-time
4145919840,3076.0,AI Data Engineer,"Responsibilities

Kforce has a client that is seeking an AI Data Engineer in Frisco, TX. Responsibilities:


 * AI Data Engineer will design, develop, and maintain scalable data pipelines and architectures for AI and machine learning projects, with a focus on Salesforce Data Cloud and Agentforce
 * Collaborate with data scientists, analysts, and other stakeholders to understand data requirements and deliver solutions using Salesforce Data Cloud
 * Implement data collection, cleansing, and preprocessing techniques to ensure data quality and integrity within the Salesforce ecosystem
 * Develop and optimize ETL (Extract, Transform, Load) processes to support data integration from various sources into Salesforce Data Cloud
 * Build and maintain databases, data warehouses, and data lakes to store and manage large volumes of structured and unstructured data within Salesforce
 * Ensure data security and compliance with relevant regulations and best practices, leveraging Salesforce's security features
 * As an AI Data Engineer, you will monitor and troubleshoot data pipeline performance and reliability within Salesforce Data Cloud
 * Utilize Agentforce to create and deploy AI agents that automate tasks and interact with customers across the business
 * Stay updated with the latest trends and advancements in AI, machine learning, and data engineering, particularly within the Salesforce ecosystem.
   
   

Requirements


 * Bachelor's or Master's degree in Computer Science, Data Engineering, or a related field
 * Proven experience as a Data Engineer, AI Engineer, or similar role, with a focus on Salesforce Data Cloud and Agentforce
 * Strong programming skills in languages such as Python, Java, or Scala
 * Experience with big data technologies like Hadoop, Spark, and Kafka
 * Proficiency in SQL and NoSQL databases
 * Familiarity with Salesforce Data Cloud and Agentforce, including their integration and customization
 * Knowledge of machine learning frameworks and libraries (e.g., TensorFlow, PyTorch)
 * Excellent problem-solving skills and attention to detail
 * Strong communication and collaboration abilities
   
   

Preferred Qualifications


 * Certifications in relevant technologies or platforms, especially Salesforce
 * Experience with data visualization tools (e.g., Tableau, Power BI)
 * Understanding of data governance and data privacy principles
   
   

The pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.

We offer comprehensive benefits including medical/dental/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.

Note: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.

This job is not eligible for bonuses, incentives or commissions.

Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.

By clicking “Apply Today” you agree to receive calls, AI-generated calls, text messages or emails from Kforce and its affiliates, and service providers. Note that if you choose to communicate with Kforce via text messaging the frequency may vary, and message and data rates may apply. Carriers are not liable for delayed or undelivered messages. You will always have the right to cease communicating via text by using key words such as STOP.",Contract
4151629160,55702.0,Amazon Connect Data Engineer,"Are you looking for a challenging role as an Amazon Connect Data Engineer?

As a leading strategic service provider (SSP), InterVision assists IT leaders & C-Suite executives in solving the most crucial business challenges they face by solving for the right technology, deployed on the right premises, and managed through the right model to fit their unique demands and meet their long-term goals.

InterVision�s mission is to transform business through the evolutionary power of technology, and we are committed to unlocking value by delivering innovative technology services through a consultative approach. Our people are the best in their field!

If you are looking for a career changing opportunity, we want to meet you!

InterVision Systems Inc. is seeking a seasoned Data Engineer with proven expertise in Amazon Connect to join our dynamic application development team. This is not an entry-level role; we are seeking a professional who has worked extensively in production environments, possesses hands-on experience with complex data engineering tasks, and has demonstrated success in delivering scalable solutions with measurable business impact.

In this role, you will lead data initiatives leveraging your deep understanding of Amazon Connect to create custom SQL queries, analyze data, and deliver actionable insights. You will collaborate across teams to optimize the reporting and analysis capabilities built by the Amazon Connect development team, focusing on advanced metrics, KPIs, and data aggregation processes.

What We�re Looking For


 * Significant Professional Experience (Required):
    * A minimum of 5 years of hands-on technical experience in data engineering, with a strong focus on SQL development and Amazon Web Services (AWS) solutions.
    * Prior work in production environments solving real-world business challenges with robust, scalable solutions.
    * Experience in managing large-scale data pipelines, cross-team collaborations, and performance-critical projects.

 * Amazon Connect Expertise (Required):
    * In-depth knowledge of data structures and flows for CTRs, Agent Events, Contact Lens, and Evaluations.
    * Proven experience extracting, analyzing, and leveraging Amazon Connect data for actionable insights.
    * Proficiency in Athena for querying Amazon Connect data.

 * SQL Mastery:
    * Advanced skills in joins, aggregations, window functions, partitioning, and ranking.
    * Demonstrated ability to write and optimize complex SQL queries in live production systems.

 * AWS Services:
    * Kinesis/Firehose: Strong understanding of data streaming and real-time processing.
    * AWS Glue: Skilled in working with external tables, partitioning, and handling semi-structured data (JSON/Parquet).
    * CloudWatch:
       * Expertise in log analysis, creating and querying CloudWatch Logs Insights, and setting up alarms/metric filters.
   
    * Lambda: Practical experience building, optimizing, and maintaining Lambda functions.
    * S3: Deep understanding of storage solutions and cross-account replication.

 * Programming Proficiency:
    * Advanced knowledge of Python (including boto3 for AWS).
    * Experience integrating Snowflake and Lambda solutions.

 * Infrastructure Expertise:
    * AWS CloudFormation, SAM, CDK: Demonstrated ability to manage infrastructure as code and build CI/CD pipelines.
    * Git: Skilled in version control, managing branches, and resolving complex merges in team environments.

 * Data Platforms:
    * Snowflake: Expertise in optimizing queries and large-scale data warehousing.
    * Tableau: Proven ability to create impactful reports and visualizations for stakeholders.
      

What You�ll Bring


 * Problem-Solving Acumen: The ability to design innovative solutions for complex data engineering challenges.
 * Demonstrated Impact: A history of delivering measurable business results through data engineering.
 * Advanced Skillset: A mastery of tools and technologies that exceeds foundational knowledge, applied in production.
 * Independent Leadership: The ability to thrive in high-impact, fast-paced environments without requiring extensive mentorship.
   
   

Not a Fit If


 * You are a recent graduate or transitioning into data engineering from another field without direct experience.
 * You lack substantial hands-on expertise in Amazon Connect or AWS services.
   
   

How Do We Back Our Strong Reputation?

GREAT PLACE TO WORK: InterVision is an AWS Premier Partner and Microsoft Azure Gold Partner with a rapidly growing team of world class AWS and Azure Solution Architects, Cloud Engineers, DevOps Specialists, Security Specialists, Network specialists, Database specialists, Big Data specialists, and ML/AI data scientists. InterVision has Architects and Engineers with many AWS, Azure, and GCP certifications. We also have Architects and Engineers with extensive edge technology and hybrid cloud experience, as well as application development experience. Our team has experience with a wide variety of AWS services, and we are increasingly growing our Azure practice so that many of our team are experts in multi-cloud environments. InterVision has many AWS competencies - Migration, DevOps, Digital Workplace, Storage, Government and Education. We do work for many different types of clients in many different business domains. Our team is widely dispersed across the US but is in constant communication using Slack and other collaboration tools, so you will immediately feel welcome and part of the team and will be able to share your experiences and learn from others. We invest in our team: All of staff have access to ongoing education and personal development.

CUSTOMER SUCCESS: When it comes to technology, our 25+ year history has guided some of the largest and most influential companies solve their problems with a broad range of innovative technologies ranging from network infrastructure to collaboration to cloud migrations.

InterVision can not only help clients refine their strategy with the right technology and the right cloud strategy, but also bring the resource models to take it to the finish line, assuring them a powerful combination of vision and capabilities.

BROAD CAPABILITIES: InterVision offers a wide range of services and solutions that organizations need to thrive in today�s dynamic IT market, including a broad range of innovative solutions for datacenter and cloud transformation, IT resiliency, modern communications, remote workforce, and advanced data analytics. We are competitive at all levels of engagement.

INDUSTRY ACCOLADES: InterVision has received some of the technology industry�s most prestigious awards and acknowledgements � repeatedly by Gartner� and Forrester� plus Inc. Magazine�s 5000 Fastest Growing Private Companies.

TOP VENDOR CERTIFICATIONS: InterVision holds the highest certifications and partner levels with leading technology vendors, and we have teams of trained, certified engineers supporting their solutions. Here are just a few of the certifications from our list of 80+ vendors: Amazon Partner Network (APN) Premier Consulting Partner (with seven competencies), NetApp Star Partner, Cisco Gold Certification, Cisco Cloud and Managed Services Master, Juniper Elite Partner, Microsoft Gold Partner, AT&T Premier Partner, Palo Alto Networks Diamond Partner, and VMware Premier Partner to name a few.

",Full-time
4120820991,10667.0,"Data Engineer, Product Analytics","As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a world-class data engineering community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Data Engineer, Product Analytics Responsibilities:


 * Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems
 * Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve
 * Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way
 * Define and manage Service Level Agreements for all data sets in allocated areas of ownership
 * Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership
 * Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains
 * Solve our most challenging data integration problems, utilizing optimal Extract, Transform, Load (ETL) patterns, frameworks, query techniques, sourcing from structured and unstructured data sources
 * Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts
 * Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts
 * Influence product and cross-functional teams to identify data opportunities to drive impact
 * Mentor team members by giving/receiving actionable feedback
   
   

Minimum Qualifications:


 * Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent
 * 4+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions
 * 4+ years of experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.)
   
   

Preferred Qualifications:


 * Master's or Ph.D degree in a STEM field
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$145,000/year to $204,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4117829484,285112.0,Data Engineer,"Job Description

Description:

POSITION/JOB TITLE: Data Engineer

DEPARTMENT: Engineering


 * REQUIREMENTS: Qualified candidates must be legally authorized to be employed in the United States on a full-time basis for any position. Omnitech will not provide sponsorship for employment visa status (e.g., H-1B or TN status) for this position.***
 * Onsite position, NO remote. ****
   
   

Do you have a data-driven, engineering mind and a consulting-type personality?

Omnitech is an established, locally owned software engineering firm that specializes in helping businesses create and fulfill opportunities through custom technology solutions. We are a Microsoft Partner that values a community of mentors to cultivate skills and interests that are in line with our client’s needs. We understand that the journey to the solution can be just as important as the destination – for both clients and our engineers.

As a Data Engineer at Omnitech, you would qualify for multiple labels including business intelligence consultant, data warehouse consultant, data acquisition (ETL) consultant, database administrator consultant, master data management consultant, data analyst, data architect, data scientist to name a few. We don’t believe in narrowly defined labels and hierarchy. We believe in helping people solve problems.

DESIRED SKILLS: (The applicable candidate must possess a number of the following.)


 * Strong T-SQL skills
 * SQL Server design and development experience
 * Understanding of data profiling techniques
 * Understanding of performance optimization, data warehousing, cube architecture
 * Understanding of common data extraction techniques across a diverse set of sources including structured and non-structured data
 * Experience with data cleansing and conforming techniques
 * Develop standards and best practices to ensure data standardization and consistency as required
 * Strong experience with dimensional modeling, star schema and Kimball Data Warehouse methodologies
 * Design and develop data warehousing solutions for clients across a variety of industries and business sizes utilizing Microsoft's SQL Server Platform
 * Perform the role of subject matter expert for Microsoft Business Intelligence technologies including SQL Server and Analysis Services
 * Knowledge of Multidimensional Expression (MDX) and Data Analysis Expressions (DAX) languages
 * Familiarity with managing dimensional attribute history through Slowly Changing Dimension (SCD) concepts
 * Working knowledge of ETL change detection solutions such as change data capture (CDC)
 * Experience with Big Data technology a plus
 * Understanding of SQL Server FastTrack and/or Parallel Data Warehouse
 * Familiarity with storage technologies (e.g. SAN, NAS, etc.) a plus
 * Translate business requirements and technical designs into well-developed solutions that meet client business goals
 * Ability to explain the pros and cons of architectural decisions
 * Evaluate and recommend new technologies as required
 * Design and implement technology best practices, guidelines and repeatable processes
 * Provide technical assistance and cross training to other team members and clients
 * Participate in the business intelligence community to promote the use of the Microsoft BI platform and general data warehousing best practices
 * Assist in pre-sales, scoping and requirements gathering process
 * Ability to work closely with other project team members such as sales analysts, project managers, and software engineers
   
   

REQUIREMENTS:


 * 3 years Data experience
 * A Bachelor’s Degree in computer science, with emphasis in mathematics, or a similar analytical degree
 * T-SQL, SQL Server, SSIS, SSRS, SSAS
 * Desire for continuous learning and to pursue professional certifications
 * Proven ability to consult and mentor other
   
   

BENEFITS AND PERKS:


 * Competitive salary with annual reviews
 * Paid Time Off and Paid Holidays
 * Insurance options include Health, Vision, and Supplemental Options
 * Employer-paid Dental, Short-Term and Long-Term Disability
 * Safe Harbor 401(k) with company match
 * Professionally drafted basic Will
 * Dependent Care Flex Accounts
 * Employee Assistance Program (EAP)
 * Food, snacks, drinks
 * Tuition reimbursement
   
   

PERSONAL CHARACTERISTICS:


 * Excellent communication, presentation, and interpersonal skills, confident with customers
 * Detail-oriented, well-organized, and excellent ability to multi-task
 * Energetic, comfortable working in a fast-paced environment
 * Hard-working and motivated, able to take initiative and meet deadlines
 * Comfortable working in a team-based environment
 * A hands-on attitude in a friendly work environment.
   
   

If you excel in a team centric learning environment and you’re passionate about technology, please apply.


 * Omnitech participates in E-Verify and will provide the federal government with Form I-9 information to confirm work authorization.
 * Omnitech is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability status, protected veteran status, or any other characteristic protected by law.
   
   

Requirements:",Full-time
4130033608,18007.0,Staff Data Engineer ( Boston or Chicago ),"Company Description

PG Forsta is the leading experience measurement, data analytics, and insights provider for complex industries—a status we earned over decades of deep partnership with clients to help them understand and meet the needs of their key stakeholders. Our earliest roots are in U.S. healthcare –perhaps the most complex of all industries. Today we serve clients around the globe in every industry to help them improve the Human Experiences at the heart of their business. We serve our clients through an unparalleled offering that combines technology, data, and expertise to enable them to pinpoint and prioritize opportunities, accelerate improvement efforts and build lifetime loyalty among their customers and employees.

Like all great companies, our success is a function of our people and our culture. Our employees have world-class talent, a collaborative work ethic, and a passion for the work that have earned us trusted advisor status among the world’s most recognized brands. As a member of the team, you will help us create value for our clients, you will make us better through your contribution to the work and your voice in the process. Ours is a path of learning and continuous improvement; team efforts chart the course for corporate success.

Our Mission:

To elevate the human experiences at the heart of business by offering insights that sharpen understanding of the needs of individuals and populations, and provide guidance on how to meet those needs.

We partner clients to gather the voice of consumers and the workforce to gain insights that address unmet needs. Through the use of integrated data, advanced analytics and strategic advisory services, we are helping clients transform their organizations to deliver high quality services and lifetime loyalty.

Our Values:

Champion the Client

We demonstrate an unwavering passion for delivering high-quality solutions and service. We commit to understanding the goals and needs of our clients. We always look for opportunities to improve and create value. Each of us understands our role in enabling client success.

All Together Better

We are united by the common purpose of our vision and mission. We promote teamwork and a culture of belonging by building strong relationships and fostering trust. We collaborate to identify and develop innovative solutions.

Embrace Change

We recognize that change is constant and presents opportunities to learn, adapt, and evolve. We seek creative solutions to challenges and e pursue them with optimism and enthusiasm.

Do the Right Thing

We demonstrate commitment to all our stakeholders, including clients, staff, and partners. We take personal accountability for our responsibilities and actions. We do right by each other by acting with honesty and kindness. We provide meaningful recognition and feedback to others.

Job Description

Press Ganey is looking to hire a self-motivated Staff Data Engineer with data platform experience. The Staff Data Engineer (Platform) will play a crucial role in designing, implementing and architecting frameworks, systems and automation that support the development, deployment and observability of state-of-the-art large language models (LLMs) and generative AI solutions. This position focuses on creating scalable, reliable systems and processes that streamline the developer experience and empower analysts and data scientists. The ideal candidate will have strong foundational skills in cloud infrastructure, automation and devops practices, as well as experience implementing data pipelines and deployment automation for ML and analytical workloads.

Duties & Responsibilities


 * Design and implement processes, systems and automation to streamline the development and deployment of AI solutions.
 * Architect robust, reliable solutions for specific AI applications using appropriate cloud-based and open source technologies.
 * Design and automate data pipelines to deliver complex data products to power training and online inference of AI systems.
 * Deploy ML models, LLMs and GenAI systems into production, ensuring reliability, efficiency, and scalability across cloud or hybrid environments.
 * Build and maintain robust CI/CD pipelines tailored to ML model lifecycle management, ensuring a streamlined and agile deployment process.
 * Monitor model performance, identify potential improvements, and integrate feedback loops for continuous learning and adaptation.
 * Integrate models with chat interfaces and conversational platforms to create responsive, user-centric applications.
 * Investigate and implement agent-based architectures that support conversational intelligence and interaction modeling.
 * Collaborate with cross-functional teams to design AI-driven features that enhance user experience and interaction within chat interfaces.
 * Work closely with data scientists, product managers, and engineers to ensure alignment on project goals, data requirements, and system constraints.
 * Mentor junior engineers and provide guidance on best practices in ML model development, deployment, and maintenance.
 * Create and maintain comprehensive documentation for model architectures, code implementations, data workflows, and deployment procedures to ensure reproducibility, transparency, and ease of collaboration.
   
   

Technical Skills


 * Experience with large-scale deployment tools and environments, including Docker, Kubernetes, and cloud platforms like AWS, Azure, or GCP.
 * Experience deploying and managing a variety of database technologies.
 * Experience deploying ML models at scale and optimizing models for low-latency, high-availability environments.
 * Strong programming skills in Python and proficiency in libraries such as NumPy, Pandas, and Scikit-learn.
 * Experience with data pipelines, ETL processes, and experience with distributed data frameworks like Apache Spark or Dask.
 * Familiarity with machine learning frameworks such as TensorFlow, PyTorch, and Hugging Face Transformers.
 * Knowledge of conversational AI, agent-based systems, and chat interface development.
 * Proven track record in deploying and maintaining ML and AI solutions in a production setting.
 * Experience with version control (e.g., Git) and CI/CD tools tailored to ML workflows.
 * Experience with MLOps.
 * Experience with Databricks is a plus.
   
   

Qualifications

Minimum Qualifications


 * 5+ years of experience in platform engineering with a focus on with a focus on data and ML systems.
 * Bachelor's degree in Computer Science, Engineering, Data Science, or a related field.
   
   

Additional Information

Press Ganey Associates LLC is an Equal Employment Opportunity/Affirmative Action employer and well committed to a diverse workforce. We do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, veteran status, and basis of disability or any other federal, state or local protected class.

Pay Transparency Non-Discrimination Notice – Press Ganey will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor's legal duty to furnish information.

The expected base salary for this position ranges from $130,000 to $160,000. It is not typical for offers to be made at or near the top of the range. Salary offers are based on a wide range of factors including relevant skills, training, experience, education, and, where applicable, licensure or certifications obtained. Market and organizational factors are also considered. In addition to base salary and a competitive benefits package, successful candidates are eligible to receive a discretionary bonus or commission tied to achieved results.

All your information will be kept confidential according to EEO guidelines.

Our privacy policy can be found here: https://www.pressganey.com/legal-privacy/",Full-time
4045413438,66321745.0,Entry Level Data Engineer (Remote),"The Job Market is Challenging due to almost 300,000 Tech Layoffs since October 2022 due to which thousands of laid off Techies are competing with existing Jobseekers. Entry level Job seekers struggle to get responses to their applications forget about getting client interviews. As the Saying goes ""when the Going gets tough the Tough get going” Candidates who want to make a tech career they need to differentiate themselves by ensuring they have exceptional skills and technologies to be noticed by clients.

Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.

All Positions are open for all visas and US citizens

We are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this challenging economy every client wants to save $$$'s and they want the best value for their money. Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs. Clients now post covid can also hire remote workers which increases even more competition for jobseekers.

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, PayPal, western union, Client, visa, Walmart labs etc. to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in IT Industry

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We also offer optionally Skill and technology enhancement programs for candidates who are either missing skills or are lacking Industry/Client experience with Projects and skills. Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. If they are qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients. Shortlisting and selection is totally based on clients discretion not ours.

please check the below links to see success outcomes of our candidates

https://www.synergisticit.com/candidate-outcomes/

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://youtu.be/Rfn8Y0gnfL8?si=p2V4KFv5HukJXTrn

https://youtu.be/-HkNN1ag6Zk?si=1NRfgsvL_HJMVb6Q

https://www.youtube.com/watch?v=OAFOhcGy9Z8

https://www.youtube.com/watch?v=EmO7NrWHkLM

https://www.youtube.com/watch?v=NVBU9RYZ6UI

https://www.youtube.com/watch?v=Yy74yvjatVg

For preparing for interviews please visit https://www.synergisticit.com/interview-questions/

We are looking for the right matching candidates for our clients

Please apply via the job posting

REQUIRED SKILLS For Java /Full Stack/Software Programmer


 * Bachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Project work on the skills
 * Knowledge of Core Java, JavaScript, C&plus;&plus; or software programming
 * Spring boot, Microservices, Docker, Jenkins and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning Positions

Required Skills


 * Bachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Project work on the technologies needed
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, PowerBI, TensorFlow

If you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Full-time
4152160855,11712114.0,Data Engineer,"Who We Are

We are a Plymouth, Michigan-based startup, developing cutting-edge technologies for Driver Assistance and Automated Driving systems using artificial intelligence, advanced controls techniques, utilizing high-end CPU/GPU and IoT technologies. We have decades of automotive development experience and expertise to build mature automotive grade products. If you're interested in getting in on the ground-floor of an opportunity that will revolutionize the trucking industry, this is it.

Who You Are

You are innovative, love a challenging problem and building a product from ground up. You want to work on cutting-edge technologies that make a difference. You want to see your work have a direct impact on company’s product. You communicate, you teach, you learn, and you love working in a diverse team.




Job Description

We are seeking an experienced and highly skilled Data Engineer to join our dynamic and innovative team. You will play a pivotal role in driving data-driven decision-making processes through the following activities.

Data Pipeline Development:

Design, build, and maintain scalable and efficient data pipelines to ingest data from various sources, including IoT sensors, vehicle telemetry, and external APIs.

Implement ETL processes to transform raw data into structured formats suitable for analysis and reporting.

Data Modeling:

Develop and optimize data models to support analytical needs, ensuring high performance and efficient storage.

Collaborate with data scientists and analysts to understand their requirements and deliver the necessary data structures.

Data Quality Assurance:

Implement data validation and quality checks to ensure the accuracy and reliability of data.

Monitor data pipelines and troubleshoot any issues related to data integrity and performance.

Collaboration and Communication:

Work closely with cross-functional teams, including software developers, data scientists, and product managers, to support data-driven initiatives.

Communicate technical concepts effectively to non-technical stakeholders.

Documentation and Best Practices:

Document data engineering processes, data flows, and architecture to ensure knowledge transfer and adherence to best practices.

Contribute to the development of data governance policies and procedures.

Tooling and Technology:

Evaluate and implement new data technologies and tools to enhance the data infrastructure.

Stay updated on industry trends and advancements in data engineering and connected vehicle technologies.




Minimum Qualifications and Skills

 * Master’s degree in Data Engineering, Computer Science, Data Science, or a related field.
 * 3+ years of experience as a Data Engineer or in a similar role, preferably within the automotive or IoT sectors.
 * Proven experience with cloud platforms (e.g., AWS, Azure, Google Cloud) and data storage solutions (e.g., SQL, NoSQL databases).
 * Proficiency in programming languages such as Python, Java, or Scala.
 * Strong knowledge of ETL tools (e.g., Apache Spark, Talend, Airflow) and data orchestration frameworks.
 * Familiarity with data warehousing solutions (e.g., Redshift, BigQuery) and data visualization tools (e.g., Tableau, Power BI).
 * Advanced level skill and experience with business intelligence & data visualization systems (e.g. MicroStrategy, Microsoft Power BI, Google Data Studio and/or Tableau)
 * Experience building and optimizing ‘big data’ data pipelines, architectures, and data sets.
 * Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
 * Strong analytic skills related to working with unstructured datasets.
 * Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
 * A successful history of manipulating, processing and extracting value from large, disconnected datasets.
 * Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
 * Ability to create reliable automated data solutions based on the identification, collection, and evaluation of business requirements. Including but not limited to data models, database objects, stored procedures, and views.
 * Ability to partner with senior marketing, business, and sales stakeholders to help optimize on our core business and website performance KPIs
 * Strong project management and organizational skills.
 * Good communication and interpersonal skills

Preferred Qualifications and Skills

 * Knowledge of connected vehicle technologies, including V2X (vehicle-to-everything) communications and automotive data standards (e.g., ISO 26262).
 * Prior experience mining data from the various sensing sources involved in automated driving such as RADAR, camera, LIDAR, IMU, GPS, High-Definition maps, among others.
 * Knowledge of automotive data networks such as CAN, LIN and FlexRay.
 * PhD in Computer Science, Data Science, Data Engineering, Statistics, or similar quantitative field.




Job Type: Full-time

Benefits:




 * 401(k)
 * 401(k) matching
 * Dental insurance
 * Health insurance
 * Paid time off
 * Parental leave




Schedule:




 * 8 hour shift
 * Monday to Friday




No third-party recruiting services please.",Full-time
4144990891,95313.0,Data Engineer,"Position details:

Job Title: Data Engineer (Snowflake Data Mart)

Duration: 6 months (Possible Extension)

Location: Austin, TX



Job Description: Develops applications by writing code based upon design specifications and business requirements under the direction of the Development Manager and Project Manager. Takes an active role in the development group by sharing knowledge and mentoring others. This candidate is a member of a team, must adhere to secure development process and configuration management process and must be able to work cooperatively and autonomously




Job Description:

Client’s Regulatory Data Team is working to build enhanced data and insights capabilities by transforming into Cloud applications. We are looking for a Software Development Engineer with exceptional communication, analytical, and organizational skills to drive application migration to Cloud warehouse. The candidate will be responsible for developing the solutions data warehouse, working closing with supporting teams and involve in release support.




Business/Division: Data Technology, Enterprise Data Products and Insights for Regulatory Data

Group Focus: Lead the efforts in the Regulatory Data Warehouse in design, development, enhancement, and application migration to Cloud to support our advisors as they manage their business. The ideal candidate will have four-plus years of experience in development utilizing Snowflake and AWS services and an understanding of working in financial services or other highly regulated environments.




Responsibilities:

• Develop and support the Data Warehouse team members in application migration to the Cloud.

• Full life cycle involvement in all aspects of DW - Cloud Snowflake, AWS (ETL, Data modeling, Data cleansing)

• Perform development, enhancement, and document technical details to support the warehouse and provide data support for the downstream applications.

• Serve as hands on engineer in all database application deliveries with a focus on overall performance.

• Support release and post production support activities of the product.







Requirements:

• Bachelor's Degree or a related study driven as a Data Engineer.

• 5+ years strong knowledge of Databases and MSSQL, PLSQL or other query languages.

• 3+ years of Snowflake experience in Cloud data warehouse technologies including Redshift, AWS S3/Lambda/Glue/Air Flow and other AWS native technologies.

• 3+ years of Python development and an in-depth understanding of Python programming/objects

• Experience with application migrations and development (conceptual, logical and physical model design, Operational Data Stores, Enterprise Data Warehouses and Data Marts).

• Familiar with data modeling practices and standards across conceptual, logical, and physical levels.







Core Competencies:

• Strong verbal and written communication skills, with an ability to express complex technical concepts into comprehensible business terminology.

• Ability to work with cross-functional teams.

• Dynamism in understanding complex data environments.

• Commitment to excellence in service, performance, and execution",Contract
3892472435,82316701.0,Data Science Engineer,"Anywhere (Remote)

We are seeking a talented and experienced Data Science Engineer to join our team. As a Data Science Engineer, you will be responsible for developing and implementing data-driven solutions that leverage advanced analytics and machine learning techniques. You will collaborate closely with data scientists, software engineers, and business stakeholders to design, build, and deploy scalable and robust data science models and applications. Your work will play a crucial role in driving data-driven decision-making and delivering actionable insights to improve business outcomes.

Responsiblities


 * Work closely with cross-functional teams to understand business requirements and identify opportunities for applying data science and machine learning techniques
 * Design and develop data science models and algorithms that solve complex business problems and deliver actionable insights
 * Implement end-to-end data science solutions, including data collection, preprocessing, feature engineering, model training, evaluation, and deployment
 * Collaborate with data engineers to ensure the availability, quality, and reliability of data for analysis and modeling
 * Conduct exploratory data analysis to gain insights and identify patterns, trends, and anomalies in the data
 * Develop and deploy scalable machine learning models and algorithms that can handle large-scale datasets and real-time data streams
 * Optimize and fine-tune models for performance, accuracy, and scalability
 * Collaborate with software engineers to integrate data science models and algorithms into production systems and applications
 * Stay up to date with the latest advancements in data science, machine learning, and artificial intelligence and apply them to solve business challenges
 * Communicate and present complex technical concepts and findings to both technical and non-technical stakeholders in a clear and understandable manner
 * Collaborate with data scientists and domain experts to understand the domain-specific challenges and requirements and translate them into data science solutions
   
   

Requirements


 * Bachelor's or master's degree in computer science, data science, statistics, or a related field
 * Proven experience as a Data Science Engineer or in a similar role, with a focus on developing and deploying data science models and applications
 * Strong programming skills in languages such as Python or R, with experience in data manipulation, statistical analysis, and machine learning libraries (e.g., Pandas, NumPy, scikit-learn, TensorFlow, PyTorch)
 * Proficiency in SQL and experience with relational databases for data retrieval and manipulation
 * Solid understanding of data preprocessing, feature engineering, and model evaluation techniques
 * Experience with big data technologies and distributed computing frameworks such as Hadoop and Spark
 * Familiarity with cloud platforms and services, such as AWS, Azure, or Google Cloud, and their data-related services (e.g., S3, EMR, ML services)
 * Strong knowledge of machine learning algorithms and techniques, including supervised and unsupervised learning, deep learning, and natural language processing
 * Familiarity with software development practices and version control systems (e.g., Git)
 * Excellent problem-solving and analytical abilities, with keen attention to detail
 * Strong communication and collaboration skills, with the ability to work effectively in cross-functional teams and present complex concepts to non-technical stakeholders
   
   

Powered by JazzHR

8gD67zYcbL",Full-time
4045411575,66321745.0,Entry Level Data Engineer (Remote),"The Job Market is Challenging due to almost 300,000 Tech Layoffs since October 2022 due to which thousands of laid off Techies are competing with existing Jobseekers. Entry level Job seekers struggle to get responses to their applications forget about getting client interviews. As the Saying goes ""when the Going gets tough the Tough get going” Candidates who want to make a tech career they need to differentiate themselves by ensuring they have exceptional skills and technologies to be noticed by clients.

Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.

All Positions are open for all visas and US citizens

We are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this challenging economy every client wants to save $$$'s and they want the best value for their money. Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs. Clients now post covid can also hire remote workers which increases even more competition for jobseekers.

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, PayPal, western union, Client, visa, Walmart labs etc. to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in IT Industry

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We also offer optionally Skill and technology enhancement programs for candidates who are either missing skills or are lacking Industry/Client experience with Projects and skills. Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. If they are qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients. Shortlisting and selection is totally based on clients discretion not ours.

please check the below links to see success outcomes of our candidates

https://www.synergisticit.com/candidate-outcomes/

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://youtu.be/Rfn8Y0gnfL8?si=p2V4KFv5HukJXTrn

https://youtu.be/-HkNN1ag6Zk?si=1NRfgsvL_HJMVb6Q

https://www.youtube.com/watch?v=OAFOhcGy9Z8

https://www.youtube.com/watch?v=EmO7NrWHkLM

https://www.youtube.com/watch?v=NVBU9RYZ6UI

https://www.youtube.com/watch?v=Yy74yvjatVg

For preparing for interviews please visit https://www.synergisticit.com/interview-questions/

We are looking for the right matching candidates for our clients

Please apply via the job posting

REQUIRED SKILLS For Java /Full Stack/Software Programmer


 * Bachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Project work on the skills
 * Knowledge of Core Java, JavaScript, C&plus;&plus; or software programming
 * Spring boot, Microservices, Docker, Jenkins and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning Positions

Required Skills


 * Bachelor's degree or Master's degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Project work on the technologies needed
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, PowerBI, TensorFlow

If you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Full-time
4137036103,2010798.0,Data Engineer - AWS,"Tiger Analytics is a fast-growing advanced analytics consulting firm. Our consultants bring deep expertise in Data Science, Machine Learning and AI. We are the trusted analytics partner for multiple Fortune 500 companies, enabling them to generate business value from data. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner. We are looking for top-notch talent as we continue to build the best global analytics consulting team in the world.

We are seeking a skilled Data Engineer to join our team. The ideal candidate will have a strong background in data engineering, cloud-based solutions, and a proven track record of building and managing scalable data pipelines on AWS. The Data Engineer will work closely with cross-functional teams to develop, maintain, and optimize data solutions that support critical business insights. We are looking for someone who can bring their vision to the table and implement positive change in taking the company's data analytics to the next level.

Requirements


 * 3-5 years of experience in data engineering with a focus on AWS cloud solutions
 * 3+ years of experience in Designing, developing, and maintaining scalable and secure ETL/ELT pipelines using AWS services
 * Creating and optimizing complex data processing and data transformation pipelines using python
 * Hands-on experience with AWS services like Glue, Lambda, S3, Redshift, and Athena
 * Strong knowledge of SQL for querying and managing relational databases
 * Experience with big data tools such as Apache Spark, Hadoop, or EMR
 * Implement best practices for cloud-based data architecture and pipeline management
 * Understanding of data modeling concepts and best practices
 * Familiarity with CI/CD pipelines and version control tools like Git
 * AWS certifications (e.g., AWS Certified Data Analytics, AWS Certified Solutions Architect)
   
   
   

Benefits

This position offers an excellent opportunity for significant career development in a fast-growing and challenging entrepreneurial environment with a high degree of individual responsibility.",Full-time
4152449308,267137.0,Data Engineer,"Company Overview

With an annual budget of $1.9 billion and more than 7,000 employees throughout the five boroughs, the New York City Department of Health and Mental Hygiene (NYC DOHMH) is one of the largest public health agencies in the world, serving 8 million New Yorkers from diverse ethnic and cultural backgrounds. We're tackling a broad range of public health issues with innovative policies and programs and getting exceptional results, but our work is never finished. The breadth of our innovative programs provides the widest range of choices for every member of our team.

Program Overview

Established in 1805, the New York City Department of Health and Mental Hygiene (DOHMH) is the oldest and largest health department in the country. Our mission is to protect and improve the health of all New Yorkers, in service of a vision of a city in which all New Yorkers can realize their full health potential, regardless of who they are, how old they are, where they are from, or where they live.

As a world-renowned public health agency with a history of building transformative public health programming and infrastructure, innovating in science and scholarship to advance public health knowledge, and responding to urgent public health crises - from New York City's yellow fever outbreak in 1822, to the COVID-19 pandemic - we are a hub for public health innovation, expertise, and programs and services. We serve as the population health strategist, and policy and planning authority for the City of New York, while also having a vast impact on national and international public policy, including programs and services focused on food and nutrition, anti-tobacco support, chronic disease prevention, HIV/AIDS treatment, family and child health, environmental health, mental health, and racial and social justice work, among others.

The Center for Population Health Data Science (CPHDS)- launched in October of 2023- aims to catalyze critical data modernization work and enable the agency to make progress toward linking public health, healthcare, and social service for timely and effective public action. We are working towards making these data more accessible, timely, equitable, meaningfully usable, and protected – and actively used to protect and promote the health and wellbeing of New Yorkers.

We aim to strengthen agency wide data capabilities by empowering our workforce, enhancing intra- and inter-agency data sharing, and using modern technology to yield trusted and integrated data and insights. A real-time and comprehensive view of city needs is needed to enhance public health actions and improve health outcomes for the most vulnerable New Yorkers.

This position will be based at the Health Department’s office in Long Island City, NY, with the possibility of hybrid work.

Summary Of Position

As a Data Engineer on our Integrated Public Health team, you will play a pivotal role in enhancing our data pipeline, crucial for our advanced public health analytics efforts. Your responsibilities include developing, maintaining, and optimizing a secure, scalable data pipeline that supports meaningful public health insights and outcomes. You will be instrumental in advancing a cross-functional approach to data pipeline, ensuring efficient data processing, scalable storage solutions, and adherence to security and governance measures. Your work will directly contribute to the effectiveness and advancement of our public health objectives, ensuring our practices not only meet current needs but are also strategically aligned to meet future challenges.

This position will be within the Health Department’s innovative Center for Population Health Data Science’s (CPHDS) Bureau of Data Technology and Strategy and reporting to the Executive Director for Data Engineering and Management. The CPHDS is working to strengthen citywide population health surveillance by better linking public health, healthcare, and social service data to fully characterize and improve the health of New Yorkers. Our vision is for these data to be accessible, timely, equitable, meaningfully usable, and protected – and being actively used to protect and promote health and wellbeing of New Yorkers. This position will involve close collaboration with the Division of Information Technology.

The selected candidate will be an employee of Public Health Solutions, a nonprofit organization which is the fiscal and administrative manager of the grant; work will be supervised by DOHMH. This is a grant-funded position ending in November 2027. This position will be based at the Health Department’s office in Long Island City, NY, with the possibility of hybrid work.

Responsibilities


 * Develop an integrated data pipeline that facilitates efficient data exchange, analysis, surveillance, and reporting.
 * Collaborate with public health experts to understand data requirements for health informatics, integrating public health data standards and practices into our integrated data architecture.
 * Develop, and maintain scalable, secure data pipelines and platform to support real-time and batch data ingestion and processing from diverse internal and external data sources.
 * Guide the selection and implementation of cutting-edge data technologies and tools to enhance our analytics and data science capabilities.
 * Promote data governance, quality, and security best practices, ensuring compliance with applicable regulations and standards.
 * Collaborate with internal and external stakeholders to align data infrastructure enhancements with the needs of diverse units.
   
   

Qualifications

Required


 * Bachelor's or Master's degree in Computer Science, Engineering, or Information Systems
 * 4 or more years of experience in data engineering, building and managing scalable data pipelines.
 * Experience with cloud-based data solutions (e.g., Azure, AWS, or GCP), programming (e.g., Python, R), Linux systems, and big data technologies (e.g., Hadoop, Spark).
 * Familiarity with health informatics, public health data standards (HL7, FHIR), and understanding of the unique needs in managing health-related data.
 * Ability to mentor more junior staff, manage projects, and collaborate across diverse functional teams.
 * Strong problem-solving and communication skills to effectively convey technical concepts to a broad audience.
   
   

Additional Desired Qualities


 * Planning and project management skills with ability to adapt to new information and needs.
 * Prioritization and time management skills.
 * Interpersonal and communications skills with ability to manage working relationships with individuals at all levels.
 * High degree of self-awareness, humility, and diplomacy.
   
   

Why Join Us


 * Directly contributes to advancing public health in New York City and setting best practices globally through innovative data products.
 * Support the transformative integration of modern data practices with epidemiology and health informatics to define the next era of timely and effective public health strategies.
 * Be part of a mission-focused organization that is one of the largest public health agencies in the world, serving 8.5 million New Yorkers from diverse ethnic and cultural backgrounds and dedicated to improving their health and wellbeing.
 * Enjoy a supportive work environment that values diversity, innovation, learning, and professional growth.
   
   

Benefits


 * Hybrid Work Schedule.
 * Generous Paid Time Off and Holidays.
 * An attractive and comprehensive benefits package including Medical, Dental and Vision.
 * Flexible Spending Accounts and Commuter Benefits.
 * Company Paid Life Insurance and Disability Coverage.
 * 403 (b) + employer matching and discretionary company contributions.
 * College Savings Plan.
 * Ongoing training and continuous opportunities for professional growth and development.
 * Salary: $135,000 - $135,000
   
   

Additional Information


 * This is a temporary grant-funded position ending in November 2027.
 * This individual must reside in the tri-state area (NY, NJ, CT) by their confirmed start date.
 * Preference may be given to individuals residing in New York City (5 boroughs) or surrounding New York State counties.
 * This individual will be expected to work non-business hours during emergencies.
   
   

At PHS, we place immense value on diversity within our teams, understanding that varied backgrounds and experiences significantly enhance our community and propel us toward our goals. If you find you don’t have experience in all the areas listed above, we still encourage you to apply and share your background and experiences in your application. We are eager to discover how your unique perspective can bring positive transformations to our team and help advance our mission of creating healthier, more equitable communities.

We look forward to learning more about you! 

PHS is proud to be an equal opportunity employer and encourages applications from women, people of color, persons with disabilities, LGBTQIA+ individuals, and veterans.

Monday-Friday

Hybrid

35 Hours per week",Full-time
4151644053,68302528.0,Software Engineer — Compute Platform,"We’re on a mission to democratize AI by building the definitive AI data development platform. The AI landscape has gone through incredible change between 2016, when Snorkel started as a research project in the Stanford AI Lab, to the generative AI breakthroughs of today. But one thing has remained constant: the data you use to build AI is the key to achieving differentiation, high performance, and production-ready systems. We work with some of the world’s largest organizations to empower scientists, engineers, financial experts, product creators, journalists, and more to build custom AI with their data faster than ever before. Excited to help us redefine how AI is built? Apply to be the newest Snorkeler!

As a Compute Platform Engineer, you will play a pivotal role in building the backbone of SnorkelFlow's infrastructure. Your focus will be on orchestration, MLOps, SDK maintainability, and other tooling development that will serve our AI and Data teams. Whether you’re an entry-level engineer eager to dive into the complexities of compute engineering or a senior engineer ready to lead impactful projects, this role provides opportunities to work on cutting-edge AI infrastructure and scale SnorkelFlow’s capabilities.

Main Responsibilities For All Levels

Orchestration and Infrastructure Development:


 * Design, implement, and maintain orchestration tools for workflows using Ray and Prefect.
 * Build and manage infrastructure for scalable data connectors to integrate with systems like S3, Snowflake, and Databricks.
 * Optimize compute resource utilization for AI pipelines and ensure reliable, fault-tolerant execution of tasks.
   
   

MLOps And SDK Development


 * Develop and maintain robust CI/CD pipelines to support seamless model deployment and orchestration workflows.
 * Enhance the SnorkelFlow SDK to provide user-friendly access to compute layer functionalities.
 * Collaborate with AI Platform and Data Platform teams to ensure SDK usability and extensibility.
   
   

Backend Development


 * Build backend services to support compute operations, including job scheduling, resource allocation, and API integrations.
 * Partner with the Application team to design APIs that enable seamless orchestration and workflow management.
   
   

Observability And Performance Optimization


 * Implement monitoring tools and dashboards to track the performance and health of compute resources.
 * Define metrics and logging strategies to optimize orchestration pipelines and SDK efficiency.
   
   

For Senior Engineers:


 * Lead the design and development of core components of the compute platform, including orchestration workflows and connectors.
 * Mentor and guide junior engineers, fostering growth within the team.
 * Identify and drive improvements in infrastructure scalability and reliability.
 * Collaborate with cross-functional teams to align the compute platform with overall product goals.
   
   

Required Qualifications Entry-Level Engineers:


 * Bachelor’s degree in Computer Science, Software Engineering, or a related field.
 * 1-2 years of experience in backend development or infrastructure engineering.
 * Proficiency in Python and familiarity with frameworks like FastAPI or Flask.
 * Basic understanding of orchestration tools and MLOps practices.
 * Strong problem-solving skills and eagerness to learn and grow in the compute engineering domain.
   
   

Senior Engineers:


 * Bachelor’s or Master’s degree in Computer Science, Software Engineering, or a related field.
 * 4-6 years of experience in backend or infrastructure engineering, including experience with orchestration tools (e.g., Prefect, Ray, Airflow).
 * Proven expertise in Python, with experience in building scalable APIs and SDKs.
 * Strong knowledge of MLOps practices, including CI/CD, Kubernetes, and model lifecycle management.
 * Experience with infrastructure scaling and integration of data connectors.
 * Proven ability to lead technical projects and mentor junior team members.
   
   

Preferred Qualifications


 * Experience with Prefect or similar for orchestration and distributed computing.
 * Experience with developing microservices pipelines and infrastructure
 * Familiarity with vector databases and data storage solutions.
 * Knowledge of containerization and orchestration tools like Docker and Kubernetes.
 * Experience building data connectors for systems like Snowflake, Databricks, or S3.
 * Familiarity with observability tools like Prometheus, Grafana, DataDog or OpenTelemetry.
   
   

What We Offer


 * A leadership role with the opportunity to influence the technical direction of SnorkelFlow.
 * Competitive salary and benefits tailored to your experience.
 * Hybrid work environment with 3 days per week at our Redwood City HQ and SF Office.
 * ""No Meeting"" Tuesdays and Thursdays to focus on deep work.
 * The chance to work on cutting-edge infrastructure and drive impactful change in an innovative, fast-paced environment.
   
   

Be Your Best At Snorkel Snorkel AI is on a mission to make machine learning practical for everyone, and it starts with building a team that welcomes, represents and gives opportunity to all. We work at the frontier of AI and software engineering, and believe that underrepresented communities need to play a part in shaping the future of these fields. At Snorkel AI, we actively work to create an environment that values end-to-end ownership, diverse forms of impact, and opportunities for personal growth. Snorkelers are supported by an amazing team and an amazing set of benefits. For Full-time employees, we offer comprehensive medical, dental, and vision plans for Snorkelers and their families, plus a yearly wellness stipend. Our 401k program lets Snorkelers plan for their future and our parental leave program lets new parents take up to 20 weeks of paid time off. Learn more about these benefits and more — like our workstation setup allowance — on our Careers page. Snorkel AI is proud to be an Equal Employment Opportunity employer and is committed to building a team that represents a variety of backgrounds, perspectives, and skills. Snorkel AI embraces diversity and provides equal employment opportunities to all employees and applicants for employment. Snorkel AI prohibits discrimination and harassment of any type on the basis of race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local law. All employment is decided on the basis of qualifications, performance, merit, and business need. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.",Full-time
4112914172,66321745.0,Junior Software Engineer (Remote),"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you need

Position open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, IT enthusiasts, Python/Java developers, Data analysts/ Data Scientists.

We welcome candidates with all visas and citizens to apply.

Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates looking to make their careers in IT Industry

Candidates who are serious about their future in the IT Industry and have set big goals for themselves.

Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill enhancement programs if the candidates are missing skills or experience which our clients need with great outcomes

Candidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancement

Candidates Who Lack Experience

Have had a break in careers

Lack Technical Competency

Different visa candidates who want to get employed and settle down in the USA

Please Also Check The Below Links

Synergisticit Pics /Salaries of Successful Candidates

Synergisticit at Oracle Cloudworld 2023

Synergisticit at Gartner Data & Analytics summit

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

If not a match candidates can opt for Skill enhancement.

REQUIRED SKILLS For Java/Software Programmers


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Core Java , javascript , C++ or software programming
 * Spring boot, Microservices and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, Python, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, Time series analysis

Please understand skills are required by clients for selection even if its Junior or entry level position the additional skills are the only way a candidate can be picked by clients.

No third party candidates or c2c candidates

Please understand skills are required by clients for selection even if its Junior or entry level position the additional skills are the only way a candidate can be picked by clients.

Please apply to the posting

No phone calls please. Shortlisted candidates would be reached out",Contract
4136239366,1910344.0,Data Engineer,"Job Description

Job Title: Data Engineer (Contract-to-Hire)

Location: Preferred locations: Evansville IN, Chicago IL, Minneapolis MN, Milwaukee WI (Consultants are expected to work four days on-site per week)

Contract Duration: 6-Month Contract-to-Hire

Position Overview: The ideal candidate will be skilled in both independent work and team collaboration, providing guidance to colleagues as needed. You should have the ability to apply critical thinking and problem-solving skills to develop efficient solutions tailored to specific tasks. A passion for advancing the bank's data platform toward modern principles is also key.

Skills And Qualifications


 * 5+ years of experience in data engineering, with a strong background in ETL/ELT development.
 * Proficiency in Python and scripting tools.
 * Experience using Azure Databricks to manage an enterprise Data Lake.
 * Familiarity with SSIS/Azure Data Factory and basic Python knowledge is preferred.
 * Expertise in building scalable data products using metadata-driven approaches.
 * Experience gathering requirements from stakeholders and translating them into repeatable data solutions.
 * Knowledge of orchestration tools and job scheduling systems for efficient data movement and processing.
 * Advanced skills in T-SQL, including complex stored procedures, UDFs, and query optimization.
 * Understanding of CDC (Change Data Capture) and experience with preserving historical data across multiple systems.
 * Strong communication skills for presenting technical designs to senior leadership.
 * Experience working in Agile environments, using tools like Azure DevOps or JIRA.
 * Familiarity with code repositories like Azure DevOps, Git, etc.
 * Exposure to data visualization tools such as Power BI.
 * Practical knowledge of cloud-based data architectures, particularly in Azure, Databricks, or Snowflake.
 * Some travel may be required for meetings or branch visits.
   
   

Key Responsibilities


 * Design, develop, and maintain ETL/ELT processes.
 * Build reusable frameworks and functions for other data engineers to utilize.
 * Ensure operational excellence through continuous monitoring and validation of data products.
 * Collaborate with teams across Enterprise Architecture, Info Security, and Data Governance.
 * Analyze system workflows, data usage, and work processes to improve efficiency.
 * Deliver thoroughly tested data products that meet business needs.
 * Follow the SDLC process, providing accurate project timelines and meeting deadlines.
 * Work with DBAs to design, model, and maintain new and existing database structures for business solutions.
   
   

**We are an equal opportunity employer and value diversity at our company. We do not discriminate based on race, religion, color, ethnic origin, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.**

",Contract
4127748524,1732084.0,Data Visualization Engineer (PowerBI),"Summary

Join Aperia Solutions, a leader in SaaS solutions for the Payments and Compliance industries. Aperia is a Texas-based fintech and managed consultancy firm that creates custom SaaS applications and other software-based solutions for the payments, banking, and processing industry. Founded in 1999, Aperia offers business intelligence, risk management, compliance, and customer intelligence platforms. With offices in Dallas, Washington DC, and Vietnam, Aperia is a fast-paced, global organization that strives to improve efficiency in compliance, risk, and customer service operations. Aperia's clients include banks, processors, payment facilitators, merchant service providers, independent sales organizations, and government entities. A career at Aperia promises a great challenge, culture, and opportunities to forge your own path.

Job Description

At Aperia, we rely on a dynamic team of developers. We're seeking a Data Visualization Engineer who is ready to work with new technologies and architectures in a forward-thinking organization that's always pushing boundaries.

Key Responsibilities:


 * Design and develop Power BI reports and dashboards to meet the business stakeholders' needs
 * Gather and understand business requirements for data visualization and analysis
 * Recommend optimal visualizations for insightful, actionable business use
 * Collaborate with data engineers and analysts to acquire and transform data for reporting purposes
 * Ensure compliance with data security best practices
 * Troubleshoot and resolve issues in Power BI reports
   
   

Required:


 * 5+ years creating data visualizations
 * 3+ years with Power BI report/dashboard development
 * Expertise in using different Power BI functionalities
 * Experience developing DAX calculations and M (Power) Queries
 * Experience with developing interactive dashboards –e.g., parameters, actions, navigation –for ease-of-use.
 * Proficiency in creating dataflows and data-marts. Experience in composite models
 * Knowledge of Power BI contexts and its types
 * Exposure to applying security to Reports, Apps and workspaces
 * 3+ years SQL experience (Oracle preferred)
 * Experience in connecting to and leveraging multitude data sources including Hive, Impala, and Oracle
 * Experience in creating pixel perfect reports using Power BI report builder
 * Excellent analytical thinking for translating data into informative visuals and reports
   
   

Preferred:


 * Familiarity with Cloudera Hadoop
 * Knowledge in emerging cloud technologies related to Big Data
 * Previous experience in Finance/Banking industry
   
   

Location:

This role is available in any of these three locations:


 * Omaha, Nebraska
 * Alpharetta, Georgia
 * Berkeley Heights, New Jersey
   
   
   
   

Schedule: Monday to Friday

Benefits


 * Health insurance
 * Dental insurance
 * Paid time off
 * Parental leave
 * Childcare assistance
   
   

This job description is not intended to be all-inclusive. An employee may also perform other reasonable related business duties as assigned by their immediate supervisor or management. Principals only.

Recruiters please don't contact this job poster. DO NOT contact us with unsolicited services or offers.",Full-time
4119482874,66321745.0,Junior Software Engineer (Remote),"Since 2010 Synergisticit has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this Job market also, our candidates are able to achieve multiple job offers and $100k &plus; salaries.

please check the below links to see success outcomes, salaries of our candidates .

https://www.synergisticit.com/candidate-outcomes/

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please visit the below videos exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

Required Skills

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, Gen AI, LLM, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full Stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java , javascript , C&plus;&plus; or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Full-time
4106731140,1292.0,Lead Data Engineer,"Disney Entertainment & ESPN Technology

On any given day at Disney Entertainment & ESPN Technology, we’re reimagining ways to create magical viewing experiences for the world’s most beloved stories while also transforming Disney’s media business for the future. Whether that’s evolving our streaming and digital products in new and immersive ways, powering worldwide advertising and distribution to maximize flexibility and efficiency, or delivering Disney’s unmatched entertainment and sports content, every day is a moment to make a difference to partners and to hundreds of millions of people around the world.

A few reasons why we think you’d love working for Disney Entertainment & ESPN Technology



 * Building the future of Disney’s media business: DE&E Technologists are designing and building the infrastructure that will power Disney’s media, advertising, and distribution businesses for years to come.
 * Reach & Scale: The products and platforms this group builds and operates delight millions of consumers every minute of every day – from Disney+ and Hulu, to ABC News and Entertainment, to ESPN and ESPN+, and much more.
 * Innovation: We develop and execute groundbreaking products and techniques that shape industry norms and enhance how audiences experience sports, entertainment & news.
   
   
   

About The Role

Subscriber Data Solutions builds and maintains best in class data products enabling business teams to analyze and measure subscriber movements and support revenue generation initiatives. The Lead Data Engineer will contribute to the Company’s success by partnering with business, analytics and infrastructure teams to design and build data pipelines to facilitate measuring subscriber movements and metrics. Collaborating across disciplines, they will identify internal/external data sources, design table structure, define ETL strategy & automated Data Quality checks. You will also help mentor and guide other more junior data engineers in their data pipeline development.

Responsibilities



 * Lead the successful design and implementation of complex technical problems.
 * Lead and contribute to the design and growth of our Data Products and Data Warehouses around Subscriber movements and metrics.
 * Use sophisticated analytical thought to exercise judgement and identify innovative solutions.
 * Partner with technical and non-technical colleagues to understand data and reporting requirements, and Collaborate with Data Product Managers, Data Architects and other Data Engineers to design, implement, and deliver successful data solutions
 * Design table structures and define ETL pipelines to build performant Data solutions that are reliable and scalable in a fast growing data ecosystem.
 * Develop Data Quality checks
 * Develop and maintain ETL routines using ETL and orchestration tools such as Airflow
 * Serve as an advanced resource to other Data Engineers on the team, and mentor and coach more junior members of the team helping to improve their skills, knowledge, and productivity.
   
   
   

Basic Requirements



 * 7+ years of data engineering experience developing large data pipelines.
 * Strong understanding of data modeling principles including Dimensional modeling, data normalization principles.
 * Good understanding of SQL Engines and able to conduct advanced performance tuning.
 * Ability to think strategically, analyze and interpret market and consumer information.
 * Strong communication skills – written and verbal presentations.
 * Excellent conceptual and analytical reasoning competencies.
 * Comfortable working in a fast-paced and highly collaborative environment.
 * Familiarity with Agile Scrum principles and ceremonies
   
   
   

Preferred Qualifications



 * 4+ years of work experience implementing and reporting on business key performance indicators in data warehousing environments, required.
 * 5+ years of experience using analytic SQL, working with traditional relational databases and/or distributed systems (Snowflake or Redshift), required.
 * 3+ years of experience programming languages (e.g. Python, Pyspark), preferred.
 * 3+ years of experience with data orchestration/ETL tools (Airflow, Nifi), preferred.
 * Experience with Snowflake, Databricks/EMR/Spark & Airflow a plus.
   
   
   

Required Education



 * Bachelor’s degree in Computer Science, Information Systems, Software, Electrical or Electronics Engineering, or comparable field of study, and/or equivalent work experience
 * Master’s Degree a plus.
   
   
   

Additional Information

#DISNEYTECH

The hiring range for this position in Santa Monica, California is $152,200 to $204,100 per year, in Seattle, Washington is $159,500 to $213,900 per year. in New York City, NY is $159,500 to $213,900 per year, and in San Francisco, California is $166,800 to $223,600 per year. The base pay actually offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.",Full-time
4045412720,66321745.0,Data Engineer - Remote,"Since 2010 Synergisticit has helped Jobseekers get employed in the tech job market by providing candidates the requisite skills, experience, and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this Job market also, our candidates are able to achieve multiple job offers and $100k &plus; salaries.

please check the below links to see the success outcomes and salaries of our candidates .

https://www.synergisticit.com/candidate-outcomes/

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

We regularly interact with the Top Tech companies to give our candidates a competitive advantage visit the below videos exhibiting at Oracle Cloud World/Oracle Java one (Las Vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like Apple, google, Paypal, Western Union, Client, visa, Walmart lab s etc to name a few.

Currently, We are looking for entry-level software programmers, Java full-stack developers, Python/Java developers, Data analysts/ Data Scientists, and Machine Learning engineers for full-time positions with clients.

Who Should Apply Recent Computer Science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

Required Skills

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, Gen AI, LLM, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

Required Skills

REQUIRED SKILLS For Java /Full stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java, Javascript, C&plus;&plus;, or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates, and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team and only connect with candidates who are matching client requirements.

No phone calls, please. Shortlisted candidates would be reached out. No third-party or agency candidates or c2c candidates",Full-time
4136915958,18106262.0,Senior Software Engineer - Infrastructure,"Who We Are




CloudKitchens helps restaurateurs around the world succeed in online food delivery - our goal is to make food more affordable, higher quality and convenient for everyone.




We take underutilized properties and transform them into smart kitchens so they can better serve restaurateurs, customers and the neighborhoods they’re in. Every time we launch a new facility we create jobs in that neighborhood, and we’re proud to provide a wide range of cuisines and options for healthy food at an affordable price.




We're changing the game for restaurateurs whether they’re entrepreneurs opening their first restaurant all the way through to your favorite global quick-service restaurant chains




Who You Are:




 * A passionate software engineer with at least 5+ years of experience in backend development, preferably using Go or Java.
 * A problem-solver who thrives in tackling diverse technical challenges and demonstrates a clear track record of growth and learning.
 * A take-charge individual who exhibits ownership and takes pride in writing clean, maintainable, and fun code.
 * An engineer who can dive deep into open source software, find issues and fix them




What You'll Do:




 * Build & evolve scalable, reliable distributed systems to solve key Observability platform challenges.
 * Own & improve the core Observability infrastructure that monitors the business-critical applications.
 * Simplify infrastructure with abstractions for enhancing observability of services.
 * Actively participate in contributing to the team's open-source efforts.




Bonus Points:




 * Expertise in Go and/or Rust development is a major plus.
 * Experience building distributed applications is highly valued.
 * Familiarity with PSQL, Kubernetes (k8s), and Observability infrastructure is a significant advantage.




Why join us




 * Growing market: You’ll be focused on an $80 billion market that’s projected to reach at least $500 billion by 2030 in the US alone.
 * Changing the restaurant industry: You’ll be part of a team that helps restaurants succeed in online food delivery.
 * Collaborative environment: You will receive support and guidance from experienced colleagues and managers, helping you to learn, grow and achieve your goals, and you’ll work closely with other teams to ensure our customer’s success.




What Else You Need To Know




 * This role is based in our Mountain View office location. We believe that people do their best work when they are together. As a company, we’re in the marketplace of ideas and innovation. When you’re constantly innovating, changing how an industry works, inventing new products and processes - and we are doing all these things - we believe we’re better as a team in-person. That’s why all of our teams (except for our field-based roles) are now working from one of our office locations 5 days a week. Looking forward to sharing more about a Career of Substance at City Storage Systems.

",Full-time
4120822724,10667.0,"Data Engineer, Product Analytics","As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a world-class data engineering community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Data Engineer, Product Analytics Responsibilities:


 * Manage and execute data warehouse plans for a product or a group of products to solve well-scoped problems
 * Identify the data needed for a business problem and implement logging required to ensure availability of data, while working with data infrastructure to triage issues and resolve
 * Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights in a meaningful way
 * Build data expertise and leverage data controls to ensure privacy, security, compliance, data quality, and operations for allocated areas of ownership
 * Design, build and launch new data models and visualizations in production, leveraging common development toolkits
 * Independently design, build and launch new data extraction, transformation and loading processes in production, mentoring others around efficient queries
 * Support existing processes running in production and implement optimized solutions with limited guidance
 * Define and manage Service Level Agreements for data sets in allocated areas of ownership
   
   

Minimum Qualifications:


 * Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent
 * 2+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions
 * 2+ years of experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala or others.)
   
   

Preferred Qualifications:


 * Master's or Ph.D degree in a STEM field
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$114,000/year to $171,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4151511276,18476.0,Data Engineer,"Job Title: Data Engineer

Remote; but with the goal of having this person come on site a few times/month in Detroit, MI




Job Description:

We are seeking a skilled Data Engineer with 2+ years of experience to join our team. The ideal candidate will have experience supporting data presentation layers that make SRE work products visible to stakeholders across projects and the organization. You should be proficient in building data workflows using Alteryx and creating dashboards with Power BI, Tableau, or similar data visualization tools.




Responsibilities:

 * Develop and maintain data presentation layers to enhance visibility into SRE work products for stakeholders.
 * Design, implement, and optimize Alteryx workflows for data processing and automation.
 * Build interactive dashboards and reports using Power BI, Tableau, or similar visualization tools.
 * Work closely with SRE teams, analysts, and business stakeholders to ensure data accuracy and usability.
 * Optimize and maintain data pipelines to support reporting and analytics.
 * Ensure data integrity, security, and efficiency in all data-related processes.




Requirements:

 * 2+ years of experience as a Data Engineer or similar role.
 * Experience with Alteryx workflows for data automation and processing.
 * Proficiency in Power BI, Tableau, or similar data visualization tools for dashboard creation.
 * Strong understanding of data modeling, ETL processes, and database management.
 * Ability to translate complex datasets into clear and actionable insights.
 * Strong problem-solving skills and attention to detail.
 * Experience working in an SRE environment (preferred but not required).




Preferred Qualifications:

 * Experience with SQL, Python, or other scripting languages for data processing.
 * Familiarity with cloud platforms (AWS, Azure, GCP) for data engineering tasks.
 * Knowledge of big data frameworks and technologies (e.g., Spark, Databricks).

",Full-time
4120827322,10667.0,"Data Engineer, Product Analytics","As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a world-class data engineering community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Data Engineer, Product Analytics Responsibilities:


 * Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems
 * Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve
 * Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way
 * Define and manage Service Level Agreements for all data sets in allocated areas of ownership
 * Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership
 * Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains
 * Solve our most challenging data integration problems, utilizing optimal Extract, Transform, Load (ETL) patterns, frameworks, query techniques, sourcing from structured and unstructured data sources
 * Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts
 * Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts
 * Influence product and cross-functional teams to identify data opportunities to drive impact
 * Mentor team members by giving/receiving actionable feedback
   
   

Minimum Qualifications:


 * Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent
 * 4+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions
 * 4+ years of experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.)
   
   

Preferred Qualifications:


 * Master's or Ph.D degree in a STEM field
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$145,000/year to $204,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4138871327,3765.0,Data Engineer/Developer,"GroupM is WPP’s media investment group and the world’s leading media investment company with a mission to shape the next era of media where advertising works better for people. The company is responsible for more than $60 billion in annual media investment, as measured by the independent research bureau COMvergence. Through its global agencies Mindshare, EssenceMediacom, and Wavemaker. GroupM’s portfolio includes Data & Technology, Investment and Services, all united in vision to shape the next era of media where advertising works better for people. GroupM leverages a unique combination of global scale, expertise, and innovation to generate sustained value for clients wherever they do business. Discover more at www.groupm.com.

Role Summary And Impact

GroupM's Data and Analytics team is proud to be a trusted data partner to PlayStation, a global leader in interactive entertainment. Embedded directly into PlayStation's internal Data & Analytics team, we empower their marketing and advertising initiatives by managing a complex global database, ensuring data quality, and developing bespoke tools. Our expertise in data quality management, tool development, and API integration ensures the accuracy and accessibility of critical information. This data-driven approach fuels PlayStation's strategic decision-making and marketing success!

We are hiring for a Data Engineer/Developer maintain bespoke tooling built to improve the efficiency with which we collect data from planning and activation teams (manual data entry) as well provide support to any custom campaign optimization tools we have developed. Embedded into the account team so you can be closer to your end users to improve requirement gather and working across both PlayStations and GroupM’s tech stack.

Responsibilities


 * Design, develop, and maintain a bespoke media planning tool for PlayStation, incorporating bug fixes, new features, and automation to streamline workflows for planning and activation teams. Focus on robust data pipelines and efficient data processing.
 * Develop and implement data integration processes to incorporate sales and audience data into media plans for benchmarking and performance forecasting.
 * Build and maintain data feeds for PlayStation's BI team to power dashboards and reporting. Ensure data quality and reliability.
 * Provide technical guidance and support to planning and activation teams on utilizing the planning tool and interpreting data insights.
 * Collaborate with stakeholders to ensure the Total Performance Doctrine (TPD) measurement framework is effectively integrated into all data processes and tooling.
 * Contribute to the development of data-driven solutions leveraging PlayStation's first-party data (sales, subscriptions, and customer demographics) for optimizing paid media campaigns.
   
   

Qualifications


 * Bachelor's or Master's degree in Computer Science, Software Engineering, or a related field. A degree in Statistical Modelling or Mathematics with relevant software development experience will also be considered.
 * Proven hands-on experience in data engineering, including proficiency with SQL, Python (Pandas and Flask), Google Cloud Platform (GCP), Snowflake, and DBT. Experience with data warehousing and ETL/ELT processes.
 * Strong understanding of data modeling, data structures, and algorithm design.
 * Experience with software development best practices, including version control (e.g., Git) and testing.
 * Excellent communication and collaboration skills, with the ability to explain technical concepts to non-technical audiences.
 * Knowledge of digital marketing, including CRM programs (a plus).
 * Understanding of data governance and compliance principles (a plus).
   
   

Life at GroupM

Our passion for shaping the next era of media includes investing in our employees to help them do their best work, and we’re just as committed to employee growth as we are to responsible media investment. GroupM employees can tap into the global GroupM & WPP networks to pursue their passions, grow their networks, and learn at the cutting edge of marketing and advertising. We have a variety of employee resource groups and host frequent in-office events showcasing team wins, sharing thought leadership, and celebrating holidays and milestone events. Our benefits include competitive medical, vision, and dental insurance, significant paid time off, preferential partner discounts, and employee mental health awareness days.  

GroupM is WPP’s media investment group and the world’s leading media investment company with a mission to shape the next era of media where advertising works better for people. The company is responsible for more than $60 billion in annual media investment, as measured by the independent research bureau COMvergence. Through its global agencies Mindshare, Wavemaker, EssenceMediacom, and T&Pm, and cross-channel performance (GroupM Nexus), data (Choreograph), entertainment (GroupM Motion Entertainment) and investment solutions, GroupM leverages a unique combination of global scale, expertise, and innovation to generate sustained value for clients wherever they do business. Discover more at www.groupm.com.

GroupM provides equal employment opportunities to applicants and employees without regard to race; color; sex; gender identity; sexual orientation; religious practices and observances; national origin; pregnancy, childbirth, or related medical conditions; status as a protected veteran or spouse/family member of a protected veteran; or disability.

GroupM is committed to providing reasonable accommodation to, among others, individuals with disabilities and disabled veterans. If you need an accommodation because of a disability to search and apply for a career opportunity with GroupM, please send an e-mail to GroupM Leave Administration at Leave.Administration@groupm.com or call (212) 297-8507 and let us know the nature of your request and your contact information.

The base salary for this position at the time of this posting may range from $75,000 to $180,000. Individual compensation varies based on job-related factors, including business needs, experience, level of responsibility and qualifications. We offer a competitive benefits package, please visit https://www.wpp.com/people/wellbeing/benefits-at-wpp-in-the-us for more details.

Reference ID: o8GEufwG",Full-time
4138249609,33636.0,Azure Data Engineer,"Job Description

We are looking for an experienced Azure Data Engineer to be part of our data & analytics team. You will develop solutions leveraging Azure cloud platform to create a Modern Enterprise data platform. You will work with cross-functional teams to ensure data is collected, stored, processed, and analyzed in a timely, efficient, and accurate manner.

You will support digital transformation journey of data and analytics team at Rheem. This exciting transformation will enable new cloud technologies that will transform the way we derive value from our data assets.

This position will serve our Enterprise Division located in Atlanta, GA (Hybrid)

Responsibilities


 * Design, develop, and deploy data solutions using Microsoft Azure cloud platform
 * Develop and maintain automated data ingestion, transformation, and validation processes to ensure data accuracy and consistency
 * Data Ingestion: Ingesting data from various sources, such as on-premises systems, cloud-based systems, and third-party services into
 * Data Transformation: Transforming data into the appropriate format, schema, and structure to meet business requirements
 * Data Loading: Loading transformed data into Azure Synapse SQL Warehouse/ Azure Data Lake Storage
 * Error Handling and Monitoring: Implementing error handling and monitoring processes to ensure data integration solutions operate smoothly and provide reliable data.
 * Performance Optimization: Optimizing data integration processes for performance and cost, by tuning queries, caching data, and managing resources.
 * Collaboration: Collaborating with other teams, such as, architects, developers, and business analysts, to ensure data solutions meet their requirements.
   
   

Qualifications


 * Bachelor’s degree in Computer Science or Data Analytics/engineering related streams
 * 5+ years of experience in developing Data warehouse/Lakehouse/Data platform on Azure Synapse Analytics/Azure Databricks/Azure Cloud Platform
 * Strong experience in creating data ingestion and transformation pipelines using Synapse Pipeline/Azure Data Factory(ADF) and Azure Databricks.
 * Should have experience in ETL/ELT. Hands - on experience using ADF/Synapse, configuration, parameters, variables, Integration services runtime.
 * Strong understanding of Azure services such as Azure Synapse, Azure Synapse Pipeline, Azure Synapse, Spark Notebooks, Azure Synapse Dedicated SQL Pool Warehouse ,Azure Databricks, Azure Functions and Azure Data Lake storage
 * Knowledge of Dimensional data modeling and familiarity with concepts like start schema, snowflake schema, and normalization.
 * Proficiency in DevOps tools and practices, including CI/CD using Git, automation and monitoring.
 * Understanding of MDM concepts and technologies.
 * Knowledge of Power BI Semantic data modeling and reporting.
 * Understanding of with various data formats like relational, json, parquet, streaming and others
 * Proficiency in SQL,T-SQL and Python/PySpark
 * Excellent problem-solving and analytical skills. Aptitude to adapt to new technologies
 * Excellent business facing and internal communication skills
   
   

Preferred Qualifications


 * Microsoft Azure Data Engineer Associate Certificate
 * Certification on Data Science/ML.
 * Manufacturing industry experience.
   
   

About Us

At Rheem, we are dedicated to bringing comfort to people’s lives. As a leading global manufacturer of heating, cooling and water heating equipment, we are innovating all-new ways to deliver just the right temperature while saving energy, water and supporting a more sustainable future. It is an exciting challenge that requires a team of talented, passionate people with a diverse set of skills. From engineers to accountants, sales professionals to support experts, Rheem depends on people to power our innovations. Join Rheem, and help shape the future of products that impact lives—every day.

Rheem is an Equal Opportunity Employer. Rheem encourages all qualified candidates to apply, including those of any race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. The job description above has been designed to indicate the general nature and level of work performed by employees within this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. Equivalent combination of education, experience, and skills may supplement above minimum job requirements.

For U.S. Based jobs, please note that Rheem is unable to hire candidates to be employed in the following states: Alaska, Hawaii, Idaho, Louisiana, Mississippi, Montana, New Mexico, North Dakota, South Dakota, Vermont, West Virginia, or Wyoming.

Rheem and its subsidiaries do not accept unsolicited resumes from recruiters or employment agencies. In the absence of an executed Recruitment Services Agreement, there will be no obligation to any referral compensation or recruiter fee.

",Full-time
4122508992,1415.0,Data Engineer,"Position Description

At CGI, we believe in the power of data to drive innovation and transformation. As a Data Engineer, you will be at the forefront of designing, developing, and maintaining the critical infrastructure and systems that support data storage, processing, and analysis with a primary focus on Google Cloud Platform (GCP). Your expertise will be essential in building and managing data pipelines that ensure efficient and reliable data integration, transformation, and delivery across the enterprise.

This position can be located anywhere in the US, but the preferred locations are Fairfax, VA, Lafayette, LA, or Knoxville, TN.

If you are located within 50 miles of a CGI Federal office, a hybrid working model is acceptable.

Your future duties and responsibilities


 * Design, develop, and maintain robust data pipelines that extract data from various sources, both legacy and modern systems, transforming it into the desired format, and loading it into the appropriate data storage systems.
 * Partner with architects, engineers, information analysts, business, and technology stakeholders to develop and deploy enterprise grade platforms that enable data-driven solutions.
 * Develop and manage ETL (Extract, Transform, Load) processes to support data transformations into XML and JSON documents, enriching them for analytics.
 * Implement and manage advanced data models, including relational databases, non-relational databases, key value pairs, and timeseries data.
 * Integrate data from different sources, including databases, data warehouses, APIs, and external systems.
 * Ensure data consistency and integrity during the integration process, performing data validation and cleaning as needed.
 * Transform raw data into a usable format by applying data cleansing, aggregation, filtering, and enrichment techniques.
 * Optimize data pipelines and data processing workflows for performance, scalability, and efficiency.
 * Monitor and tune data systems, identify and resolve performance bottlenecks, and implement caching and indexing strategies to enhance query performance.
 * Implement data quality checks and validations within data pipelines to ensure the accuracy, consistency, and completeness of data.
 * Optimize and administer application environments to ensure high performance and reliability.
 * Collaborate with cross-functional teams to deliver comprehensive data solutions.
 * Ensure data quality, security, and governance across all data processes.
 * Communicate effectively with stakeholders to understand requirements and deliver actionable insights.
 * Operate within agile teams, contributing to continuous improvement in data engineering practices and processes.
 * Utilize cloud platforms such as GCP, AWS, and Azure to build scalable data solutions.
   
   

Required Qualifications To Be Successful In This Role


 * Minimum of 8 years of experience in data engineering.
 * At least 5 years of work experience in data management disciplines, including data integration, modeling, optimization and data quality, or other areas directly relevant to data engineering responsibilities and tasks.
 * Proficiency in modern data modeling techniques and data administration.
 * Strong knowledge of SQL, Python, Java.
 * Experience with cloud platforms such as GCP, AWS and Azure.
 * Good problem-solving skills, including debugging skills, allowing the determination of sources of issues in unfamiliar code or systems, and the ability to recognize and solve repetitive problems.
 * Good communication skills and a proactive “getting things done” mindset.
 * Experience working in Agile teams and familiarity with Agile methodologies including Scaled Agile (SAFe) and Kanban.
 * Ability to design, build, and deploy data solutions that capture, explore, transform, and utilize data to support AI, ML, and BI.
 * Experience in the design and implementation of modern data architectures and concepts such as cloud services (AWS, Azure, GCP) and modern data warehouse tools (Snowflake, Databricks).
 * Experience with database technologies such as SQL, NoSQL, Oracle, Hadoop, or Teradata.
 * Ability to collaborate within and across teams of different technical knowledge to support delivery of data products.
   
   

CGI is required by law in some jurisdictions to include a reasonable estimate of the compensation range for this role. The determination of this range includes various factors not limited to skill set, level, experience, relevant training, and license and certifications. To support the ability to reward for merit-based performance, CGI typically does not hire individuals at or near the top of the range for their role. Compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range for this role in the U.S. is $111,600.00 - $219,600.00.

CGI Federal anticipates accepting applications for this position through Feb 28, 2025.

CGI Federal's benefits are offered to eligible professionals on their first day of employment to include:


 * Competitive compensation
 * Comprehensive insurance options
 * Matching contributions through the 401(k) plan and the share purchase plan
 * Paid time off for vacation, holidays, and sick time
 * Paid parental leave
 * Learning opportunities and tuition assistance
 * Wellness and Well-being programs
   
   

#CGIFederalJob

#DICE

#

Together, as owners, let’s turn meaningful insights into action.

Life at CGI is rooted in ownership, teamwork, respect and belonging. Here, you’ll reach your full potential because…

You are invited to be an owner from day 1 as we work together to bring our Dream to life. That’s why we call ourselves CGI Partners rather than employees. We benefit from our collective success and actively shape our company’s strategy and direction.

Your work creates value. You’ll develop innovative solutions and build relationships with teammates and clients while accessing global capabilities to scale your ideas, embrace new opportunities, and benefit from expansive industry and technology expertise.

You’ll shape your career by joining a company built to grow and last. You’ll be supported by leaders who care about your health and well-being and provide you with opportunities to deepen your skills and broaden your horizons.

Come join our team—one of the largest IT and business consulting services firms in the world.

Qualified applicants will receive consideration for employment without regard to their race, ethnicity, ancestry, color, sex, religion, creed, age, national origin, citizenship status, disability, pregnancy, medical condition, military and veteran status, marital status, sexual orientation or perceived sexual orientation, gender, gender identity, and gender expression, familial status or responsibilities, reproductive health decisions, political affiliation, genetic information, height, weight, or any other legally protected status or characteristics.

CGI provides reasonable accommodations to qualified individuals with disabilities. If you need an accommodation to apply for a job in the U.S., please email the CGI U.S. Employment Compliance mailbox at US_Employment_Compliance@cgi.com. You will need to reference the Position ID of the position in which you are interested. Your message will be routed to the appropriate recruiter who will assist you. Please note, this email address is only to be used for those individuals who need an accommodation to apply for a job. Emails for any other reason or those that do not include a Position ID will not be returned.

We make it easy to translate military experience and skills! Click here to be directed to our site that is dedicated to veterans and transitioning service members.

All CGI offers of employment in the U.S. are contingent upon the ability to successfully complete a background investigation. Background investigation components can vary dependent upon specific assignment and/or level of US government security clearance held. Dependent upon role and/or federal government security clearance requirements, and in accordance with applicable laws, some background investigations may include a credit check. CGI will consider for employment qualified applicants with arrests and conviction records in accordance with all local regulations and ordinances.

CGI will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with CGI’s legal duty to furnish information.

",Full-time
4120743018,18007.0,Staff Data Engineer ( Chicago or Boston ),"Company Description

PG Forsta is the leading experience measurement, data analytics, and insights provider for complex industries—a status we earned over decades of deep partnership with clients to help them understand and meet the needs of their key stakeholders. Our earliest roots are in U.S. healthcare –perhaps the most complex of all industries. Today we serve clients around the globe in every industry to help them improve the Human Experiences at the heart of their business. We serve our clients through an unparalleled offering that combines technology, data, and expertise to enable them to pinpoint and prioritize opportunities, accelerate improvement efforts and build lifetime loyalty among their customers and employees.

Like all great companies, our success is a function of our people and our culture. Our employees have world-class talent, a collaborative work ethic, and a passion for the work that have earned us trusted advisor status among the world’s most recognized brands. As a member of the team, you will help us create value for our clients, you will make us better through your contribution to the work and your voice in the process. Ours is a path of learning and continuous improvement; team efforts chart the course for corporate success.

Our Mission:

To elevate the human experiences at the heart of business by offering insights that sharpen understanding of the needs of individuals and populations, and provide guidance on how to meet those needs.

We partner clients to gather the voice of consumers and the workforce to gain insights that address unmet needs. Through the use of integrated data, advanced analytics and strategic advisory services, we are helping clients transform their organizations to deliver high quality services and lifetime loyalty.

Our Values:

Champion the Client

We demonstrate an unwavering passion for delivering high-quality solutions and service. We commit to understanding the goals and needs of our clients. We always look for opportunities to improve and create value. Each of us understands our role in enabling client success.

All Together Better

We are united by the common purpose of our vision and mission. We promote teamwork and a culture of belonging by building strong relationships and fostering trust. We collaborate to identify and develop innovative solutions.

Embrace Change

We recognize that change is constant and presents opportunities to learn, adapt, and evolve. We seek creative solutions to challenges and e pursue them with optimism and enthusiasm.

Do the Right Thing

We demonstrate commitment to all our stakeholders, including clients, staff, and partners. We take personal accountability for our responsibilities and actions. We do right by each other by acting with honesty and kindness. We provide meaningful recognition and feedback to others.

Job Description

We are seeking an experienced Staff Data Engineer to join our team. The ideal candidate will be responsible for designing, developing, and maintaining our company's data infrastructure, which includes data warehouses, data pipelines, and data integration platforms. The Staff Data Engineer works directly with the data science, analytics, and data quality teams to ensure that the data infrastructure supports the company's business objectives.

Duties & Responsibilities:


 * Design, develop, and maintain our data infrastructure, which includes data warehouses, data pipelines, and data integration platforms.
 * Work with the data science, analytics, and data quality teams to ensure that the data infrastructure supports the company's business objectives.
 * Develop and maintain ETL pipelines and data integration workflows.
 * Optimize and fine-tune data structures and queries to ensure high performance and scalability.
 * Develop and maintain data quality and data governance processes.
 * Collaborate with cross-functional teams to define and implement data models that support business requirements and new analytic models and algorithms.
 * Ensure that data is collected, stored, and processed in compliance with data privacy regulations.
 * Develop and maintain documentation for all data-related processes and systems.
 * Stay up-to-date with emerging trends and technologies in the data engineering field.
   
   

Qualifications

Technical Skills:


 * Expertise in SQL and NoSQL databases, data warehousing, and data modeling.
 * Fluency in Python and SQL. Additional data or system languages (e.g. Java, Scala, Go, R) a plus.
 * Experience with data warehousing technologies such as Google BigQuery, Delta Lake, Amazon Redshift or Snowflake.
 * Experience using data pipeline frameworks such as Apache Beam or Apache Spark at scale.
 * Experience with data orchestration / automation frameworks such as Airflow, Databricks and MLFlow.
 * Experience with data modeling and data governance best practices.
 * Experience with data visualization tools such as Tableau or Power BI.
   
   

Minimum Qualifications:


 * Bachelor's or Master's degree in Computer Science, Data Science, or a related field.
 * 5+ years experience in data engineering, with a track record of designing, developing, and maintaining large-scale data infrastructure.
 * Strong analytical and problem-solving skills.
 * Excellent communication and collaboration skills.
   
   

Preferred Qualifications:


 * Master’s degree in Computer Science, Engineering, or a related field.
 * Experience in machine learning or data science.
   
   

Additional Information

Press Ganey Associates LLC is an Equal Employment Opportunity/Affirmative Action employer and well committed to a diverse workforce. We do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, veteran status, and basis of disability or any other federal, state or local protected class.

Pay Transparency Non-Discrimination Notice – Press Ganey will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor's legal duty to furnish information.

The expected base salary for this position ranges from $140,000 to $160,000. It is not typical for offers to be made at or near the top of the range. Salary offers are based on a wide range of factors including relevant skills, training, experience, education, and, where applicable, licensure or certifications obtained. Market and organizational factors are also considered. In addition to base salary and a competitive benefits package, successful candidates are eligible to receive a discretionary bonus or commission tied to achieved results.

All your information will be kept confidential according to EEO guidelines.

Our privacy policy can be found here: https://www.pressganey.com/legal-privacy/",Full-time
3696899083,79907466.0,Data Engineer,"We have partnered with a large consulting firm in the Washington, DC area to provide them with a Data Engineer

Responsibilities Of The Data Engineer


 * Designing and developing ongoing data ingestion and cleaning using Python and Spark.
 * Support Requirements gathering activities, especially from the data migration perspective.
 * Using programming skills to create big data pipelines that can deal with both structured and unstructured data.
 * Support other teams' ineffective use of big data tools and provide guidance in writing efficient code in Python and/or R.
 * Analyzes and loads data for use by a larger audience.
 * Analyzes databases to improve the speed of data access.
 * Writes views for consultants to simplify data access.
 * Diagnoses and corrects database performance bottlenecks.
 * Analyzes data provided by project consultants and makes it available in our database; provides access to the database to those that have a need.
 * Develops strategies for data acquisitions, archive, recovery, and implementation of a database.
 * Maintains the database and cleans data as required.
 * Designs and develops databases, data warehouses, and multidimensional databases.
 * Leads and directs data management work of others as applicable.
 * Reports to the office on a regular basis to allow for in-person interactions including providing oversight and mentorship to the team, attending meetings with other employees, candidates, and vendors, participating in performance conversations, attending firm meetings, or as otherwise requested by the direct supervisor.
   
   

Requirements Of The Data Engineer


 * Bachelor's degree required.
 * 5+ years of experience working with big data.
 * 3+ years of experience with software development lifecycle.
 * 3+ years of developing data ingestion and transformation processes associated with big data technologies (e.g. Hadoop, Spark, etc.)
 * 5+ years of hands-on Python coding experience.
 * Experience with data modeling, integration, and warehousing.
 * Hands-on experience with CI/CD automation is preferred.
 * Working knowledge with UNIX variants preferred.
 * Previous experience working with Cloud (e.g. AWS) is a plus.
 * Experience with Databricks is a plus
 * Experience with performance tuning of ETL jobs.
 * Ability to communicate technical issues to non-technical staff.
 * Ability to perform essential functions with or without reasonable accommodation.
 * May require more than 40.0 hours per week to perform the essential duties of the position.
   
   

Benefits Of The Data Engineer


 * Medical Insurance
 * Dental Insurance
 * Profit-Sharing Program",Full-time
4127811315,96139831.0,Data Engineer,"DataAnnotation is committed to creating quality AI. Join our team to help train AI chatbots while gaining the flexibility of remote work and choosing your own schedule.




We are looking for a proficient Data Engineer to join our team to train our AI chatbots to code. You will work with the chatbots that we are building in order to measure their progress, as well as write and evaluate code.




To apply to this role, you will need to be proficient in either Python and/or JavaScript. Your role will require proficiency in at least one programming language (JavaScript, Python, C#, C++, HTML, SQL, or Swift) in order to solve coding problems (think LeetCode, HackerRank, etc). For each coding problem, you must be able to explain how your solution solves the problem.




Benefits:




 * This is a full-time or part-time REMOTE position
 * You’ll be able to choose which projects you want to work on
 * You can work on your own schedule
 * Projects are paid hourly, starting at $40+ USD per hour, with bonuses for high-quality and high-volume work




Responsibilities:




 * Come up with diverse problems and solutions for a coding chatbot
 * Write high-quality answers and code snippets
 * Evaluate code quality produced by AI models for correctness and performance




Qualifications:




 * Fluency in English (native or bilingual level)
 * Proficient in either Python and/or JavaScript
 * Excellent writing and grammar skills
 * A bachelor's degree (completed or in progress)
 * Previous experience as a Software Developer, Coder, Software Engineer, or Programmer




Note: Payment is made via PayPal. We will never ask for any money from you. PayPal will handle any currency conversions from USD. This job is only available to those in the US, UK, Canada, Australia, or New Zealand. Those located outside of these countries will not see work or assessments available on our site at this time.",Contract
4149953083,165602.0,Data Engineer,"Immediate need for a talented Data Engineer. This is a 12+ Months Contract opportunity with long-term potential and is located in Charlotte, NC(Onsite). Please review the job description below and contact me ASAP if you are interested.




Job ID:25-58807




Pay Range: $68 - $73/hour. Employee benefits include, but are not limited to, health insurance (medical, dental, vision), 401(k) plan, and paid sick leave (depending on work location).



Key Responsibilities:




 * Key responsibilities of the role include developing solutions and processes for delivering features based on their knowledge of design/architectural patterns and Agile/DevOps practices.
 * This role ensures the systems design and requirements are aligned to achieve the desired business outcomes, and that team practices and coding/quality principles are aligned to achieve the desired technology outcomes.
 * Candidate should have built significant experience through multiple software implementations and has developed both depth and breadth in a number of technical competencies.




Key Requirements and Technology Experience:




 * Skills-Python, Oracle and Hadoop, Data Management and Data warehousing.
 * Minimum 7 years of experience handling data platforms (E2E data solutioning - including integration with other upstream / downstream, data processing with common data model build out, Analytics and BI Integration).
 * RDBMS experience in Oracle (Exadata) is a must.
 * Proficient in Advanced SQL Skills.
 * Strong Analytics skills.
 * Proficient with DevOps / CICD.
 * Working knowledge on Autosys Scheduling.
 * Working in Agile Team (and familiar with SAFe Agile Practices).
 * Experience with Shell Scripting.
 * Should be flexible in learning new Analytical Tools.
 * Should be able to independently work through implementation (along with taking care of Release Management).
 * Required Education: College Degree.
 * Deal Breaker: Little Experience with large data support teams.
 * Overview of work: Candidate will be working with new data management governance items.
 * Working on Data Governance Team.




Our client is a leading Banking and Financial Industry and we are currently interviewing to fill this and other similar contract positions. If you are interested in this position, please apply online for immediate consideration.




Pyramid Consulting, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.




By applying to our jobs you agree to receive calls, AI-generated calls, text messages, or emails from Pyramid Consulting, Inc. and its affiliates, and contracted partners. Frequency varies for text messages. Message and data rates may apply. Carriers are not liable for delayed or undelivered messages. You can reply STOP to cancel and HELP for help. You can access our privacy policy here.",Contract
4045416052,66321745.0,Data Engineer - Remote,"Since 2010 and almost 14 years SynergisticIT has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients.

Post Covid the tech Layoffs have been massive—In 2022 there were 165,269 tech layoffs, In 2023 there were 264,220 tech layoffs and so far in 2024 there have been 126,382 tech layoffs. (Source Layoffs.fyi ) -Total layoffs as per this 555,871 tech layoffs.

Client, Dell and Cisco have announced 15,000/12,500 and 4000 tech layoffs respectively in August.

The Job market is Hyper Competitive. For 1 position 500-2000 candidates or more are applying and laid off job seekers are also competing for entry level Job positions.

Acquiring the right technology skillsets which are being demanded by clients and getting yourself in front of clients is the way to get to get Interviews and eventually a Job Offer. Survival of the Fittest is the only way to get a tech Job in this job market.

In this Layoffs fueled market also SynergisticIT's candidates are able to achieve multiple job offers and $100k &plus; salaries once they acquire the required skills.

please check the below links to see success outcomes, salaries of our candidates .

https://www.synergisticit.com/candidate-outcomes/

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please visit the below videos exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, we are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Data Engineers, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

Required Skills

REQUIRED SKILLS For Java /Full stack/Devops Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Knowledge of Core Java , javascript , C&plus;&plus; or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

For data Science/Data Analyst/AI/Machine learning Positions

Required Skills

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude

Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidate.",Full-time
4138437124,1586.0,"Data Engineer - AI/ML, Amazon Robotics","Description

Are you excited about developing generative AI and foundation models to revolutionize automation, robotics and computer vision? Are you looking for opportunities to build and deploy them on real problems at truly vast scale? At Amazon Fulfillment Technologies and Robotics we are on a mission to build high-performance autonomous systems that perceive and act to further improve our world-class customer experience - at Amazon scale. We are looking for scientists, engineers and program managers for a variety of roles.

The Infrastructure and Operations team within the Fleet Mobility AI program is seeking a passionate Data Engineer to provide massive data for training state-of-the-art Foundation Models and power the future of Amazon’s fleet of over 750,000 mobile robots. This includes merging data from multiple sources to aid in building multi-robot models that are able to predict, reason about, and generate scenarios for multi-robot systems. It also includes supporting the new AI initiatives by owning the data pipelines that fuel the Foundation Models and the downstream innovations. If you are a passionate Data Engineer with a knack for extracting value from complex data sources, this is the perfect opportunity to make your mark in an exciting, dynamic field.

Key job responsibilities


 * Work with cross-functional teams to gather and analyze the data requirements for building state-of-the-art AI models.
 * Design, develop, and maintain data pipelines to collect, clean, and store data from multiple diverse sources.
 * Implement data quality and validation mechanisms to ensure data and model integrity.
 * Work closely with Science teams to assist the downstream use cases of their models.
 * Optimize data processing, storage, and retrieval solutions for scalability, cost, and performance tradeoffs.
 * Feedback data issues and opportunities to various teams and support the improvement of data collection practices and processes.
   
   

A day in the life


 * Participate in the team's agile ceremonies, including planning, daily updates, review, and retrospectives.
 * Work with data scientists, software engineers, and data professionals to gather and clarify requirements, set goals and success metrics, and check progress against requirements.
 * Dive into exploration, profiling, and cleaning to support data analysis and model building.
 * Design and implement data pipelines.
 * Troubleshoot data issues, and feedback your findings with stakeholders.
 * Share knowledge across the organization and play a role in the Data Engineering Community of Practice.
   
   

Amazon offers a full range of benefits for you and eligible family members, including domestic partners and their children. Benefits can vary by location, the number of regularly scheduled hours you work, length of employment, and job status such as seasonal or temporary employment. The benefits that generally apply to regular, full-time employees include:


 * Medical, Dental, and Vision Coverage
 * Maternity and Parental Leave Options
 * Paid Time Off (PTO)
 * 401(k) Plan
   
   

If you are not sure that every qualification on the list above describes you exactly, we'd still love to hear from you! At Amazon, we value people with unique backgrounds, experiences, and skillsets. If you’re passionate about this role and want to make an impact on a global scale, please apply!

About The Team

You will be joining a research/innovation team with diverse, passionate engineers and data scientists who are dedicated to pushing the boundaries of Warehouse Robotics. The team adopts a highly collaborative innovation management process and an agile framework. Your expertise will contribute to the advancements aspired by the team from ideation to production.

Basic Qualifications


 * 3+ years of data engineering experience
 * 3+ years of analyzing and interpreting data with Redshift, Oracle, NoSQL etc. experience
 * Knowledge of distributed systems as it pertains to data storage and computing
 * Experience with data modeling, warehousing and building ETL pipelines
 * Experience working on and delivering end to end projects independently
 * Experience programming with at least one modern language such as C++, C#, Java, Python, Golang, PowerShell, Ruby
 * Experience with Redshift, Oracle, NoSQL etc.
 * Master's degree in computer science, engineering, analytics, mathematics, statistics, IT or equivalent
 * Familiarity and comfort with Python, SQL, Docker, and Shell scripting. Java preferred but not necessary.
   
   

Preferred Qualifications


 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
 * Experience as a data engineer or related specialty (e.g., software engineer, business intelligence engineer, data scientist) with a track record of manipulating, processing, and extracting value from large datasets
 * Experience in at least one modern scripting or programming language, such as Python, Java, Scala, or NodeJS
 * Experience with Apache Spark / Elastic Map Reduce
 * Experience with continuous delivery, infrastructure as code, microservices, in addition to designing and implementing automated data solutions using Apache Airflow, AWS StepFunctions, or equivalent
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.


Company - Amazon.com Services LLC

Job ID: A2886908",Full-time
4143583675,10196036.0,Data Engineer (Foundry Workshop),"Looking for a new challenges? This is your opportunity!




WHAT we’ll bring:

People first: Sngular is a collaborative people-oriented company, we impact society through technology while we are developing our talent as a team. We embrace diverse perspectives and value unique human experiences. Our number one value is ""People before results"" and all decisions are taken together accordingly.

Growth and training: During your time with us, you will be offered opportunities to learn new skills: the newest technologies, gain new certification, become a Tech lead or a Manager…leave your comfort zone the way YOU want it! Your career path and treatment will be always personalized, tell us what is your goal so we can reach it together. Our Global CEO also started as a Developer with us!

 * Continuous professional growth: Internal training, Annual training allowance, Free unlimited access to UDEMY; Bonus for Obtaining Certifications, Tech talks + Language training
 * Work-life balance: Respected schedule, Digital disconnection, PTO...
 * Welcome KIT
 * Very fun virtual and face to face events
 * Great work environment with the best professional team
 * Stability and professional growth opportunities
 * Technical challenges




WHAT your responsibilities will be:

 * Our Foundry engineers build and operate a reliable, scalable and secure data platform for one of our clients in the Pharmaceutical industry. They partner with product-engineering teams to deliver data-powered functionality for customers, they work with cross functional stakeholders to enable visibility into business critical metrics, and they collaborate with analysts and data scientists to enhance modeling and analytics capabilities.







WHAT you will need to succeed in this role:

 * Experience in Palantir Foundry and specifically with the Workshop application.
 * Training or experience in TypeScript
 * Training or experience in PySpark




Nice to have

 * Foundry Function, Slate, Quiver, Contour
 * Outstanding interpersonal and communication skills
 * Strong analytical, problem solving and critical thinking skills
 * Proficiency in Python and SQL.
 * Experience running ETL processes on large scale data sets
 * Experience supporting data ingestion pipeline on AWS EMR and Spark.







*This job is not eligible to be performed in the states of New York, New Jersey, California or Colorado.




Open to new challenges? Send us your resume and the Talent team will contact you as soon as possible! :D",Full-time
4078427663,23772.0,"Data Engineer, Research & Development","Job Details

Description

Department: Baseball Operations, Research and Development

Supervisor: Sr. Director, Research and Development

Classification: Full-Time/Exempt

Location: Houston, TX

The Houston Astros baseball organization is accepting applications for a Data Engineer to join our Research & Development team within Baseball Operations. We are seeking an applicant to support the growth of our data architecture using cloud-based data lake technologies. This role will work within a team of software developers supporting the broad need of Baseball Operations and will be central to the workflow of departments across the organization, including opportunities to interface with and understand the needs of other departments and drive creative solutions.

Essential Functions & Responsibilities

Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.


 * Collaborate with the team on the design and implementation of a cloud-based data architecture.
 * Leverage Spark-based solutions to develop and maintain data processing pipelines that provide efficient access to data at various stages of transformation.
 * Integrate structured, semi-structured, and unstructured data sources, handling various formats including Parquet, JSON, and more.
 * Automate workflows and monitoring procedures to promote a maintainable infrastructure.
 * Write clean and iterative code and leverage continuous integration practices to deploy, support and operate data pipelines.
 * Interact with stakeholders internal to R&D (research analysts, application developers, ) and external to understand their needs from our architecture and data.
 * Participate in a rotating on-call schedule to tend to any immediate issues with our architecture and data.
 * Perform other duties as assigned.
   
   

Qualifications


 * Experience with one or more cloud platforms such as Azure, AWS, GCP.
 * Experience building and maintaining ETL processes with Databricks, Snowflake, or other data lake technologies.
 * Experience with Apache Spark (especially PySpark) a plus.
 * Proficiency with Python, including best practices and OOP design.
 * Proficiency with SQL and relational database structures.
 * Experience working on software teams and promoting software development best practices, including continuous integration, documentation, process automation, and monitoring.
 * Resilient in evolving environments and advocates for technical excellence.
   
   

Work Environment

This job operates in an office setting. This role routinely uses standard office equipment such as computers, phones and photocopiers. The noise level is usually moderate but can be loud within the stadium environment.

Physical Demands

While performing the duties of this job, the employee is occasionally required to stand; walk; sit (for long periods of time); use hands to handle or feel objects, tools or controls; reach with hands and arms; climb stairs; talk or hear. The employee may occasionally lift or move equipment, up to 20 pounds.

Specific vision abilities required by this job include close and focused vision.

Position Type and Expected Hours of Work

Ability to work a flexible schedule, including extended hours, evenings, weekends, and holidays.

Travel

Some travel may be expected in this role.

Other Duties

Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.

We are an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.

EOE/M/F/Vet/Disability",Full-time
4145176711,25030011.0,Data Engineer,"At Accenture Federal Services, nothing matters more than helping the US federal government make the nation stronger and safer and life better for people. Our 13,000+ people are united in a shared purpose to pursue the limitless potential of technology and ingenuity for clients across defense, national security, public safety, civilian, and military health organizations.

Join Accenture Federal Services to do the work you love in an inclusive, collaborative, and caring community, where you can be empowered to grow, learn and thrive through hands-on experience, certifications, industry training and more.

Join us to drive positive, lasting change that moves missions and the government forward!

Job Description

As a Data Engineer in this role, you will be at the forefront of transforming financial data into actionable insights for a mission-driven customer. Your primary responsibility will be to develop, optimize, and maintain robust ETL processes and data pipelines. You will leverage your expertise in Python and SQL to condition and normalize both raw and structured data, enhancing its usability and searchability within downstream enterprise tools. Your work will be pivotal in implementing cutting-edge technology, including AI models, to improve data fidelity and accelerate data engineering tasks. Familiarity with Apache Airflow and Apache Hop will be beneficial as you build new and repeatable workflows to support the team's objectives.

Your success in this position will be bolstered by your ability to work independently as well as collaboratively with a team of technical experts, data managers, and operational stakeholders. Experience with Amazon Web Services (AWS) will be crucial as you deploy scalable solutions in a cloud environment. While not mandatory, a background in Kubernetes will give you an edge, as will any experience with financial data and language translation models.

In this dynamic role, you will not only support the team in conditioning financial data but also play a key role in the adoption of modern data engineering practices. Your contributions will directly impact the efficiency and effectiveness of data processing, setting the stage for advanced data analysis and decision-making. The ideal candidate will bring a proven track record of building and implementing ETL processes, with a keen eye for optimizing data for various enterprise applications. If you have a passion for data engineering and are ready to take on a challenge that marries technical prowess with mission-critical analysis, this is the opportunity for you.

Here is what you need:


 * 5 years of experience in data engineering
 * Experience with Python
 * Experience with Structured Query Language (SQL)
 * Experience with Apache Airflow
 * Experience with Apache Hop
 * Experience normalizing raw, unstructured, and structured data
 * Ability to work independently and collaboratively
 * Experience building, optimizing, and implementing ETL processes and data pipelines
 * Experience with Amazon Web Services (AWS)
   
   

Bonus if you have:


 * Experience with financial data
 * Experience with language translation models
 * Experience using Kubernetes
   
   

Education:


 * Bachelor's Degree Preferred
   
   

Security Clearance:


 * Active TS/SCI with polygraph clearance
   
   

As required by local law, Accenture Federal Services provides reasonable ranges of compensation for hired roles based on labor costs in the states of California, Colorado, Hawaii, Illinois, Maryland, Minnesota, New York, Washington, and the District of Columbia. The base pay range for this position in these locations is shown below. Compensation for roles at Accenture Federal Services varies depending on a wide array of factors, including but not limited to office location, role, skill set and level of experience. Accenture Federal Services offers a wide variety of benefits. You can find more information on benefits here. We accept applications on an on-going basis and there is no fixed deadline to apply.

The pay range for the states of California, Colorado, Hawaii, Illinois, Maryland, Minnesota, New York, Washington, and the District of Columbia is:

$140,400—$265,300 USD

What We Believe

We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture Federal Services has the responsibility to create and sustain an inclusive environment.

Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here

Equal Employment Opportunity Statement

Accenture Federal Services is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.

All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Accenture is committed to providing veteran employment opportunities to our service men and women.

For details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy Statement.

Requesting An Accommodation

Accenture Federal Services is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture Federal Services and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.

If you are being considered for employment opportunities with Accenture Federal Services and need an accommodation for a disability or religious observance during the interview process or for the job you are interviewing for, please speak with your recruiter.

Other Employment Statements

Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.

Candidates who are currently employed by a client of Accenture Federal Services or an affiliated Accenture business may not be eligible for consideration.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.

California requires additional notifications for applicants and employees. If you are a California resident, live in or plan to work from Los Angeles County upon being hired for this position, please click here for additional important information.

",Full-time
4138818048,162656.0,Data Engineer,"Data Engineer

W2 Contract-to-Hire

Salary Range: $156,000 - $176,800 per year

Location: Dublin, CA - Hybrid Role

Duties and Responsibilities:

 * Perform installation, patching, configuration, and maintenance of StreamSets on-prem runtime instances.
 * Provide L3 escalation support for existing production systems and assist with related enhancement activities.
 * Ensure proper testing and adherence to business change management practices and procedures.




Requirements and Qualifications:

 * Strong technical expertise in cloud applications, data ingestion, and data lake architecture
 * A StreamSets SME knowledgeable on the data landing needs into Snowflake for data analytics and reporting needs.
 * In-depth knowledge of StreamSets cloud and on-prem architecture, including environment configuration and deployment models
 * Hands-on experience and strong technical knowledge with Linux and Windows, authentication systems, networking, clustering, load balancers, Java, SSL, and certificates




Desired Skills and Experience

StreamSets, data ingestion, data lake, Snowflake, data analytics, reporting, cloud, on-prem, Linux, Windows, authentication, networking, clustering, load balancers, Java, SSL, certificates







Bayside Solutions, Inc. is not able to sponsor any candidates at this time. Additionally, candidates for this position must qualify as a W2 candidate.




Bayside Solutions, Inc. may collect your personal information during the position application process. Please reference Bayside Solutions, Inc.'s CCPA Privacy Policy at www.baysidesolutions.com.",Contract
4132748771,35143.0,Data Engineer,"Overview

Own Your Future.

Modern Technology Solutions, Inc. (MTSI) is searching for Data Engineer to support United States Space Force (USSF) by developing software in support of Space Systems Command (SSC) Defensive Cyber Operations rapid agile development of defensive cyber solutions to protect, defend, and respond to both ground and space based cyber adversarial threats.

Why is MTSI known as a Great Place to Work?


 * Interesting Work: Our co-workers support some of the most important and critical programs to our national defense and security.
 * Values: Our first core value is that employees come first. We challenge our co-workers to provide the highest level of support and service, and reward them with some of the best benefits in the industry.
 * 100% Employee Ownership: we have a stake in each other's success, and the success of our customers. It's also nice to know what's going on across the company; we have company wide town-hall meetings three times a year.
 * Great Benefits - Most Full-Time Staff Are Eligible for:
    * Starting PTO accrual of 20 days PTO/year + 10 holidays/year
    * Flexible schedules
    * 6% 401k match with immediate vesting
    * Semi-annual bonus eligibility (July and December)
    * Company funded Employee Stock Ownership Plan (ESOP) - a separate qualified retirement account
    * Up to $10,000 in annual tuition reimbursement
    * Other company funded benefits, like life and disability insurance
    * Optional zero deductible Blue Cross/Blue Shield health insurance plan

 * Track Record of Success: We have grown every year since our founding in 1993
   

Modern Technology Solutions, Inc. (MTSI) is a 100% employee-owned engineering services and solutions company that provides high-demand technical expertise in Digital Transformation, Modeling and Simulation, Rapid Capability Development, Test and Evaluation, Artificial Intelligence, Autonomy, Cybersecurity and Mission Assurance.

MTSI delivers capabilities to solve problems of global importance. Founded in 1993, MTSI today has employees at over 20 offices and field sites worldwide.

For more information about MTSI, please visit www.mtsi-va.com.

Responsibilities

Modern Technology Solutions, Inc. (MTSI) is searching for a Data Engineer to support United States Space Force (USSF) Space Systems Command (SSC) Defensive Cyber Operations in the development and deployment of defensive cyberspace capabilities across Space mission and weapon systems. A successful candidate should have a diverse technical background and be leader and problem solver with a proven ability to deliver superior results as part of a high performing team in an Agile, fast-paced environment.

Your essential job functions will include but may not be limited to:


 * Assembles large, complex sets of data that meet non-functional and functional requirements
 * Identifies, designs, and implements internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes
 * Builds required infrastructure for optimal extraction, transformation and loading of data from various data sources
 * Curate and maintain data that is stored in support of metrics and evaluation.
 * Working with developers to make sure key data points are stored in a Postgres database.
 * Working with data providers and back-end API developers to normalize schemas and define data flows for persistence and analytics.
 * Design, build, test, maintain, and automate data collection/pipelines
 * Develop Dashboards for Data Analytics.
 * Implement Artificial Intelligence/Machine Learning
 * Using Agile methodologies to develop software.
   
   

Qualifications

Required Qualifications


 * Minimum three (3) years of relevant experience as a Data Engineer/Scientist.
 * Experience developing data pipelines and normalizing data.
 * Experience using AWS cloud services.
 * Experience with PostgreSQL database.
 * Ability to work efficiently on small, distributed teams.
 * Familiarity with Agile principles.
   
   

Desired Qualifications


 * Experience developing Tableau Dashboards.
 * ELK Stack Experience.
 * Real-time event streaming.
 * AWS S3, EC2, Lambda, Kinesis.
 * Apache Spark, NiFi.
 * Confluent Kafka.
 * Experience with Containers (Docker, Docker Compose).
 * DevSecOps utilizing test-driven development.
 * Gitlab experience.
   
   

Education Requirements


 * Bachelor of Science or higher in Computer Science or related field.
   
   

Clearance


 * Must possess an active DoD Secret Clearance.
 * A Top Secret (TS) security clearance (with SCI and SAP eligibility) is HIGHLY desired.
   
   

The pay range for this position in Colorado is $80,000/year to $120,000/year; however, base pay offered may vary depending on established government contract rates, job-related knowledge, skills, and experience, and other factors. MTSI also offers a full range of medical, financial, and other benefits, dependent on the position offered. This information is provided per the Colorado Equal Pay Act. Base pay information is based on market location. Applicants should apply via MTSI’s internal or external careers site

#SSC-BH

#MTSI

",Full-time
4151641970,18244263.0,Healthcare Data Engineer (LANES),"We have a diverse team of healthcare IT experts devoted to solving real-world healthcare problems. We’re looking for a driven, smart, creative, and fun candidate who shares our passion for optimizing the intersection of consumer health, engagement, technology, and innovation.

LANES is a community-based Qualified Health Information Organization (QHIO) whose mission is to improve health care delivery by building a platform that enables cost-effective and secure electronic exchange of patient medical records among public and private health care providers and health plans in the larger Los Angeles County region. LANES seeks to make personal health information available when and where it is needed for patient care, safely and securely.

LANES uses the Mirth technology, AWS cloud, Google Big Query and FHIR, to link healthcare organizations and to maintain the core technology infrastructure of the Health Information Organization.

LANES created a unique new opportunity for a talented and motivated Healthcare Data Engineer responsible for the development of LANES’ portfolio of SQL queries, stored procedures, dashboards, and other data and business intelligence products. By joining LANES, you will be able to learn from work-renowned experts in the fields of healthcare data interoperability and healthcare information technology. You could make an impact by changing healthcare and providing unique insights into healthcare data and by improving health outcomes, public health, and operational efficiencies.

Special Note: This is a virtual home-based position. Will be required to attend in-person meetings in Los Angeles area on an as-needed basis.

This is a full-time, exempt, benefitted position. Employment is provided by Heluna Health.

The pay rate for this position is $150,000-$180,000 annually

Essential Functions


 * Develop, document, and update SQL queries and stored procedures
 * Develop clinical and operational reports
 * Develop repeatable processes for reporting
 * Develop and maintain dashboards and other Business Intelligence (BI) products providing actionable insights
 * Develop data repositories and data analytics sandboxes for expert customers to execute their own queries and build their own analytics tools
 * Optimize performance of large and complex queries.
 * Contribute to strategy development for LANES’ future data products.
 * Proactively identify new technologies, methodologies, and processes to address evolving data management challenges
   
   

Non-essential Functions


 * Other duties as assigned
   
   

Job Qualifications

Education/Experience


 * A bachelor’s degree in computer science or a related field. 5+ year data engineering experience in healthcare. 5+ year hands-on SQL development experience
 * Experience with NodeJS
 * Experience in relational and dimensional data modeling and schema design
 * Experience with data architecture, data quality improvement, metadata, and data governance
 * Experience with postgres and Google BigQuery
 * Experience with Microsoft PowerBI
 * Experience with cloud-based data platforms (AWS and/or Google Cloud Services)
 * Familiarity with Clinical Informatics concepts, terminologies, and coding systems including ICD-10, SNOMED CT, LOINC, and CPT.
 * Good software documentation skills
 * Familiarity with healthcare cybersecurity and privacy regulations and standards, e.g., HIPAA, HITECH, and HITRUST.
   
   

Other Knowledge, Skills, And Abilities


 * Experience with ADT, CCD, DQ/DR messages and documents used in healthcare
 * Experience with HL-7 and FHIR healthcare data standards
 * Experience with Mirth Connect
 * Experience with data modeling, data warehousing and building ETL pipelines
 * Experience with Google Cloud Healthcare API
 * Experience with dashboard development
 * Ability to work effectively independently and as a member of a diverse and cross-functional team of engineers, business system analysts, project managers, subject matter experts, management, and clinical stakeholders.
 * Attention to detail and quality
 * Experience working as a member of Agile Scrum project teams.
 * Ability to work collaboratively using Atlassian JIRA, Confluence, and SharePoint productivity tools.
 * Experience with big data in healthcare.
 * Excellent problem-solving skills with a track record of ensuring data quality and integrity across complex datasets
   
   

Certificates/Licenses/Clearances


 * Successful clearance of background and reference check.
   
   

PHYSICAL DEMANDS


 * Stand=Frequently
 * Walk=Frequently
 * Sit=Frequently
 * Handling / Fingering=Occasionally
 * Reach Outward=Occasionally
 * Reach Above Shoulder=Occasionally
 * Climb, Crawl, Kneel, Bend=Occasionally
 * Lift / Carry=Occasionally - Up to 25 lbs.
 * Push/Pull=Occasionally - Up to 25 lbs.
 * See=Constantly
 * Taste/ Smell=Not Applicable
   
   

Key


 * Not Applicable: Not required for essential functions
 * Occasionally: (0 - 2 hrs./day)
 * Frequently: (2 - 5 hrs./day)
 * Constantly: (5+ hrs./day)
   
   

WORK ENVIRONMENT

General Office Setting, Indoors Temperature Controlled.

APLICATION PROCEDURES

Interested candidates should submit a resume and cover letter for consideration.

It is the policy of Heluna Health to provide equal employment opportunities without regard to race, color, religion, sex, national origin, age, disability, marital status, veteran status, sexual orientation, genetic information, or any other protected characteristic under applicable law.",Full-time
4130462605,218487.0,Data Engineer,"Data Analytic Engineer




Full time Permanent

Remote




Unfortunately, we are unable to sponsor or work with our C2C Corp to Corp partners on this job opportunity.




All candidates must possess an active IRS MBI Clearance




 * Tableau and Engineering data tools: Splunk, CloudWatch, AppDyanamics, and Datadog
 * Supporting Data Scientist who will be leading and supporting the program in executing modeling of customer experience and engineering execution.
 * Build out Data Dashboards for various data scenarios related to customer consumption of the product (Direct File application), Perform data analytics of incoming data, automate data, manage KPI data, etc.
 * Active IRS MBI clearance

",Full-time
4151321464,11855072.0,Senior Data Engineer,"About Dune

Dune is on a mission to make crypto data accessible. We’re a collaborative multi-chain analytics platform used by thousands of developers, analysts, & investors to understand the on-chain world and the frontiers of finance. We’re a team of ~50 employees, working together across Europe and eastern US timezones 🌍️. We believe in our mission, and in building a powerful, open product that allows individuals and communities to do deep research into important ecosystems like Bitcoin, Ethereum, Solana, and many more.

We’re backed by some of the world's best investors. In February 2022, we announced our Series B funding round led by Coatue and Union Square Ventures, an important milestone that allowed us to double down on our mission. We’re using the funds to educate, reward and empower a new generation of onchain analysts aka Wizards 🧙‍♀️

If you want to have one of the highest impact jobs on the planet, come join our wonderful team of Galaxy brains.

Learn more about us:

The Dune Manifesto

Dune's Vision

Values and working at Dune

Meet the team

What We Are Building

Blockchain data, like many open data sources, requires extensive domain knowledge to wrangle it into useful formats before one can derive value from it. We are building a collaborative open-source ETL for blockchain data, Spellbook. In addition to this we also build several custom pipelines that drive some of the most popular and impactful datasets on Dune, such as labels, prices and balances.

Impact


 * Build data pipelines that powers some of the most popular data on Dune.
 * Support analysts to build new powerful datasets.
 * Assume ownership of data transformation pipelines that take community contributed SQL transformations as an input.
 * Orchestrate robust pipelines that are resilient to user error in a fast-paced contribution pipeline.
 * Understand and prioritize the needs of our diverse community from amateur data sleuths to professional data scientists and engineers.
   
   

Requirements


 * Proven experience with building robust data pipelines and using orchestration tools, for example with DBT and Prefect.
 * Proficiency and hands-on experience with data warehouses, with expertise in at least one of Trino, Snowflake or Clickhouse
 * Strong ability to independently analyze, debug, and fix data pipeline issues.
 * Deployment and infrastructure in public cloud platforms (e.g. Kubernetes).
 * Solid foundation in computer science fundamentals and system design.
 * Ability to work collaboratively in a remote setting, contributing to a positive and inclusive team culture.
 * Based in the US East Coast (EST) or Europe West (GMT or CEST).
   
   

Desired Qualifications


 * You have experience with database internals, data lakes, massive data storage and processing, and systems performance
 * Proficiency in programming languages such as Python and SQL.
 * You know your way around crypto and/or smart contracts.
 * Strong analytical and troubleshooting skills.
 * Experience working across multiple time zones.
   
   

Perks & Benefits


 * A competitive salary and equity package 🚀. Both salary and equity is top 25% of companies in the space
 * Our employee equity scheme has world-class employee-friendly terms with a heavily discounted strike price (~90%) and a 10-year exercise window
 * 5 weeks PTO + local public holidays (that can be swapped to suit you) 🏖
 * A fully remote-first approach 🧑‍💻 within a distributed team with flexible working hours; you structure your own day
 * Say goodbye to meeting overload! We believe in a healthy mix of async and sync work, so you can focus on what truly matters—no more wasted time on endless meetings!
 * Good health is important, so we offer private medical insurance, dental & vision as standard 🩺
 * We believe in paid parental leave 👶 to help you celebrate this important milestone, transition to your new life, and bond with your new baby. We offer 16 weeks to primary and 6 weeks to secondary caregivers, fully paid. Plus a 2-week part-time phased return at full pay to help you get used to your new (and slightly more complex!) schedule
 * Quarterly offsites in various exciting locations as a company or team to connect, work together and have fun (so far in Tuscany 🇮🇹 Berlin 🇩🇪 Austria 🇦🇹 and Athens 🇬🇷).
 * On top of this 👆each person gets a yearly travel allowance to connect and co-work with someone or a team of people for a few days.
 * An allowance for your at-home setup, to ensure you are happy, comfortable and productive. If you prefer a local co-working space, we’ll pay for your desk.
 * Work with some of the best people you’ll ever get to meet!
 * And of course, you get some awesome Dune swag! ✌️😎
   
   

We are dedicated to building a diverse, inclusive, and authentic workplace, so if you’re excited about this role but your experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles.

",Full-time
4120827285,10667.0,"Data Engineer, Product Analytics","As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a world-class data engineering community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Data Engineer, Product Analytics Responsibilities:


 * Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems
 * Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve
 * Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights visually in a meaningful way
 * Define and manage Service Level Agreements for all data sets in allocated areas of ownership
 * Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership
 * Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains
 * Solve our most challenging data integration problems, utilizing optimal Extract, Transform, Load (ETL) patterns, frameworks, query techniques, sourcing from structured and unstructured data sources
 * Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts
 * Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts
 * Influence product and cross-functional teams to identify data opportunities to drive impact
 * Mentor team members by giving/receiving actionable feedback
   
   

Minimum Qualifications:


 * Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent
 * 7+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions
 * 7+ years of experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala or others.)
   
   

Preferred Qualifications:


 * Master's or Ph.D degree in a STEM field
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$173,000/year to $242,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4149259819,11241935.0,Senior Software Engineer - Cloud Infrastructure,"Reliable and abundant energy is essential for human progress, and our team is dedicated to driving this future. We are a group of problem-solvers, engineers, and operators who thrive on tackling tough challenges and building innovative solutions.




Cloud services play a crucial role in driving our mission and overall success. Our systems manage a distributed network of energy solutions, oversee electricity services for homes across Texas, and streamline deployment operations through automation and advanced tooling. As a software engineer on this team, you’ll be responsible for designing and developing resilient software systems to oversee, monitor, and control our core infrastructure.




Responsibilities:

 * Design, build, and maintain scalable cloud services and infrastructure, primarily using Golang.
 * Contribute to code reviews, testing, and deployment workflows to ensure high-quality, dependable software and uphold a strong engineering culture.
 * Collaborate with teams across Base to diagnose issues and implement enhancements in our cloud infrastructure.
 * Develop tools, services, and processes that improve engineering team efficiency.
 * Design real-time trading architecture.
 * Build a platform for iterating and deploying trading algorithms.
 * Create tooling and monitoring solutions for fleet operations.
 * Integrate market data into cloud-based systems.




Required Skills & Qualifications:

 * A first-principles mindset when approaching software engineering challenges.
 * 5+ years of experience in designing, developing, and maintaining high-performance cloud services.
 * Strong grasp of the software development lifecycle, including version control, code reviews, testing, and quality assurance.
 * Expertise in SQL, relational databases, and time-series databases.
 * Hands-on experience scaling cloud services using modern cloud technologies.




Please note - due to the nature of projects this role supports, we cannot consider anyone who now, or in the future, will requires VISA sponsorship or transfer.",Full-time
4045416336,66321745.0,Junior/Entry Level Software Engineer - Remote,"Since 2010 and almost 14 years SynergisticIT has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients.

Post Covid the tech Layoffs have been massive—In 2022 there were 165,269 tech layoffs, In 2023 there were 264,220 tech layoffs and so far in 2024 there have been 126,382 tech layoffs. (Source Layoffs.fyi ) -Total layoffs as per this 555,871 tech layoffs.

Client, Dell and Cisco have announced 15,000/12,500 and 4000 tech layoffs respectively in August.

The Job market is Hyper Competitive. For 1 position 500-2000 candidates or more are applying and laid off job seekers are also competing for entry level Job positions.

Acquiring the right technology skillsets which are being demanded by clients and getting yourself in front of clients is the way to get to get Interviews and eventually a Job Offer. Survival of the Fittest is the only way to get a tech Job in this job market.

In this Layoffs fueled market also SynergisticIT's candidates are able to achieve multiple job offers and $100k &plus; salaries once they acquire the required skills.

please check the below links to see success outcomes, salaries of our candidates .

https://www.synergisticit.com/candidate-outcomes/

https://www.synergisticit.com/roi-of-computer-science-degree-colleges-vs-synergisticit/

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please visit the below videos exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, we are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Data Engineers, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

Required Skills

REQUIRED SKILLS For Java /Full stack/Devops Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Knowledge of Core Java , javascript , C&plus;&plus; or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

For data Science/Data Analyst/AI/Machine learning Positions

Required Skills

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude

Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Full-time
4149722974,9402.0,Data Engineer,"Job Summary

Job Description

Job Summary

We are looking for a full-stack Data Engineer who can design, develop, and maintain data pipelines and reporting solutions for our business needs. You will be responsible for creating and optimizing data models, extracting, transforming, and loading data from various sources, and delivering insights and reports using data visualization tools. You will also collaborate with other data engineers, analysts, and stakeholders to ensure data quality, reliability, and scalability.

Major Responsibilities

Development and Testing: Designs and implements ETL processes, including data capture, data quality, cleansing, testing, and validation methods. Develops standards, policies, and procedures for data integration-related activities.

Involved in reviewing BI enhancements during all project phases – requirements gathering, design, testing, implementation, and issue resolution.

Working closely with the team to ensure on-time delivery of quality solutions with minimal rework.

Responsible for driving continuous improvement within the team processes and deliverables.

Develops and documents use cases when necessary.

Assist with QA testing when necessary.

Requirements:


 * A bachelor's degree in computer science, engineering, mathematics, statistics, or a related field
 * At least 4 years of experience in business intelligence, data engineering or a similar role
 * Proficiency in SQL for data manipulation and analysis
 * Proficiency with data visualization tools such as Power BI, Tableau, Alteryx, etc.
 * Experience with data modeling techniques and tools such as ERD, UML, Star Schema, Snowflake Schema, etc.
 * Experience with ETL tools and frameworks such as Talend, SSIS, Informatica, Airflow, etc.
 * Bonus if you have experience with cloud platforms and services such as the Power Platform, Azure Data Factory, Azure Databricks, Azure Synapse Analytics, etc.
 * Bonus if you have experience with API consumption
 * Excellent communication and problem-solving skills
 * Ability to work independently and as part of a team
 * Ability to test and document end-to-end processes.
   
   

Medline Industries, LP, and its subsidiaries, offer a competitive total rewards package, continuing education & training, and tremendous potential with a growing worldwide organization.

The Anticipated Salary Range For This Position:

$110,240.00 - $165,360.00 Annual

The actual salary will vary based on applicant’s location, education, experience, skills, and abilities. This role is bonus and/or incentive eligible. Medline will not pay less than the applicable minimum wage or salary threshold.

Our benefit package includes health insurance, life and disability, 401(k) contributions, paid time off, etc., for employees working 30 or more hours per week on average. For a more comprehensive list of our benefits please click here. For roles where employees work less than 30 hours per week, benefits include 401(k) contributions as well as access to the Employee Assistance Program, Employee Resource Groups and the Employee Service Corp.

Every day, we’re focused on building a more diverse and inclusive company, one that recognizes, values and respects the differences we all bring to the workplace. From doing what’s right to delivering business results, together, we’re better. Explore our Diversity, Equity and Inclusion page here.

Medline Industries, LP is an equal opportunity employer. Medline evaluates qualified applicants without regard to race, color, religion, gender, national origin, age, sexual orientation, gender identity or expression, protected veteran status, disability/handicap status or any other legally protected characteristic.",Full-time
4045411716,66321745.0,Junior/Entry Level Data Engineer,"Since 2010 Synergisticit has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this Job market also, our candidates are able to achieve multiple job offers and $100k &plus; salaries.

please check the below links to see success outcomes, salaries of our candidates .

https://www.synergisticit.com/candidate-outcomes/

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please visit the below videos exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

Required Skills

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, Gen AI, LLM, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full Stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java , javascript , C&plus;&plus; or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Full-time
3992356957,91445367.0,Data Engineer III (Contingent),"*Position contingent upon contract award*


Aretum, a leading government contracting company specializing in technology-enabled mission support services, is looking for a skilled and motivated Data Engineer to join our team. As a Data Engineer at ARETUM, you will be responsible for developing, constructing, testing, and maintaining scalable and reliable data solutions for our clients.

Aretum is known for providing cutting-edge solutions and outstanding service to Federal clients in various sectors, including Next Generation Analytics, Engineering Services, Training Services, IT Systems, Cyber Security, PMO Support, and Financial Consulting. Our mission is to deliver technology-driven solutions that meet the unique needs of our government clients, enabling them to achieve their objectives effectively and efficiently.


Responsibilities


 * Design, build, and maintain scalable data pipelines and workflows
 * Implement data storage solutions that can handle large volumes of data efficiently
 * Develop and manage data integration processes and tools
 * Ensure data quality and integrity by implementing appropriate data cleaning and validation procedures
 * Collaborate with data scientists and analysts to support their data needs
 * Optimize data processes and query performance
 * Implement data security measures to protect sensitive information
 * Stay up-to-date with the latest data engineering trends, technologies, and best practices
   
   
   
   
   
   

Requirements


 * Active Secret Clearance
 * Bachelor's degree in Computer Science, Engineering, or a related field
 * 3+ years of experience as a Data Engineer or in a similar role
 * Proficiency in SQL and one or more programming languages (Python, Java, Scala, etc.)
 * Experience with data warehousing and database design
 * Strong knowledge of data modeling, data integration, and ETL processes
 * Experience with big data technologies such as Hadoop, Spark, or Kafka
 * Familiarity with cloud platforms such as AWS, Azure, or Google Cloud
 * Knowledge of data security concepts and best practices
 * Experience with version control systems (Git, SVN, etc.)
 * Excellent problem-solving and analytical skills
 * Strong communication and collaboration skills
   
   

Aretum is committed to fostering a workplace rooted in excellence, integrity, and equal opportunity for all. We adhere to merit-based hiring practices, ensuring that all employment decisions are made based on qualifications, skills, and ability to perform the job, without preference or consideration of factors unrelated to job performance.

As an Equal Opportunity Employer, Aretum complies with all applicable federal, state, and local employment laws.

We are proud to support our nation's veterans and military families, providing career opportunities that honor their service and experience.

If you require a reasonable accommodation during the hiring process due to a disability, please contact our Talent Acquisition team for assistance.",Full-time
4138872120,3765.0,Data Engineer/Developer,"GroupM is WPP’s media investment group and the world’s leading media investment company with a mission to shape the next era of media where advertising works better for people. The company is responsible for more than $60 billion in annual media investment, as measured by the independent research bureau COMvergence. Through its global agencies Mindshare, EssenceMediacom, and Wavemaker. GroupM’s portfolio includes Data & Technology, Investment and Services, all united in vision to shape the next era of media where advertising works better for people. GroupM leverages a unique combination of global scale, expertise, and innovation to generate sustained value for clients wherever they do business. Discover more at www.groupm.com.

Role Summary And Impact

GroupM's Data and Analytics team is proud to be a trusted data partner to PlayStation, a global leader in interactive entertainment. Embedded directly into PlayStation's internal Data & Analytics team, we empower their marketing and advertising initiatives by managing a complex global database, ensuring data quality, and developing bespoke tools. Our expertise in data quality management, tool development, and API integration ensures the accuracy and accessibility of critical information. This data-driven approach fuels PlayStation's strategic decision-making and marketing success!

We are hiring for a Data Engineer/Developer maintain bespoke tooling built to improve the efficiency with which we collect data from planning and activation teams (manual data entry) as well provide support to any custom campaign optimization tools we have developed. Embedded into the account team so you can be closer to your end users to improve requirement gather and working across both PlayStations and GroupM’s tech stack.

Responsibilities


 * Design, develop, and maintain a bespoke media planning tool for PlayStation, incorporating bug fixes, new features, and automation to streamline workflows for planning and activation teams. Focus on robust data pipelines and efficient data processing.
 * Develop and implement data integration processes to incorporate sales and audience data into media plans for benchmarking and performance forecasting.
 * Build and maintain data feeds for PlayStation's BI team to power dashboards and reporting. Ensure data quality and reliability.
 * Provide technical guidance and support to planning and activation teams on utilizing the planning tool and interpreting data insights.
 * Collaborate with stakeholders to ensure the Total Performance Doctrine (TPD) measurement framework is effectively integrated into all data processes and tooling.
 * Contribute to the development of data-driven solutions leveraging PlayStation's first-party data (sales, subscriptions, and customer demographics) for optimizing paid media campaigns.
   
   

Qualifications


 * Bachelor's or Master's degree in Computer Science, Software Engineering, or a related field. A degree in Statistical Modelling or Mathematics with relevant software development experience will also be considered.
 * Proven hands-on experience in data engineering, including proficiency with SQL, Python (Pandas and Flask), Google Cloud Platform (GCP), Snowflake, and DBT. Experience with data warehousing and ETL/ELT processes.
 * Strong understanding of data modeling, data structures, and algorithm design.
 * Experience with software development best practices, including version control (e.g., Git) and testing.
 * Excellent communication and collaboration skills, with the ability to explain technical concepts to non-technical audiences.
 * Knowledge of digital marketing, including CRM programs (a plus).
 * Understanding of data governance and compliance principles (a plus).
   
   

Life at GroupM

Our passion for shaping the next era of media includes investing in our employees to help them do their best work, and we’re just as committed to employee growth as we are to responsible media investment. GroupM employees can tap into the global GroupM & WPP networks to pursue their passions, grow their networks, and learn at the cutting edge of marketing and advertising. We have a variety of employee resource groups and host frequent in-office events showcasing team wins, sharing thought leadership, and celebrating holidays and milestone events. Our benefits include competitive medical, vision, and dental insurance, significant paid time off, preferential partner discounts, and employee mental health awareness days.  

GroupM is WPP’s media investment group and the world’s leading media investment company with a mission to shape the next era of media where advertising works better for people. The company is responsible for more than $60 billion in annual media investment, as measured by the independent research bureau COMvergence. Through its global agencies Mindshare, Wavemaker, EssenceMediacom, and T&Pm, and cross-channel performance (GroupM Nexus), data (Choreograph), entertainment (GroupM Motion Entertainment) and investment solutions, GroupM leverages a unique combination of global scale, expertise, and innovation to generate sustained value for clients wherever they do business. Discover more at www.groupm.com.

GroupM provides equal employment opportunities to applicants and employees without regard to race; color; sex; gender identity; sexual orientation; religious practices and observances; national origin; pregnancy, childbirth, or related medical conditions; status as a protected veteran or spouse/family member of a protected veteran; or disability.

GroupM is committed to providing reasonable accommodation to, among others, individuals with disabilities and disabled veterans. If you need an accommodation because of a disability to search and apply for a career opportunity with GroupM, please send an e-mail to GroupM Leave Administration at Leave.Administration@groupm.com or call (212) 297-8507 and let us know the nature of your request and your contact information.

The base salary for this position at the time of this posting may range from $75,000 to $180,000. Individual compensation varies based on job-related factors, including business needs, experience, level of responsibility and qualifications. We offer a competitive benefits package, please visit https://www.wpp.com/people/wellbeing/benefits-at-wpp-in-the-us for more details.

Reference ID: o8GEufwG-CytDWfwk",Full-time
4045409561,66321745.0,Data Science Engineer (Entry Level),"SynergisticIT is a full service staffing and placement firm servicing client in America from past 12&plus; years. We are dedicated towards fulfilling the IT needs of our clients. From staffing to full implementation of projects we provide the highest quality IT Services. We provide Java and Data Science Training to candidates, who we think would fit a job requirement with one of our clients.

Who Should Apply

Candidates who have difficulty finding jobs even after completing their bachelors and masters.

Candidates who are working on redundant technologies and want to become relevant again to boost their growth.

Candidates who want to enhance their skill portfolio.

Candidate who are open to invest 4-5 months in learning about Java or Data Science and then have a job in the Fortune 500 Companies.

After training you will get an opportunity to work with companies like Apple, Google, Wells Fargo, Client, PayPal, eBay etc.*

Required Qualifications


 * Bachelors or Masters in Computer Science/MIS/IT/Mathematics/Statistics etc.
   
   

Skills Required


 * Basic knowledge of C, C&plus;&plus;,Core Java,Python etc.
   
   

Benefit's Of Working With Our Clients


 * E-Verified.
 * Filing of H1b and Green Card.
 * On Job Technical Support.
   
   

Interested candidates please send a word or PDF copy of your resume at Email Id: rahul@synergisticit.com or call at (510)347-8191 (Rahul)

If you do respond via e-mail please include a daytime phone number so I can reach you. In considering candidates, time is of the essence, so please respond ASAP. Thank you",Full-time
4106314510,76439524.0,Data Engineer,"At MedScout, our mission is to empower MedTech commercial teams with the data, insights, and tools they need to deliver life-changing medical innovations to the patients who need them most. We’re creating a best-in-class revenue acceleration platform that unites the latest medical claims intelligence with an intuitive user experience built specifically for sales professionals at medical device and diagnostic companies.

We just closed a $15M Series A and we’re ready to bring on new team members to join our Engineering team. As a Data Engineer, you'll help us build and optimize the data infrastructure that processes billions of healthcare claims, turning complex data into actionable insights that drive business decisions. You'll work alongside our talented engineering team to evolve and scale our data architecture, using modern technologies like Databricks and Elasticsearch, while having significant opportunities to grow technically and drive business impact.

How will you help us build this company?


 * You will design, implement, and maintain scalable data pipelines to process large volumes of healthcare claims data using Databricks, Python, and PySpark. You’ll be ensuring high data quality and performance optimization for downstream analytics.
 * You will develop processes to integrate multiple data sources, including healthcare claims databases, into a unified data model that powers MedScout's sales enablement platform.
 * You will work with Product, Customer Success, and Sales leaders to understand what our customers are looking to achieve with our platform and use those insights to inform and validate your thinking as you make design and implementation decisions.
 * You will collaborate with data scientists and analysts to implement data transformations that support efficiently delivering advanced analytics, market insights, and predictive modeling capabilities for the platform.
 * You will troubleshoot and resolve complex data pipeline issues, optimize system performance, and contribute to the continuous improvement of MedScript's data infrastructure and engineering practices.
 * You will optimize workloads and cluster configurations to reduce compute costs while maintaining performance, including implementing auto-scaling policies, right-sizing clusters, and monitoring resource utilization patterns.
   
   

What does an ideal background look like?


 * You have 3+ years of experience building, maintaining, and operating data pipelines in a modern data warehouse like Databricks, Snowflake, or AWS Redshift.
 * You feel confident using Python and PySpark.
 * You have a good understanding of data modeling and schema design, particularly in contexts involving complex relationships and high-volume data processing.
 * You’re an expert with data quality frameworks, including automated testing, validation, and monitoring of data pipelines.
 * You have familiarity with modern software development practices including version control (Git), CI/CD, and infrastructure as code.
 * You are able to work effectively with cross-functional teams, translating business requirements into technical specifications and communicating complex technical concepts to non-technical stakeholders.
   
   

Are we a fit for each other?

At our stage, we believe how you operate is more important than what you’ll do day-to-day. As an early team member, we’re looking for individuals with strong alignment with the following core values.


 * Effort on our inputs: We prepare diligently, leave it all on the ""field"", and move on quickly. Focusing on good habits and work ethic, not individual outcomes, ultimately creates a winning culture and a successful company.
 * Earn Trust: We keep our commitments to our customers, partners, and each other. We listen attentively, speak candidly, and treat others respectfully. We strive to demonstrate empathy, inclusion, and intellectual honesty.
 * Intelligence Drives Operations: We learn continuously and have the humility to quickly recognize when our assumptions are wrong so we can readjust accordingly.
 * Hire And Develop The Best: Good players like playing on good teams. We look to raise the bar with every hire and promotion. We work hard to identify and develop high potential.
 * Take Decisive Action: The only sure path to continuous improvement is a hypothesis-driven approach with a bias for speed of experimentation.
   
   

What is the interview process?


 * Introductory call with the VP of Engineering.
 * Technical Review with members of the data team.
 * A walk through of a product scenario with our Head of Product and Data Lead.
 * Culture Interviews with both the engineering team and other cross functional team members.
   
   

What can you expect from us?


 * 100% covered healthcare and a great vision, dental, and 50% dependent
 * A generous benefits package investing in our employees both in and out of the office
 * You will feel heard. You will hear, ""Yes, let's do that!"" and then have the opportunity to execute your ideas successfully.
 * Remote first culture and frequent on-sites with the rest of the MedScout Team.
 * Generous budget for learning and development + any tools you feel would make you more effective.
   
   

MedScout embraces diversity and equal opportunity in a serious way. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. We believe the more inclusive we are, the better our work will be.

We will ensure that individuals with disabilities are provided reasonable accommodation who need it. We want you to be able to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. If you require any accommodation please let us know!",Full-time
4127689239,3831.0,Data Engineer,"About Northern Trust

Northern Trust, a Fortune 500 company, is a globally recognized, award-winning financial institution that has been in continuous operation since 1889.

Northern Trust is proud to provide innovative financial services and guidance to the world’s most successful individuals, families, and institutions by remaining true to our enduring principles of service, expertise, and integrity. With more than 130 years of financial experience and over 22,000 partners, we serve the world’s most sophisticated clients using leading technology and exceptional service.

Northern Trust is currently looking for a Data Engineer to join our growing Data Delivery team in the Portfolio Accounting domain. This is a critical role leveraging cloud-based tools and provide thought leadership in enhancing existing data solutions.

The successful candidate will be customer-focused and passionate about leveraging modern data architecture and technology to create significant business impact across organizational boundaries. This engineer will bring experience with SaaS/cloud solutions (Snowflake/Azure), data engineering techniques, DevSecOps automation, and best practices for building, maintaining, and enhancing state-of-the-art big data platforms.

Responsibilities


 * Define and deliver a large enterprise-scale big data ecosystem; evaluate existing data architecture and work with the team members to continuously enhance and evolve the data technology stack.
 * Perform hands-on tasks of implementing data ingestion and transformation pipelines using Snowflake SQL and procedures.
 * Ensure that all Non-Functional Requirements (e.g., security, performance, availability and DR/fail-over, scalability, compliance etc.) are properly articulated, designed, implemented, and well documented.
 * Evaluate, prototype and recommend emerging Cloud data technologies and platforms from open source or vendors. Independently conduct POC projects.
 * Communicate complex technical topics to non-technical business personnel and assist with scoping and architecting cloud data solutions.
 * Partner with Data Governance team to ensure the completion and accuracy in metadata collections using Collibra.
 * Promote data mesh technology to broad user groups in both technology and business organizations.
   
   

Required


 * At least 8 years of experience developing data and services in an enterprise and/or cloud environment.
 * Deep understanding of data warehouse, data lake architecture and data management processes.
 * Strong proficiency in developing and optimizing SQL modules.
 * Hands-on expertise of multiple modern cloud storages and services such as Snowflake, Azure.
 * Hands-on experience of DevOps and automation tooling such as Terraform, and Github.
 * Working experience using ETL/analytics tools such as DataBricks, or ADF, etc.
 * Skilled in variety of languages or framework, such as Java or Python.
 * Familiarity with Data Governance practices and tooling such as Collibra.
 * Strong organization and communication skills.
 * Bachelor's degree in Computer Science or related discipline.
   
   

Preferred Specific Skills


 * Knowledge of data analytics technology and methodology, such as advanced analytics or machine learning.
 * Experience with DevOps, DataOps and/or MLOps using ADO.
 * Working knowledge of data security such as SecuPi.
 * Working experience with Azure and AWS cloud data and service offerings.
 * Experience in writing scripts for Linux shell and Windows PowerShell.
   
   

Salary Range

$99,600 - 169,200 USD

Salary range is a good faith estimate of base pay. Northern Trust provides a comprehensive benefits package including retirement benefits (401k and pension), health and welfare benefits (medical, dental, vision, spending accounts and disability), paid time off, parental and caregiver leave, life & accident insurance, and other voluntary and well-being benefits. Northern Trust also provides a discretionary bonus program that may include an equity component.

Working With Us

As a Northern Trust partner, greater achievements await. You will be part of a flexible and collaborative work culture in an organization where financial strength and stability is an asset that emboldens us to explore new ideas.

Movement within the organization is encouraged, senior leaders are accessible, and you can take pride in working for a company committed to assisting the communities we serve! Join a workplace with a greater purpose.

We’d love to learn more about how your interests and experience could be a fit with one of the world’s most admired and sustainable companies! Build your career with us and apply today. #MadeForGreater

Reasonable accommodation

Northern Trust is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation for any part of the employment process, please email our HR Service Center at MyHRHelp@ntrs.com.

We hope you’re excited about the role and the opportunity to work with us. We value an inclusive workplace and understand flexibility means different things to different people.

Apply today and talk to us about your flexible working requirements and together we can achieve greater.",Full-time
4106067409,3762.0,Data Engineer (multiple openings) - IHM,"Discover. A brighter future.

With us, you’ll do meaningful work from Day 1. Our collaborative culture is built on three core behaviors: We Play to Win, We Get Better Every Day & We Succeed Together. And we mean it — we want you to grow and make a difference at one of the world's leading digital banking and payments companies. We value what makes you unique so that you have an opportunity to shine.

Come build your future, while being the reason millions of people find a brighter financial future with Discover.

Job Description

Employer: DFS Corporate Services LLC

Job Title: Data Engineer (multiple openings)

Job Location: Riverwoods, IL

Job Type: Full Time

Duties: Develops and troubleshoots data integration solutions with complex data transformations and provides guidance to other team members. Influences other team members to achieve commitments per guidance from Chapter Leads and actively contributes to agile ceremonies. Telecommuting and/or working from home may be permissible pursuant to company policies.

Requirements: Employer will accept a Bachelor's degree in Computer Science, Software Engineering, Information Systems Engineering, Information Technology, or related field and 3 years of experience in the job offered or in a Data Engineer-related occupation.

Position required skills: Position requires 3 years of experience in the following: Agile Software development methodologies utilizing Ab initio, Github, Jenkins, AWS, Big Data platform, Python, Oracle, Teradata, or Spark; Jira; Design and development of ETL data integration solutions in data warehouse environment; Relational databases and Cloud-based technologies; Design and architecture experience on large-scale ETL solutions; and Work with Enterprise Data warehouse data models and dimensional modeling concepts, source to target mapping and Data Integration architecture.

Position eligible for incentives under Employee Referral Program

Rate of Pay: The base pay for this position generally ranges between $96,741 to $146,100. Additional incentives may be provided as part of a market competitive total compensation package. Factors, such as but not limited to, geographical location, relevant experience, education, and skill level may impact the pay for this position. We also offer a range of benefits and programs based on eligibility. Learn more at MyDiscoverBenefits.com.

QUALIFIED APPLICANTS: Please apply directly through our website by clicking on “Apply Now.”

Application Deadline

The application window for this position is anticipated to close on Feb-17-2025. We encourage you to apply as soon as possible. The posting may be available past this date, but it is not guaranteed.

Benefits

We also offer a range of benefits and programs based on eligibility. These benefits include:


 * Paid Parental Leave
 * Paid Time Off
 * 401(k) Plan
 * Medical, Dental, Vision, & Health Savings Account
 * STD, Life, LTD and AD&D
 * Recognition Program
 * Education Assistance
 * Commuter Benefits
 * Family Support Programs
 * Employee Stock Purchase Plan
   
   

Learn more at mydiscoverbenefits.com.

What are you waiting for? Apply today!

All Discover employees place our customers at the very center of our work. To deliver on our promises to our customers, each of us contribute every day to a culture that values compliance and risk management.

Discover is committed to a diverse and inclusive workplace. Discover is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or other legally protected status. (Know Your Rights & Pay Transparency Nondiscrimination Provision)

Discover complies with federal, state, and local laws applicable to qualified individuals with disabilities and is committed to providing reasonable accommodations. If you require a reasonable accommodation to search for a position, to complete an application, and/or to participate in an interview, please email HireAccommodation@discover.com. Any information you provide regarding your accommodation needs will be kept confidential and will only be used to determine and provide necessary accommodation.",Full-time
4090656526,102017555.0,AWS/Python Data Engineer," * Title: AWS/Python Data Engineer
 * Work Location: Onsite in Malvern, PA (Every Tuesday, Wednesday, and Thursday)
 * Interview Process: Onsite interviews
   
   

Preferred Candidates

Strong preference for candidates with current or previous experience as contractors at Vanguard.

Technical Requirements


 * ETL Experience: Hands-on expertise with AWS EMR and Glue is mandatory.
 * Technical Skills: Proficiency in the following:
    * SQL, PySpark, Python
    * Jupyter Notebooks, GitHub Functions, CI/CD Pipelines

 * AWS Cloud Services Knowledge:
    * EMR, Glue, S3, EC2, Service Catalog
    * PostgreSQL, Lambda, CloudFormation, SNS, EventBridge
      

Additional Tools (Preferred)

Experience with any of the following is a plus:


 * Attunity, Athena, Redshift, Step Functions
 * SageMaker, Control-M, Collibra, Splunk
 * Iceberg, Tableau, Lake Formation, Docker, ECS",Full-time
4149299895,1353.0,Data Engineer,"We are looking for an individual who would be responsible for the following:


 * Work hand in hand across teams with data owners to gather, interpret, and visualize data to answer specific questions
 * Build efficient SQL queries and dynamic reports in Tableau and Splunk
 * Drive discussions with various domain experts to define proper analysis methodologies
   
   

Must-Have Skills


 * BS or MS in Data Science, Computer Science, or 3+ years Data Science experience
 * Experience in building data visualization in Tableau. Splunk experience is a plus.
 * Experience using SQL. SQL with Cloudera Impala is a plus
 * Strong ability to independently identify nuances and drive clarity in requirements starting with high level questions
 * Excellent written and verbal communication skills and experience presenting data to cross-functional teams and/or management
 * Strong attention to detail and ability to deep dive technically
   
   

Salary Range : $63,400-$137,000 a year

",Full-time
4140322130,77547.0,Data Engineer - Cleveland/Columbus,"THIS IS NOT A REMOTE POSITION - WE WILL ONLY ACCEPT APPLICATIONS FROM THE SURROUNDING CLEVELAND AND COLUMBUS AREAS.

The Data Engineer will work in conjunction with key stakeholders to gather, analyze and compile data to utilize in strategic business planning to achieve company objectives.

Data Engineer Schedule


 * Monday through Friday. 8am-5pm reporting to our location in Cleveland, Ohio or Columbus, Ohio
   
   

Data Engineer Benefits Include


 * Paid training and career development
 * Company supplied technical equipment
 * Workout facility
 * Vacation time, personal days, and paid holidays
 * Company events
 * Safe work environment
 * Medical, Dental, Vision
 * HSA
 * Prescription drug coverage
 * 401(k)
 * Additional benefits
   
   

Data Engineer Job Functions


 * Gather data inputs from multiple sources and develop workflows for processing data
 * Build deep understanding of data structures and our technology stack (Tableau, Alteryx, database and cloud-storage, embedding)
 * Build custom data sources using your data wrangling skills
 * Develop dashboards, reporting tools and workflows to meet product development business objectives
 * Partner with stakeholders to create a shared vision on how to solve client challenges
 * Validate and test your work to ensure accuracy and quality of data
 * Provide support and training to stakeholders on reporting tools and reports
 * Collaborate with our team of creative and passionate professionals
   
   

What You Need For The Data Engineer Role


 * Bachelors degree or equivalent work experience
 * 3+ years of data analytics and/or BI and Analytics experience
 * Love for statistical modeling and machine learning algorithms, including but not limited to regression, simulation, scenario analysis, clustering, decision trees, neural networks
 * Demonstrated understanding of SQL, relational database structures, and cloud-based data platforms
 * Practical knowledge of industry standard BI tools such as Tableau (preferred), Power BI, Looker, Qlik, etc.; as well as ETL tools such as Alteryx (preferred), SSIS, Informatica, etc.
 * Experience with cloud platforms and their components (AWS and Azure, including their data transformation and ETL functionality)
 * ETL / Data Integration Experience, Web-Scraping
 * Real world experience with current object-oriented programming languages such as Python, R, Ruby, Java, Scala, etc.
 * Web development experience with JavaScript, HTML, CSS, React.JS, Django, Node.JS
 * An intuitive ability to use data to tell compelling stories supported by creative and engaging visualizations
 * Attention to detail, speedy cadence, people skills that motivate and a habit of improvement",Full-time
4137033613,2010798.0,Data Engineer - AWS,"Tiger Analytics is a fast-growing advanced analytics consulting firm. Our consultants bring deep expertise in Data Science, Machine Learning and AI. We are the trusted analytics partner for multiple Fortune 500 companies, enabling them to generate business value from data. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner. We are looking for top-notch talent as we continue to build the best global analytics consulting team in the world.

We are seeking a skilled Data Engineer to join our team. The ideal candidate will have a strong background in data engineering, cloud-based solutions, and a proven track record of building and managing scalable data pipelines on AWS. The Data Engineer will work closely with cross-functional teams to develop, maintain, and optimize data solutions that support critical business insights. We are looking for someone who can bring their vision to the table and implement positive change in taking the company's data analytics to the next level.

Requirements


 * 3-5 years of experience in data engineering with a focus on AWS cloud solutions
 * 3+ years of experience in Designing, developing, and maintaining scalable and secure ETL/ELT pipelines using AWS services
 * Creating and optimizing complex data processing and data transformation pipelines using python
 * Hands-on experience with AWS services like Glue, Lambda, S3, Redshift, and Athena
 * Strong knowledge of SQL for querying and managing relational databases
 * Experience with big data tools such as Apache Spark, Hadoop, or EMR
 * Implement best practices for cloud-based data architecture and pipeline management
 * Understanding of data modeling concepts and best practices
 * Familiarity with CI/CD pipelines and version control tools like Git
 * AWS certifications (e.g., AWS Certified Data Analytics, AWS Certified Solutions Architect)
   
   
   

Benefits

This position offers an excellent opportunity for significant career development in a fast-growing and challenging entrepreneurial environment with a high degree of individual responsibility.",Full-time
4053077877,2833966.0,AWS Data Engineer,"Must Have Skills

Spark, AWS, data lake, data pipelining

python

Job Description

As an AWS Data Engineer, you will play a crucial role in designing, developing, and maintaining our data infrastructure. You will be responsible for onboarding data sources into our data lake, building robust data pipelines, and ensuring data quality and governance. Your expertise in AWS services and data engineering best practices will be essential in driving our data initiatives forward.

Key Responsibilities


 * Data Onboarding: Onboard various data sources into the data lake, ensuring seamless integration and data consistency.
 * Data Pipeline Development: Design, develop, and maintain scalable and efficient data pipelines using AWS services such as Lambda, Step Functions, and EMR.
 * Data Registration: Register data sources and manage metadata to ensure data discoverability and accessibility.
 * Data Quality Management: Implement data quality checks and transformations to ensure the accuracy and reliability of data.
 * Data Governance: Comply with data governance principles and best practices to ensure data security, privacy, and compliance.
 * Infrastructure as Code: Utilize Terraform scripting to manage and automate AWS infrastructure.
 * Data Processing: Leverage Spark and other big data technologies to process and analyze large datasets.
 * Orchestration: Use Airflow and Step Functions to orchestrate complex data workflows.
 * Data Modeling: Work with Snowflake, Iceberg table formats, and other data modeling tools to design and optimize data storage solutions.
 * Collaboration: Collaborate with data scientists, analysts, and other stakeholders to understand data requirements and deliver high-quality data solutions.
   
   

Required Skills And Qualifications


 * AWS Services: Proficiency in AWS Lake Formation, Step Functions, Lambda (serverless), EC2, EMR, and EKS.
 * Scripting and Programming: Strong experience with Python and Terraform scripting.
 * Data Tools: Experience with Jupyter Notebook, RDS, Snowflake, and Iceberg table formats.
 * Big Data Technologies: Expertise in Spark and data pipeline orchestration tools like Airflow and dbt.
 * Data Engineering: Solid understanding of data engineering principles, including ETL processes, data warehousing, and data modeling.
 * Data Governance: Knowledge of data governance principles and best practices.
 * Problem-Solving: Strong analytical and problem-solving skills with the ability to troubleshoot and resolve data-related issues.
 * Communication: Excellent communication skills with the ability to collaborate effectively with cross-functional teams.
   
   

Preferred Qualifications


 * Certifications: AWS Certified Data Engineer or Analytics – Specialty, AWS Certified Solutions Architect, or other relevant certifications.
 * Experience: Previous experience in a similar role within a fast-paced, data-driven environment",Contract
4146308710,1373602.0,Senior Frontend Software Engineer - Checkout (100% remote),"Hopper Technology Solutions (HTS) Checkout combines market-leading payment services, best-in-class fraud detection, and digital wallet capabilities to enhance the travel experience for users and drive revenue for partners. Our hosted checkout solution offers global coverage and currency support, a comprehensive suite of payment methods, industry-leading anti-fraud technology, and an integrated wallet designed to boost loyalty.

We are seeking a frontend software engineer with expertise in building high-quality web applications from the ground up. As part of a cross-functional team of exceptional engineers and product managers, you will develop new features and provide best-in-class support to help our partners scale their businesses.

Tech Stack

Our frontend will be web apps using React + TypeScript, and you will play a large part in evolving this

Our backend systems are written in Scala, and we use a suite of GCP services

What Would Your Day-to-day Look Like


 * Design, build and review code for our HTS Checkout web frontend
 * Operate autonomously but work closely with your fellow engineers as well as PM to ensure high alignment
 * Explore engineering improvements for the team and the product
 * Collaborate cross-functionally with the product team and other Hopper teams
 * Our group operates with very few meetings and emphasizes strong alignment and asynchronous decision making
   
   

An ideal candidate has


 * Senior-level experience & familiarity with React
 * The ability to effectively drive towards a solution in a thoughtful and creative manner
 * The ability to work autonomously, iterate on solutions, and manage different contexts
 * Dealt with ambiguity and can balance building out multiple features at once without jeopardizing the quality of the code
   
   

Perks And Benefits Of Working With Us


 * Well-funded and proven startup with large ambitions, competitive salary and upsides of pre-IPO equity packages
 * Unlimited PTO
 * Please ask us about our very generous parental leave, much above industry standards!
 * Carrot Cash travel stipend
 * Flexdesk Access Pass & Work-from-home stipend
 * Entrepreneurial culture where pushing limits and taking risks is everyday business
 * Open communication with management and company leadership.
 * Small, dynamic teams = massive impact
 * 100% coverage of employee premiums for EOR-provided health, dental, life, and short-term disability insurance
 * Monthly meal vouchers
   
   

About Hopper - Careers Page

At Hopper, we are on a mission to build the world’s best travel products – combining a world-class travel agency with proprietary fintech ancillaries to help users travel better and our partners earn more. We are a global travel platform that powers the Hopper app, Hopper.com, and our B2B business, HTS (Hopper Technology Solutions).

By leveraging massive amounts of data and advanced machine learning algorithms, Hopper developed a proprietary portfolio of fintech ancillaries that offer peace of mind when booking travel and address common customer pain points, including price volatility, trip flexibility, and avoiding trip disruptions.

The Hopper platform serves hundreds of millions of travelers globally and continues to capture market share around the world. Ranked the third largest online travel agency in North America and named the #1 Most Innovative Travel Company in 2024 by Fast Company, the Hopper app has been downloaded over 120 million times and has become largely popular among younger travelers – with 70% of its users being Gen Z and millennials.

In recent years, Hopper has evolved into a global travel agency and e-commerce and travel fintech provider that powers some of the world’s largest brands and financial institutions. Through HTS, our B2B division, the company supercharges its partners’ direct channels by integrating our fintech products on their sites or powering end-to-end travel portals.

Today, our partners include leading travel brands like Capital One, Nubank, AirAsia MOVE, Air Canada, and many more. HTS operates sales channels that range from Hopper, the premier app for Gen Z in North America, to a worldwide network of travel rewards portals for credit card holders and mobile marketplaces for leading brands like Tripadvisor.

Here are just a few stats that demonstrate the company’s recent growth:


 * Hopper sells billions worth of travel and travel fintech every year across the Hopper app, Hopper.com and its global HTS partners.
 * The app has over 120 million downloads, and 70% of our users are Gen-Z and Millennials travelers.
 * Our fintech products – including Cancel for Any Reason, Disruption Assistance for Any Reason and Price Freeze – have exceptionally strong CSAT because the terms are always clear, and customers receive instant, no-questions-asked resolutions.
 * Almost 30% of our app customers purchase at least one fintech product when making a booking. Of Hopper app customers who purchase fintech, they purchase 1.7 fintech products on average per order.
 * Given the success of its fintech products, Hopper launched in B2B business, HTS (Hopper Technology Solutions), which today represents more than 75% of the business.
 * Through HTS, any travel provider (airlines, hotels, banks, travel agencies, etc.) can integrate and seamlessly distribute Hopper’s fintech or travel inventory on their direct channels.
   
   

As its first HTS partnership, the company partnered with Capital One to co-develop Capital One Travel, a new travel portal designed specifically for cardholders. - Other HTS partners include Air Canada, AirAsia MOVE, CommBank, Nubank, Tripadvisor and many more – with several new partnerships to be announced this year.

Hopper has raised over $750 million USD of private capital and is backed by some of the largest institutional investors and banks in the world.

Come take off with us!",Full-time
4068205917,69338417.0,Data Engineer,"Company Overview And Culture

EXL (NASDAQ: EXLS) is a leading data analytics and digital operations and solutions company. We partner with clients using a data and AI-led approach to reinvent business models, drive better business outcomes and unlock growth with speed. EXL harnesses the power of data, analytics, AI, and deep industry knowledge to transform operations for the world's leading corporations in industries including insurance, healthcare, banking and financial services, media and retail, among others. EXL was founded in 1999 with the core values of innovation, collaboration, excellence, integrity and respect. We are headquartered in New York and have more than 55,000 employees spanning six continents. For more information, visit http://www.exlservice.com.

EXL is hiring a Data Engineer for its Data and Analytics business. This position is based out of our Hartford, CT office.

Required Skills

Knowledge in building data pipelines using SQL, Hive and Python.

Desired Skills

Logical thinking, problem-solving, knowledge in statistical theories and analysis.

Job Description


 * Coordinate with data scientists, product managers and business leaders to understand data needs and deliver on those needs
 * Define technical roadmap and drive key technology decisions with senior technology stakeholders
 * Build the infrastructure for optimal extraction, transformation and loading data from a wide variety of data sources using big data technologies
 * Work on pipeline creation, data ingestion, storage, wrangling, cataloguing, quality, security features
 * Automate jobs (ingestion & pipelines), notifications and reports
 * Prioritize to manage ad-hoc requests in parallel with ongoing sprints
   
   

What We Offer


 * EXL Health offers an exciting, fast-paced and innovative environment, which brings together a group of sharp and entrepreneurial professionals who are eager to influence business decisions. From your very first day, you get an opportunity to work closely with highly experienced, world-class Healthcare consultants.
 * You can expect to learn many aspects of businesses that our clients engage in. You will also learn effective teamwork and time-management skills - key aspects for personal and professional growth
 * We provide guidance/coaching to every employee through our mentoring program wherein every junior level employee is assigned a senior level professional as advisors.
 * The sky is the limit for our team members. The unique experiences gathered at EXL Health sets the stage for further growth and development in our company and beyond.",Full-time
4133521108,76312.0,Data Engineer,"Brief Description

DATA ENGINEER

Position Summary

The data analytics team’s objective is to provide an efficient, reliable, and seamless user experience across the organization’s systems and platforms that enables functional groups to make informed, data-driven decisions. The team collaborates with the information technology and process improvement teams to scope system and stakeholder requirements, propose solutions, and ensures the deliverables meet the business need.

We are seeking a Data Engineer to design, build, and maintain our Enterprise Data Warehouse and data pipelines within Microsoft Fabric. This role is instrumental in developing robust ETL/ELT pipelines, collaborating with stakeholders across the business, and ensuring our data infrastructure supports reliable, high-quality analytics. The ideal candidate will have expertise in Power BI, advanced DAX, T-SQL, and Python, along with a strong understanding of data modeling best practices.

About Us

Founded in 1918, Okland Construction operates as a regional general contracting and construction management company with now nearly 1,000 employees and growing. It supervises the architectural, engineering, bidding, contracting, building, inspection from the beginning to the end of the project and specializes in concrete self-preform on large commercial scale.

LOCATION

Salt Lake City, UT

WHY OKLAND?


 * A people focused culture united by our shared values
 * Progressive leadership
 * Growth, training, and development opportunities
 * Competitive salary rates
 * Generous PTO
 * Health, Life, & Disability Insurance
 * 401k with company match
 * Employee Recognition and rewards
 * Company bonus eligibility
 * A commitment to delivering the most remarkable experience for all stakeholders
   
   

Essential Duties And Responsibilities


 * Design, implement, and maintain an Enterprise Data Warehouse to support company-wide analytics and reporting needs.
 * Develop scalable ETL/ELT pipelines in Microsoft Fabric, leveraging Stored Procedures, Notebooks, and Dataflows for efficient data processing.
 * Engage with stakeholders at all levels of the business to gather requirements and translate them into scalable data solutions.
 * Collaborate with Power BI Developers to ensure that the data model aligns with reporting and visualization requirements.
 * Troubleshoot and resolve data discrepancies at all stages of the data lifecycle, ensuring data accuracy and integrity.
 * Mentor and provide technical guidance to junior Data Engineers and Report Developers to foster team growth.
 * Define and implement data engineering best practices, ensuring repeatable, scalable, and maintainable processes.
   
   

Required Technical Expertise And Skills


 * Extensive hands-on experience with Power BI and Microsoft Fabric, including Fabric Lakehouses, Warehouses, Notebooks, Dataflows, and Pipelines.
 * Strong proficiency in T-SQL and Python for data transformation and automation.
 * Expertise in Power BI development, including advanced DAX functions, Power Query (M), and performance tuning techniques.
 * Ability to troubleshoot and optimize Power BI reports, ensuring efficiency and accuracy in analytics.
 * Excellent communication skills, both written and verbal, to collaborate with stakeholders, provide project updates, and explain technical details in a business-friendly manner.
 * Experience following SDLC best practices for developing, testing, and deploying data solutions.
 * Strong attention to detail with a focus on data quality and governance.
   
   

Preferred Qualifications


 * Experience with Microsoft Azure technologies such as Azure Data Factory, Synapse Analytics, and Azure SQL Database.
 * SQL Server expertise, including stored procedures, indexing, and performance tuning.
 * Industry experience in construction, engineering, or related fields, with an understanding of domain-specific data challenges.
 * Experience in delivering training sessions or presenting data solutions to both technical and non-technical audiences.
   
   

__________________________________________________________________

Okland is an equal opportunity employer and considers all applicants for employment based on merit, competence, performance, and business needs. We do not discriminate on the basis of any status protected under federal, state, or local law. Applicants will be considered regardless of their race, color, sex, gender identity or expression, age, religion, creed, national origin, citizenship status, sexual orientation, genetic information, physical or mental disability, military status or any other characteristic protected under federal, state, or local law. In addition to complying with all applicable laws, Okland also has a strong corporate commitment to inclusion.

Notice to all Employment, Staffing & Recruiting Agencies and Recruiters: Please could we ask that you do not directly email, call, or visit our hiring managers. Okland Construction does not accept unsolicited resumes,and should any be received from a third party they will be considered at no fee unless a signed agreement is in place. If you would like to discuss becoming a preferred staffing vendor for Okland Construction, please contact your local recruitment team who will advise you on the process.",Full-time
4127766410,37538.0,"Data Engineer (Python, Java, Azure)","Data Engineer (Python, Java, Azure)

Must Have:

 * 7+ years of experience in building out data pipelines in Python or Java
 * 2+ years of experience working in Azure Cloud Service
 * Experience with data processing platform, such as Azure Data Factory
 * Experience with data lake/data marts/data warehouse
 * Experience with transactional database engines, such as SQL server
 * Fluent with SQL for data analysis
 * Excellent analytical and problem-solving skills with the ability to think quickly and offer alternatives both independently and within teams.
 * Exposure working in an Agile environment with Scrum Master/Product owner and ability to deliver
 * Bachelor's degree Computer Science or a related field.

Nice to Have:

 * Experience with Spark
 * Experience working in Hadoop or other Big data platforms
 * Exposure to deploying code through pipeline
 * Good exposure to Containers like ECS or Docker
 * Working experience in a Linux based environment
 * Direct experience supporting multiple business units for foundational data work and sound understanding of capital markets within Fixed Income
 * Knowledge of Jira, Confluence, SAFe development methodology & DevOps",Contract
4045427537,66321745.0,Entry Level Data Engineer,"Since 2010 and almost 14 years SynergisticIT has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients.

Post Covid the tech Layoffs have been massive—In 2022 there were 165,269 tech layoffs, In 2023 there were 264,220 tech layoffs and so far in 2024 there have been 126,382 tech layoffs. (Source Layoffs.fyi ) -Total layoffs as per this 555,871 tech layoffs.

Client, Dell and Cisco have announced 15,000/12,500 and 4000 tech layoffs respectively in August.

The Job market is Hyper Competitive. For 1 position 500-2000 candidates or more are applying and laid off job seekers are also competing for entry level Job positions.

Acquiring the right technology skillsets which are being demanded by clients and getting yourself in front of clients is the way to get to get Interviews and eventually a Job Offer. Survival of the Fittest is the only way to get a tech Job in this job market.

In this Layoffs fueled market also SynergisticIT's candidates are able to achieve multiple job offers and $100k &plus; salaries once they acquire the required skills.

please check the below links to see success outcomes, salaries of our candidates.

https://www.synergisticit.com/candidate-outcomes/

https://www.synergisticit.com/roi-of-computer-science-degree-colleges-vs-synergisticit/

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please visit the below videos exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, we are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Data Engineers, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

REQUIRED SKILLS For Java /Full Stack/Devops Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Knowledge of Core Java , javascript , C&plus;&plus; or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

For data Science/Data Analyst/AI/Machine learning Positions

Required Skills

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude

Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Full-time
4146291743,1441.0,"Software Engineer III, Generative AI, Data Analytics","Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Sunnyvale, CA, USA; Kirkland, WA, USA; New York, NY, USA.Minimum qualifications:


 * Bachelor's degree in Computer Science, similar technical field of study, or equivalent practical experience.
 * 2 years of experience developing ML models and launching AI/ML powered products, with experience in data analytics.
 * 2 years of experience with software development in one or more programming languages (Java, C++, Python, or Go) or 1 year of experience with an advanced degree in an industry setting.
 * Experience in Data analytics and Vertex AI within a cloud based environment
   
   

Preferred qualifications:


 * Master's degree or PhD in Computer Science or a related technical field.
 * 2 years of experience with AI/ML techniques including generative AI, Natural Language Processing (NLP), information retrieval, etc.
 * Experience with Python, Notebooks, ML Frameworks (e.g., TensorFlow).
 * Experience with data systems.
 * Ability to drive process improvements, with excellent problem solving and analytical skills.
   
   

About The Job

Google Cloud's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google Cloud's needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. You will anticipate our customer needs and be empowered to act like an owner, take action and innovate. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward.

You will work with a team of experts to research, explore, and develop innovative solutions that will bring generative AI to the forefront of GCP Data Analytics for customers.

Google Cloud accelerates every organization’s ability to digitally transform its business and industry. We deliver enterprise-grade solutions that leverage Google’s cutting-edge technology, and tools that help developers build more sustainably. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems.

The US base salary range for this full-time position is $136,000-$200,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .

Responsibilities


 * Design and develop next-generation software systems for data analytics.
 * Participate in, or lead design reviews with peers and stakeholders to decide on available technologies.
 * Review code developed by other developers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency).
 * Contribute to existing documentation or educational content and adapt content based on product/program updates and user feedback.
 * Triage product or system issues and debug/track/resolve by analyzing the sources of issues and the impact on hardware, network, or service operations and quality.
   
   
   

Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",Full-time
4137490397,1681.0,Data Engineer,"This is a full-time, direct hire role based in Bethesda, MD, requiring onsite work four days a week and offering full benefits.




Job Overview: We are seeking a Data Engineer at a mid-level experience to join our growing Data Engineering team. The ideal candidate will have hands-on experience working with Azure to build and maintain data pipelines, data lakes, and understanding of data warehousing principles. The role will also require building quality and audit checks for data pipelines, ensuring the reliability and integrity of the data flow beyond just traditional ETL processes.

Key Responsibilities:

 * Build and maintain robust data pipelines on Azure, specifically within the Azure Data Lake environment.
 * Work closely with the team to implement data warehousing strategies, ensuring efficient data storage and retrieval.
 * Collaborate with Power BI developers to ensure smooth data reporting integration with Power BI.
 * Conduct data validation checks and build audits for data pipelines to ensure the accuracy and quality of the data.
 * Assist in troubleshooting and optimizing the data pipeline processes.
 * Collaborate cross-functionally to ensure that all data engineering needs are addressed with reliability and scalability.

Required Qualifications:

 * 5-6 years of experience working with Azure, including building pipelines for data lakes.
 * Strong understanding of data warehousing principles and architecture.
 * Experience with Azure Synapse Analytics for reporting and integration with Power BI.
 * Hands-on experience with data quality checks, audits, and validation in pipeline processes.
 * Ability to work collaboratively in a team environment and contribute to overall project success.

Preferred Skills:

 * Previous experience working with large-scale data systems and ensuring data reliability.

",Full-time
4141180643,14653152.0,Data Engineer,"Job details

Posted

03 February 2025

Location

Marshall Creek, Roanoke, TX 76262

Job type

Permanent

Reference

952322

Job Description


 * Bachelor’s or master’s degree or equivalent experience in a technology related field like Computer Science or Engineering with consistent track record.
 * Object oriented Python programming and proven experience with machine learning libraries – Pandas, NumPy, Scikit-learn, TensorFlow, etc.
 * Hands on event-based systems, functional programming, new technologies and messaging frameworks such as Kafka.
 * Ensures alignment with enterprise data architecture strategies.
 * Improves data availability via APIs and shared services and recommends optimization solutions using cloud technologies for data processing, storage, and advanced analytics.
 * Provides technical mentorship for cyber security on database technologies.
 * Performs risk assessments and implement validation of data processing system to ensure app functionality and security measures.
 * Performs independent and sophisticated technical and functional analysis for multiple projects supporting several divisional initiatives.
 * Building technical infrastructure required for efficient Extraction, Transformation, and Loading (ETL) of data from a wide variety of data sources by improving, object-oriented/object function scripting languages such as Python.
 * Expertise with relational databases, Splunk, Snowflake, YugabyteDB, Aerospike, S3 and similar data management platforms.
 * Experience with DB2, writing and stored procedures to process data is
 * Data parsing/analytics experience in large data sets using Python, scripting, and other similar technologies, integrating with and consuming APIs.
 * Familiarity with quantitative techniques and methods, statistics, econometrics – including probability, linear regression, time series data analysis and optimizations.
 * Knowledge of hybrid on-prem and cloud data architectures and services, especially data streaming, storage and processing functionality
 * Experience in Agile methodologies (Kanban and SCRUM) is a plus.
   
   

Dexian is a leading provider of staffing, IT, and workforce solutions with over 12,000 employees and 70 locations worldwide. As one of the largest IT staffing companies and the 2nd largest minority-owned staffing company in the U.S., Dexian was formed in 2023 through the merger of DISYS and Signature Consultants. Combining the best elements of its core companies, Dexian’s platform connects talent, technology, and organizations to produce game-changing results that help everyone achieve their ambitions and goals.

Dexian’s brands include Dexian DISYS, Dexian Signature Consultants, Dexian Government Solutions, Dexian Talent Development and Dexian IT Solutions. Visit https://dexian.com/ to learn more.

Dexian is an Equal Opportunity Employer that recruits and hires qualified candidates without regard to race, religion, sex, sexual orientation, gender identity, age, national origin, ancestry, citizenship, disability, or veteran status.

Apply Now

""*"" indicates required fields

This field is hidden when viewing the form

Applicant Tracking

Name*

First Last

Email*

Resume*

Accepted file types: pdf, docx, doc, txt, Max. file size: 50 MB.

Phone*

Current Zip Code

We are an equal opportunity employer. We honor diversity and are committed to creating an inclusive environment for everyone. Help us get to know you better by responding to these optional questions.

Race & Ethnicity

Hispanic or LatinoWhiteBlack or African AmericanAsianNative or Alaska NativeTwo or more racesI do not wish to disclose

Gender

MaleFemale

Disability

I Don't Have a Disability or Have a Record of Having a Disability.I Have a Disability or Have a Record of Having a Disability.I Do Not Wish to Answer

Protected Veteran

I am not a protected veteranI identify as one or more of the classificationsI choose not to self identify

By registering you agree to our Privacy Policy **

By registering you agree to our Privacy Policy *

Alternative

WPA",Full-time
4117462306,7075.0,Entry Level Data Engineer,"As a family company, we serve people and communities. When you work at Meijer, you’re provided with career and community opportunities centered around leadership, personal growth and development. Consider joining our family – take care of your career and your community!

Meijer Rewards


 * Weekly pay
 * Scheduling flexibility
 * Paid parental leave
 * Paid education assistance
 * Team member discount
 * Development programs for advancement and career growth
   
   

Please review the job profile below and apply today!

The Meijer MarTech development team is seeking an Entry Level Data Engineer with experience in data engineering and tool configuration and administration. This person will be responsible for coding, and testing data movement flows and configuring supporting applications; will be capable of solving targeted technical problems on their own and able to work with the team on system performance optimization and interoperability issues.

Hiring Details

This position is not eligible for visa sponsorship, including OPT student visas.

This is a hybrid role, which will require you to be in our Grand Rapids office location Monday - Wednesday. Relocation Assistance may be provided for those interested in relocating.

What You'll Be Doing


 * Codes, tests, and implements data movement artifacts and configures/administers supporting applications. Develops appropriate programs and systems documentation according to SAFe Agile principles and industry standards.
 * Runs unit tests. Monitors test results and takes required corrective action.
 * Competent understanding of both systems and/or business knowledge and able to contribute software engineering advice.
 * Demonstrates the initiative and method for solving different problems and proposes effective solutions for those problems.
 * Assists in the deployment of data movement flows and supporting applications or coordinates, implements, and configures vendor software applications.
 * Collaborates with the Business Product Owner and IT partners to create and refine user stories and acceptance criteria for projects.
 * Aids in systems development planning and monitoring.
 * Understands and practices secure coding techniques and processes while using the Agile framework.
 * Participates in structured walk-throughs, secure coding, and technical reviews.
 * Participates with other IT members, customers and other stakeholders in new product reviews, tests and pilots.
 * Actively participates in all Agile team ceremonies.
 * Assist in production support and maintenance of data movement flows and supporting applications as needed
 * This job role may also provide facilitation of activities for Agile teams within ITS as acting Scrum Master
 * This job profile is not meant to be all-inclusive of the responsibilities of this position; may perform other duties as assigned or required
   
   

What You Bring With You (Qualifications)


 * Bachelor’s degree in Computer Science, Computer Information Systems, Business Information Systems, Engineering or related discipline or equivalent work experience and technical training is required
 * Minimum 3 years of experience in data engineering development; any tool support and administration or application development experience a plus
 * Working knowledge of Python and SQL a must
 * Experience building data and analytics solutions using Azure ADLS, Data Factory, Databricks, Synapse Analytics is preferred
 * Familiarity with digital marketing domain and/or experience supporting Google Marketing Platform (CM360, DV360, SA360, GAM) and Salesforce MCI/Datorama a plus
 * Experience as a team member on project teams in a cross-functional environment.
 * Experience on Agile teams is preferred.
 * Knowledge of data movement development tools, coding and/or scripting languages and testing.
 * Knowledge and understanding of structured analysis and technical design techniques.
 * Knowledge of database management and file access methods is desirable.
 * Strong analytical and problem-solving skills.
 * Strong verbal and written communication skills with an ability to express complex technical concepts in business terms.
 * Solid teamwork, interpersonal and communication skills. Ability to work well on cross-functional project teams and foster team commitment to tasks.
 * Knowledge of agile practices in a cross-functional environment preferred
 * Ability to effectively adapt to rapidly changing technology and apply it to business needs.
 * Ability to establish and maintain a high level of customer trust and confidence.
 * Ability to provide high level of quality and productivity.",Full-time
4078473933,68692234.0,Data Engineer,"Key Qualifications


 * Strong knowledge of SQL (T-SQL is preferable).
 * Experience with Azure (Azure Service Bus, ADF, Azure Function, SQL Managed Instance).
 * Good knowledge of python.
 * Good knowledge of any modern RDBMS (what are indexes, views, functions, triggers, etc)
 * Proficient in exploring databases and identify data elements with minimal documentation.
 * Experience with ETL tool (SSIS, ADF).
 * Proficient in data modelling of DWH.
 * Experience and understanding of testing, coding, design, documentation and change management procedures.
 * Strong work ethic with a highly positive, hands-on, can-do attitude and flexible team player.
 * Ability to manage tasks independently, take ownership of responsibilities and work with minimal supervision.
 * High level of integrity, takes accountability of work and good attitude over teamwork; and Takes initiative to improve the current state of things and adaptable to embrace new changes.
   
   

Additionally


 * Proficient in foundational data visualization concepts, ability to identify appropriate visual tools (charts) for dashboard development.
 * Experience with Power BI or SQL Analysis Service (Tabular).
 * Knowledge of DAX.
   
   

Your responsibility and scope


 * Building the DWH for which all data is collected, organized, and analyzed
 * Ingesting all data into this DWH
 * Cleanse data ingested into DWH
 * Prep data for analysis based on guidance from data modelers and data analysts/scientists
 * Maintain and support these environments to ensure reliability and performance
 * Perform ongoing monitoring of data pipelines and work with stakeholders to troubleshoot and performance tune.
 * Create and maintain accurate and complete documentation of the DWH platform and the pipelines developed to ensure its currency.
 * Maintain awareness of industry trends on regulatory compliance, emerging threats and appropriate steps to mitigate the risks; and
 * Highlight any potential concerns/risks and proactively shares best risk management practices.
 * Any other ad-hoc duties as assigned.
   
   

We offer


 * Full-time, relocation to Mexico-City;
 * Latest tech stack, high load distributed application development challenges;
 * International team of experienced and talented professionals;
 * Ability to become a Technical/Team leader in a fast growing team.",Full-time
4105018732,78627785.0,Data Engineer Intern (Summer 2025),"Who We Are

Electra is reinventing iron production to tackle the nearly 10% of global carbon dioxide emissions produced from iron and steelmaking. Its patented process uses chemistry and renewable energy to transform a variety of grades of iron ore into environmentally responsible pure iron at scale. By maximizing the value of Earth’s resources and minimizing our environmental footprint and carbon emissions, Electra is forging a green future from the ground up. With a collaborative culture and passion for disrupting the status quo, careers at Electra offer challenge, reward, and the opportunity to bring to market solutions that dramatically improve the health of the planet.

Internship Program Summary

The 2025 Summer Internship Program is open to current undergraduate and graduate students pursuing majors in related fields.

The goal of the program is to provide students with hands-on, industry experience while offering the opportunity to make valuable contributions at Team Electra.

In This You Will


 * Develop automation for data processing, analysis, and data pipeline maintenance
 * Write libraries for data analysis and visualization using Python
 * Write REST API endpoints using FastAPI
 * Write automated tests for backend data processing software
 * Create new visualizations and data entry forms for end users to interact with our scientific database
   
   

Qualifications


 * Must be actively enrolled in an accredited college or university and pursuing an undergraduate or graduate degree in Mechanical Engineering, Chemical Engineering, Electrical Engineering, or another related technical degree.
 * Experience with and understanding of relational databases
 * Experience with SQL and PostgreSQL
 * Understanding of and ability to work with both vanilla Javascript and Typescript
 * Knowledge of and experience with Python
 * Well-versed in the use of version control software, specifically Git
 * Ability to work onsite in the office
   
   

Preferred Qualifications


 * Familiar with the principles of software architecture and design
 * Experience programming APIs
   
   

What Is In It For You


 * Hands-on experience in an industry environment
 * Opportunity to work on novel technologies
 * Opportunity to collaborate with other teams
   
   

Compensation


 * The pay rate for this position is $29.00 per hour for undergraduate students and $32.00 per hour for graduate students.
   
   

Interns are responsible for finding and paying for their housing solutions for the summer. Electra will provide suggestions for housing and will assist with connecting you with other interns after an accepted offer.",Internship
4045415030,66321745.0,Data Engineer (Remote),"2024 is finally here and we hope the Job market improves however as per a resume builder survey based on response from more than 900 companies 4 out of 10 companies are planning to have layoffs in 2024 or have a hiring freeze. Almost 390,000 tech employees have been laid off since 2022 and it's still ongoing. The effect of this has led hundreds of thousands of laid off Tech employees competing with existing Jobseekers.

AI is replacing many normal jobs which were done by people. As per news reports Google is planning to Client off 30,000 employees in its ad sales who will be replaed by AI ad technology.

Entry level Job seekers struggle to get responses to their applications, are getting ghosted after interviews. In such a scenario the Job seekers need to differentiate themselves by ensuring to obtain exceptional skills and technologies so that they can wear multiple roles at a client as clients now would want to expand roles and responsibilities assigned to a particular job to save costs.

Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.

All Positions are open for all visas and US citizens

We are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this challenging economy every client wants to save $$$'s and they want the best value for their money. Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs as Clients now post covid can also hire remote workers which increases even more competition for jobseekers.

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart lab s etc to name a few.

We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We also offer Skill and technology enhancement programs for candidates who are either missing skills or are lacking Industry/Client experience with Projects and skills. Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. If a Jobseeker is qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients. Shortlisting and selection are totally based on clients discretion not ours.

If you applied for a job and got emails from our skill enhancement team please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.

please check the below links to see success outcomes of our candidates and our participation at different Tech industry events and how we are different from other organizations in helping Jobseekers secure Tech careers

https://www.synergisticit.com/candidate-outcomes/

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

https://youtu.be/Rfn8Y0gnfL8?si=p2V4KFv5HukJXTrn

https://youtu.be/-HkNN1ag6Zk?si=1NRfgsvL_HJMVb6Q

https://www.youtube.com/watch?v=NVBU9RYZ6UI

https://www.youtube.com/watch?v=EmO7NrWHkLM

https://www.youtube.com/watch?v=OAFOhcGy9Z8

For preparing for interviews please visit https://www.synergisticit.com/interview-questions/

We are looking for the right matching candidates for our clients

Please apply via the job posting

REQUIRED SKILLS For Java /Full Stack/Software Programmer


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Project work on the skills
 * Knowledge of Core Java , javascript , C&plus;&plus; or software programming
 * Spring boot, Microservices, Docker, Jenkins and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning Positions

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Project work on the technologies needed
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, PowerBI, SAS, Tensorflow

If you get emails from our skill enhancement team please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Full-time
4088679789,1586.0,"Data Engineer, DS2-Science & Data Technology team","Description

The Amazon Devices team designs and engineers high-profile consumer electronics, including the best-selling Kindle family of products. We have also produced groundbreaking devices like Fire tablets, Fire TV, Amazon Dash, and Amazon Echo.

What will you help us create?

The Team: How often have you had an opportunity to be a founding member of a team that is solving a significant problem through innovative technology? Would you like to know more about how we are envisioning the use of data analytics, machine learning, AI and linear programming to solve these problems? If this sounds intriguing, then we’d like to talk to you about a role on a new Amazon team that's tackling a set of problems requiring significant innovation and scaling.

We are seeking a Data Engineer with strong analytical, communication and project management skills to join our team. Working closely with business stakeholders, software development engineers and scientist colleagues, you will design, evangelize, and implement state-of-the-art solutions for never-before-solved problems, helping Amazon Device to provide customer great products and keep the data secure. You will work with the most complicated data environment, employ right architecture to handle big data and support various analytics use cases, including business reporting, production data pipeline, machine learning, optimization models, statistical models, simulation, etc. Your work will have a direct impact on the day-to-day decision making in the Amazon Devices Sales & Operations Technology, and end customers.

You are an individual with outstanding analytical abilities, excellent communication skills, good business understanding, and technically savvy. The successful candidate will be an analytical problem solver who enjoys diving into data, is excited about solving ambiguity problems, can multi-task, and can credibly interface between technical teams and business stakeholders.

Key job responsibilities


 * Design, implement and support an analytical data infrastructure using AWS technologies
 * Build robust and scalable data integration (ETL) pipelines using SQL, and AWS data storage technologies like Aurora, Red Shift etc.
 * Design and develop Analytics applications using modern scripting languages (Python, R, PHP, etc) supporting critical business functions.
 * Gather business and functional requirements and translate these requirements into robust, scalable, operable solutions with a flexible and adaptable data architecture.
 * Lead architecture design and implementation of next generation BI solution
 * Continually improve ongoing reporting and analysis processes, automating or simplifying self-service modeling and production support for customers.
   
   

About The Team

Our team's north star is to empower the device software and services organization, along with its business partners, to make accurate and well-contextualized decisions quickly, helping them focus on delivering the best possible device customer experiences. We achieve this by integrating business intelligence and machine learning into human and system decision flows through scalable, configurable, and reusable foundational services.

Basic Qualifications


 * 3+ years of data engineering experience
 * Experience with data modeling, warehousing and building ETL pipelines
 * Experience with SQL
   
   

Preferred Qualifications


 * Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
 * Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
   
   

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.

Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you’re applying in isn’t listed, please contact your Recruiting Partner.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.


Company - Amazon.com Services LLC

Job ID: A2843070",Full-time
4151639731,2980860.0,Software Engineer,"Who are we?

Optimized Payments is the only fintech firm purpose-built to find and unlock value wherever it resides in our portfolio’s payment ecosystem. We’ve assembled a team with deep expertise across payments specialties to develop a proprietary analytics platform that finds actionable insights. We are an Atlanta based 17-year-old, and growing, company looking for talented individuals who want to grow with us.

Our client portfolio includes Fortune 500 firms such as Apple, Staples, Safeway, Priceline, AutoNation, and the U.S. Postal Service.

Who are you?

Are you analytical, collaborative, detail-oriented and looking to join a growing fintech? Look no further! Our dynamic team is seeking a Software Engineer to join us.

OP is seeking an innovative and dedicated individual committed to both serving our customers and having fun! Driven, with an entrepreneurial spirit and a heart for fintech. We’re looking for someone who wants to make a significant impact on the Company, Clients, and your Career. At Optimized Payments, our people embrace these qualities, so if this sounds like you then please read on!

The Role

We are looking for a highly motivated and talented Software Engineer who has a strong foundation in Spring Boot and API development. The ideal candidate will be responsible for building high-performance, scalable applications primarily in Java, and be comfortable with building high-quality RESTful APIs. In addition, the candidate will leverage Spring Batch and cloud native big data technologies such as Azure functions & snowpipes.

While this is a hybrid position, you will have the opportunity to work remote primarily.

Responsibilities


 * Design and develop scalable, high-performance applications using Java and Spring Boot.
 * Implement batch processing solutions using Spring Batch to handle large volumes of data efficiently.
 * Build and maintain RESTful APIs that integrate with various internal and external services
 * Collaborate with cross-functional teams such as Front-End developers and Product Owners
 * Troubleshoot, debug, and resolve issues in a timely manner.
 * Participate in code reviews and ensure adherence to best practices in software development.
   
   

Skills And Qualifications


 * Excellent verbal and written communication skills.
 * Strong analytical and problem-solving skills.
 * Bachelor’s degree in Computer Science, Information Technology, or a related field.
 * 5+ years of experience with Java with in-depth knowledge of Java 8+
 * Strong experience in building RESTful APIs
 * Knowledge of Spring Batch for developing batch processing solutions.
 * Experience with relational databases like MySQL, Oracle, PostgreSQL. (plus, for experience in Snowflake)
 * Cloud Native big data development (preferably Azure relate tools and services)
 * Proficient in object-oriented programming and design patterns.
 * Experience in version control systems like Git and build tools such as Maven
 * Experience working in an Agile environment.
 * Some knowledge of C#, node.Js and python is a plus
 * Experience with CI/CD pipelines and automated deployments is a plus
   
   

What We Offer

For Full-time Optimized Payments employees, we’re offering the following benefits and perks


 * Competitive salary and benefits package.
 * Stock Options
 * 401(K) Plan
 * Flexible Discretionary PTO + Paid Holidays
 * Opportunity to be part of a dynamic, fast-growing company that will double in size in two years.
 * Hybrid work environment with flexibility to work from home 3 days a week.
 * A collaborative and inclusive company culture where your ideas are valued.
 * Free onsite covered parking and access to a full gym with showers.
   
   

Employment Equity

Optimized Payments strongly supports equal employment opportunity for all applicants regardless of race, color, religion, sex, gender identity, pregnancy, national origin, ancestry, citizenship, age, marital status, physical disability, mental disability, medical condition, sexual orientation, genetic information, or any other characteristic protected by provincial and/or federal law. Accommodations for candidates with disabilities are available on request during all aspects of the recruitment and selection process. If accommodation is needed during the recruitment and selection process, please contact us and we will work with you to meet your accessibility needs.",Full-time
4145998617,89522484.0,Data Engineer,"Our client is seeking an experienced Data Engineer to join our Houston-based team. In this role, you’ll leverage your expertise in data integration, data warehousing, and data modeling to design and implement high-quality data solutions that empower our organization’s decision-making.







Responsibilities:

 * Design, build, and maintain scalable data pipelines and integration processes to support business operations and analytics.
 * Develop and implement data models and data warehousing solutions to ensure reliable and efficient data storage.
 * Write efficient, reusable, and testable code using Python for data processing and transformation tasks.
 * Create and optimize DAX (Data Analysis Expressions) calculations to support data visualization and reporting needs.
 * Collaborate with cross-functional teams, including analysts, and business stakeholders, to understand data requirements and deliver solutions.
 * Work with tools like Palantir and Foundry to build, manage, and optimize data workflows (experience with Palantir and Foundry is a plus).
 * Ensure data accuracy, security, and quality through regular monitoring and governance practices.
 * Document processes, pipelines, and best practices for future scalability and team collaboration.




Qualifications:

 * 4+ years of experience in data integration, data warehousing, and data modeling.
 * Proficient in Python for data development and processing.
 * Experience developing and managing DAX calculations for business intelligence purposes.
 * Knowledge of or experience with Palantir and Foundry is a plus.
 * A degree in Computer Science, Engineering, or a related field is preferred but not required.
 * Strong analytical thinking and problem-solving skills and the ability to work effectively in a fast-paced, team-oriented environment.
 * Houston-based; this position is on-site only with no remote work option.

",Full-time
4051126357,2833966.0,Data Engineer Azure,"Jersey City, NJ

Job Description

Bachelor's Degree (required) or Master's Degree (preferred) in Computer Science, Information Systems, or a related field


 * 10+ years of overall technology experience strategizing, engineering, configuring and implementing software solutions and services
 * 5+ years in the data engineering space with deep experience delivering enhanced analytic and data access capabilities
 * Domain knowledge of the Insurance Industry (preferably P&C) and value chain as well as the technologies and solutions relevant to this industry is desired
 * Hands-on knowledge of current technology standards/trends coupled with a desire to continually expand personal knowledge/skills
 * Ability and interest in mentoring technical staff and raising our collective technical competencies
 * Ability to establish and maintain relationships with other business and technology leaders
 * Strong written and verbal communication skills coupled with the ability to tailor communication to all levels of an organization
 * Open-minded with proven ability to work collaboratively with others in team environment
 * Strong understanding of IT environments, technologies in relation to business needs
 * Demonstrate strong ability to work in a team environment and foster cross-team collaboration
 * Experience executing technology modernization initiatives including migration to cloud native and API Strategies
 * Strong grasp of value creation and business capability models
 * Deep experience architecting data and analytics capabilities within a complex multi-national organization that meet requirements for availability, resiliency, stability, scalability, and security.
 * Current experience with Azure, APIs, accelerators, DevSecOps, Infrastructure as Code, Containers and Event driven messaging applications (Kafka, MQ)
 * Experience in Azure Cloud technologies like ADLS, ADF, Databricks, Synapse Analytics is a huge plus
 * Proficient use of tools, techniques, and manipulation including programming languages (Python, PySpark, SQL etc.), and an understanding of data engineering practices
 * Experience implementing, developing and integrating Data Management Capabilities (Meta Data, MDM, Reference Data)
 * Deep understand on the advanced analytics techniques using ML and AI
 * Experience with the MLOps Tools like mlFlow, DVC (data version control) and other MLOps frameworks
 * Experience in developing and maintaining CI/CD pipelines for automated deployment of ML models using Azure Devops and databricks webhooks.
 * Experience in designing & managing data pipeline using ADF, Databricks and delta lake to ensure reliable data flow for model training and scheduling automated retraining.
 * Experience in implementing model monitoring solution to track ML performance, detect data drift and setting up alerts for proactive maintenance and troubleshooting.",Contract
3875376292,46623.0,Data Engineer,"Description

Your role at GEI.

GEI Consultants has an opening in our Operational Development Team for a qualified Data Engineer to support a variety of systems and data engineering tasks focused on data flow activities. The majority of our systems are based in MS SQL Server, Tableau Server, Azure, and FastField Forms. This person will primarily work closely with members of the Operational Development Team and with members of our IT staff. The ideal candidate will be focused, detail-oriented, and driven to attain and maintain very high standards for efficiency and accuracy in data acquisition and integration into our systems. The ideal candidate will have more than 3 years of data engineering experience in the AEC industry or in similar science and/or engineering environments. GEI seeks a committed, self-motivated, organized and detail-oriented individual who anticipates issues and thrives on creative, independent problem solving within a rapid, deadline-driven environment.

Essential Responsibilities & Duties


 * ETL of data from a wide variety of sources
 * Database and Data Warehouse design/expansion/backup & recovery
 * Index management and optimization
 * Support data sources for Tableau Server, Power BI, and ArcGIS
 * Stored procedure development and maintenance
 * Identify new opportunities within GEI where existing business approaches to data can be replaced with a more efficient/automated data flow and presentation of data for analysis
 * Develop and optimize ETL/SSIS packages to facilitate data transfer between FTP, remote data loggers, Azure, and on-premises databases
 * Troubleshoot SSIS package permission issues related to execute-as/data source read/write access
 * SQL Agent Job development and monitoring
 * Develop data reporting and visualizations as specified by clients using Tableau, SSRS, etc
 * Perform DML and DDL via tsql/stored procedures executed directly within SSMS and remotely via SSIS
 * Develop test plans, implementation plans, and project timelines for various data engineering projects
 * Define, prioritize, communicate, and foster shared understanding of project objectives and scope
 * Coordinate the development of standard operating procedures (SOPs), technical training programs, and QA/QC procedures for staff and work product
 * Team with all staff necessary to complete assignments
 * Collaborate with technical team members to ensure the solution design satisfies project objectives and business requirements
 * Other duties as assigned
   
   

Minimum Qualifications


 * 3+ years of experience in a position performing similar data engineering tasks
 * Proven record of ability to design, manage, and support MS SQL Server and Azure databases
 * Ability to work with the following programming/mark-up/scripting languages preferred: VB.net, python, XML, javascript, and R
 * Bachelor's Degree, from an accredited college or university
 * MS SQL Server/Azure certification preferred
 * Ability to develop project plans and meet deadlines
 * Self-starter with attention to detail and stakeholder needs
 * Able to critically analyze and solve problems of a complex nature
 * Excellent Communication skills
 * Able to work on multiple projects of moderate complexity simultaneously and independently
 * Proficient in organization and time management skills
 * Familiarity with engineering, environmental science, and/or chemistry subject matter preferred.
 * Able to work effectively in GEI’s partnership model, including a team environment, building rapport and relationships.
   
   

We are GEI.

Some of the world’s most pressing problems - from climate change to sustainable development, to critical infrastructure and the future of our energy supply - need our brightest and diverse minds working together to create safer, more resilient communities for tomorrow.

We are technical experts, collaborators, and entrepreneurs who draw from diverse backgrounds to solve our clients’ most complex challenges.

With nearly 60 offices across North America, we offer a range of engineering, science, and technical consulting services. Our range of expertise, project types, and culture make us the choice for top talent in the AEC industry.

Employee-owned. Employee-focused.

As a 100% employee-owned company, our employees support our flat leadership structure, have a say in how our business operates and benefit from our financial success. We are committed to employee growth with career development opportunities, competitive total rewards, a well-being program, flexible work arrangements and more. Our company culture is driven by our 4 Cs - we are Client-Centered, Curious, Collaborative, and Community Minded - which support our focus on sustainability, safety, diversity, equity and inclusion. Get to know us better by visiting GEI’s career site here.

GEI’s Total Rewards Package


 * Market-Competitive Compensation, including Eligibility for an Annual Performance Bonus
 * Pay Range For This Position: $33.65-72.11/hour
 * Comprehensive Benefits Program, including Medical, Dental, Vision, Life, Disability and More
 * Well-Being Program and Paid Parental Leave
 * Commuter Benefits
 * Hybrid Work Schedules and Cell Phone Stipends
 * GEI University (GEIU) with Continuing Education Assistance and Tuition Reimbursement
 * Connecting Conversation Program with a Focus on Professional Development and Opportunities for Advancement
 * Support and Financial Rewards for Publication Awards, Professional Dues, and Professional Licenses
 * Paid Holidays and Generous Paid Time Off Program
 * Rewards and Recognition
 * GEI-Funded Profit Sharing and 401(k)
 * Opportunity to be an Owner and Shareholder (Learn more here)
 * A Vibrant Culture that is Focused on Partnership, Sustainability, Giving Back to Our Communities and Diversity, Equity and Inclusion
 * And More…
   
   

Physical Job Requirements

Sedentary

X

Light

Medium

Other

Activity Level Throughout Workday

Physical Activity Requirements

Occasional

(0-35% of day)

Frequent

(33-66% of day)

Continuous

(67-100% of day)

Not Applicable

Sitting

X

Standing

X

Walking

X

Climbing

X

Lifting (floor to waist level) (in pounds)

X

Lifting (waist level and above) (in pounds)

X

Carrying objects

X

Push/pull

X

Twisting

X

Bending

X

Reaching forward

X

Reaching overhead

X

Squat/kneel/crawl

X

Wrist position deviation

X

Pinching/fine motor skills

X

Keyboard use/repetitive motion

X

Taste or smell (taste=never)

X

Talk or hear

X

Accurate 20/40

Very Accurate 20/20

Not Applicable

Near Vision

X

Far Vision

X

Yes

No

Not Applicable

Color Vision (ability to identify and distinguish colors)

X

Sensory Requirements

Minimal

Moderate

Accurate

Not Applicable

Depth perception

X

Hearing

X

Environmental Requirements

Occupational Exposure Risk Potential

Reasonably Anticipated

Not Anticipated

Blood borne pathogens

X

Chemical

X

Airborne communicable diseases

X

Extreme temperatures

X

Radiation

X

Uneven surfaces or elevations

X

Extreme noise levels

X

Dust/particular matter

X

Other (exposure Risks)

Usual workday hours:

X

8

10

12

Other work hours

GEI is an AA/equal opportunity employer, including disabled and veterans.",Full-time
4151699756,68313053.0,Data Analytics Engineer,"Journey with us! Combine your career goals and sense of adventure by joining our incredible team of employees at Royal Caribbean Group. We are proud to offer a competitive compensation and benefits package, and excellent career development opportunities, each offering unique ways to explore the world.

We are proud to be the vacation-industry leader with global brands — including Royal Caribbean International, Celebrity Cruises and Silversea Cruises — the most innovative fleet and private destinations, and the best people. Together, we are dedicated to turning the vacation of a lifetime into a lifetime of vacations for our guests.

Royal Caribbean Group’s Revenue Planning & Analysis has an exciting career opportunity for a full time Analyst Engineer ,Data reporting to the Sr. Mgr, RM Dev & Systems

This position will work on-site in Miami, Florida.

Position Summary

The Revenue Management Development and Systems team is responsible for all data, decision tools, reporting and information needs for the Revenue Planning and Revenue Management teams. This position assists in supporting the team’s database, jobs, and reports. Serves as contact person for the department to help explain the tools and data results. Responsibilities include the design, development, and implementation of data processes, reporting, and analytics solutions. This individual can work under minimal supervision. They are responsible for interacting with various departments within Royal Caribbean to find, consolidate, and manipulate data from multiple large data sets; to analyze and understand results; and to create reports.

Essential Duties And Responsibilities


 * Meet with business stakeholders to clarify and document reporting requirements
 * Works with management & other team members to understand & clarify data analysis and reporting needs
 * Meet with technical stakeholders to perform code reviews and elicit feedback
 * Assist in developing, implementing, and maintaining business intelligence reporting and user tools
 * Recommend data architecture and engineering structures necessary to support reports
 * Develop new reporting by creating new queries or coding new processes. Aggregates large data sets in SQL, Python, and other analytical tools for analysis. Develops data strategies, specifically around data structures, identifying critical information, as well as the tools used to retrieve and analyze the data. Performs research and analysis on large data sets - data exploration, trending, etc.
 * Continuously search for potential business improvements, revenue opportunity and efficiency gains.
 * Clearly explain tools and results to teams and management. Develop and conduct clear, concise presentations, communicating technical methods and impacts in business terms.
   
   

Performs other duties as required. This job description in no way states or implies that these are the only duties to be performed by the employee occupying this position. Employees will be required to perform any other job-related duties assigned by their supervisor or management.

Qualifications, Knowledge And Skills


 * Bachelor's degree preferably in Mathematics, Statistics, Computer Science, Economics, Analytics, Business, Engineering or BS/BA with combination thereof and related analytic work experience or relevant certifications.
 * 2 years of work experience in data analysis, data mining, business case development or other related analytical projects.
 * Equivalent combination of education and experience will be considered
 * Strong proficiency in query/reporting tools, SQL, Python or other development tools.
 * Understanding of forecasting, data cleansing and transformations
 * Experience working with databases, including Oracle, Databricks, or SQL Server
   
   

Strong quantitative, analytical, and problem-solving skills.


 * Strong quantitative, analytical, and problem-solving skills.
 * Demonstrated ability to develop and implement applications using programming languages
 * Experience with SQL required
 * Experience in supporting and interpreting reporting using business Intelligence tools (Azure, Synapse, and Databricks experience a plus).
 * Ability to handle dynamic workload, balancing short- and long-term projects.
 * Ability to communicate clearly and effectively to business and technical audiences in both spoken and written formats.
   
   

We know there's a lot to consider. As you go through the application process, our recruiters will be glad to provide guidance, and more relevant details to answer any additional questions. Thank you again for your interest in Royal Caribbean Group. We'll hope to see you onboard soon!

It is the policy of the Company to ensure equal employment and promotion opportunity to qualified candidates without discrimination or harassment on the basis of race, color, religion, sex, age, national origin, disability, sexual orientation, sexuality, gender identity or expression, marital status, or any other characteristic protected by law. Royal Caribbean Group and each of its subsidiaries prohibit and will not tolerate discrimination or harassment.

",Full-time
4149752686,12241.0,Data Engineer Intern,"Soar with us at Wawa.

We believe we can make life a little better every day – one smile, hoagie, or experience at a time. And there’s one secret ingredient that truly sets Wawa apart: Our Associates. At Wawa, you’ll be part of a caring team that’s dedicated to helping all of us fly high – together. We’re team players, day-brighteners, and go-getters: and we know that Wawa is a place where we can build skills to thrive and open doors to new career opportunities. We’re proud to be a part of a winning team of Associate owners who shape our success. We’re committed to helping our communities and one another at every turn, because we know that when we fly together, there’s no limit to how far we can go. Ready to be part of a team that helps you reach new heights? Join our flock and get ready to soar.


 * This internship begins on May 19th, 2025 and runs until August 7th, 2025. This role is a full time commitment (37.5 hour work week)*
   
   

Salary: $25.00/hour

Job Description

Job Title: Data Engineer Intern

Location: Corporate Office

Department: IT

Job Summary: The Data Engineering intern will work with the Data Engineering, Data Architecture, and Data Analytics teams. Tasks will include collecting, cleaning, and analyzing various datasets, building data pipelines, and creating visualizations to convey valuable insights.

Principal Duties


 * Exploratory Data Analysis - Build processes to perform initial investigations to discover patterns, spot anomalies, check assumptions with the help of summary statistics.
 * Data Cleaning and Preprocessing - Assist in cleaning and preparing raw data for analysis, such as removing duplicates, handling missing values, and standardizing formats.
 * Data Pipeline Development - Help with the development and maintenance of data pipelines, ensuring data flows smoothly from source to destination.
 * Database Development - Write and optimize SQL queries for retrieving, updating, and analyzing data in relational databases.
 * Data Validation - Assist in creating scripts to check the integrity of data, ensuring it matches expected formats, ranges, and business rules.
 * Documentation - Document code, processes, entity relationship diagrams, and data flow diagrams.
 * Data Visualization – Create reports and dashboards to analyze data sets.
   
   

Essential Functions


 * Strong analytical and problem-solving skills
 * Strong interpersonal, written and verbal communication skills
 * Detail oriented with strong organization and time management skills
 * Ability to work independently as well as within a team environment
 * Ability to organize thoughts into action plans
   
   

Basic Qualifications


 * Pursuing bachelor’s degree with a concentration or major in Computer Science or Information Technology
 * Knowledge of Java, Python, and SQL Preferred
 * Understanding of data visualization platforms such as Tableau, PowerBI, or Qlik
 * Understanding of cloud platforms such as AWS
 * Minimum GPA of 3.0 or Higher
 * Candidates must be currently enrolled in a college or university for the Spring 2025 semester – Fall 2026 semester
 * Candidate must be available from May 19, 2025 – August 7, 2025
 * Wawa currently observes a 4-day in office schedule Monday - Thursday with an opportunity to work remote on Friday. Can you commit to the 4-day in office commitment your potential department will have?
   
   

Wawa will provide reasonable accommodation to complete an application upon request, consistent with applicable law. If you require an accommodation, please contact our Associate Service Center at asc@wawa.com or 1-800-444-9292.

Wawa, Inc. is an equal opportunity employer. Wawa maintains a work environment in which Associates are treated fairly and with respect and in which discrimination of any kind will not be tolerated. In accordance with federal, state and local laws, we recruit, hire, promote and evaluate all applicants and Associates without regard to race, color, religion, sex, age, national origin, ancestry, familial status, marital status, sexual orientation or preference, gender identity or expression, citizenship status, disability, veteran or military status, genetic information, domestic or sexual violence victim status or any other characteristic protected by applicable law. Unlawful discrimination will not be a factor in any employment decision.",Part-time
4151643730,7162834.0,Senior Data Engineer,"The Rock Family of Companies is made up of nearly 100 separate businesses spanning fintech, sports, entertainment, real estate, startups and more. We’re united by our culture – a drive to find a better way that fuels our commitment to our clients, our community and our team members. We believe in and build inclusive workplaces, where every voice is heard and diverse perspectives are welcomed. Working for a company in the Family is about more than just a job – it’s about having the opportunity to become the best version of yourself.

As a Senior Data Engineer, you’ll engage in the design, development and maintenance of data platforms and solutions, including applying data management principles to pipelines and delivering analytical and operational solutions to provide visibility and enable decision-making. You’ll develop data integration solutions and work with cross-functional teams to build products and services to meet business needs. As a senior member of the team, you’ll also mentor and support the development of your teammates.

About The Role


 * Guide the identification, investigation and resolution of data quality issues and ensure data is secure and reliable
 * Develop Extract, Load, Transform (ELT) processes from various data repositories and APIs across the enterprise, ensuring data quality and process efficiency
 * Develop data processing scripts
 * Work in a hybrid data environment with on-premises and cloud data warehouses
 * Develop relational and non-relational data models to shape data to meet user needs
 * Monitor performance and scalability issues in a large-scale data lake environment
 * Mentor team members on any of the above
 * Assist leadership with improving flow by identifying and helping address technical debt and process issues for the team
   
   

About You

Minimum Qualifications


 * 7 years of experience or equivalent competency building data solutions, including relational and non-relational databases, and supporting implementation and maintenance of batch and real-time data pipelines using cloud services
 * 5 years of experience or equivalent competency analyzing data to identify deliverables, gaps and inconsistencies
 * Experience innovating solutions to complex problems
 * Expertise writing simple and complex queries (SQL/NoSQL)
 * Expertise debugging and troubleshooting applications
 * Proficiency in a functional or object-oriented programming language
 * Knowledge of Linux system administration, shell scripting and basic networking skills
 * Experience accessing and developing REST APIs
   
   

Preferred Qualifications


 * Degree or equivalent competency in computer science, information technology, or a related field
 * 5 years of experience with big data and distributed data tools, such as Python and Lambda
 * 5 years of experience with continuous integration and continuous delivery (CI/CD) and automated deployments
 * Experience mentoring and developing others
   
   

What You’ll Get

Our team members fuel our strategy, innovation and growth, so we ensure the health and well-being of not just you, but your family, too! We go above and beyond to give you the support you need on an individual level and offer all sorts of ways to help you live your best life. We are proud to offer eligible team members perks and health benefits that will help you have peace of mind. Simply put: We’ve got your back. Check out our full list of Benefits and Perks.

About Us

RKT Holdings is a centralized hub that delivers thoughtful and innovative solutions for Rocket Companies®. We’re a Detroit-based company made up of businesses that provide simple, fast and trusted digital solutions for complex transactions. The name comes from our flagship business, now known as Rocket Mortgage®, which was founded in 1985. Today, we’re a publicly traded company involved in many different industries, including mortgages, fintech, real estate and more. We’re insistently different in how we look at the world and are committed to an inclusive workplace where every voice is heard. Apply today to join a team that offers career growth, amazing benefits and the chance to work with leading industry professionals.

This job description is an outline of the primary responsibilities of this position and may be modified at the discretion of the Company at any time. Decisions related to employment are not based on race, color, religion, national origin, sex, physical or mental disability, sexual orientation, gender identity or expression, age, military or veteran status or any other characteristic protected by state or federal law. The Company provides reasonable accommodations to qualified individuals with disabilities in accordance with applicable state and federal laws. Applicants requiring reasonable accommodations in completing the application and/or participating in the application process should contact a member of the Human Resources team at Careers@myrocketcareer.com.

The Company is an Equal Employment Opportunity employer, and does not discriminate in any hiring or employment practices. The Company provides reasonable accommodations to qualified individuals with disabilities in accordance with state and federal law. Applicants requiring reasonable accommodation in completing the application and/or participating in the employment application process should notify a representative of the Human Resources Team, The Pulse, at Careers@myrocketcareer.com.",Full-time
3646129422,280637.0,Software Engineer/Developer,"Software Engineer / Developer

Job Type: Full time, On-Site, potential for hybrid schedule

Clearance Requirements: Active TS/SCI clearance.

Northstrat has various positions available, such as front-end, back-end, and full stack software engineering. You will be responsible for designing, developing, testing, deploying, and maintaining software solutions..

As a Northstrat software engineer, you will have the opportunity to join amazing teams that deliver strategic IT solutions for meaningful problems in the defense and intelligence sectors. You will tackle unique and complex challenges, using cutting-edge technologies to build scalable and secure solutions with DevSecOps and Agile methods.

Duties and Responsibilities:


 * Develop and implement software enhancements to mission systems in Federal Government agencies
 * Integrate multiple applications and systems to streamline process workflows
 * Design, develop, document, test, and debug software that contains logical and mathematical solutions to mission problems
 * Use diagrams to document software functionality
 * Build scalable and secure solutions to mission problems
 * Communicate effectively when writing and/or contributing to end user instructions or manuals
 * Perform code reviews and provide feedback to your peers
 * Apply research and development techniques to progress product from an idea into production
   
   

Common Tech Stacks at Northstrat:

React, Angular, Vue.js, Javascript


 * Java, NodeJS, Ruby, Clojure, Python
 * Docker, Kubernetes, Redis, Kafka, SciPy, NumPy, Pandas
 * CM processes/tools: GIT, JIRA, Confluence
   
   

Soft Skills


 * Teamwork
 * Communication Skills
 * Self-Motivated
 * Time Management Skills
 * Adaptability to an agile work environment
   
   
   

Requirements

Required Skills


 * Creative problem-solving using innovative analytical solutions
 * Software Development with modern languages
 * Must have an active US government TS/SCI clearance. No exceptions
   
   
   

Desired Skills


 * Enterprise system development
 * Rapid prototyping and Agile based software development methodologies
 * Understanding of web application development concepts
 * Understanding DevSecOps pipelines for enterprise systems
 * Understanding of Frontend/Backend development
 * Working with modern databases
 * Developing automated testing
 * Working with Configuration Management software such as GIT
 * Understanding APIs and web service interfaces such as REST and GraphQL
 * Linux operating systems
 * NiFi automation
 * Development in microservice-based architectures
 * AWS APIs and deployment
 * Understanding of machine learning concepts
   
   

Education and Certifications:


 * Bachelors or Pursuing Bachelor's or Master's degree
    * Certifications preferred but not required based upon customer requirements: AWS Certification (Developer, DevOps and/or, Architect, etc.) and Security+ Certification
      
      

Benefits

Work/Life Balance

Northstrat values true work life balance. We offer power of choice benefits designed to best meet the needs of you and your lifestyle. Our benefits programs are designed to support and encourage wellness, healthy living, retirement investment, and lifetime learning.

Pay Range

There are a host of factors that can influence final salary including, but not limited to, geographic location, Federal Government contract labor categories and contract wage rates, relevant prior work experience, specific skills and competencies, education, and certifications. We also offer competitive compensation, benefits, and profession development opportunities. Please refer to our Benefits section for additional details.

Flex Time

Northstrat does not mandate specific working hours. Although project requirements may dictate schedules, a Northstrat employee is only required to work an average of 8 hours per weekday over the course of a month. For example: John worked 12 hours on June 1st to meet a project deadline. On June 15th, John only worked 4 hours because he left early for a long weekend. John's IBA was not debited for time off because flex time allowed him to carry over those 4 hours from June 1st.

Individual Benefits Account (IBA)

To attract and retain the highest quality staff, Northstrat provides a unique and versatile benefits package, the Individual Benefit Account (IBA), which places the power of choice in the hands of our greatest asset - the employee.

The purpose of the IBA is to provide attractive benefits to all full-time employees of Northstrat on a flexible basis that enables each covered employee to select a package that best suits his or her needs. Whether those needs are paid time off, medical expenses, prescription drug expenses, cash disbursement, or a combination of any of these, the IBA provides flexibility to help you meet your specific goals. The IBA can be used for such things as:


 * Medical and Vision Insurance through United Health Care; Dental insurance through Delta Dental
 * 100% Medical Reimbursement
 * Time Off with Pay
 * Profit Sharing Plan
 * 401k
 * Educational Benefits
 * Additional Income
   
   

IBA Benefits accrue each month in the amount equivalent to 50% of the employee's monthly compensation rate. That is, the effective dollar amount of this accrual is in addition to an employee's salary.

Profit Sharing Plan (PSP)

The PSP is a qualified retirement plan that Northstrat funds quarterly on the employee's behalf through the IBA in the amount equivalent to 25% (up to the IRS contribution limit) of the employee's compensation. That is, of the 50% accrual in the IBA, half of the amount accrued is applied to the PSP.

Stock Options

Because Northstrat is an employee-owned company, all new employees are offered stock options. Employees have the opportunity to receive additional stock options based on accomplishment of individual performance goals. Stock owners elect the Board of Directors and are directly impacted by the success of the company.

Lifelong Learning

Our culture promotes and nurtures a growth environment. We hire and scale rapidly to meet the needs of our partner customers. Through the use of company provided online learning opportunities, periodic company sponsored training events, and the ability to use IBA funds for reimbursement of work-related education expenses you will have the opportunity to continually grow your skills and abilities.

Bring Your True Self

We embrace diversity and encourage inclusion. We support employee led interest groups and challenge our employees to support others and be their best self. We are so true to our beliefs that we offer employee referral incentives. When you like it here, your friends and family will too!

Northstrat is an Equal Opportunity Employer

We are committed to fostering an inclusive, diverse workplace. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, disability, veteran status or other legally protected status.",Full-time
4149939456,1663.0,Data Analytics Engineer,"At Lilly, we unite caring with discovery to make life better for people around the world. We are a global healthcare leader headquartered in Indianapolis, Indiana. Our employees around the world work to discover and bring life-changing medicines to those who need them, improve the understanding and management of disease, and give back to our communities through philanthropy and volunteerism. We give our best effort to our work, and we put people first. We’re looking for people who are determined to make life better for people around the world.

Actual compensation will depend on a candidate’s education, experience, skills, and geographic location. The anticipated wage for this position is

$63,750 - $180,400

Company Overview

At Lilly, we unite caring with discovery to make life better for people around the world. We are a global healthcare leader headquartered in Indianapolis, Indiana. Our 38,000 employees around the world work to discover and bring life-changing medicines to those who need them, improve the understanding and management of disease, and give back to our communities through philanthropy and volunteerism. We give our best effort to our work, and we put people first. We’re looking for individuals who are determined to make life better for people around the world.

Position Description

The MQ Tech at Lilly Data Analytics engineer for Global Supply Chain will be responsible for building solutions to bring transparency into Lilly’s Supply Chain.

Key Responsibilities


 * Data Architecture Design: Develop and maintain scalable data architectures and models that support supply chain analytics and reporting.
 * Data Integration: Integrate data from various sources, including ERP systems, inventory management systems, and external data feeds, ensuring data quality and consistency.
 * Analytics and Reporting: Create advanced analytics and reporting tools to provide insights into supply chain performance, inventory levels, demand forecasting, and supplier performance.
 * Collaboration: Work closely with supply chain managers, analysts, and IT teams to understand data needs and ensure alignment with business objectives.
 * Optimization: Identify opportunities for process improvements and cost savings through data analysis and reporting.
 * Technical Documentation: Document data processes, technical specifications, and system configurations for future reference and compliance.
 * Problem Solving: Troubleshoot data-related issues and provide technical support to end-users.
 * Stay Current: Keep abreast of industry trends, best practices, and emerging technologies related to data engineering and supply chain management.
   
   
   

Basic Qualifications


 * Bachelor’s degree in Computer Science, Data Science, Supply Chain Management, or a related field. Master’s degree preferred.
 * 5-7 years of experience in data engineering, analytics and reporting. Preferably experience in Supply Chain Management, but not require
   
   
   

Technical Skills


 * Proficiency in programming languages (e.g., Python, R, SQL).
 * Proficiency in Microsoft Fabric
 * Preferred proficiency in Jupiter Notebooks but not mandatory.
 * Experience with data visualization tools (specificallyPower BI, but other tools considered).
 * Familiarity with cloud platforms (e.g., AWS, Azure) and big data technologies (e.g., Spark).
 * Knowledge of database management systems (e.g., Azure SQL, AWS RDS, Redshift).
 * Analytical Skills: Strong analytical and problem-solving skills, with the ability to interpret complex data sets.
 * Communication: Excellent verbal and written communication skills, with the ability to convey technical concepts to non-technical stakeholders.
   
   
   

Preferred Skills


 * Understanding of supply chain processes and metrics.
 * Experience with machine learning techniques and statistical analysis.
 * Familiarity with ERP systems (e.g., SAP S/4 HANA,BW4HANA ) and supply chain planning software.
 * Certifications in AWS and Azure.
   
   
   

Work Environment

Position will be based in Indianapolis at the Eli Lilly Corporate Headquarters.


 * Typically works in an office setting..
 * May require occasional travel to supplier sites or company facilities.
   
   
   

Lilly is dedicated to helping individuals with disabilities to actively engage in the workforce, ensuring equal opportunities when vying for positions. If you require accommodation to submit a resume for a position at Lilly, please complete the accommodation request form (https://careers.lilly.com/us/en/workplace-accommodation) for further assistance. Please note this is for individuals to request an accommodation as part of the application process and any other correspondence will not receive a response.

Lilly is an EEO/Affirmative Action Employer and does not discriminate on the basis of age, race, color, religion, gender, sexual orientation, gender identity, gender expression, national origin, protected veteran status, disability or any other legally protected status.

Our employee resource groups (ERGs) offer strong support networks for their members and help our company develop talented individuals for future leadership roles. Our current groups include: Africa, Middle East, Central Asia Network, African American Network, Chinese Culture Network, Early Career Professionals, Japanese International Leadership Network (JILN), Lilly India Network, Organization of Latinos at Lilly, PRIDE (LGBTQ + Allies), Veterans Leadership Network, Women’s Network, Working and Living with Disabilities. Learn more about all of our groups.

Full-time equivalent employees also will be eligible for a company bonus (depending, in part, on company and individual performance). In addition, Lilly offers a comprehensive benefit program to eligible employees, including eligibility to participate in a company-sponsored 401(k); pension; vacation benefits; eligibility for medical, dental, vision and prescription drug benefits; flexible benefits (e.g., healthcare and/or dependent day care flexible spending accounts); life insurance and death benefits; certain time off and leave of absence benefits; and well-being benefits (e.g., employee assistance program, fitness benefits, and employee clubs and activities).Lilly reserves the right to amend, modify, or terminate its compensation and benefit programs in its sole discretion and Lilly’s compensation practices and guidelines will apply regarding the details of any promotion or transfer of Lilly employees.

#WeAreLilly",Full-time
4120828110,10667.0,"Data Engineer, Product Analytics","As a Data Engineer at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Reality Labs, Threads). Your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience for our 3 billion plus users, as well as our internal employee community.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a world-class data engineering community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a strong focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Data Engineer, Product Analytics Responsibilities:


 * Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems
 * Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve
 * Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way
 * Define and manage Service Level Agreements for all data sets in allocated areas of ownership
 * Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership
 * Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains
 * Solve our most challenging data integration problems, utilizing optimal Extract, Transform, Load (ETL) patterns, frameworks, query techniques, sourcing from structured and unstructured data sources
 * Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts
 * Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts
 * Influence product and cross-functional teams to identify data opportunities to drive impact
 * Mentor team members by giving/receiving actionable feedback
   
   

Minimum Qualifications:


 * Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent
 * 4+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions
 * 4+ years of experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.)
   
   

Preferred Qualifications:


 * Master's or Ph.D degree in a STEM field
   
   

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$145,000/year to $204,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",Full-time
4098468281,3657.0,Data Engineer,"APPLICATION INSTRUCTIONS:


 * CURRENT PENN STATE EMPLOYEE (faculty, staff, technical service, or student), please login to Workday to complete the internal application process. Please do not apply here, apply internally through Workday.
 * CURRENT PENN STATE STUDENT (not employed previously at the university) and seeking employment with Penn State, please login to Workday to complete the student application process. Please do not apply here, apply internally through Workday.
 * If you are NOT a current employee or student, please click “Apply” and complete the application process for external applicants.
   
   

JOB DESCRIPTION AND POSITION REQUIREMENTS:

We are seeking a talented, experienced, and highly-motivated Data Research Engineer to join the Algorithms, Prototyping and Integration (API) Department of the Applied Research Laboratory (ARL) at Penn State University. You will assist in providing our customers with state-of-the-art visualization and decision support software based solutions.

ARL’s purpose is to research and develop innovative solutions to challenging scientific, engineering, and technology problems in support of the Navy, the Department of Defense (DoD), and the Intel Community (IC).

ARL is an authorized DoD SkillBridge partner and welcomes all transitioning military members to apply.

You will:


 * Assemble large, complex sets of data that meet research requirements
 * Build required infrastructure for optimal extraction, transformation and loading of data from various data sources using cloud and SQL technologies
 * Integrate analytical tools to utilize the data pipeline, solving research problems posed by the stakeholders and data science team
 * Work with a team of engineers, faculty, students and customers and to assist them with data-related technical and resource issues
 * Execute tasking within an Agile development process
 * Keep current with relevant emerging technologies and trends by attending conferences and workshops relevant to department and project goals
   
   

Additional responsibilities of the higher level include:


 * Coordinate Data Engineering related research and development activities between disciplines involving exploration of subject area, definition of scope and selection of problems for investigation and development of novel concepts and approaches
 * Mentor and train employees in the development of Data Engineering related technical, project, and business development skills
   
   

This job will be filled at the Intermediate Professional or Advanced Professional level, depending upon the successful candidate's education, and experience. Minimally requires a Bachelor’s Degree in an Engineering or Science discipline plus 2 years of related experience for the intermediate professional level. Additional education and/or experience required for higher level positions.

Required skills/experience areas include:


 * Data flow automation using NiFi or similar applications
 * PostgreSQL
   
   

Preferred skills/experience areas include:


 * PostGIS
 * Python
 * FastAPI
 * Security+ or similar level of certification
 * Active TS/SCI clearance
 * Master's Degree
   
   

The position will be located in either State College, PA or Reston, VA and will report to the API Department head in State College, PA.

ARL at Penn State is an integral part of one of the leading research universities in the nation and serves as a University center of excellence in defense science, systems, and technologies with a focus in naval missions and related areas.

You will be subject to a government security investigation, and you must be a U.S. citizen to apply. Employment with the ARL will require successful completion of a pre-employment drug screen.

ARL is committed to diversity, equity, and inclusion; we believe this is central to our success as a Department of Defense designated University Affiliated Research Center (UARC). We are at our best when we draw on the talents of all parts of society, and our greatest accomplishments are achieved when diverse perspectives are part of our workforce.

FOR FURTHER INFORMATION on ARL, visit our web site at www.arl.psu.edu.


 * The proposed salary range may be impacted by geographic differential.**
   
   

The salary range for this position, including all possible grades is:

$86,300.00 - $164,000.00

Salary Structure - additional information on Penn State's job and salary structure.

CAMPUS SECURITY CRIME STATISTICS:

Pursuant to the Jeanne Clery Disclosure of Campus Security Policy and Campus Crime Statistics Act and the Pennsylvania Act of 1988, Penn State publishes a combined Annual Security and Annual Fire Safety Report (ASR). The ASR includes crime statistics and institutional policies concerning campus security, such as those concerning alcohol and drug use, crime prevention, the reporting of crimes, sexual assault, and other matters. The ASR is available for review here.

Employment with the University will require successful completion of background check(s) in accordance with University policies.

EEO IS THE LAW

Penn State is an equal opportunity, affirmative action employer, and is committed to providing employment opportunities to all qualified applicants without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. If you are unable to use our online application process due to an impairment or disability, please contact 814-865-1473.

Federal Contractors Labor Law Poster

PA State Labor Law Poster

Affirmative Action

Penn State Policies

Copyright Information

Hotlines

University Park, PA",Full-time
4137135684,2646.0,"(USA) Staff, Data Engineer","Position Summary...

What you'll do...

Come join our People Data Engineering Team @Walmart where you’ll have the opportunity to manage people data at Walmart scale and make sure the consistent data is being utilized across transactional and analytical systems.

About Team

The Enterprise People Technology team supports the successful deployment and adoption of new People technology across the enterprise. As a Fortune #1 company, our work impacts millions of associates globally. We strive to continuously improve people technology and products to help managers and associates so they can focus on what matters most - supporting our customers and members. People Technology is one of the major segments of Walmart Global Tech’s Enterprise Business Services, which is invested in building a compact, robust organization that includes service operations and technology solutions for Finance, People, and the Associate Digital Experience.

What You'll Do


 * Design, Build and Enhance high performance reusable framework for data pipeline
 * Develop and deploy cutting edge solutions at scale, impacting millions of customers worldwide to drive value from data at Walmart Scale
 * Support People Data applications ensuring Data Quality and Governance standards.
 * Interact with Walmart engineering teams across geographies to leverage expertise and contribute to the technical community.
 * Provide guidance and mentorship to junior data engineers.
 * Ensure data ingested and processed is accurate and of high quality by implementing data quality checks, data validation, and data cleaning processes
   
   

What You'll Bring


 * Bachelor's/master’s degree in computer science or a related field
 * With 8+ years' experience in development of big data technologies/data pipelines 
 * Proficiency in managing and manipulating huge datasets in the order of terabytes (TB) is essential. 
 * Expertise in big data technologies like Hadoop, Apache Spark (Scala preferred), Apache Hive, or similar frameworks on the cloud (GCP preferred, AWS, Azure etc.) to build batch data pipelines with strong focus on optimization, SLA adherence and fault tolerance.  
 * Expertise in building idempotent workflows using orchestrators like Airflow.  
 * Expertise in writing SQL to analyze, optimize, profile data preferably in Big Query or SPARK SQL 
 * Strong data modeling skills are necessary for designing a schema that can accommodate the evolution of data sources and facilitate seamless data joins across various datasets. 
 * Ability to work directly with stakeholders to understand data requirements and translate that to pipeline development / data solution work. 
 * Strong analytical and problem-solving skills are crucial for identifying and resolving issues that may arise during the data integration and schema evolution process. 
 * Ability to move at a rapid pace with quality and start delivering with minimal ramp up time will be crucial to succeed in this initiative. 
 * Effective communication and collaboration skills are necessary for working in a team environment and coordinating efforts between different stakeholders involved in the project. 
   
   

About Walmart Global Tech

Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. That’s what we do at Walmart Global Tech. We’re a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world’s leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.

Walmart’s culture is a competitive advantage, and it’s fostered by being together. Working together in person allows us to collaborate, align quickly and innovate with greater speed. We use our campuses to create purposeful connection rooted in deepening understanding and investing in the development of our associates.

Our hubs: Walmart is a global company with offices across the United States and around the world. Our global headquarters is in Bentonville, Arkansas, with primary hubs in the San Francisco Bay area and New York/New Jersey.

Benefits

Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.

Equal Opportunity Employer

Walmart, Inc. is an Equal Opportunity Employer – By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions – while being inclusive of all people.

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎

You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎

Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For Information About Benefits And Eligibility, See One.Walmart.

‎

The annual salary range for this position is $110,000.00-$220,000.00

‎

Additional Compensation Includes Annual Or Quarterly Performance Bonuses.

‎

Additional Compensation For Certain Positions May Also Include

‎

‎


 * Stock
   
   

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelor’s degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years’ experience in software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related field.

3 years' experience in data engineering, database engineering, business intelligence, or business analytics.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Master’s degree in Computer Science or related field and 4 years' experience in software engineering or related field, We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

508 Sw 8Th St, Bentonville, AR 72712, United States of America",Full-time
4101116282,66321745.0,Data Engineer - Remote,"Are you passionate about coding or technology and ready to make your mark in tech? For more than 14 years, SynergisticIT has been helping aspiring developers like you excel in the tech industry. We focus on equipping you with the skills and experience needed to not only secure a job but to thrive in your career!

Why Partner with SynergisticIT?


 * Customized inputs to achieve the desired output : designed with industry needs in mind, ensuring you're equipped with the most sought-after skills.
 * Exclusive Opportunities: Our extensive network allows you to connect with leading tech firms.
 * Outstanding Outcomes: Many of our candidates land multiple job offers, often with starting salaries of $100k or more!
   
   

Synergisticit Pics /Salaries of Successful Candidates

Synergisticit at Oracle Cloudworld 2023

Synergisticit at Gartner Data & Analytics summit

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

Who Should Apply? We're looking for recent grads in Mathematics, Statistics , Computer Science or Engineering or candidates with gaps in their career or people wanting to switch careers into tech. SynergisticIT is committed to supporting your journey!

Preferred SKILLS For Java /Full Stack/Devops Positions

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Knowledge of Core Java , javascript , C++ or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

For data Science/Data Analyst/AI/Machine learning Positions

Preferred SKILLS

Associate or Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT, Statistics, Mathematics or having good logical aptitude

Knowledge of Statistics, Gen AI, LLM, Sagemaker, Python, Computer Vision, data visualization tools

Candidates lacking technical skills or relevant experience can research our Job Placement Programs which can assist in landing a Job

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates

Embrace Your Future! We also assist with F1 OPT to transition into H1B and Green Card byproviding comprehensive support. All positions are open to candidates of all visa types and US citizens.

Are you ready to make an impact?",Contract
4151046028,3302167.0,"Data Engineer II, Search Boundaries","Mapbox is the leading real-time location platform for a new generation of location-aware businesses. Mapbox is the only platform that equips organizations with the full set of tools to power the navigation of people, packages, and vehicles everywhere. More than 3.5 million registered developers have chosen Mapbox because of the platform’s flexibility, security and privacy compliance. Organizations use Mapbox applications, data, SDKs and APIs to create customized and immersive experiences that delight their customers.

What We Do

Mapbox Boundaries is an expertly curated set of global boundary data that allows you to add boundaries to your maps, dashboards, and data visualizations. Mapbox Boundaries consists of multiple data layers that come cartographically-matched, georeferenced, and processed as a Mapbox vector tileset ready for integration with your maps and data. From business intelligence analysis and data journalism to territory planning and logistics management, customers utilize boundary maps data in countless solutions.

Here Are Some Of Our Recent Boundaries Blog Posts


 * Advanced Geospatial Analysis with Mapbox Boundaries Flat File Format
 * Expanded Coverage with Mapbox Boundaries 4.3
 * Introducing the Mapbox Snowflake Native App
 * How Topology Improves GIS Data Quality
 * Expanding the Boundaries of Visualization
   
   

Our Boundaries team is a part of the Search Data org that supplies address, boundaries, place, and points of interest (POI) data for global searches in countries around the world. Search is crucial for our customers’ applications and we are a key partner to the Maps and Navigation organizations at Mapbox. Whether you’re trying to find a place among the vast ocean of data on a global map or to find the exact location of a venue a few miles down the road, Search is in the critical path of our customers’ experiences.

What You'll Do

Our world is not static and, therefore, our data cannot be static. It needs to be constantly updated and available for Mapbox developers to utilize when they want to build a BI dashboard, create a navigation app, or customize the world for their audience. We want to expand our Boundaries data offerings to allow our users to consume more of our data to create their version of a living map and location service. This role will be focused on data engineering for feature expansion, improving coverage, increasing polygon precision, and building pipelines to ingest new data sources.

As a Geospatial Data Engineer, you will have the opportunity to work on the Boundaries team at Mapbox - an exciting and challenging opportunity!


 * As a data engineer on the Boundaries team, you will:
 * Integrate third-party data sources from different geographic areas into our data pipelines
 * Inspect and edit geospatial data using open-source tools
 * Develop geographic data processing pipelines
 * Interface with engineers from other teams to understand their needs for geospatial data and provide solutions
 * Implement automated quality metrics to ensure we are continuously delivering high quality data to our customers
 * Mentor other software engineers to develop all aspects of their engineering skill sets, including participating in design and code reviews
   
   

What We Believe Are Important Traits For This Role


 * 5+ years of industry experience working with data pipelines
 * Expertise with GIS tools and processes, preferably open-source ones such as QGIS, Postgres/PostGIS, GDAL/OGR, GeoJSON
 * Experience with AWS technologies like S3 and Athena (experience with Lambda, Glue, and EMR is a bonus)
 * Experience writing bash scripts and running command line tools
 * Working knowledge with SQL databases and ideally experience writing custom functions (e.g. with pl/pgsql)
 * Proficiency in at least one modern programming language (like Python or Java) suitable for data processing
 * Excellent debugging experience and performance profiling that includes running QA or test systems at scale
 * Strong experience with batch data processing and developed judgment to implement new data pipelines and best practices around it
 * Comfortable working with a git-based environment (such as GitHub)
 * Familiarity with Docker
 * Familiarity with CI/CD processes
 * Integrating data with APIs and querying data through APIs
 * Familiarity working with Apache Spark, Pandas, or Hadoop-based technologies is a bonus
   
   

Domain Knowledge


 * Experience working with OSM and Wikidata data
 * Cartography experience is a plus
 * Knowledge of global boundary disputes is a plus
   
   

Problem Solving Approach


 * Empathy when it comes to listening and understanding complex problems and finding simple solutions
 * Autonomy and ability to drive project completion in the face of ambiguity for the customer’s favor
 * Ability and willingness pivot to new languages, skills, and techniques quickly
 * Desire to share your expertise through documentation, mentorship, and both written and vocal discussion
 * Openness to building internal tools to accelerate workflows
   
   

What We Value

In addition to our core values, which are not unique to this position and are necessary for Mapbox leaders:


 * We value high-performing creative individuals who dig into problems and opportunities.
 * We believe in individuals being their whole selves at work. We commit to this through supportive health care, parental leave, flexibility for the things that come up in life, and innovating on how we think about supporting our people.
 * We emphasize an environment of teaching and learning to equip employees with the tools needed to be successful in their function and the company.
 * We strongly believe in the value of growing a diverse team and encourage people of all backgrounds, genders, ethnicities, abilities, and sexual orientations to apply.
   
   

Our annual base compensation for this role ranges from $139,400 - $188,600 for most US locations and 5% to 10% higher for US locations with a higher cost of labor. Job level and actual compensation will be decided based on factors including, but not limited to, individual qualifications objectively assessed during the interview process (including skills and prior relevant experience, potential impact, and scope of role), market demands, and specific work location. Please discuss your specific work location with your recruiter for more information.

By applying for this position, you acknowledge that you agree to the Mapbox Privacy Policy which is linked here.

Mapbox participates in E-Verify to confirm employee work authorization. Please refer to the Notice of E-Verify Participation and Right to Work posters for more information.

Mapbox is an EEO Employer - Minority/Female/Veteran/Disabled/Sexual Orientation/Gender Identity.

",Full-time
4012338272,96139831.0,Data Engineer,"DataAnnotation is committed to creating quality AI. Join our team to help train AI chatbots while gaining the flexibility of remote work and choosing your own schedule.




We are looking for a proficient Data Engineer to join our team to train our AI chatbots to code. You will work with the chatbots that we are building in order to measure their progress, as well as write and evaluate code.




To apply to this role, you will need to be proficient in either Python and/or JavaScript. Your role will require proficiency in at least one programming language (JavaScript, Python, C#, C++, HTML, SQL, or Swift) in order to solve coding problems (think LeetCode, HackerRank, etc). For each coding problem, you must be able to explain how your solution solves the problem.




Benefits:




 * This is a full-time or part-time REMOTE position
 * You’ll be able to choose which projects you want to work on
 * You can work on your own schedule
 * Projects are paid hourly, starting at $40+ USD per hour, with bonuses for high-quality and high-volume work




Responsibilities:




 * Come up with diverse problems and solutions for a coding chatbot
 * Write high-quality answers and code snippets
 * Evaluate code quality produced by AI models for correctness and performance




Qualifications:




 * Fluency in English (native or bilingual level)
 * Proficient in either Python and/or JavaScript
 * Excellent writing and grammar skills
 * A bachelor's degree (completed or in progress)
 * Previous experience as a Software Developer, Coder, Software Engineer, or Programmer




Note: Payment is made via PayPal. We will never ask for any money from you. PayPal will handle any currency conversions from USD. This job is only available to those in the US, UK, Canada, Australia, or New Zealand. Those located outside of these countries will not see work or assessments available on our site at this time.",Contract
4136516236,222322.0,Data Engineer,"Kwik Trip, Inc. operates Kwik Trip, Kwik Star, Tobacco Outlet Plus Grocery, and Stop-N-Go Stores in Wisconsin, Minnesota, Iowa, Michigan, South Dakota, and Illinois with over 30,000+ coworkers’ company wide.







Kwik Trip, Inc.’s Information Technology Department is seeking a full-time Data Engineer. This position is a functional contributor to several data projects and initiatives at Kwik Trip.







Position Overview: We are looking for a Data Engineer to join our IT Data Engineering team. The ideal candidate will have a background in Snowflake, Databricks, data warehousing, and Data Engineering best practices. As a Data Engineering, you will play a crucial role in designing, implementing, and optimizing our data infrastructure to support the data-driven initiatives of the business at Kwik Trip.







Responsibilities include but are not limited to:

 * Research, design, build, optimize and maintain reliable, efficient, and scalable data pipelines, data models, and data products.
 * Efficiently replicate data from source systems, curate data according to business standards, model data for downstream consumption by reporting tools and other data driven use cases.
 * Collaborate with business stakeholders to optimize data collection, storage, and understand business use cases to maximize the value of information within supported systems.
 * Translate business needs into robust data engineering solutions.
 * Collaborate with data engineering team on best practices, infrastructure optimization, performance and cost optimization, pipeline monitoring, tool and library evaluation, quality assurance, and documentation.







Qualifications:

 * Bachelor's degree in Computer Science, Information Technology, or a related field, or equivalent practical experience.
 * Expertise in SQL and Python.
 * Experience with Snowflake and Databricks platforms.
 * Strong understanding of dataframes, Pandas, PySpark, SQL, dbt, Airflow/Astronomer, Azure Data Factory.
 * Understanding of database architecture; experience with MS SQL, DB2, SAP Hana, and MySql a plus.
 * Familiarity with cloud architecture, Azure Cloud Services, streaming APIs, RESTful APIs.
 * Understanding of container development, Docker, and container orchestration.
 * Experience developing, monitoring, maintaining and error handling with data pipelines.
 * Ability to use and complex query statements and advanced database tools, as well as working with data at scale.
 * Experience with git, source code version control, and release management.
 * Familiarity with machine learning concepts, feature engineering, modeling, and training strategies.
 * Understanding of data governance and compliance.







If you are passionate about data engineering, possess the required skills, and are eager to contribute to a dynamic and growing organization, we would love to hear from you!







Work Schedule: Monday through Friday, daytime hours.",Full-time
4126600812,18633749.0,Lead Data Engineer,"Company Summary




My client is the modern platform for battery science. They provide battery and clean technology companies the core data platform they need to innovate, securely at scale.




They're a well-funded, VC-backed start-up with customers and recurring revenue. We’re backed by world-class investors like Y Combinator, Giant Ventures and Collaborative Fund, and angels such as founders of Zendesk and Voi, and executives from Google, Meta and Figma.




The platform operates in battery labs across three continents and our reach is growing rapidly, which presents career-defining opportunities for ambitious engineers to accelerate their growth and contribute to a quickly evolving startup in SF. You’ll be joining our in-person team of engineers and physicists with backgrounds from U. Cambridge, Georgia Tech, U. Waterloo and other YC start-ups.




Your Mission




 * You’ll take ownership for delivery and maintenance of a secure, scalable, reliable data pipeline that can support 100+ TB data processed / year.
 * You’ll take ownership for management, operation and improvement of our associated cloud infrastructure.
 * You’ll take ownership for integration of new customer data for 25-50 new businesses.
 * For the right candidate, this role has potential to develop into a Head of Engineering leadership role.




We might be a fit for you if:




 * You have previously built and delivered a reliable, scalable data pipeline for processing large amounts of data.
 * Extreme ownership mentality - you own problems end-to-end and you’ll leverage all your resources to get the job done.
 * You’re a team player. You have a humble attitude, you take actions to help your colleagues, and you want to do whatever it takes to make the team succeed. You’re reliable on delivering on technical milestones.
 * You communicate effectively and respectfully. You pay attention to details. You express ideas clearly, you listen with curiosity. You are not afraid to communicate what is working and what needs to improve.
 * You set an exceptionally high performance bar for yourself and everyone on the team.




Technical Qualifications




 * BS or MS in Computer Science, Engineering, or a related field.
 * You have experience owning the production, operations and reliability of a data pipeline.
 * You have 3+ years experience in ETL processes, data modeling, and data engineering best practices.
 * You have experience with streaming technologies (e.g. Spark, Flink, Google Pub/Sub, Kafka, Amazon Kinesis)
 * You have experience with NoSQL and distributed database technologies (e.g. Cassandra, HBase, DynamoDB, BigTable, ClickHouse)
 * You are well-versed with cloud environments such as AWS, Azure, and GCP, associated cloud storage technologies (S3, GCS) and Kubernetes-based orchestration.",Full-time
4149764190,245926.0,SQL Developer Data Engineer,"ONLY PERMANENT EMPLOYEES IN THE TITLE AND THOSE THAT ARE REACHABLE ON THE COMPUTER SPECIALIST (SOFTWARE) CIVIL SERVICE LIST ARE ELIGIBLE TO APPLY.

Agency Description

Established in 1805, the New York City Department of Health and Mental Hygiene (the NYC Health Department) is the oldest and largest health department in the country. Our mission is to protect and improve the health of all New Yorkers, in service of a vision of a city in which all New Yorkers can realize their full health potential, regardless of who they are, how old they are, where they are from, or where they live.

As a world-renowned public health agency with a history of building transformative public health programming and infrastructure, innovating in science and scholarship to advance public health knowledge, and responding to urgent public health crises from New York City’s yellow fever outbreak in 1822, to the COVID-19 pandemic we are a hub for public health innovation, expertise, and programs, and services. We serve as the population health strategist, and policy, and planning authority for the City of New York, while also having a vast impact on national and international public policy, including programs and services focused on food and nutrition, anti-tobacco support, chronic disease prevention, HIV/AIDS treatment, family and child health, environmental health, mental health, and racial and social justice work, among others.

Our Agency’s five strategic priorities, building off a recently completed strategic planning process emerging from the COVID-19 emergency, are:


 * To re-envision how the Health Department prepares for and responds to health emergencies, with a focus on building a “response-ready” organization, with faster decision-making, transparent public communications, and stronger surveillance and bridges to healthcare systems
 * Address and prevent chronic and diet-related disease, including addressing rising rates of childhood obesity and the impact of diabetes, and transforming our food systems to improve nutrition and enhance access to healthy foods
 * Address the second pandemic of mental illness including: reducing overdose deaths, strengthening our youth mental health systems, and supporting people with serious mental illness
 * Reduce black maternal mortality and make New York a model city for women’s health
 * Mobilize against and combat the health impacts of climate change
   
   

Our 7,000-plus team members bring extraordinary diversity to the work of public health. True to our value of equity as a foundational element of all our work, and a critical foundation to achieving population health impact in New York City, the NYC Health Department has been a leader in recognizing and dismantling racism’s impacts on the health of New Yorkers and beyond. In 2021, the NYC Board of Health declared racism as a public health crisis. With commitment to advance anti-racist public health practices that dismantle systems that perpetuate inequitable power, opportunity and access, the NYC Health Department continues to work in and with communities and community organizations to increase their access to health services and decrease avoidable health outcomes.

___

The Bureau of Vital Statistics is responsible for registering and maintaining records of all births and deaths that occur in New York City. The bureau issues, analyzes and reports on 285,000 vital events each year. The bureau is a very large customer service operation, providing death certification services on a 24/7 basis, issuing more than 900,000 certified copies of birth and death records, and fulfilling hundreds of data requests annually.

Duties Will Include But Not Be Limited To


 * Various aspects of the software development lifecycle including researching, designing, building, and testing various aspects of the eVital ecosystem.
 * Supporting and enhancing new and existing interfaces (APIs).
 * Modernizing development of workflows for data reporting and data sharing using fast healthcare interoperable resources (FHIR).
 * Implementing and refining data integration processes including ETL tasks to support data accuracy and availability.
 * Co-administration of the evital system including oversight of user access controls, system configurations and related interfaces.
 * Ensure rigorous adherence to data security standards and compliance with privacy laws.
 * Assist in the analysis of large data sets to produce actionable insights and support strategic decision-making.
 * Troubleshoot database issues and provide timely solutions.
   
   

ADDITIONAL INFORMATION **IMPORTANT NOTES TO ALL CANDIDATES**

Please note: If you are called for an interview, you will be required to bring to your interview copies of original documentation, such as:


 * A document that establishes identity for employment eligibility, such as: A Valid U.S. Passport, Permanent Resident Card/Green Card, or Driver’s license.
 * Proof of Education according to the education requirements of the civil service title.
 * Current Resume
 * Proof of Address/NYC Residency dated within the last 60 days, such as: Recent Utility Bill (i.e., telephone, Cable, Mobile Phone)
   
   

Additional documentation may be required to evaluate your qualification as outlined in this posting’s “Minimum Qualification Requirements” section. Examples of additional documentation may be, but not limited to college transcript, experience verification or professional trade licenses.

If after your interview you are the selected candidate, you will be contacted to schedule an on-boarding appointment. By the time of this appointment, you will be asked to produce the originals of the above documents along with your original Social Security card.

""FINAL APPOINTMENTS ARE SUBJECT TO OFFICE OF MANAGEMENT & BUDGET APPROVAL”

TO APPLY

Apply online with a cover letter to https://a127-jobs.nyc.gov/. In the Job ID search bar, enter job ID number.

We appreciate the interest and thank all applicants who apply, but only those candidates under consideration will be contacted.

The NYC Health Department is committed to recruiting and retaining a diverse and culturally responsive workforce. We strongly encourage people of color, people with disabilities, veterans, women, and lesbian, gay, bisexual, and transgender and gender non-conforming persons to apply.

All applicants will be considered without regard to actual or perceived race, color, national origin, religion, sexual orientation, marital or parental status, disability, sex, gender identity or expression, age, prior record of arrest; or any other basis prohibited by law.

COMPUTER SPECIALIST (SOFTWARE) - 13632

Minimum Qualifications


 * A baccalaureate degree from an accredited college, including or supplemented by twenty-four (24) semester credits in computer science or a related computer field and two (2) years of satisfactory full-time software experience in designing, programming, debugging, maintaining, implementing, and enhancing computer software applications, systems programming, systems analysis and design, data communication software, or database design and programming, including one year in a project leader capacity or as a major contributor on a complex project; or
 * A four-year high school diploma or its educational equivalent and six (6) years of full-time satisfactory software experience as described in “1"" above, including one year in a project leader capacity or as a major contributor on a complex project; or
 * A satisfactory combination of education and experience that is equivalent to (1) or (2) above. College education may be substituted for up to two years of the required experience in (2) above on the basis that sixty (60) semester credits from an accredited college is equated to one year of experience. A masters degree in computer science or a related computer field may be substituted for one year of the required experience in (1) or (2) above. However, all candidates must have a four year high school diploma or its educational equivalent, plus at least one (1) year of satisfactory full-time software experience in a project leader capacity or as a major contributor on a complex project.
   
   

NOTE: In order to have your experience accepted as Project Leader or Major Contributor experience, you must explain in detail how your experience qualifies you as a project leader or as a major contributor. Experience in computer operations, technical support, quality assurance (QA), hardware installation, help desk, or as an end user will not be accepted for meeting the minimum qualification

requirements.

Special Note

To be eligible for placement in Assignment Level IV, in addition to the Qualification Requirements stated above, individuals must have one year of satisfactory experience in a project leader capacity or as a major contributor on a complex project in data administration, database management systems, operating systems, data communications systems, capacity planning, and/or on-line applications programming.

Preferred Skills

Applicants should have the following experience and abilities: - Designing, constructing, and managing SQL databases tailored for complex data management needs - Developing and optimizing SQL scripts, stored procedures, and functions to enhance database performance and functionality. - Working collaboratively with various stakeholders to identify and meet data requirements for public health research and reporting - Maintaining documentation for database and software solutions to ensure sustainability and compliance with city regulations. IT IS DESIRED THAT ALL APPLICANTS HAVE: - Proficient in SQL with extensive experience in managing large-scale databases, preferably in a government or public health context. - Proficiency with SQL, ASP, .NET, Web services, XML, XSL, XSLT & SOAP, C#, JAVA, VBSCRIPT, HL7 and FHIR formats. - Functional knowledge of HTML5, JavaScript and SQL, object-oriented coding methodologies. - Hands-on web-based application development experience. - Hands-on experience with large relational database design and implementation. - Demonstrate understanding of different software development life-cycle methodologies. - Experience with and knowledge of various ETL technologies. - Familiarity with health informatics, public health data standards (HL7, FHIR), and understanding of the unique needs in managing health-related data. - Excellent communication and collaboration skills, capable of working with a diverse range of municipal stakeholders.

55a Program

This position is also open to qualified persons with a disability who are eligible for the 55-a Program. Please indicate at the top of your resume and cover letter that you would like to be considered for the position through the 55-a Program.

Public Service Loan Forgiveness

As a prospective employee of the City of New York, you may be eligible for federal loan forgiveness programs and state repayment assistance programs. For more information, please visit the U.S. Department of Education’s website at https://studentaid.gov/pslf/.

Residency Requirement

New York City Residency is not required for this position

Additional Information

The City of New York is an inclusive equal opportunity employer committed to recruiting and retaining a diverse workforce and providing a work environment that is free from discrimination and harassment based upon any legally protected status or protected characteristic, including but not limited to an individual's sex, race, color, ethnicity, national origin, age, religion, disability, sexual orientation, veteran status, gender identity, or pregnancy.

, $100,743.00 – $115,854.00",Full-time
4045408987,66321745.0,Junior Software Engineer ( Remote),"SYNERGISTICIT is aware that the Job Market is Challenging due to almost 300,000 Tech Layoffs within the past year due to which The Job market is flooded with thousands of laid off Techies who are competing with existing Jobseekers. For entry level Job seekers to get client interviews and jobs they need to differentiate themselves by ensuring they have exceptional skills and technologies to be noticed by clients.

Since 2010 we have helped Jobseekers differentiate themselves by providing the clients with candidates who have the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers. All Positions are open for all visas and US citizens

We are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this economy no client wants or has the resources to take an entry level person and spend resources on upgrading their skills and on top of that pay the jobseeker. That's the specific reason there are so many techies both experience and freshers who are unemployed.

Clients have now the option to hire remote workers from anywhere so for a Jobseeker its important to introspect and see how they can become better and have the skills and technologies to meet client requirements. We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped thousands of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few. We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients. Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates looking to make their careers in IT Industry We welcome candidates with all visas and citizens to apply. We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We also offer optionally Skill and technology enhancement programs for candidates who are either missing skills or are lacking Industry/Client experience with Projects and skills. Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. If they are qualified with enough skills and have hands on project work at clients then you should be good to be submitted to clients. Shortlisting and selection is totally based on clients discretion not ours.

If you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.

Candidates who Lack Experience or are freshers with No actual on Job experience with projects with clients Have had a break in careers Lack Technical Competency or skills being demanded by clients Different visa candidates (Like OPT/H4EAD/L2EAD )who want to get employed and settle down in the USA please check the below links to see success outcomes of our candidates https://www.synergisticit.com/candidate-outcomes/

We are also silver sponsors at Oracle Cloudworld , Las vegas from sept 18-21st— please visit us

https://www.oracle.com/cloudworld/sponsor-listing/#synergistic-it

Watch the below videos of us participating at Industry events with the Top companies in Technology at Oracle Cloud world /Oracle Java one (Las vegas) and at Gartner Data Analytics Summit (Florida)

Oracle CloudWorld Event (OCW) Las Vegas 2022 | SynergisticIT - YouTube https://www.youtube.com/watch?v=OAFOhcGy9Z8

https://www.youtube.com/watch?v=EmO7NrWHkLM https://www.youtube.com/watch?v=NVBU9RYZ6UI

https://www.youtube.com/watch?v=Yy74yvjatVg SynergisticIT at Gartner Data and Analytics Summit 2023 - YouTube

If you have relevant skills and industry experience, please apply

For preparing for interviews please visit

https://www.synergisticit.com/interview-questions/

REQUIRED SKILLS For Java /Software Programmers


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Project work on the skills
 * Knowledge of Core Java , javascript , C&plus;&plus; or software programming
 * Spring boot, Microservices, Docker, Jenkins and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Project work on the technologies needed
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, PowerBI, Time series analysis

Please understand skills and relevant experience on real world projects are required by clients for selection even if its Junior or entry level position the additional skills and Project work with hands on experience building projects at client site are the only way a candidate can be picked by clients. If not having the skills or hands on project work at client site then candidates can optionally opt for skill enhancement to gain the required skills and project work. No third party candidates or c2c candidates

please only apply to the posting

No phone calls please. Shortlisted candidates would be reached out.",Full-time
4118589048,66321745.0,Junior Software Engineer - Remote,"Since 2010 Synergisticit has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this Job market also, our candidates are able to achieve multiple job offers and $100k + salaries.

please check the below links to see success outcomes, salaries of our candidates .

https://www.synergisticit.com/candidate-outcomes/

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please visit the below videos exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

Required Skills

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, Gen AI, LLM, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full Stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java , javascript , C++ or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Contract
4120222585,165640.0,Data Engineer - 100% Remote,"See yourself at Radian? We see you here too.

At Radian, we see you. For the person you are and the potential you hold. That’s why we’ve embraced a new way of working that lets our people across the country be themselves, be their best and be their boldest. Because when each of us is truly seen, each of us gives our best – and at Radian, we’ll give you our best right back.

Studies have shown that job seekers may hesitate to apply for jobs unless they meet every single qualification listed. We strive to see the potential in each applicant, so if you’re excited about this role but your experience or education level doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles.

See Yourself as a Data Engineer

As the Data Engineer you will be responsible for maintaining and creating new database objects such as stored procedures, tables etc. You will have to work on multiple SQL server database along with Oracle database.

See Your Primary Duties And Responsibilities


 * Program, test, implement and maintain any data object.
 * Perform SQL tuning for PL/SQL procedures, Views, Reports, etc.
 * Create and Maintain daily, weekly, and monthly data operations and schedule processes.
 * Participation in design sessions chaired by stakeholders.
 * Develop and implement the error handling.
 * Assist with ensuring documentation is create and up to date on all projects and operational systems.
 * Perform bug fixing, troubleshooting and assist with user support for existing applications.
 * Positive and solution-oriented mindset.
 * Ability to thrive in a geographically distributed organization.
 * Share our values, and work in accordance with those values.
 * Perform other duties as assigned or apparent.
   
   

Job Specification

Your Knowledge


 * 6+ years experience in database development (Microsoft SQL Server 2008+ and Oracle)
 * Demonstrated ability to work closely with other parts of the organization
 * Self-motivated and self-managing, with strong organizational skills.
 * Ability to learn new technologies and methodologies and apply them to what we are building.
 * Financial/Mortgage Industry Experience a plus.
   
   

Your Skills And Abilities


 * Proven ability to work autonomously, independent thinker with strong communication/interpersonal skills.
 * Proven ability to quickly understand client requirements and translate them into software developer requirements.
 * Strong technical estimating skills.
 * Ability to manage multiple assignments/projects simultaneously.
 * Strong analytical ability.
   
   

Additional Qualifications

Your Education, Certifications and Prior Work-Related Experience:


 * Degree Requirement: Bachelor's Degree or Equivalent Experience
 * Degree Preferred: Bachelor's Degree in Computer Science, Information Systems, Economics/Finance, Mathematics, Engineering or other Physical Science required; Advance degree and/or certification considered in lieu of work experience.
 * Work Experience: 6 or more years of prior work related experience
   
   

See Your Location

Radian is committed to a flexible work environment for many of our roles. This is a *Work From Anywhere* role meaning you have the flexibility to work from home (or another designated workspace that fits your needs).

This role provides additional flexibility should you want to work on-site at a Radian office. Explore our office locations here and let your Talent Acquisition Partner know you would be interested in working on-site.


 * Work From Anywhere is subject to Radian’s Alternative Work Policy and business needs.
   
   

See Why You Should Work With Us


 * Competitive Compensation: anticipated base salary rate from $87,300 to $124,800 based on skills and experience. This position is eligible to participate in an annual incentive program and a long-term incentive program.
 * Rest and Relaxation. This role is eligible for 25 days of paid time off annually, which is prorated in the year of hire based on hire date. In addition, based on your hire date, you will be eligible for 9 paid holidays + 2 floating holiday in support of our DEI culture. Parental leave is also offered as an opportunity for all new parents to embrace this exciting change in their lives.
 * Our Company Makes an Impact. We’ve been recognized by multiple organizations like Bloomberg’s Gender-Equality Index, HousingWire’s Tech 100, and The Forum of Executive Women’s Champion of Board Diversity. Radian has also pledged to PwC’s CEO Action for Diversity & Inclusion commitment.
 * Comprehensive Health Benefits. Multiple medical plan choices, including HSA and FSA options, dental, vision, and basic life insurance.
 * Prepare for your Future. 401(k) with a top of market company match (did we mention the company match is immediately vested?!) and an opportunity to participate in Radian’s Employee Stock Purchase Plan (ESPP).
 * Homebuyer Perks. Our Homebuyer Perks program helps employees navigate the home searching, buying, selling, and refinancing processes and provides valuable financial benefits to encourage, enable, and support home ownership.
 * Additional Benefits. To learn more about our benefits offerings, visit our Benefits Page.
   
   

The application period for the job is estimated to be 20 days from the job posting date. However, this timeline may be shortened or extended depending on business needs and the availability of qualified candidates.

Radian will consider for employment qualified applicants with arrest or conviction records in a manner consistent with the requirements of the law, including any applicable fair chance law.

See More About Radian

Radian is a fintech servicing the mortgage and real estate services industry. As a team, we pride ourselves on seeing the potential of every person, every idea and every day.

Seeing each other at Radian goes far beyond our open, flexible culture. It means seeing our people’s potential – and creating inspiring career paths that help them get there. Or seeing new pathways and innovating for the future of our industry. It means seeing each other for all that we are. And it means seeing our purpose as one that extends beyond the bottom line – having an impact on communities across the country to help more people achieve the American Dream of homeownership.

We hope you’ll see yourself at Radian. See more about us at Radian.com.

Defining Roles for Radian's Future

Understanding the qualities and characteristics that define a Leader and an Employee is important to building our future-fit workforce. Radian's future is only as bright as its people. For that reason, our People Plan includes profiles to support the qualities and characteristics that each Leader as well as each Employee should embody upon hire or via development.

EEO Statement

Radian complies with all applicable federal, state, and local laws prohibiting discrimination in employment. All qualified applicants will receive consideration for employment without regard to gender, age, race, color, religious creed, marital status, gender identity, sexual orientation, national origin, ethnicity, ancestry, citizenship, genetic information, disability, protected veteran status or any other characteristic protected by applicable federal, state, or local law.

Equal Opportunity Employer Details

To learn more about Radian’s Code of Conduct and Ethics and workplace conduct, please click [here]. Radian participates in E-Verify [Link] (en español [Link]). Learn more about your rights under immigration laws [Link] (en español [Link]). View the ""Know Your Rights: Workplace Discrimination is Illegal"" poster [Link]. View “Employee Rights under FMLA” [Link]. View “Employee Rights under EPPA"" [Link]. View Pay Transparency Nondiscrimination Provision [Link].

Accommodation

Whether you require an accommodation for the job application or interview process, Radian is dedicated to a barrier-free employment process and encourages a diverse workforce. If you have questions about the accommodation process, please e-mail careers@radian.com.

Please note that you may redact or remove age-related information that identifies your age, date of birth, or dates of attendance at or graduation from an educational institution on any additional application materials you submit as part of the application. Additional application materials include but are not limited to, resumes, CVs, transcripts, or certifications.

",Full-time
4104638528,66321745.0,Entry Level Data Engineer,"Since 2010 Synergisticit has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this Job market also, our candidates are able to achieve multiple job offers and $100k &plus; salaries.

Please Check The Below Links

https://www.synergisticit.com/candidate-outcomes/

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://www.youtube.com/playlist?list=PLJgkOBQ51j5AHT5I6n29glr0q6trzkxYD

https://synergisticit.wistia.com/medias/k6t6a1n4kb

Why do Tech Companies not Hire recent Computer Science Graduates | SynergisticIT

Technical Skills or Experience? | Which one is important to get a Job? | SynergisticIT

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.

Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.

Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

Required Skills

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, Gen AI, LLM, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

REQUIRED SKILLS For Java /Full Stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java , javascript , C&plus;&plus; or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.

No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates",Full-time
4147666529,21279.0,Data Engineer (Developer IV),"Job consists of setting up Change Data Capture (or CDC) for multiple types of databases for the purpose of hydrating a data lake.

Debezium Or Other CDC Knowledge Required.

Along with data hydration, job requires knowledge on ETL transformations using Apache spark, both streaming and batch processing of data.

Engineer needs to know how to work with Apache Spark Data Frames, ETL jobs, and streaming data pipelines that will orchestrate raw CDC data and transform it into useable and query-able data for analytics. Big Data concepts, including performance tuning is a plus.

Skill set:

Java - Mid to Senior level experience

Python - Mid level experience (pyspark)

Apache Spark - Data Frames, Spark SQL, Spark Streaming and ETL pipelines

Apache Airflow

Scala - not required but a plus

Apache Hudi - not required, but a plus

Apache Griffin - not required, but a plus

AWS Skillset:

Extensive knowledge with S3 and S3 operations (CRUD)

EMR & EMR Serverless

Glue Data Catalog

Step Functions",Full-time
4140121386,30324.0,Data Engineer,"Pay rate range - $65/hr. to $70/hr. on W2




Top Skills:

GCP Big Query, Python, ETL pipelines




Summary:

The main function of the Data Engineer is to develop, evaluate, test, and maintain architectures and data solutions within our organization.

The typical Data Engineer executes plans, policies, and practices that control, protect, deliver, and enhance the value of the organization's data assets.




Qualifications:

5-7 years of experience in designing and implementing large-scale data processing/data storage/data distribution systems

Extensive experience working with large data sets with hands-on technology skills to design and build robust Big Data solutions using Spark framework, GCP Big data services, and industry-standard frameworks

Ability to work with multi-technology/cross-functional teams and key stakeholders to guide/manage a full life-cycle solution

Extensive experience in Relational and MPP database platforms like (GCP Bigquery/Hive/Cloud SQL etc)

Open-source Hadoop stack/Spark framework

Strong understanding of Big Data Analytics platforms and ETL in the context of Big Data

Excellent problem-solving, hands-on engineering skills and communication skills

Broad understanding and experience of real-time analytics

Participate in the full Software Development Life Cycle (SDLC) of the Big Data Solution




Technical Skills Required

Any combination of the below technical skills

Hadoop: HDFS, MapReduce, Hive, Airflow

DW: Bigquery, Hive

Languages: Python, PySpark, Shell Scripting, SQL Scripting

Cloud: GCP Big data native services

Any RDBMS/DWBI technologies

Spark(Mandatory): Spark on GCP Dataproc




Roles & Responsibilities

Position Activities and Tasks

Should be able to design complex and high-performance Data architecture

Developing and maintaining strong relations with senior executives—developing new insights into the client’s business model and pain points, and delivering actionable, high-impact results

Participating and leading key engagements, in developing plans and strategies of data management processes and IT programs for the business, providing hands-on assistance in data modeling, technical implementation of big data solutions

Facilitating, guiding, and influencing the clients and teams toward right information technology architecture and becoming the interface between Business leadership, Tech leadership, and the delivery teams

Leading and mentoring other developers within the team

Identify the performance bottle-necks and resolve the same

Should be able to work in a team

Ability to produce high-quality work products under pressure and within deadlines

To coordinate with developers / other architects / other stakeholders and cross-functional teams from the organization




Education:

Bachelors Degree

",Contract
4151637300,12906038.0,Senior Data Engineer,"About The Company

ResortPass is completely redefining what it means to be a guest at a hotel. By offering day access to luxury hotel experiences, including breathtaking pools, private beaches, deluxe spas, and more, ResortPass allows people to escape – without ever leaving town. If you’re moved to contribute to our vision, we’d love your help.

Our growing team of innovative tech and hospitality experts has partnered with over 1,800 leading hotels and resorts including Ritz-Carlton, Four Seasons, Westin, and Fairmont. We’ve connected over 3 million people with relaxation and luxury in their own neighborhoods, making rest more mindful, togetherness more meaningful, and escape more accessible. Fresh off a Series B $30M raise, co-led by Declaration Partners and 14W with additional investment from previous investor Charles River Ventures, and new investors Endeavor, Jessica Alba, Adam Grant and others, ResortPass is at the beginning of creating a new category of hospitality.

About the role ResortPass is seeking our first in-house Data Engineer. In this role, you will work along with our Product Engineering, Business Intelligence and the leadership team to drive forward our data initiatives. You will be responsible for building out and maintaining our data infrastructure, ensuring our data stakeholders have access to high fidelity data in a timely manner, and that it’s all maintained in a high performant data warehouse.

We are looking for someone who thrives at the intersection of technical expertise and understanding business needs who knows that data isn’t just about numbers—it’s a powerful tool for solving real-world problems and driving business success. You understand the importance of building scalable and flexible data environments that ensure data from various sources is clean, organized, and easily accessible. You likely enjoy collaborating with teams across the business to identify the most valuable data points and integrate them into systems that enable faster, smarter decision-making. Ultimately, you’re focused on providing the tools and insights that empower the business to grow and succeed.

We are looking for someone who is located in or near the NYC area, as this role will be in person at our NYC headquarters. The base salary for this role will range from $160,000 - $200,000 per year, plus equity, commensurate with experience. What you'll do


 * Design, implement, and maintain robust ETL processes, ensuring data accuracy, timeliness, and accessibility for analysis
 * Collaborate with engineering teams to ensure comprehensive data instrumentation
 * Maintain our data warehouse by being the primary administrator and making sure it is well provisioned and optimized.
 * Promote effective self-service analytics infrastructure
   
   

Your experience We encourage candidates to apply even if they don’t have 100% of the below qualifications. We believe in a holistic approach when evaluating talent for our team and post new roles often, so even if this role isn’t quite right, we want to meet you!


 * 5+ years of data engineering experience, ideally in a high growth startup
 * Strong understanding of cloud technologies (AWS preferred)
 * Strong Experience ingesting data from REST APIs to a data warehouse or data lake using various modern tooling ranging from fundamental technologies like Airflow to self-serve tooling like Fivetrant
 * Strong understanding of data warehousing technologies (Redshift preferred)
 * Expert-level SQL skills and exposure to data transformation technologies such as DBT
 * Exposure to Looker or equivalent BI tools
 * Demonstrated experience working cross team and cross functionally
   
   

Benefits


 * Health, Dental & Vision — We're deeply invested in the health and well-being of our team and are proud to contribute to the monthly premiums of these insurance plans.
 * Stock Option Plan — We offer employees the opportunity to become part-owners in our mission. Let’s redefine what it means to be a guest, together.
 * 401k plan — Save for your future with a 401k plan offering.
 * Unlimited Paid Time Off (PTO) — Enjoy life away from work to be inspired and fully recharge with unlimited paid time off.
 * Commuter Benefits
 * Paid parental leave
 * Annual ResortPass credit — Our mission is to bring delight and relaxation to people around the world; including our employees! Access private beaches, deluxe saunas, awesome pools, and much more with your annual credit",Full-time
4151487502,29289303.0,Data Engineer,"Our client is seeking a dedicated and innovative Data Engineer to join their dynamic team. This hybrid role offers the flexibility of working from home on Fridays, with the rest of the week spent collaborating in-person at our client's location.

As a Data Engineer, you will play a pivotal role in the analysis, design, development, testing, implementation, and maintenance of new and existing data structures. Your primary responsibility will be to optimize our data and data pipeline architecture, enhancing data flow and collection for cross-functional teams. You will also support software developers, data architects, data analysts, and data scientists on data initiatives.

Key Responsibilities:


 * Build infrastructure for optimal extraction, transformation, and loading of data from various sources
 * Maintain optimal data pipeline architecture
 * Identify, design, and implement internal process improvements
 * Build analytics tools to provide actionable insights into operational efficiency and other key business performance metrics
 * Collaborate with stakeholders and business teams to resolve data-related technical issues
   
   
   

Qualifications:


 * 2-3 years of relevant and progressive professional experience in data analysis, design, and development
 * Bachelor's degree in a related field or equivalent education and/or experience
 * Ability to work in a dynamic problem-solving environment and synthesize strategy, plans, and solutions
 * Demonstrated ability to deliver in a complex business environment
   
   
   

Our client's team is committed to fostering a culture of innovation, strong relationships, and appreciation for individuality. They offer a career with purpose, supporting the farmers and ranchers who create food, fuel, and fiber for the world. As part of a financially strong and well-capitalized insurer, they are known for their quick response and fast, accurate claims settlement. They are seeking energetic and confident individuals to join their team of professionals, offering competitive benefits and a commitment to integrity, loyalty, and customer service.

Our client is an equal-opportunity employer, committed to Diversity, Equity, and Inclusion principles.

Horizontal facilitates valuable and productive conversations between you and potential employers. We can assist you in growing your career by partnering you with employers that offer challenging assignments. For those that join the team, we offer competitive compensation and benefits including medical, dental, vision, and retirement. Check out all we have to offer and how you can become part of the Horizontal Talent Team. The salary range for this role is $100,000 - $120,000. This is not a guarantee of compensation or salary, as final offer amount may vary based on factors including but not limited to experience and geographic location.

Once you apply for this position, you may receive a phone call, SMS or email from our Virtual Recruiter, Alex, to conduct an initial interview.

",Full-time
4133415618,27423.0,"College Intern, Data Engineer","Republic National Distributing Company (RNDC) is a family-owned business with roots extending before Prohibition that has evolved into one of the nation's largest wine and spirits wholesalers. Our success is grounded in our core values of Family, Service, Accountability, Honesty, and Professionalism. We offer a vibrant, inclusive culture and workplace experience for individuals who want a career that makes them feel accomplished and engaged. RNDC values the health and well-being of our associates, inside and outside the office, offering dynamic health and wellness benefits that supply exceptional care and value. RNDC is geared toward growing our footprint and our people. Join our team of energetic professionals who believe in many happy hours and are experts in our craft.

**Summary**

RNDC's IT College Intern program provides students with hands-on experience in a dynamic and innovative technology environment. Interns will work alongside IT professionals, contributing to projects such as system support, data analysis, software development, cybersecurity, and troubleshooting technical issues. This role is ideal for students pursuing a degree in Information Technology, Computer Science, or a related field who are eager to enhance their technical skills, gain industry insight, and explore career opportunities within a leading beverage distributor. Candidates should have strong problem-solving abilities, familiarity with IT tools and systems, and a willingness to learn and adapt in a fast-paced setting.

**In this role, you will**

**Data Engineer Intern**


 * Design and optimize data pipelines and Snowflake queries for efficient data handling.
 * Build and model large data sets to meet business needs and ensure data reliability.
 * Create data tools, tag data for organizational visibility, and improve data quality.
 * Adhere to privacy policies and Agile development processes while supporting analytics teams.
   
   

**What you bring to RNDC**

Data Engineer College Intern


 * Enrolled in Computer Science or related field, with data engineering knowledge.
 * Familiar with SQL, Python/Java, Snowflake, Apache Airflow, and big data tools like Kafka.
 * Experience with Agile, CI/CD, and GitHub.
   
   

**What's in it for you**


 * 401(k) with company matching
 * Medical, dental and vision benefits\*
 * Paid Time Off Program – work your way up to 5 weeks of PTO a year with the ability to carryover unused PTO
 * Paid volunteer time
 * Paid parental leave
 * Paid caregivers leave
 * Fertility benefits
 * Paid training
 * Company paid life insurance, short-term disability, and company-paid holidays
 * Associate resource groups, and diversity, equity, and inclusion programs available for all associates
   
   

\*Participation in these programs is subject to applicable wait periods and all plan and program terms and eligibility

COVID-19 Considerations

We follow CDC Guidelines and have a fun and safe environment for our teams.

**Bonus if you bring**

Republic National Distributing Company and National Distributing Company are Equal Opportunity/Affirmative Action employers. It is our policy not to discriminate against any Employee or Applicant. All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, sex, age, status as a protected veteran, among other things, or status as a qualified individual with disability. This policy of nondiscrimination in employment includes but is not limited to: recruitment, hiring, placement, promotion, transfer, employment advertising or solicitations, compensation, layoff or termination of employment.

RNDC is committed to providing reasonable accommodation to people with disabilities throughout the job application and interview process, to the point of undue hardship. If you require an accommodation during the application or interview process, please click here.",Other
4045415046,66321745.0,Data Engineer - Remote,"Since 2010 Synergisticit has helped Jobseekers get employed in the tech job market by providing candidates the requisite skills, experience, and technical competence to outperform at interviews and at clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this Job market also, our candidates are able to achieve multiple job offers and $100k &plus; salaries.

please check the below links to see the success outcomes and salaries of our candidates .

https://www.synergisticit.com/candidate-outcomes/

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

We regularly interact with the Top Tech companies to give our candidates a competitive advantage visit the below videos exhibiting at Oracle Cloud World/Oracle Java one (Las Vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like Apple, google, Paypal, Western Union, Client, visa, Walmart lab s etc to name a few.

Currently, We are looking for entry-level software programmers, Java full-stack developers, Python/Java developers, Data analysts/ Data Scientists, and Machine Learning engineers for full-time positions with clients.

Who Should Apply Recent Computer Science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

Required Skills

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, Gen AI, LLM, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

Required Skills

REQUIRED SKILLS For Java /Full stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java, Javascript, C&plus;&plus;, or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernates, and REST API's experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team and only connect with candidates who are matching client requirements.

No phone calls, please. Shortlisted candidates would be reached out. No third-party or agency candidates or c2c candidates",Full-time
4146385796,91447303.0,Data Engineer," * Bachelor's or Master's Degree in a technology related field (e.g. Engineering, Computer Science, etc.) required with 5+ years of experience.
 * Advanced SQL/PLSQL knowledge.
 * 2+ years of Python development.
 * Experience with Unix scripting and scheduling tools.
 * Good experience in working with AWS or similar Cloud Technologies.
 * Strong data modeling skills doing either Dimensional or Data Vault models.
 * Proven data analysis skills.
 * Experience working with snowflake database is a plus.
 * Hands-on experience on SQL query optimization and tuning to improve performance is desirable.
 * Hands-on experience with ETL tool like Informatica is a desirable
 * Working experience with some or all the following: AWS, Containerization, associated build, and deployment CI/CD pipelines.
 * Experience with DevOps, Continuous Integration and Continuous Delivery (Jenkins, Stash, Concourse, Artifactory).
 * Experience in Agile methodologies (Kanban and SCRUM) is a plus.
 * Proven track record to handle ambiguity and work in fast paced environment.
 * Good interpersonal skills to work with multiple teams in the organization.
   

Dexian is a leading provider of staffing, IT, and workforce solutions with over 12,000 employees and 70 locations worldwide. As one of the largest IT staffing companies and the 2nd largest minority-owned staffing company in the U.S., Dexian was formed in 2023 through the merger of DISYS and Signature Consultants. Combining the best elements of its core companies, Dexian's platform connects talent, technology, and organizations to produce game-changing results that help everyone achieve their ambitions and goals.


Dexian's brands include Dexian DISYS, Dexian Signature Consultants, Dexian Government Solutions, Dexian Talent Development and Dexian IT Solutions. Visit https://dexian.com/ to learn more.


Dexian is an Equal Opportunity Employer that recruits and hires qualified candidates without regard to race, religion, sex, sexual orientation, gender identity, age, national origin, ancestry, citizenship, disability, or veteran status.",Full-time
4045411900,66321745.0,Data Engineer,"Since 2010 Synergisticit has helped Jobseekers get employed in the tech Job market by providing candidates the requisite skills, experience, and technical competence to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a tech Job we make careers.

In this Job market also, our candidates can achieve multiple job offers and $100k &plus; salaries.

please check the below links to see the success outcomes and salaries of our candidates .

https://www.synergisticit.com/candidate-outcomes/

https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalog

We regularly interact with the Top Tech companies to give our candidates a competitive advantage visit the below videos exhibiting at Oracle Cloud World/Oracle Java One (Las Vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023

https://synergisticit.wistia.com/medias/tmwjwchxz5

https://synergisticit.wistia.com/medias/n8487768di

https://synergisticit.wistia.com/medias/o5gmv7i9eu

https://synergisticit.wistia.com/medias/k6t6a1n4kb

https://synergisticit.wistia.com/medias/pgrvq4fgni

https://synergisticit.wistia.com/medias/ce4syhm853

All Positions are open for all visas and US citizens

We at Synergistic understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like Apple, google, Paypal, Western Union, Client, visa, Walmart lab s etc to name a few.

Currently, We are looking for entry-level software programmers, Java full-stack developers, Python/Java developers, Data analysts/ Data Scientists, and Machine Learning engineers for full-time positions with clients.

Who Should Apply Recent Computer Science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and are looking to make their careers in the Tech Industry.

We assist in filing for STEM extension and also for H1b and Green card filing to Candidates

We want Data Science/Machine learning/Data Analyst and Java Full stack candidates

For data Science/Machine learning Positions

Required Skills

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Project work on the technologies needed

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Knowledge of Statistics, Gen AI, LLM, Python, Computer Vision, data visualization tools

Excellent written and verbal communication skills

Preferred skills: NLP, Text mining, Tableau, PowerBI, Databricks, Tensorflow

Required Skills

REQUIRED SKILLS For Java /Full stack/Software Positions

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT

Highly motivated, self-learner, and technically inquisitive

Experience in programming language Java and understanding of the software development life cycle

Project work on the skills

Knowledge of Core Java, Javascript, C&plus;&plus;, or software programming

Spring boot, Microservices, Docker, Jenkins, Github, Kubernetes, and REST API experience

Excellent written and verbal communication skills

If you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team and only connect with candidates who match client requirements.

No phone calls, please. Shortlisted candidates would be reached out. No third-party or agency candidates or C2C candidates",Full-time
4151644720,2873708.0,Data Engineer - Junior,"Job Type: Full- Time

Workplace Type: Onsite in Chantilly, VA

Clearance: TS/SCI with a CI Poly

Must be a U.S. Citizen

Benefits: Medical, dental, and vision coverage, 401k matching, generous PTO, paid holidays, professional training opportunities, and even pet insurance to ensure your furry friends are cared for too.

Job Summary

Castalia Systems is seeking a Data Engineer-Junior to support one of our government customers in Chantilly, Virginia. The Data Engineer utilizes a diverse range of data-focused skills, experience, deep technical and analytical problem solving, and team-centered solutioning for complex problems to satisfy priority information enabling operations. This position requires strong attributes for problem solving, data analysis, troubleshooting, analytical thinking, and experimentation, often under time sensitive decisions.

Roles And Responsibilities

A qualified candidate will perform the following duties and responsibilities, but are not limited to:


 * Utilize statistical techniques to analyze and extract relevant information from large amounts of data
 * Automate and optimize data extraction, cleaning, processing and analysis functions
 * Develop, validate, and implement data models to solve problems/answer questions
 * Develop and implement novel statistical approaches to address complex issues
 * Perform data science/engineering with little guidance and independently write reports detailing methods, results, and impacts to assigned issues
 * Support in the acquisition of systems, software, and data science related capabilities. experience performing data science/engineering work and writing reports based upon the resulting work/accomplishments
 * Proficiency in statistics packages such as SPSS, SAS, S-PLUS, and R
 * Programming skills sufficient to extract, transform, and clean multi-terabyte databases
 * Significant current experience (i.e., within last 2 years) in data science/engineering work
   
   

Required Qualifications


 * Bachelor of Science Degree in Science, Technology, Engineering, or Mathematics
 * 0 - 5+ years of progressive, relevant work experience.
 * Develop and implement methods of automation and optimization of data and products to present to upper management
 * Demonstrate understanding of statistical analysis such as regression, anomaly detection and clustering
 * Create data packages in the form of databases (DBs), reports, and interactive visualizations
 * Demonstrate effective communication skills to relay data science activities, technical findings, and data products for both technical and non-technical customers
 * Ability to combine a diverse set of data sources containing multiple forms of information including, but not limited to, Open Source, Publicly Available Information (PAI), Commercially Available Information (CAI), and intelligence records to provide technical information to produce data packages
 * Demonstrated ability to use technical and analytic skills to solve complex problem
   
   

Desired Qualifications


 * Hands-on experience using commercially available data exploitation and visualization tools for analysis (e.g., MS Excel, Tableau, Power BI, Wireshark)
 * Knowledge of National Intelligence Agencies and Department of Defense elements
 * Advanced Statistical knowledge and analysis methods (e.g., Linear models, multivariate analysis)
 * Experience in analytical tool development, identification, and integration
 * Master's degree in a science related field
   
   

Physical Requirements/Work Environment


 * Normal office environment.
   
   

Travel


 * CONUS and OCONUS travel may be required. (10%)
   
   

Company Description

Castalia Systems is a proven business partner providing mission critical solutions to the Federal Government. We provide cutting edge solutions from Securing and Managing Data to Systems Engineering and Development. Castalia Systems is a pioneer in Artificial Intelligence Design and Application.

With our vast knowledge of our customers� needs and relevant technology, our team is able to bring successful solutions to every mission. We are one-upping our competitors by providing premium IT solutions and platforms with cutting-edge technology so it�s so evident when you compare us with anyone.

Disclaimer

Castalia Systems is an equal employment opportunity and affirmative action employer and strives to comply with all applicable laws prohibiting discrimination based on race, color, creed, sex, sexual orientation, age, national origin, or ancestry, physical or mental disability, veteran status, marital status, HIV-positive status, as well as any other category protected by federal, state, or local laws. All such discrimination is unlawful, and all persons involved in the operations of the company are prohibited from engaging in this type of conduct.

#CJ",Full-time
4103521197,3088.0,Data Engineer II -- AWS/Databricks/Snowflake/Python/SQL/ETL,"Who Are We?

Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.

Compensation Overview

The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.

Salary Range

$123,000.00 - $203,000.00

Target Openings

1

What Is the Opportunity?

Travelers BI Modernization Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate stories found in data by leveraging a variety of data programming techniques. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning, data analytics and business intelligence/insights.

What Will You Do?


 * Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.
 * Design complex data solutions
 * Provide technical leadership, staying up to date on trends and technologies to help the team develop effective solutions
 * Mentor and provide guidance to a team of data engineers
 * Empower team members, providing team members with autonomy and ownership over their work
 * Strong knowledge and hands-on skills on Databricks, Python , Snowflake and AWS/Cloud for building data pipelines
 * Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.
 * Incorporate core data management competencies including data governance, data security and data quality.
 * Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.
 * Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.
 * Support BI Mod Ingestion and data domains ecosystem job monitoring, defect fixing and currency up grades.
 * Test data movement, transformation code, and data components.
 * Perform other duties as assigned.
   
   

What Will Our Ideal Candidate Have?


 * Bachelor’s Degree in STEM related field or equivalent
 * Eight years of related experience
 * Highly proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and a full understanding of modern software engineering practices.
 * The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.
 * Demonstrated track record of domain expertise including understanding technical concepts necessary and industry trends, and possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems.
 * Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues.
 * Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners.
 * Ability to lead team members and help create a safe environment for others to learn and grow as engineers. and a proven track record of self-motivation in identifying opportunities and tracking team efforts.
   
   

What is a Must Have?


 * Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
 * Four years of data engineering or equivalent experience.
   
   

What Is in It for You?


 * Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.
 * Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
 * Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
 * Wellness Program: The Travelers wellness program is comprised of tools, discounts and resources that empower you to achieve your wellness goals and caregiving needs. In addition, our mental health program provides access to free professional counseling services, health coaching and other resources to support your daily life needs.
 * Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.
   
   

Employment Practices

Travelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.

In accordance with local law, candidates seeking employment in Colorado are not required to disclose dates of attendance at or graduation from educational institutions.

If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you.

Travelers reserves the right to fill this position at a level above or below the level included in this posting.

To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/.",Full-time
4151573330,17900793.0,Software Engineer,"Waymo is an autonomous driving technology company with the mission to be the most trusted driver. Since its start as the Google Self-Driving Car Project in 2009, Waymo has focused on building the Waymo Driver—The World's Most Experienced Driver™—to improve access to mobility while saving thousands of lives now lost to traffic crashes. The Waymo Driver powers Waymo One, a fully autonomous ride-hailing service, and can also be applied to a range of vehicle platforms and product use cases. The Waymo Driver has provided over one million rider-only trips, enabled by its experience autonomously driving tens of millions of miles on public roads and tens of billions in simulation across 13+ U.S. states.

Software Engineering builds the brains of Waymo's fully autonomous driving technology. Our software allows the Waymo Driver to perceive the world around it, make the right decision for every situation, and deliver people safely to their destinations. We think deeply and solve complex technical challenges in areas like robotics, perception, decision-making and deep learning, while collaborating with hardware and systems engineers. If you’re a software engineer or researcher who’s curious and passionate about Level 4 autonomous driving, we'd like to meet you.

In this hybrid role, you will report to a Senior Engineering Manager.

You Will


 * Design, develop, and deploy components of data pipeline, storage, and query infrastructure that powers the Waymo Driver training and evaluation.
 * Write high-quality, testable, and maintainable code in C++ and SQL.
 * Participate in code reviews and improve engineering practices.
 * Improve existing systems for performance, scalability, and reliability.
 * Monitor system health and performance, proactively addressing issues and providing user support.
 * Collaborate with data scientists, product managers, and engineers across Waymo to understand data needs in Simulation, Planner, Behavior, Perception, and Commercialization.
   
   

You Have


 * Bachelor's degree in Computer Science or related field.
 * 4+ years of professional software engineering experience, focused on backend systems and infrastructures.
 * 2+ years of experience with data structures and algorithms.
 * 2+ years of experience with large-scale distributed systems and data processing frameworks.
 * Proficiency in at least one programming language (C++, Java, or Python).
 * 2+ years of experience with SQL and relational databases.
   
   

We Prefer


 * Proficiency in C++ and SQL.
 * Background in developing databases and query engines.
 * Background in developing large-scale data processing infrastructure.
 * Experience working with data scientists, product managers, and infrastructure engineers to solve business problems.
   
   

The expected base salary range for this full-time position across US locations is listed below. Actual starting pay will be based on job-related factors, including exact work location, experience, relevant training and education, and skill level. Your recruiter can share more about the specific salary range for the role location or, if the role can be performed remote, the specific salary range for your preferred location, during the hiring process.

Waymo employees are also eligible to participate in Waymo’s discretionary annual bonus program, equity incentive plan, and generous Company benefits program, subject to eligibility requirements.

Salary Range

$158,000—$200,000 USD",Full-time
4143046451,101021.0,Data Engineer (Cleared),"Data Engineer (cleared)

Location: Arlington, VA (Hybrid in The Washington DC area)

Clearance: US Public Trust

People Centered. Data Driven

Elder Research Inc. is a Data Science consulting firm specialized in providing analytic solutions to clients in Commercial and Government industries. Providing analytic solutions to hundreds of companies across numerous industries, our team enjoys a great variety in the type of work they do and exposure to a wide range of techniques and tools. We are trusted advisors to our clients, building lasting relationships and partnering as preferred analytics providers. We use a variety of programming languages and tools to create analytic solutions, often fitting within our clients’ environment and needs.

Summary Of Position

As a Data Engineer, you will work directly with clients, managers, and technical staff to understand business needs, develop technical plans, and deliver data-driven analytical solutions and tools that solve client problems. The Data Engineer will primarily create and deploy robust, repeatable, and automated data pipelines that will ingest and transform raw data to support various advanced analytics and machine learning models. The resulting pipeline should be developed to be deployed into existing large-scale applications or different data visualization platforms available.

This position will be part of our Government Civilian Team serving Federal Civilian agencies as our primary customers. To be considered for this position, you must be currently eligible to legally obtain a US Public Trust issued by the US. Government.

Essential Functions


 * Strong troubleshooting and problem-solving capabilities
 * Demonstrated experience with various types and sizes of data sets, both quantitative and text
 * Work collaboratively with data scientists, data analysts, and client engagement managers to create and deploy dynamic data applications or data visualization tools that help our customers make meaningful business decisions.
 * Writing re-usable code in Python, SQL, Java or other languages, and working to refine it through code review and discussion
 * Develop and deploy robust data pipelines and end-to-end systems in an air-gapped environment
 * Participate in every stage of the engineering lifecycle, from ideation and requirements gathering through implementation, testing, deployment, and maintenance
 * Provide leadership and coordination for certain stages of the engineering lifecycle as needed
 * Perform other technical tasks as needed, including writing project reports, managing, implementing, and/or maintaining technical infrastructure, etc.
 * Ability to consider both long-term stability and scalability while taking a user-focused approach to development and deployment.
 * Meetings and discussions with clients and co-workers to refine understanding of the business problem at hand.
 * Preparing presentations, writing reports (technical and non-technical), and working to communicate technical results to clients with varying levels of analytic sophistication.
 * Ability to work independently in a collaborative, dynamic, cross-functional environment.
 * Demonstrate strong communication and consulting skills, facilitating effective collaboration within a diverse team.
   
   

Job Specifications/Requirements


 * Undergraduate and graduate degrees in engineering, computer science, analytics, math, finance, accounting, management information systems, social sciences, physics, or decision science.
 * Design, build, and deploy data engineering pipelines that extracts, transforms raw data into analytics base tables to support downstream machine learning models using languages such as Python, R and SQL
 * Develop end-to-end ML pipelines, responsible for integration from back to front end in on-premises and cloud environments.
 * Collaborate closely with data scientists, data analysts, client engagement managers, and product managers to understand business requirements and provide solutions.
 * Improve and modernize existing ML pipelines and operations, emphasizing best practices and efficiency gains.
 * Work in a fast-paced environment, contributing to a collaborative and agile development process.
 * Experience engaging and interacting with clients, stakeholders and subject matter experts (SMEs) to understand, gather and document requirements.
 * Comfortable learning new things and working outside of your comfort zone.
 * Communicate clearly both verbally and in writing to teammates and clients.
 * Humble and willing to learn, teach, and share ideas.
 * Travel to and work on-site at clients both local and non-local. Number of days at client site vary depending on project requirements.
 * Must currently possess a Public Trust Clearance
   
   

Desired Skills


 * Advanced degree (MS) in a relevant field (analytics, math, statistics, computer science, management information systems, social sciences, engineering, physics, decision science, or business, etc.,)
 * Experience using version control (e.g. git, svn, Mercurial) and collaborative programming techniques (e.g. pair programming, code reviews)
 * Experience with containerization and environment management (venv, conda, etc.,)
 * Experience with one or more technologies, such as R Shiny, Databricks, AWS, Azure
 * Familiarity with vector, object, and document storage databases
 * Experience implementing data engineering processes in a remote, austere environment to include using bash,
 * Experience with business intelligence and data visualization platforms (Power BI, Tableau, etc.,).
 * Understanding of the data analytics lifecycle (e.g. CRISP-DM).
   
   

Elder Research, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

To be considered for this position, you must be eligible to legally obtain a US Public Trust.",Full-time
4142822863,75530431.0,Data Engineer,"Interwell Health’s Data Engineer role is responsible for corporate claims data acquisition, file loading and structure development. The ideal candidate will have a strong background in data engineering and will be responsible for designing and developing database systems, processes, and documentation. This includes collecting data, analyzing data, designing algorithms, drawing flowcharts, and implementing code, and maintaining the EDW databases.




The work you will do:




 * Collaborates effectively with the development groups to deliver projects to the satisfaction of the client in a timely fashion.
 * Maintains current knowledge of the latest and newest technologies in the areas of specific relevancy to the Data Architecture group for utilization as appropriate within the department. Identifies and researches enhancement options and process improvements, making suggestions to senior managers as needed and drive continued improvement and innovation.
 * Assist with schema design, code review, SQL query tuning.
 * Write and deploy SQL code.
 * Guide and mentor junior teammates acting as a resource with respect to the definition of development processes, methodologies and frameworks and other technical aspects of the projects and provides direction and assistance regarding working with users and the process and issues encountered with user interaction.
 * Become skilled with the architecture and technology supporting the Datawarehouse, to design and develop accordingly.
 * Ensure the distribution of knowledge for processes being designed and built within the team to ensure assigned jobs are completed accurately and according to schedule and that all deadlines are met.
 * Ensure the design of sufficient documentation for easy and smooth hand-over of projects.
 * Participate in the formulation and design of methodologies.
 * Trains in developing tools that are available with the Datawarehouse and Lakehouse infrastructure and help with development, where appropriate.
 * Monitor and troubleshoot data pipelines to identify and resolve performance issues, bottlenecks, and data anomalies.




The skills and qualifications you need:




 * 3-5 years related experience in data engineering with bachelor’s degree; or a master’s degree with 3 years’ experience.
 * Ability to architect simple and complex solutions related to integration with other applications and design.
 * Excellent communication skills, both verbal and written.
 * Strong presentation skills. Ability to present formally to users and customers during gathering requirements, workshops, and feedback sessions.
 * Experience working under tight deadlines while maintaining high product relevance and quality.
 * Azure/SQL focus
 * Strong understanding of data lake and Lakehouse architecture principles, data modeling techniques, and data warehousing concepts.
 * 3-5 years’ experience using Azure Data Factory pipelines and Databricks.
 * 5 years’ experience working with Azure databases.
 * Extensive experience with MS SQL stack. (SSIS and ADF)
 * Extensive experience with Azure - Cloud migration.
 * Python experience.",Full-time
4151634755,809238.0,Jr. Big Data Engineer,"Big Data Engineer

Are you seeking to grow and enhance your technical career to new heights, in a full-time, W-2 opportunity?

What if an organization existed solely for the purpose of investing in YOU, being of service to YOU, showing you how, and supporting you every step of the way?

Is a customized and personalized approach to your learning journey, career development, and overall ability to maximize your earning potential important to you?

Let’s make it happen – together!

What’s In It For YOU?


 * Full time, W-2 employment, with FREE, paid 8-week training in Big Data engineering (an Industry-Proof Technology) at our headquarters in Atlanta, GA
 * Complete and total support post training to secure and thrive while working for end-clients
 * Paid corporate-sponsored housing during above mentioned training
 * Relocation assistance for training and all projects, as needed
 * Robust W2 employee benefits
 * Full coverage medical, dental, vision insurance coverage through Cigna Open Access POS plans
 * 401K eligibility after one calendar year of employment, 3% company match
 * Basic life/AD&D, Dependent Disability (short/long term) coverage
 * Work visa sponsorship for Foreign Nationals
 * Opportunity for nationwide U.S. travel
 * Company-sponsored technical certifications, as necessary, per technology
 * Learn to become a best-in-class engineer, developer, and consultant
 * Development in proven soft skills and interviewing skills methods
 * An expert technical engineer development program
 * Project deliverable support (once on project)
 * Exposure to a breadth and depth of best-practice production environments, code bases, and tech stacks with 100’s of industry-leading end clients
 * Opportunities to assist our end clients across multiple states architect, test, deploy, maintain, document, and scale upward
   
   

Who Are We?

First – we're a top-tier IT consulting firm, providing best-in-class Big Data solutions for companies across an array of industries including finance, energy, ecomm, logistics, travel, retail, entertainment, auto, and healthcare. We serve many end clients, some of which include Microsoft, Google, Johnson & Johnson, Fannie Mae, Walmart, PayPal, T-Mobile, McDonalds, CVS, Verizon, Charter, Nike, Dell, Wells Fargo, Capital One, Charles Schwab...just to name a few!

As a consultant, this means you, too, will have these well-known, industry-leading end-client experiences when you join our team!

Second – we're a people development firm. When you join our organization, you come to us with the required foundational technical skills, coding ability, educational degree, and general understanding that will serve as a foundation to learning Big Data Engineering. It’s our mission to mentor, develop, and train you, as mentioned above, to learn Big Data, so you can then gain experience and provide world-class consultative services to our end clients.

Company Highlights


 * Our Expertise: IT consultative services and quality engineer development through recruiting, hiring, and coaching our consultants
 * Longevity: 25+ years of combined domestic and international experience in IT consulting
 * Depth: Hundreds of Fortune 1000, 500, and innovative start-up end clients with 1000’s of successfully completed and on-going projects across the US, EU, and UK
 * Global Reach: Employee work force is diverse, spanning across 4 continents of North America, Europe, South America, and Asia
 * Growth & Innovation: Active monitoring and measurement of the market across all technological sectors to adapt to and implement what's ""next”
   
   

How We Will Help You


 * Teach and Develop: We will instruct and train you in Big Data to become a best-in-class consultant through our proven method and program, capable of delivering end-client deliverables, through our paid, 6-8-week training course
 * Customized Support: Several teams will be ready to support and collaborate with you in a custom-tailored way; this includes our teams of Development Managers, Tech Subject Manager Experts, Project Deliverable Support, Corporate Trainers, Interview Coaches, Client Placement Specialists, and Immigration Specialists (for our foreign national candidates)
 * Project Placement: Our dedicated market-expertise sales team will help you seek, secure and maintain a project with our myriad end clients
 * Career Growth: You will gain the necessary industry experience to drive and propel your technical profession forward for many years to come!
   
   

What You Bring To The Role


 * Degree in Computer Science, Information Systems, or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role, master's degree would be not required but preferred.
 * 5+ years of experience working in a corporate environment within IT or 5-8 years of company work experience with 2 of those years being within IT.
 * Great interview skills as you will be interviewing with many companies and leads in the tech industry.
 * Demonstrated ability to build processes that support data transformation, data structures, metadata, dependent, and workload management.
 * Strong interpersonal skills and ability to project manage and work with cross-functional teams.
 * Working SQL knowledge with relational databases, query authoring, as well as working familiarity with a variety of databases
 * Availability to travel (80% after Training portion) and live in the U.S.
 * Strong English written and verbal communication skills
 * Excited by being a data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up
 * Looking to be optimizing or even re-designing a company’s data architecture to support next generation and data initiatives
 * Ability to be self-directed and comfortable supporting the data needs of multiple teams, systems and products
 * Nice-to-have:
    * Relational SQL and NoSQL databases
    * Object-oriented/Object function scripting languages such as Python, Scala, etc.",Full-time
4076964254,5262441.0,GCP Data Engineer,"Senior GCP Data Engineer


 * Design and develop big data applications using the latest open source technologies.
 * Desired working in offshore model and Managed outcome
 * Develop logical and physical data models for big data platforms.
 * Automate workflows using Apache Airflow.
 * Create data pipelines using Apache Hive, Apache Spark, Apache Kafka.
 * Provide ongoing maintenance and enhancements to existing systems and participate in rotational on-call support.
 * Learn our business domain and technology infrastructure quickly and share your knowledge freely and actively with others in the team.
 * Mentor junior engineers on the team
 * Lead daily standups and design reviews
 * Groom and prioritize backlog using JIRA
 * Act as the point of contact for your assigned business domain
   
   

Requirements

GCP Experience


 * 3+ years of recent GCP experience
 * Experience building data pipelines in GCP
 * GCP Dataproc, GCS & BIGQuery experience
 * 5+ years of hands-on experience with developing data warehouse solutions and data products.
 * 5+ years of hands-on experience developing a distributed data processing platform with Hadoop, Hive or Spark, Airflow or a workflow orchestration solution are required
 * 4+ years of hands-on experience in modeling and designing schema for data lakes or for RDBMS platforms.
 * Experience with programming languages: Python, Java, Scala, etc.
 * Experience with scripting languages: Perl, Shell, etc.
 * Practice working with, processing, and managing large data sets (multi TB/PB scale).
 * Exposure to test driven development and automated testing frameworks.
 * Background in Scrum/Agile development methodologies.
 * Capable of delivering on multiple competing priorities with little supervision.
 * Excellent verbal and written communication skills.
 * Bachelor's Degree in computer science or equivalent experience.",Full-time
4061748662,2646.0,"Principal, Data Engineer","Position Summary...

What you'll do...

About The Role

We are seeking a highly motivated and experienced Principal Data Engineer to join our growing team. In this role, you will play a critical part in designing, building, and scaling our next-generation data and analytical platform for advertising systems. You will be a key technical leader, driving innovation and ensuring we deliver a robust and scalable platform that empowers data-driven decisions across the organization. This role involves working with cutting-edge open-source technologies on cloud platforms like GCP and Azure.

What You Will Do


 * Architect, design, and implement high-performance data pipelines and ETL processes for large-scale advertising data.
 * Develop and maintain data infrastructure and platforms using open-source technologies, ensuring scalability, reliability, and security.
 * Collaborate with data scientists to build and deploy machine learning models that generate insights and recommendations for optimizing advertising campaigns.
 * Work closely with stakeholders to understand business requirements and translate them into technical solutions.
 * Champion data quality, governance, and best practices across the organization.
 * Mentor and guide junior data engineers, fostering a culture of technical excellence.
 * Stay abreast of industry trends and emerging technologies, identifying opportunities to enhance our data and analytical capabilities.
 * Contribute to the development and evolution of our data strategy and roadmap.
   
   

What You Will Bring


 * Deep understanding of data warehousing concepts, dimensional modeling, and ETL best practices.
 * Strong proficiency in SQL and at least one scripting language like Python or Java.
 * Hands-on experience with open-source big data technologies such as Hadoop, Spark, Kafka, and Hive.
 * Experience with cloud platforms like GCP or Azure, including their data storage, processing, and analytics services.
 * Familiarity with data modeling tools and techniques.
 * Excellent communication and collaboration skills, with the ability to work effectively in a cross-functional team.
 * Passion for data and a strong desire to solve complex problems.
 * Experience with advertising systems and data a plus.
 * Experience with machine learning and data science concepts is a plus.
   
   

Preferred Qualifications


 * Advanced degree in data science, computer science, statistics, operation research, or related fields
 * 8+ years of experience in data engineering, with a proven track record of building and scaling data-intensive applications.
 * Experience leading teams is a big plus.
   
   

Bonus Points


 * Experience with data visualization tools (e.g., Tableau, Looker)
 * Experience with data governance and data privacy best practices
 * Experience with real-time data processing and streaming technologies
   
   

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

‎

‎

‎

You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.

‎

For information about PTO, see https://one.walmart.com/notices.

‎

‎

Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

‎

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.

‎

For Information About Benefits And Eligibility, See One.Walmart.

‎

The annual salary range for this position is $143,000.00-$286,000.00

‎

Additional Compensation Includes Annual Or Quarterly Performance Bonuses.

‎

Additional Compensation For Certain Positions May Also Include

‎

‎


 * Stock
   
   

‎

‎

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelor’s degree in Computer Science and 5 years' experience in software engineering or related field. Option 2: 7 years’ experience in software engineering or related field. Option 3: Master's degree in Computer Science and 3 years' experience in software engineering or related field.

4 years' experience in data engineering, database engineering, business intelligence, or business analytics.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Master’s degree in Computer Science or related field and 5 years' experience in software engineering or related field, We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart’s accessibility standards and guidelines for supporting an inclusive culture.

Primary Location...

680 West California Avenue, Sunnyvale, CA 94086-4834, United States of America",Full-time
4125160318,2010798.0,Data Platform Engineer,"Tiger Analytics is a fast-growing advanced analytics consulting firm. Our consultants bring deep expertise in Data Science, Machine Learning and AI. We are the trusted analytics partner for several Fortune 100 companies, enabling them to generate business value from data. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner. We are looking for top-notch talent as we continue to build the best analytics global consulting team in the world.

Requirements

High Level Design: Lead the solution design and implementation of end-to-end

data pipelines that support real-time streaming, data syndication, and integration

across multiple platforms, focusing on high availability, scalability, and

performance.

Technical Leadership: Manage and mentor a team of engineers, providing

guidance on technical approaches, troubleshooting, and problem resolution.

Lead the implementation of best practices for coding, testing, deployment, and

monitoring of data products.

Data Platform Modernization: Drive modernization efforts for existing data

platforms, ensuring smooth migration and integration with cloud-native

technologies and streaming data frameworks.

Streaming Technologies: Design and implement robust streaming data

pipelines using technologies such as Apache Kafka, Kinesis, Flume, and other

relevant tools to enable real-time data processing and integration.

Cloud Integration: Intimately understand AWS to architect and deploy cloud-

based data solutions that integrate seamlessly with the larger data ecosystem.

Performance Optimization: Identify bottlenecks in data workflows and

implement solutions to improve performance, reduce latency, and increase

throughput.

Reliability & Maintenance: Ensure that the data platform is reliable, resilient,

and able to handle high-volume data processing workloads, with a strong focus

on monitoring, incident management, and uptime.

Data Engineering Practices: Advise and enforce best practices around data

management processes, batch vs. real-time processing, data storage strategies,

and data quality.

Collaboration with Stakeholders: Work closely with cross-functional teams,

including data scientists, product managers, business analysts, and IT

operations, to deliver business value and ensure alignment of architecture with

organizational goals.

Technical Expertise

Data Engineering: Proven experience designing and implementing scalable,

high-performance data systems in cloud environments, specifically for large-

scale data ingestion, storage, and processing.

Streaming Technologies: Advanced knowledge of real-time data streaming

platforms such as Apache Kafka and AWS Kinesis.

Cloud Platforms: Expertise in working with AWS as well as a deep

understanding of the intricacies involved in moving cloud workloads to on-prem

having a common interface to be able to easily move workloads from cloud to on-

prem. Experience designing compute agnostic and multi-tenant solutions.

Databricks: Proficiency in Databricks for big data processing, particularly in

managing data pipelines and large-scale analytics workloads.

Programming: Strong hands-on experience with Scala and Java for developing

data-intensive applications, data pipelines, and stream processing systems.

Big Data Frameworks: Familiarity with Apache Spark for distributed data

processing.

Kubernetes: Experience with Kubernetes or other orchestration frameworks.

Experience writing infrastructure as code.

Benefits

Significant career development opportunities exist as the company grows. The position offers a unique opportunity to be part of a small, challenging, and entrepreneurial environment, with a high degree of individual responsibility.",Full-time
4132152657,2908890.0,Data Engineer,"Job Summary

Data engineer role will help shape AbsoluteCare’s Data Warehouse and Data Strategy for current and future implementations. The Data Engineer with work in close collaboration with AbsoluteCare Leaders to translate Business asks into IT solutions.

The Data Engineer will work on identifying the right solution for both existing and new requirements by enhancing / converting existing systems or creating newer solutions.

Duties


 * Design and build robust healthcare platform on MS SQL Server
 * Analyze and integrate healthcare payer data and Clinical EHR data.
 * Follow best SDLC practices for developing IT solutions
 * Document and communicate strategy used for Design and Development.
 * Develop and deliver on key milestones on roadmap for Data Warehouse.
 * Automate manual reporting and develop novel reporting using the Microsoft BI stack and other reporting tools
   
   

Education And Experience


 * Bachelor’s degree in business, information technology, statistics, mathematics, health sciences, or related field or equivalent work experience required.
 * 2+ years of combined working experience on Microsoft stack including SQL, SSIS, SSMS, .NET OR C#
 * Preferred 1-3 years of developing SQL Development
 * Preferred 1-3 years of C# Development
 * Preferred 3 years of health care data experience
 * Preferred 1 year of Python experience
 * Intermediate proficiency with Microsoft Excel required.
 * Technical knowledge of relational databases (SQL server), querying, data warehouses, and decision support tools required.",Full-time
4147102729,5322.0,Data Engineer,"100% Remote

Long Term Contract


 * Contribute to data architecture of a Snowflake data warehouse
 * Create ELT process to gather data from numerous client data sources into a snowflake database
    * Using Kafka, DBT, Airflow and custom tools to move/transform data

 * Setup views and permissions in Snowflake to share data with 3 rd party Snowflake accounts.

Skill set:

Python, DBT or Apache Airflow (Nice to Have), SQL,

Snowflake Data Architecture, JavaScript, Azure DevOps",Full-time
4151624945,36095797.0,Software Engineer - Full-Stack (All Levels),"EvenUp is on a mission to support injury law firms across America in providing a consistent and high standard of representation, ensuring that every injury victim who seeks legal assistance can expect a fair resolution. We’ve helped thousands of victims get fair compensation by empowering their representation with best-in-class insights, automation, and document creation.

As a Full-Stack Engineer at EvenUp, you'll be a pivotal part of our rapidly growing team, playing a crucial role in developing our groundbreaking legal platform. You’ll work closely with an innovative team of engineers, data scientists and legal experts to actively shape the product’s development and deliver mission critical, user-centric and intuitive interfaces. This role is not just about coding, it’s about building first-of-a-kind technology with a meaningful impact on millions of lives.

This is a hybrid role with 2-3 days per week spent collaborating with the team in the office. We are open to applicants located in either the Greater Toronto Area or in the San Francisco Bay Area.

What You'll Do


 * Build and refine the front-end of our AI-driven platform to deliver an intuitive, responsive and user-friendly interface
 * Collaborate closely with backend engineers, product owners & designers to develop efficient, innovative solutions
 * Implement robust, maintainable, reusable code in a modern tech-stack including React, Typescript, and other technologies
 * Optimizing application performance and responsiveness to ensure a smooth user experience
 * Rapidly prototype and iterate on ideas with a focus on delivering production-ready code in a fast-paced environment
 * Engage in continuous learning opportunities including exposure to ML, data engineering, and DevOps practices
 * Actively engage in the full project lifecycle, with full ownership from conception to deployment and iteration
 * Work with a world-class team: Our team has deep expertise in technology, machine learning, law, and finance, combining experiences from careers at Google, Uber, Waymo, Quora, Vimeo, Blizzard, and more
   
   

What We Look For


 * Extensive experience in building frameworks, libraries, and distributed systems with an eye for reliability, observability, and performance
 * Proven proficiency in software development, with hands-on experience in Python or other programming languages such as Go, Java, Node.js or C++
 * An understanding of modern frontend technologies, particularly TypeScript, React, JavaScript, CSS, and the DOM, with 3+ years of frontend development experience
 * Ability to craft and deliver high-quality software solutions, including production-ready code, RESTful APIs, and managing infrastructure to industry standards
 * Track record of successfully delivering complex projects with clear, structured thinking and leadership from concept to deployment
 * Experience working in dynamic, fast-paced environments, such as startups, thriving in collaborative, growth-oriented settings
 * Excellent communication skills, with the ability to collaborate effectively with cross-functional teams from diverse backgrounds
 * Strong ownership and personal accountability which are driven by your problem-solving skills, creativity, and initiative in driving projects to completion
   
   

Bonus: Experience in AI, legal tech, or social impact projects.

Benefits & Perks

Our goal is to empower every team member to contribute to our mission of fostering a more just world, regardless of their role, location, or level of experience. To that end, here is a preview of what we offer:


 * Choice of medical, dental, and vision insurance plans for you and your family
 * Flexible paid time off
 * 10 US observed holidays, and Canadian statutory holidays by province
 * A home office stipend
 * 401(k) for US-based employees
 * Paid parental leave
 * Sabbatical program
 * A meet-up program to get together in person with colleagues in your area
 * Offices in San Francisco and Toronto
   
   

Please note the above benefits & perks are for full-time employees

About EvenUp

EvenUp is on a mission to level the playing field in personal injury cases. EvenUp applies machine learning and its AI model known as Piai™ to reduce manual effort and maximize case outcomes across the personal injury value chain. Combining in-house human legal expertise with proprietary AI and software to analyze records. The Claims Intelligence Platform™ provides rich business insights, AI workflow automation, and best-in-class document creation for injury law firms. EvenUp is the trusted partner of personal injury law firms. Backed by top VCs, including Bessemer Venture Partners, Bain Capital Ventures (BCV), SignalFire, NFX, DCM, and more, EvenUp’s customers range from top trial attorneys to America’s largest personal injury firms. EvenUp was founded in late 2019 and is headquartered in San Francisco. Learn more at www.evenuplaw.com.

EvenUp is an equal opportunity employer. We are committed to diversity and inclusion in our company. We do not discriminate based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

",Full-time
4125894638,2684081.0,Data Engineer," * Qualifications:Strong experience in AWS development and/or architecture with a financial services background.
 * Proficiency in AWS Glue, Athena, Lambda, S3, Event Bridge, and SNS.
 * Deep knowledge of infrastructure components like Direct Connect and Transit Gateway.
 * Hands-on experience in database migrations and Informatica transformations.
 * Proven ability to design and implement scalable, secure, and reliable AWS solutions.
 * Excellent problem-solving skills, with the ability to work independently and collaboratively.
 * Strong leadership and communication skills to coordinate across teams.



 * Key Responsibilities for AWS Developer:Develop and implement solutions using AWS Glue and Athena for data analysis and transformation.
 * Create and maintain Lambda functions to support business processes and event-driven architectures.
 * Leverage AWS services such as S3 buckets, Event Bridge, and SNS for application development and integration.
 * Collaborate with teams to ensure efficient development and delivery of cloud-based solutions.
 * Assist with database migrations and/or Informatica transitions from on-prem to cloud environments.

",Contract
4126028518,27116538.0,Data Engineer,"Who We Are: ThinkTek LLC is a fast-growing Certified SBA 8(a) and Service-Disabled Veteran-Owned Small Business (SDVOSB) company. We specialize in providing management and technology consulting services to support the business and technology modernization efforts of the Federal Government. ThinkTek was formed with the specific purpose of providing its clients a tailored solution around Program & Project Management, Strategic Planning, and IT Operations.

Position Description: We are seeking a highly skilled and motivated Data Engineer to join our dynamic team. The ideal candidate will be responsible for performing data mapping, data quality management, metadata management, and master data management, as well as conducting in-depth data analysis to inform and progress our current and future data operating models. The Data Engineer will play a critical role in shaping our data architecture and ensuring the integrity and quality of our data assets.


 * Develop, maintain, optimize, and document SQL queries for data analysis and reporting tasks to ensure, reuse and meet stakeholder needs.
 * Identify and fix data issues (e.g., missing values, outliers, duplicates, inconsistencies) by developing and executing Oracle DML statements, and clean and preprocess raw data for accuracy and consistency.
 * Using Excel and SQL to prepare, analyze, and transform data; conduct statistical analyses; and create visual reports to highlight trends and insights.
 * Communicate findings and insights clearly to both non-technical and technical stakeholders using tools such as Excel, Word, PowerPoint, and Visio.
 * Continuously monitor and implement data validation checks, manage data quality, metadata, and master data, and perform data mapping and analysis. Document findings, provide recommendations, and develop data architecture artifacts to enhance current and future data operating models.
 * Leverage AWS services (e.g., S3, RDS, Lambda) to manage, store, and process large datasets, ensuring data security and compliance with best practices.
 * Monitor and manage data storage costs in AWS, ensuring efficient use of resources and scalability of the database environment.
   
   

Salary Range: 100k-125k - Commensurate with the candidate's skills, experience, location, and qualifications.

Required Qualifications


 * Clearance: Active US DoD Top Secret security clearance or higher.
 * Associate/bachelor's degree with 3+ years of relevant experience
 * Proficiency in Excel, Visio, and Oracle SQL Developer.
 * Experience performing the tasks identified above in AWS and Oracle environments.
 * Strong expertise in data analysis, data architecture, and data services development.
 * Ability to work independently and as part of a team, effectively collaborating with various stakeholders.
 * Advanced analytical and troubleshooting skills with good problem-solving abilities.
 * Experience working with and supporting Agile development teams.
 * Excellent written and verbal communication skills
   
   

Preferred Qualifications


 * Experience with data visualization tools (e.g., Tableau, Power BI, or Pentaho Report Designer) is a plus.
 * Knowledge of data governance and data management best practices is also a plus.
 * Security+ Certification, preferred
   
   

ThinkTek offers telework and other flexible work arrangements to the greatest extent possible. ThinkTek LLC is proud to be an Equal Opportunity Employer (EOE), making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. ThinkTek offers medical, dental, and vision insurance to all full-time employees; PTO and a variety of other paid leave options are also available. You can read more about ThinkTek benefits at https://www.thinktekllc.com/careers/.",Full-time
4151623324,72494634.0,Senior Data Engineer,"Acrisure Innovation

Austin, TX

Why Choose Acrisure?

Acrisure Innovation is where human expertise meets advanced technology.

Acrisure Innovation is a fast paced, AI-driven team building innovative software to disrupt the $6T+ insurance industry. Our mission is to help the world share its risk more intelligently to power a more vibrant economy. To do this, we are transforming insurance distribution and underwriting into a science.

At the core of our operating model is our technology: we’re building a digital marketplace for risk and applying it at the center of Acrisure, a privately held company recognized as one of the world's top 10 insurance brokerages and the fastest growing insurance brokerage globally. By leveraging technology to push the boundaries of understanding and transferring risk, we are systematically converting data into predictions, insights, and choices, and we believe we can remove the constraints associated with scale, scope, and learning that have existed in the insurance industry for centuries.

Our culture is strong. We are a collaborative company of entrepreneurial, innovative, and talented people who believe in our future. We outthink and out work the competition. We look outside our walls and are energized by our fast-paced trajectory.

Our vision for the future is clear. We have limitless potential to achieve unprecedented success in the insurance industry. To achieve our opportunity, a best-in-class Team must support us.

Learn more about Acrisure Innovation: https://builtin.com/company/acrisure-innovation

Position Overview

The Innovation team’s mission is to unify data across the enterprise to optimize business decisions made at the strategic, tactical, and operational levels of the organization. We accomplish this by building a data lakehouse that powers analytics and reporting platforms, and business processes that provide quality data, in a timely fashion, from any channel of the company and present them in such a manner as to maximize the value of that data for both internal and external customers. 

The Senior Data Engineer is responsible for designing and developing complex ELT processes required to populate our data lakehouse which supplies data for the Product, AI & Data Intelligence teams.  Responsibility includes hands-on contributions in data engineering and data architecture working with a team of full time and contracted developers as well as coaching and mentoring junior and mid-level developers. Ensuring high quality and best practices are maintained through the development cycle is key to this position. 

Responsibilities: 


 * Leverage established guidelines and custom designs to create complex ELT processes to meet the needs of the business. 
 * Onboard and curate data sources including data preparation/ELT and modeling to enable data consumption by analytics and AI teams
 * Act as a Solution Architect and Technology Leader – ability to make decisions in the face of ambiguity and solve difficult technical problems.
 * Lead discovery, requirements, level of effort estimation and project planning for strategic company initiatives. 
 * Independently determine methods and procedures for new or existing requirements and functionality. 
 * Onboard, Lead, and Mentor junior and mid-level developers.
 * Work closely with Data Source contacts, Analysts, Product and Data Intelligence teams to identify opportunities and assess improvements of our products and services. 
 * Contribute to workshops with the business user community to further their knowledge and use of the data ecosystem. 
 * Produce and maintain accurate project documentation, project planning and presentations. 
 * Collaborate with various data providers to resolve dashboard, reporting and data related issues. 
 * Perform Data benchmarking, enhancements, optimizations, and platform analytics. 
 * Participate in the research, development, and adoption of trends in technology, data and analytics
   
   

Qualifications & Requirements: 

Bachelor's degree preferred or equivalent experience along with a demonstrated desire for continuing education and improvement. 

Experience: 


 * Minimum 8-10 years in Data Engineering, preferably with expertise in an Azure environment with Data Bricks, Azure Data Factory, Azure Data Lake.  
 * Minimum 8-10 years architecting and designing data warehouses, data modeling, and end-to-end ELT processes
 * Successfully delivered 5+ end to end projects – from Inception to Execution - in Data Engineering / Data Science / Data Integration as a Tech Lead/Principal
 * Strong hands-on experience with Data Lake & Delta Lake Concepts.
 * Strong hands-on experience with Databricks Unity Catalog and usage in dealing with Delta tables.
 * Ability to Analyze, summarize, and characterize large or small data sets with varying degrees of fidelity or quality, and identify and explain any insights or patterns within them.
 * Experience with multi-source data warehouses  
 * Experience with other cloud environments (GCP) a definite plus. 
 * Experience in data analytics and reporting, particularly with Power BI a plus
 * Hands on experience building logical data models and physical data models
 * Write SQL fluently, recognize and correct inefficient or error-prone SQL, and perform test-driven validation of SQL queries and their results.
 * Create and share standards, best practices, documentation and reference examples for data warehouse, integration/ELT systems, and end user reporting
 * Apply disciplined approach to testing software and data, identifying data anomalies, and correcting both data errors and their root causes
 * Should be well versed with Key Vault \ create & maintenance and usage of secrets in both Databricks & ADF
 * Should be knowledgeable in Stored procedures \ functions and be able to use them by ADF & Databricks as this is a widely used Practice in Acrisure.
 * Should be familiar with DevOps process for Azure artifacts and database artifacts.
 * Should be well versed with ADF concepts like chaining pipelines, passing parameters, using APIs for ADF & Databricks to perform various activities.
 * Should be well versed with Agile and Scrum principles and procedures, and working with Jira
   
   

Additional Qualifications


 * Excellent organizational skills with the ability to prioritize, communicate and execute tasks across multiple projects with tight deadlines and aggressive goals. 
 * Expert working knowledge of SQL, Python and Spark, and demonstrated ability to create ad-hoc SQL queries to analyze data, create prototypes, etc. 
 * Ability to understand complex issues and clearly articulate complex ideas. 
 * Demonstrated ability to champion change, influence, and drive results in a complex organization. 
 * Ability to mentor junior developers and contribute to the growth of the team. 
 * Excellent verbal and written communication skills. 
 * Experience working in a Multi-Cloud Environment a Plus
 * Experience working with dbt a Plus
 * Knowledge of the Insurance Industry or FinTech a Plus
   
   

Acrisure is equally committed to supporting social issues. In its home of Grand Rapids, Acrisure provided $15 million to create the Acrisure Center for Innovation in Children’s Health at Helen DeVos Children’s Hospital.

Acrisure is committed to employing a diverse workforce. All applicants will be considered for employment without attention to race, color, religion, age, sex, sexual orientation, gender identity, national origin, veteran or disability status.

We are interested in every qualified candidate who is eligible to work in the United States. We are not able to sponsor visas for this position.

To Executive Search Firms & Staffing Agencies: Acrisure does not accept unsolicited resumes from any agencies that have not signed a mutual service agreement. All unsolicited resumes will be considered Acrisure’s property, and Acrisure will not be obligated to pay a referral fee. This includes resumes submitted directly to Hiring Managers without contacting Acrisure’s Human Resources Talent Department.

https://www.acrisure.com/acrisureacastaffprivacynotice/

#BI-Hybrid

",Full-time
4045407905,66321745.0,JUNIOR SOFTWARE ENGINEER (REMOTE),"SYNERGISTICIT wants every candidate to know that the Job Market is Challenging and to stand out, you need to have exceptional skills and technologies and that's where we come in to make sure you get the attention which you need

SynergisticIT understands the complex nature of the job market and how difficult it can be to secure a position, especially for fresh graduates. Therefore, we assist and help tech-savvies to convert their passions into professions. We go above and beyond to keep you working in your niche.

As we focus on long-term success, we provide complete career development solutions. From job search to upskilling portfolio and interview preparation, we can guide you at every step of your career.

SynergisticIT spares no efforts to connect you with a large network of tech giants, including Google, Apple, PayPal, Dell, Cisco, Client, etc. Presently, we are actively looking for JUNIOR SOFTWARE ENGINEER (REMOTE) a driven mindset. Get the right opportunity and gain experience in building web-centric solutions on Java.

Who Should Apply : Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or anyone looking to make their career in IT Industry

We also assist in filing for STEM extension and H1b and Green card filing.

Candidates who are serious about their future in the IT Industry and have set big goals for themselves.

Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. We also offer Skill Enhancement Programs if the candidates are missing skills or experience which our clients need with great outcomes

Candidates can benefit from skill enhancement if they fall into the below categories. If they are qualified with enough skills then no need for skill enhancement

Candidates Who Lack Experience

Have had a break in careers

Lack Technical Competency

candidates who want to get employed and make a career in the Tech Industry

Please Also Check The Below Links

https://www.synergisticit.com/candidate-outcomes/

https://www.synergisticit.com/java-track/

https://www.synergisticit.com/data-science-track/

https://www.synergisticit.com/which-is-the-best-option-for-tech-job-seekers-staffing-companies-consulting-companies-bootcamps-or-synergisticit/

https://www.synergisticit.com/contact-us/

If the skills are not a match candidates can opt for Skill enhancement. Or their resume can be sent out to clients to see if responses are achievable

REQUIRED SKILLS For Java/Software Programmers


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Core Java , javascript , C&plus;&plus; or software programming
 * Spring boot, Microservices and REST API's experience
 * Excellent written and verbal communication skills
   
   

For data Science/Machine learning

Required Skills


 * Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT
 * Highly motivated, self-learner, and technically inquisitive
 * Experience in programming language Java and understanding of the software development life cycle
 * Knowledge of Statistics, Python, data visualization tools
 * Excellent written and verbal communication skills
   
   

Preferred skills: NLP, Text mining, Tableau, Time series analysis

Technical skills are required by clients for selection even if its Junior or entry level position each additional Technical skill helps a candidate's resume to be picked by clients over other job seekers.

Clients hire candidates with the right technical skills which they need and reject candidates who lack the required technical skills.

No third party candidates or c2c candidates

Please apply to the posting

No phone calls please. Shortlisted candidates would be reached out",Full-time
4115753891,2010798.0,Data Engineer - Snowflake,"Tiger Analytics is a fast-growing advanced analytics consulting firm. Our consultants bring deep expertise in Data Science, Machine Learning and AI. We are the trusted analytics partner for multiple Fortune 500 companies, enabling them to generate business value from data. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner. We are looking for top-notch talent as we continue to build the best global analytics consulting team in the world.

The Data Engineer will be responsible for architecting, designing, and implementing advanced analytics capabilities. The right candidate will have broad skills in database design, be comfortable dealing with large and complex data sets, have experience building self-service dashboards, be comfortable using visualization tools, and be able to apply your skills to generate insights that help solve business challenges.We are looking for someone who can bring their vision to the table and implement positive change in taking the company's data analytics to the next level.

Requirements

Key Responsibilities:

Data Integration:

Implement and maintain data synchronization between on-premises Oracle databases and Snowflake using Kafka and CDC tools.

Support Data Modeling:

Assist in developing and optimizing the data model for Snowflake, ensuring it supports our analytics and reporting requirements.

Data Pipeline Development:

Design, build, and manage data pipelines for the ETL process, using Airflow for orchestration and Python for scripting, to transform raw data into a format suitable for our new Snowflake data model.

Reporting Support:

Collaborate with data architect to ensure the data within Snowflake is structured in a way that supports efficient and insightful reporting.

Technical Documentation:

Create and maintain comprehensive documentation of data pipelines, ETL processes, and data models to ensure best practices are followed and knowledge is shared within the team.

Tools and Skillsets:

Data engineering: proven track record of developing and maintaining data pipelines and data integration projects

Databases: Strong experience with Oracle, Snowflake, and Databricks.

Data Integration Tools: Proficiency in using Kafka and CDC tools for data ingestion and synchronization.

Orchestration Tools: Expertise in Airflow for managing data pipeline workflows.

Programming: Advanced proficiency in Python and SQL for data processing tasks.

Data Modeling: Understanding of data modeling principles and experience with data warehousing solutions.

Cloud Platforms: Knowledge of cloud infrastructure and services, preferably Azure, as it relates to Snowflake and Databricks integration.

Collaboration Tools: Experience with version control systems (like Git) and collaboration platforms.

CI/CD Implementation: Utilize CI/CD tools to automate the deployment of data pipelines and infrastructure changes, ensuring high-quality data processing with minimal manual intervention.

Communication: Excellent communication and teamwork skills, with a detail-oriented mindset. Strong analytical skills, with the ability to work independently and solve complex problems.

Requirements


 * 8+ years of overall industry experience specifically in data engineering
 * 5+ years of experience building and deploying large-scale data processing pipelines in a production environment
 * Strong experience in Python, SQL, and PySpark
 * Creating and optimizing complex data processing and data transformation pipelines using python
 * Experience with ""Snowflake Cloud Data warehouse"" and DBT tool
 * Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
 * Understanding of Datawarehouse (DWH) systems, and migration from DWH to data lakes/Snowflake
 * Understanding of ELT and ETL patterns and when to use each. Understanding of data models and transforming data into the models
 * Strong analytic skills related to working with unstructured datasets
 * Build processes supporting data transformation, data structures, metadata, dependency and workload management
   
   
   

Benefits

This position offers an excellent opportunity for significant career development in a fast-growing and challenging entrepreneurial environment with a high degree of individual responsibility.",Full-time
4146527170,923974.0,Data Engineer,"Dit ga je doen als Junior Data Engineer

Als Junior Data Engineer bij iqbs ondersteun je bij het bouwen en optimaliseren van onze data-infrastructuur. Je leert hoe je data uit verschillende systemen ontsluit, transformeert en integreert in een datawarehouse. Onder begeleiding van ervaren collega’s werk je aan uitdagende projecten en ontwikkel je jezelf tot een allround Data Engineer.

Je Werkzaamheden Zijn


 * Ontwikkelen van technische koppelingen om data te importeren in de BI-omgeving in Azure.
 * Het extracten van data uit bronsystemen en voorbereiden in een staging area.
 * Ondersteunen bij het ontwerpen en bouwen van datawarehouses met tools zoals SQL en Databricks.
 * Samenstellen van datamodellen die de basis vormen voor analyses en dashboards.
 * Automatiseren van datawarehouse laadprocessen met Azure Data Factory of Fabric.
 * Samenwerken met het team om gestroomlijnde data-oplossingen te leveren.
   
   

Collega's over iqbs

Over iqbs

Werken bij iqbs betekent werken aan uitdagende projecten en voor mooie klanten waar je echt impact kan maken. Samen met een team van professionele collega's maak jij dagelijks het verschil.

Lees alle ervaringen

Maartje

Het leukste aan mijn werk is samenwerken met enthousiaste collega's en samen successen behalen.

Erik

Erik beschrijft de cultuur van iqbs als vrij en flexibel: ""Je beheert je eigen agenda en regelt zelf veel met klanten.""

Dit verwachten we van jou


 * Een afgeronde hbo-opleiding in Informatica, Data Science, (Technische) Bedrijfskunde, of een vergelijkbare richting.
 * Affiniteit met data-engineering en interesse in technologieën zoals Azure, Python, SQL, en Power BI.
 * Analytisch sterk, leergierig en een echte teamspeler.
 * Basiskennis van data-integratie en modellering is een pré, maar geen vereiste.
   
   

Dit mag je van ons verwachten

Je verdient het

Je verdient tussen de €3.000 - €4.200. Ook kun je extra bonussen ontvangen, afhankelijk van jouw prestaties en die van de organisatie.

Flexibel werken

We faciliteren je in een werkplek waar je altijd en overal kan werken. Thuis, op kantoor of bij één van de andere bedrijven van Axelio. Zo voel je je overal thuis.

Ontwikkeling

Wij stimuleren jou om in jezelf te investeren en jezelf te ontwikkelen. Per jaar investeren we 10 dagen die je kan inzetten voor studie & trainingen.

Mobiliteit

Wij bieden jou een mobiliteitsbudget dat je kan inzetten voor een leaseauto, een leasefiets, het openbaar vervoer of kan laten uitkeren als een bruto vergoeding.

Werk & Privé

Bij iqbs krijg je 28 vakantiedagen en heb je de mogelijkheid om extra dagen bij te kopen maar ook om dagen te verkopen. Flexibiliteit die past bij jouw situatie.

Win as a team

Bij iqbs is werken meer dan jouw functie goed uitoefenen. We hechten veel waarde aan een goede sfeer en organiseren regelmatig gezellige borrels en teamuitjes.

Welzijn

Jouw welzijn staat voorop. Met toegang tot psychologen, mindfulness sessies en zelfhulpmodules blijf je in balans, op het werk en daarbuiten.

Over iqbs

Met meer dan 15 jaar ervaring hebben we uitgebreide kennis opgebouwd in het ontsluiten van ERP-systemen, het ontwikkelen van een eigen datawarehouse en het bouwen van dashboards. Dit wordt allemaal ondersteund door automatiseringen binnen ons eigen framework. Iqbs heeft uitgebreide ervaring met het toegankelijk maken van data uit ERP-systemen zoals Business Central, Infor, SAP en Odoo. Bovendien bieden wij organisaties ondersteuning met trainingen en het beantwoorden van specifieke vragen, zoals het ontsluiten van data uit verschillende bronnen.

Je gaat aan de slag in een team van professionals, die elke dag werken om leads en klanten mee te nemen in de kansen die Data Analytics, Business Intelligence en Cloud hen bieden. Bedrijven en mensen die aan de slag willen met Power BI komen veelal via een korte online zoektocht bij ons uit. Het is aan jou om door goede kwalificatie van de leads die projecten te spotten waar de complexere datavraagstukken liggen. Dat is waar we goed in zijn, dat is waar we blij van worden. Als onderdeel van Axelio profiteer je van alle kansen die het werken bij een groep biedt.

Meer over iqbs

Solliciteer nu

Door op de button 'solliciteer' te klikken, ga je akkoord met het Privacy Statement van Axelio b.v.

CV uploaden (Optioneel)

Geen bestand gekozen

Motivatiebrief uploaden (Optioneel)

Geen bestand gekozen",Full-time
